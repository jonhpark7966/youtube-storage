1
00:00:00,500 --> 00:00:03,720
[음악 재생]

2
00:00:05,502 --> 00:00:07,960
DHAVI HARIHARAN: 안녕하세요, 저는 Google DeepMind에서

3
00:00:07,960 --> 00:00:10,040
유전체학을 담당하는 제품 매니저 Dhavi입니다.

4
00:00:10,040 --> 00:00:15,880
오늘은 유전체 팀을 이끄는 Ziga, 그리고 Natasha, Tom,

5
00:00:15,880 --> 00:00:17,480
Jun과 함께했습니다.

6
00:00:17,480 --> 00:00:20,880
저희는 최근 작업인 AlphaGenome을 “Nature”에 발표했습니다.

7
00:00:20,880 --> 00:00:24,760
AlphaGenome은 DNA 서열에서 기능으로의 예측을

8
00:00:24,760 --> 00:00:26,760
통합적으로 수행하는

9
00:00:26,760 --> 00:00:28,960
모델로, 유전 변이의 기능적

10
00:00:28,960 --> 00:00:32,360
영향을 예측합니다.

11
00:00:32,360 --> 00:00:36,460
오늘은 그 뒤에 있는 과학, 왜 만들었는지, 어떻게 나오게 됐는지,

12
00:00:36,460 --> 00:00:38,380
무엇을 공개했는지, 그리고 다음으로 무엇을 기대하는지 이야기해 보겠습니다.

13
00:00:38,380 --> 00:00:41,862
[음악 재생]

14
00:00:43,360 --> 00:00:45,080
아마 시작하기에 가장 좋은 질문은,

15
00:00:45,080 --> 00:00:47,040
왜 AlphaGenome을 만들었느냐일 것 같습니다.

16
00:00:47,040 --> 00:00:50,137
Ziga, 이게 팀의 전체 미션과는 어떻게 맞물리나요?

17
00:00:50,137 --> 00:00:51,720
ZIGA AVSEC: 저희 팀의 미션은

18
00:00:51,720 --> 00:00:55,200
유전체 서열을 해독할 수 있게 해주는 AI 시스템을 구축하는 것입니다.

19
00:00:55,200 --> 00:00:56,480
유전체, 즉 DNA는

20
00:00:56,480 --> 00:00:58,880
진화가 수백만 년에 걸쳐

21
00:00:58,880 --> 00:01:01,740
프로그래밍해 온

22
00:01:01,740 --> 00:01:03,860
소스 코드이고, 수백만 년과 수백만—

23
00:01:03,860 --> 00:01:06,420
수많은 종에 걸쳐 그러했습니다.

24
00:01:06,420 --> 00:01:10,060
그러니 이것은 생명의 소스 코드입니다.

25
00:01:10,060 --> 00:01:12,980
이 소스 코드를 해독하면 건강을 비롯한

26
00:01:12,980 --> 00:01:16,700
여러 분야에 엄청난 이점이 있을 것입니다.

27
00:01:16,700 --> 00:01:19,797
그리고 이 목표를 향한 진척을 측정하는 한 가지 방법은

28
00:01:19,797 --> 00:01:22,380
돌연변이의 효과, 즉 DNA의 작은 변화가

29
00:01:22,380 --> 00:01:26,500
이 DNA를 읽어들이는 세포의 분자적 메커니즘에

30
00:01:26,500 --> 00:01:28,740
어떤 영향을 주는지 얼마나 잘 예측하는지 보는 것입니다.

31
00:01:28,740 --> 00:01:30,800
DHAVI HARIHARAN: 그리고 왜 이게 중요하죠,

32
00:01:30,800 --> 00:01:34,580
유전체를 이해하고 해독하는 데 도움이 되는 AI가요?

33
00:01:34,580 --> 00:01:37,380
JUN CHENG: 네, 유전체에 대한 이해를 향상시키는 건

34
00:01:37,380 --> 00:01:39,660
유전 질환으로 고통받는 모든 사람들을 생각하면

35
00:01:39,660 --> 00:01:43,620
모두의 삶에 매우 깊은 영향을 미칩니다.

36
00:01:43,620 --> 00:01:45,220
그리고 실제로 희귀 유전 질환의 큰 비율이

37
00:01:45,220 --> 00:01:49,940
현재까지도 진단되지 못한 채 남아 있습니다.

38
00:01:49,940 --> 00:01:53,020
그래서 AI는 실제로—

39
00:01:53,020 --> 00:01:55,220
저희는 유전체 전체에 대한 이해가 너무 부족합니다.

40
00:01:55,220 --> 00:01:58,740
그리고 AI는 유전체를 읽고

41
00:01:58,740 --> 00:02:01,800
유전 변이에 대해 의미 있는 예측을 만드는 데 아주 좋은 도구입니다.

42
00:02:01,800 --> 00:02:05,500
저에게는 유전체를 이해하고

43
00:02:05,500 --> 00:02:09,560
돌연변이를 예측하는 것이 AI가 할 수 있는

44
00:02:09,560 --> 00:02:13,480
가장 큰 영향력의 적용 분야 중 하나라고 생각합니다.

45
00:02:13,480 --> 00:02:15,800
DHAVI HARIHARAN: 이 분야에는 어떻게 관심을 갖게 되셨나요?

46
00:02:15,800 --> 00:02:18,320
JUN CHENG: 저는 박사 과정 때 유전 변이를 예측하는 일을 시작했고,

47
00:02:18,320 --> 00:02:22,520
그 이후로 계속 관심을 가져 왔습니다.

48
00:02:22,520 --> 00:02:27,240
DeepMind에 합류했을 때 저는

49
00:02:27,240 --> 00:02:31,160
AlphaMissense 프로젝트를 이끌고 있었는데,

50
00:02:31,160 --> 00:02:33,560
이는 유전체의 단 2%에 해당하는 코딩 영역의 변이로부터

51
00:02:33,560 --> 00:02:36,280
유전적 영향을 예측하는 방법이었습니다.

52
00:02:36,280 --> 00:02:40,520
그런데 유전체의 나머지 98%는 어떨까요?

53
00:02:40,520 --> 00:02:41,640
그래서 오늘 AlphaGenome을 소개드리는 것입니다.

54
00:02:41,640 --> 00:02:45,400
이 방법은 유전체의 비코딩 부분에 집중하며,

55
00:02:45,400 --> 00:02:47,880
[청취 불가]가 대부분을 차지하는

56
00:02:47,880 --> 00:02:51,920
유전체 영역에 조금이나마 빛을 비추기를 바랍니다.

57
00:02:51,920 --> 00:02:55,840
그리고 좀 더 개인적으로 말씀드리면,

58
00:02:55,840 --> 00:02:57,360
제가 생물학에 관심을 갖게 된 이유는

59
00:02:57,360 --> 00:03:00,800
고등학교 때 대학 교과서를 읽었는데,

60
00:03:00,800 --> 00:03:04,180
거기에 생명의 환상적이고 복잡하면서도

61
00:03:04,180 --> 00:03:08,040
우아한 분자적 메커니즘들이 설명되어 있었습니다.

62
00:03:08,040 --> 00:03:11,040
그래서— 그래서 저는 제 커리어로 생물학을 해야겠다고

63
00:03:11,040 --> 00:03:13,820
결심했습니다.

64
00:03:13,820 --> 00:03:16,060
그리고 Tom, 그쪽 경험은 어떠신가요?

65
00:03:16,060 --> 00:03:18,640
TOM WARD: 이렇게 다학제적인 팀을 갖게 된 건 정말 좋은 일입니다.

66
00:03:18,640 --> 00:03:20,403
저희는 모두 서로 다른 배경에서 왔고

67
00:03:20,403 --> 00:03:21,820
각자 다른 것들을 테이블 위에 가져옵니다.

68
00:03:21,820 --> 00:03:23,820
그래서 저에게는, 그리고 생물학에서 일해 본 적이 없었던

69
00:03:23,820 --> 00:03:25,860
다른 분들에게도 그렇겠지만,

70
00:03:25,860 --> 00:03:28,668
유전학은 정말 매혹적인 분야라고 생각합니다.

71
00:03:28,668 --> 00:03:30,460
아직 탐험되지 않은 문제 공간이 굉장히 큰 것처럼 느껴집니다.

72
00:03:30,460 --> 00:03:34,020
그리고 DNA의 아주 작은 변화가

73
00:03:34,020 --> 00:03:35,920
인간과 다른 종들에서 어떤 결과를 낳는지

74
00:03:35,920 --> 00:03:39,940
밝혀낼 수 있다는 건 정말 흥미롭습니다.

75
00:03:39,940 --> 00:03:44,300
그리고 이 분야는— 특히 머신러닝 쪽에서

76
00:03:44,300 --> 00:03:47,620
계산생물학 분야가 정말, 정말 빠르게 발전하고 있는 것 같습니다.

77
00:03:47,620 --> 00:03:49,980
그 분야에서는 많은 일들이 일어나고 있습니다.

78
00:03:49,980 --> 00:03:52,320
그래서 일하기에 정말 흥미로운 곳입니다.

79
00:03:52,320 --> 00:03:54,980
ZIGA AVSEC: 저는 아직도 DeepMind에 오기 전에,

80
00:03:54,980 --> 00:03:57,560
제가 [? vp.net, ?]에서 일하던 때를 기억합니다.

81
00:03:57,560 --> 00:04:00,240
오늘날 기준으로는 아주 작은 네트워크였는데,

82
00:04:00,240 --> 00:04:02,720
입력으로 DNA의 1,000개 염기쌍을 받고

83
00:04:02,720 --> 00:04:04,120
아주 높은 해상도로 전사인자 결합을 예측했습니다.

84
00:04:04,120 --> 00:04:06,340
저는 염기 단위 해상도에서 이런 정보가

85
00:04:06,340 --> 00:04:09,580
얼마나 풍부하고 정밀해질 수 있는지에 매료되었습니다.

86
00:04:09,580 --> 00:04:12,440
하지만 동시에, 특정 과정만을 아주 확대해서 본

87
00:04:12,440 --> 00:04:14,320
그림처럼 느껴지기도 했습니다.

88
00:04:14,320 --> 00:04:15,860
그래서 DeepMind에 합류했을 때는

89
00:04:15,860 --> 00:04:20,480
더 복잡한 과정들을 다루고 싶었습니다.

90
00:04:20,480 --> 00:04:22,240
그래서 Calico의 David Kelley와 함께

91
00:04:22,240 --> 00:04:25,280
DNA 서열로부터 유전자 발현을 예측하는 일을 했는데,

92
00:04:25,280 --> 00:04:27,660
이건 매우 어려운 문제입니다.

93
00:04:27,660 --> 00:04:30,040
그리고 그 문제를 위해서는 가능한 한 많은 관련 요소를 포착하려고

94
00:04:30,040 --> 00:04:33,620
더 복잡한 과정들을 다루기 위해서였습니다.

95
00:04:33,620 --> 00:04:36,400
그래서 우리는 Calico의 David Kelley와 함께 일했습니다.

96
00:04:36,400 --> 00:04:38,880
DNA 서열로부터 유전자 발현을 예측하는 일에요,

97
00:04:38,880 --> 00:04:41,200
이는 매우 어려운 문제입니다.

98
00:04:41,200 --> 00:04:43,880
그리고 그 문제를 위해 우리는

99
00:04:43,880 --> 00:04:46,760
서열의 길이를 상당히 늘려야 했습니다,

100
00:04:46,760 --> 00:04:50,127
가능한 한 많은 관련 정보를 포착하기 위해서요.

101
00:04:50,127 --> 00:04:51,960
하지만 그렇게 하려면 우리는 절충을 해야 했습니다.

102
00:04:51,960 --> 00:04:56,580
BPNet을 그렇게 흥미롭게 만들었던 해상도를요.

103
00:04:56,580 --> 00:04:59,520
그래서 항상 이 두 가지 사이에서 어느 정도 절충을 하는 느낌이었습니다,

104
00:04:59,520 --> 00:05:01,800
즉 서열 길이와 해상도 사이에서요.

105
00:05:01,800 --> 00:05:04,380
DHAVI HARIHARAN: 다른 모델들도 많이 있었던 것 같습니다.

106
00:05:04,380 --> 00:05:06,340
이 분야를 앞으로 밀어왔죠.

107
00:05:06,340 --> 00:05:09,060
우리가 정말로 채우려 했던 공백은 무엇이었고

108
00:05:09,060 --> 00:05:10,480
AlphaGenome으로 무엇을 채우려 했나요?

109
00:05:10,480 --> 00:05:12,313
NATASHA LATYSHEVA: 다른 DNA

110
00:05:12,313 --> 00:05:14,020
서열-기능 모델들이 이전에도 있었습니다.

111
00:05:14,020 --> 00:05:15,820
AlphaGenome과 가장 비슷한 것은 아마

112
00:05:15,820 --> 00:05:20,180
이 팀의 Informa와, David Kelley의

113
00:05:20,180 --> 00:05:21,540
Calico 그룹의 Borzoi일 것입니다.

114
00:05:21,540 --> 00:05:25,000
그리고 더 특화된 단일 작업 모델들도 많이 있습니다.

115
00:05:25,000 --> 00:05:27,440
스플라이싱을 위한 SpliceAI가 있고요.

116
00:05:27,440 --> 00:05:30,320
접촉 지도에는 Orca와 Akita가 있고,

117
00:05:30,320 --> 00:05:32,860
접근성에는 ChromBPNet 같은 것들이 있으며, 등등이 있습니다.

118
00:05:32,860 --> 00:05:35,460
저는 AlphaGenome이 채운 공백은

119
00:05:35,460 --> 00:05:39,940
하나의 모델에서 이전보다 더 많은 모달리티를 모델링한다는 점이라고 생각합니다.

120
00:05:39,940 --> 00:05:42,580
입력 서열 길이는 매우 길고,

121
00:05:42,580 --> 00:05:45,480
예측은 매우 세밀합니다.

122
00:05:45,480 --> 00:05:48,580
그래서 저는 이것이 정말 강력한 조합이라고 생각합니다,

123
00:05:48,580 --> 00:05:51,540
이 세 가지, 즉 모달리티 커버리지,

124
00:05:51,540 --> 00:05:55,100
DNA 서열의 메가베이스 규모, 그리고 단일 염기 해상도의 출력이

125
00:05:55,100 --> 00:05:57,540
많은 출력 유형에서 가능하다는 점의 조합입니다.

126
00:05:57,540 --> 00:05:59,580
저는 그것이 이 모델을, 네, 상당히 유용하게 만든다고 생각합니다.

127
00:05:59,580 --> 00:06:01,288
변이 영향 예측과 변이

128
00:06:01,288 --> 00:06:04,160
해석에 유용하고, 물론 또한 증가한

129
00:06:04,160 --> 00:06:06,120
전반적인 예측 정확도도

130
00:06:06,120 --> 00:06:07,560
이러한 다양한 출력 전반에서요.

131
00:06:07,560 --> 00:06:11,000
그리고 유용성과 편의성 측면도, 저는,

132
00:06:11,000 --> 00:06:12,740
사실 매우 강력하다고 생각합니다.

133
00:06:12,740 --> 00:06:16,920
이제 하나의 모델로 변이가 미치는 영향을

134
00:06:16,920 --> 00:06:19,960
여러 관점에서 보고 그 영향들을

135
00:06:19,960 --> 00:06:22,800
분자생물학의 서로 다른 층위에서 고려할 수 있습니다.

136
00:06:22,800 --> 00:06:25,640
반면 예전에는 많은 다른 모델들을

137
00:06:25,640 --> 00:06:26,980
써야 그 분석을 할 수 있었을지도 모릅니다.

138
00:06:26,980 --> 00:06:30,456
[음악 재생]

139
00:06:32,258 --> 00:06:34,300
DHAVI HARIHARAN: 왜 별도의 모델들이 필요했나요?

140
00:06:34,300 --> 00:06:37,620
왜 긴 문맥과

141
00:06:37,620 --> 00:06:41,360
고해상도 다중 모달리티를 동시에 하는 것이 그렇게 어려운가요?

142
00:06:41,360 --> 00:06:43,280
TOM WARD: DNA 서열-기능 모델은

143
00:06:43,280 --> 00:06:45,640
기본적으로 DNA의 한 조각을 가져와서

144
00:06:45,640 --> 00:06:50,200
모델이 실제 세계의 실험 데이터를 예측하도록 하는 방식으로 작동합니다.

145
00:06:50,200 --> 00:06:52,600
그래서 말씀하신 것처럼 복잡성은

146
00:06:52,600 --> 00:06:57,360
더 장거리 범위의 서열

147
00:06:57,360 --> 00:06:59,760
예측을 더 높은 해상도로 하면서

148
00:06:59,760 --> 00:07:02,140
또 많은 서로 다른 모달리티까지 포함하려 할 때 생기고,

149
00:07:02,140 --> 00:07:05,860
결국 이런 계산상의 한계에 부딪히며

150
00:07:05,860 --> 00:07:08,700
메모리 사용량이 커져서

151
00:07:08,700 --> 00:07:12,620
공학적인 관점에서 매우 어렵게 만듭니다.

152
00:07:12,620 --> 00:07:15,220
그래서 AlphaGenome에서는 우리는 정말로

153
00:07:15,220 --> 00:07:19,580
그런 절충을 깨고, 그 모든 것들을

154
00:07:19,580 --> 00:07:20,675
하나의 모델에서 해내고자 했습니다.

155
00:07:20,675 --> 00:07:23,300
DHAVI HARIHARAN: 그렇다면 그 문제를 실제로 어떻게

156
00:07:23,300 --> 00:07:24,660
해결하셨나요?

157
00:07:24,660 --> 00:07:26,220
ZIGA AVSEC: 네, 우리는 결국--

158
00:07:26,220 --> 00:07:29,380
서열을 가져와서 이를 잘라

159
00:07:29,380 --> 00:07:31,180
서로 다른 하위 서열들로 나눈 다음

160
00:07:31,180 --> 00:07:34,860
여러 TPU를 사용해 이 하위 서열들을 처리했는데, 이것들은

161
00:07:34,860 --> 00:07:36,900
그 결과 길이가 훨씬 짧습니다.

162
00:07:36,900 --> 00:07:44,380
그렇게 해서 단일 TPU에서 훨씬 적은 메모리를 쓸 수 있었습니다.

163
00:07:44,380 --> 00:07:45,900
우리가 반드시 확인해야 했던 핵심은

164
00:07:45,900 --> 00:07:47,858
그들이 여전히 서로 소통한다는 점이었고,

165
00:07:47,858 --> 00:07:50,220
그래서 TPU 1이 여전히 소통할 수 있어야 했습니다,

166
00:07:50,220 --> 00:07:53,980
서열의 마지막 TPU와요.

167
00:07:53,980 --> 00:07:55,820
그래서 유전체에서 구간을

168
00:07:55,820 --> 00:07:59,180
무작위로 샘플링하는 대신 서로 인접하게 샘플링했고

169
00:07:59,180 --> 00:08:02,120
그 다음 이 TPU들이 서로 대화할 수 있게 했습니다.

170
00:08:02,120 --> 00:08:04,120
저는 우리가

171
00:08:04,120 --> 00:08:06,000
동료 Guido와 점심을 먹던 날을 아직도 기억합니다.

172
00:08:06,000 --> 00:08:08,540
제가 이 아이디어를 그와 공유했고, 우리는 논의를 시작했습니다.

173
00:08:08,540 --> 00:08:10,665
그리고 점심이 끝날 무렵에는, 우리는 사실 확신이 없었습니다.

174
00:08:10,665 --> 00:08:12,480
이게 작동할지 말지를요.

175
00:08:12,480 --> 00:08:15,000
며칠 뒤에 그가 제게 와서 말했습니다,

176
00:08:15,000 --> 00:08:18,520
가짜 데이터로 돌아가는 프로토타입을 만들었고,

177
00:08:18,520 --> 00:08:23,600
우리 Informa 학습 루프만큼 거의 빠르게 돌아가며,

178
00:08:23,600 --> 00:08:26,200
이 매우 긴 서열들을

179
00:08:26,200 --> 00:08:27,800
고해상도로 처리할 수 있다고요.

180
00:08:27,800 --> 00:08:30,040
그 순간 저는 정말 흥분했습니다,

181
00:08:30,040 --> 00:08:32,679
이론적으로 이것이

182
00:08:32,679 --> 00:08:35,380
긴 서열과 고해상도의 한계를 깨뜨릴 수 있다는 것을 알았기 때문입니다.

183
00:08:35,380 --> 00:08:36,880
다만 실제로는,

184
00:08:36,880 --> 00:08:39,280
정말로 이것을 실제로

185
00:08:39,280 --> 00:08:40,440
작동하게 만드는 데에는 아직 꽤 멀었다는 것이 드러났죠, 맞죠 Tom?

186
00:08:40,440 --> 00:08:42,815
TOM WARD: 네, 그래서 모델 병렬화를

187
00:08:42,815 --> 00:08:44,440
작동시킨 뒤에, 다음으로 우리가 해야 했던 것은

188
00:08:44,440 --> 00:08:47,600
이 모델에 방대한 양의 학습

189
00:08:47,600 --> 00:08:48,100
데이터를 먹일 수 있게 하는 것이었습니다.

190
00:08:48,100 --> 00:08:49,642
어느 시점에는, 우리는

191
00:08:49,642 --> 00:08:52,240
대략 40~50기가바이트의 데이터를

192
00:08:52,240 --> 00:08:54,880
모델의 학습 속도를 따라잡기 위해 로드하고 있었습니다.

193
00:08:54,880 --> 00:08:57,300
그래서 우리는 두 가지 큰 깨달음을 얻었습니다.

194
00:08:57,300 --> 00:09:00,420
하나는 데이터가 사실 매우 희소하다는 점이었습니다.

195
00:09:00,420 --> 00:09:05,380
일부 모달리티에서는 값의 99%가 0에 가깝습니다.

196
00:09:05,380 --> 00:09:07,060
우리가 학습하던 것들에서요.

197
00:09:07,060 --> 00:09:10,220
그래서 사실 우리가 집중해야 할 것은 결국

198
00:09:10,220 --> 00:09:13,220
데이터를 압축하고 해제하는 것을

199
00:09:13,220 --> 00:09:15,100
가능한 한 빠르게 하는 일이었습니다.

200
00:09:15,100 --> 00:09:17,220
그래서 그렇게 하면서 우리는

201
00:09:17,220 --> 00:09:20,260
모델에 공급해 학습시키기에 충분할 만큼 빠른 데이터 로딩 병목을

202
00:09:20,260 --> 00:09:22,920
깨뜨릴 수 있었습니다.

203
00:09:22,920 --> 00:09:24,420
그리고 두 번째로 한 일은

204
00:09:24,420 --> 00:09:26,060
학습에 넣는 데이터를 아주 엄격하게

205
00:09:26,060 --> 00:09:28,740
선별했다는 점입니다.

206
00:09:28,740 --> 00:09:31,220
품질 점검을 한두 차례, 그러니까 몇 번의 패스를 돌려

207
00:09:31,220 --> 00:09:35,060
데이터가 정말 고품질이거나

208
00:09:35,060 --> 00:09:38,380
아니면 모델의 다양성에 기여하는지

209
00:09:38,380 --> 00:09:42,020
그래서 학습하고 일반화 능력을 조금 더 키우거나

210
00:09:42,020 --> 00:09:44,060
새로운 능력을 학습할 수 있도록 했습니다.

211
00:09:44,060 --> 00:09:47,580
그래서 데이터 로딩이 제대로 돌아가자,

212
00:09:47,580 --> 00:09:50,300
그다음에는 모델을 아주 효율적으로 학습시킬 수 있었고

213
00:09:50,300 --> 00:09:54,100
모델링을 가능한 한 많이 반복 개선할 수 있었습니다.

214
00:09:54,100 --> 00:09:57,580
그래서 1차원(1D) 표현 데이터는 학습하고

215
00:09:57,580 --> 00:09:58,518
예측하는 것까지

216
00:09:58,518 --> 00:10:01,060
할 수 있게 됐습니다.

217
00:10:01,060 --> 00:10:05,880
그리고 다음으로 우리가 정말 기대하며 작업한 것은 2차원 데이터였고, 콘택트 맵과 스플라이싱이었습니다.

218
00:10:05,880 --> 00:10:08,300
Jun, 스플라이싱은 많이 담당하셨던 것으로 알고 있습니다.

219
00:10:08,300 --> 00:10:10,552
확실히 아주 까다로운 문제였습니다.

220
00:10:10,552 --> 00:10:11,260
JUN CHENG: 네.

221
00:10:11,260 --> 00:10:12,700
정말 까다로웠습니다.

222
00:10:12,700 --> 00:10:16,560
스플라이싱은 유전자가

223
00:10:16,560 --> 00:10:19,720
단백질을 제대로 발현하는 데 필요한 과정입니다.

224
00:10:19,720 --> 00:10:24,360
그리고 이것은 유전체에 암호화된 유전 정보가

225
00:10:24,360 --> 00:10:26,440
비연속적으로 존재하기 때문에 필요한 과정입니다.

226
00:10:26,440 --> 00:10:29,540
따라서 기능성 단백질을 발현하려면

227
00:10:29,540 --> 00:10:32,880
이렇게 비연속적으로 흩어져 있는 정보를

228
00:10:32,880 --> 00:10:33,500
한데 모아야 합니다.

229
00:10:33,500 --> 00:10:35,840
그 과정이 스플라이싱입니다.

230
00:10:35,840 --> 00:10:37,680
상상하실 수 있듯이, 이 과정은 쉽게

231
00:10:37,680 --> 00:10:40,640
유전적 돌연변이로 인해 오류가 날 수 있습니다.

232
00:10:40,640 --> 00:10:42,440
그리고 실제로 많은 유전 질환이

233
00:10:42,440 --> 00:10:46,200
스플라이싱 결함 때문에 발생합니다.

234
00:10:46,200 --> 00:10:48,972
저는 박사 과정 때 이 문제를 연구했고,

235
00:10:48,972 --> 00:10:50,680
그때 발표했던 [들리지 않음] 방법은

236
00:10:50,680 --> 00:10:52,820
MS Splice라고 불렸습니다.

237
00:10:52,820 --> 00:10:56,080
우리는 접합부(junction) 간의 경쟁을 모델링하려고 했지만,

238
00:10:56,080 --> 00:10:59,160
모델 성능은 지금만큼 좋지 않았습니다.

239
00:10:59,160 --> 00:11:03,480
그래서 이걸 제대로 하는 방법에 대한 아이디어를 계속 마음속에 갖고 있었습니다.

240
00:11:03,480 --> 00:11:06,540
그리고 AlphaGenome 작업을 시작했을 때

241
00:11:06,540 --> 00:11:10,620
이게 정말 자연스럽게 딱 맞는 주제라는 걸 깨달았습니다.

242
00:11:10,620 --> 00:11:14,300
또 훌륭한 팀원들, Guido와 Tom, 그리고 다른 분들과 함께

243
00:11:14,300 --> 00:11:16,900
마침내 필요한 기술적 조각들이 모두 갖춰졌고

244
00:11:16,900 --> 00:11:20,020
이 모델링 작업을 제대로 수행할 수 있게 됐습니다.

245
00:11:20,020 --> 00:11:23,820
다만 말씀드린 것처럼 실제로는 그렇게 쉽지 않았습니다.

246
00:11:23,820 --> 00:11:27,300
왜냐하면 출력 포맷과 입력

247
00:11:27,300 --> 00:11:29,100
포맷이 꽤 달랐기 때문입니다.

248
00:11:29,100 --> 00:11:33,780
그리고 우리는 1D 트랙이 아니라 2D의 극도로 희소한 배열을

249
00:11:33,780 --> 00:11:35,220
예측하고 있었습니다.

250
00:11:35,220 --> 00:11:38,840
하지만 결국 마침내 동작하게 만들었습니다.

251
00:11:38,840 --> 00:11:41,600
그래서 정말, 정말 만족합니다.

252
00:11:41,600 --> 00:11:44,380
이런 종류의 역량은 사실 이 분야에서도 새롭습니다.

253
00:11:44,380 --> 00:11:47,860
팀에게도 분명히 새로운 일이었습니다.

254
00:11:47,860 --> 00:11:50,100
그리고 이 부분을

255
00:11:50,100 --> 00:11:54,060
마무리한 다음, 다음 큰 파트는 콘택트 맵인데요, Natasha,

256
00:11:54,060 --> 00:11:55,960
그걸 어떻게 구현했는지 말씀해 주시겠어요?

257
00:11:55,960 --> 00:11:57,740
NATASHA LATYSHEVA: 네, 콘택트 맵입니다.

258
00:11:57,740 --> 00:12:00,620
콘택트 맵은 2차원 행렬로,

259
00:12:00,620 --> 00:12:04,360
DNA 구간들 사이의 상호작용을 포착합니다.

260
00:12:04,360 --> 00:12:06,320
그리고 이런 상호작용은

261
00:12:06,320 --> 00:12:09,100
본질적으로 유전자 조절에 매우 중요하다는 것이 밝혀졌습니다.

262
00:12:09,100 --> 00:12:11,000
즉, 핵 안의 유전체는

263
00:12:11,000 --> 00:12:14,300
복잡한 3차원 형태로 접혀 있습니다.

264
00:12:14,300 --> 00:12:16,160
그리고 구간들 사이의 근접성은

265
00:12:16,160 --> 00:12:18,440
예를 들어

266
00:12:18,440 --> 00:12:20,340
프로모터-인핸서 상호작용 같은 것에 매우 중요합니다.

267
00:12:20,340 --> 00:12:22,440
이는 조절 영역의 두 종류로,

268
00:12:22,440 --> 00:12:25,520
유전자의 발현에 큰 영향을 줄 수 있습니다.

269
00:12:25,520 --> 00:12:27,960
또 특정하게

270
00:12:27,960 --> 00:12:29,680
이런 상호작용을 막는 인슐레이터 요소도 있습니다.

271
00:12:29,680 --> 00:12:32,527
따라서 이는 기본적인 생물학적 과정들입니다.

272
00:12:32,527 --> 00:12:34,360
그리고 이것은 우리가 분명히

273
00:12:34,360 --> 00:12:36,760
모델에 포함시키고 싶었던 생물학입니다.

274
00:12:36,760 --> 00:12:39,400
다행히도 우리는 이를 모델에 추가하는 데 성공했고

275
00:12:39,400 --> 00:12:41,060
엔드투엔드로 학습이 되도록 만들었습니다.

276
00:12:41,060 --> 00:12:44,280
그리고 실제로 이 모달리티를 추가해도

277
00:12:44,280 --> 00:12:46,960
이미 가지고 있던 다른 모달리티들의 성능이

278
00:12:46,960 --> 00:12:48,268
전혀 떨어지지 않는 것을 보고 기뻤습니다.

279
00:12:48,268 --> 00:12:50,560
ZIGA AVSEC: 네, 그것을 보는 게 꽤 흥미로웠습니다.

280
00:12:50,560 --> 00:12:54,440
어떻게 1D 모달리티와

281
00:12:54,440 --> 00:12:57,960
스플라이싱과 콘택트 맵 같은 2D 모달리티까지

282
00:12:57,960 --> 00:13:01,820
모델 성능을 해치거나 속도를 늦추지 않고

283
00:13:01,820 --> 00:13:03,500
추가할 수 있었다는 점이요.

284
00:13:03,500 --> 00:13:05,600
돌이켜 보면 어느 정도 이해가 됩니다.

285
00:13:05,600 --> 00:13:07,740
이런 모든 모달리티나 측정값은

286
00:13:07,740 --> 00:13:11,260
결국 같은 기반 과정을 측정하고 있기 때문입니다.

287
00:13:11,260 --> 00:13:13,540
예를 들면 전사나 스플라이싱 같은 것들입니다.

288
00:13:13,540 --> 00:13:18,300
그럼에도 불구하고 이렇게 잘 된 것은 반가운 일입니다.

289
00:13:18,300 --> 00:13:21,240
DHAVI HARIHARAN: 이렇게 새로운 모달리티를 계속 추가할 때,

290
00:13:21,240 --> 00:13:23,780
성능을 해치지 않는지 어떻게 확인하시나요?

291
00:13:23,780 --> 00:13:25,120
어떻게 평가하나요?

292
00:13:25,120 --> 00:13:27,370
NATASHA LATYSHEVA: 저희 평가 전략은

293
00:13:27,370 --> 00:13:29,560
두 갈래, 두 축으로 나뉘었습니다.

294
00:13:29,560 --> 00:13:31,700
첫 번째는 모델이 얼마나 잘

295
00:13:31,700 --> 00:13:35,078
이전에 본 적 없는 새로운 DNA 서열에서 작동하는지 확인하는 것입니다.

296
00:13:35,078 --> 00:13:37,620
이런 다양한 모달리티를 얼마나 정확하게 예측할 수 있는지,

297
00:13:37,620 --> 00:13:40,740
DNA 서열을 따라 존재하는 여러 신호를 얼마나 잘 예측하는지입니다.

298
00:13:40,740 --> 00:13:44,140
두 번째 절반은 저희가 확실히 더 흥미롭다고 생각하는 부분인데,

299
00:13:44,140 --> 00:13:46,340
후속 응용 측면에서는 다시 말해

300
00:13:46,340 --> 00:13:47,740
변이 영향 예측입니다.

301
00:13:47,740 --> 00:13:51,020
즉 DNA 서열에 작은 돌연변이가 주어지면,

302
00:13:51,020 --> 00:13:53,360
그로 인해 후속 변화가 발생할 수 있습니다.

303
00:13:53,360 --> 00:13:56,420
그리고 모델이 이를 얼마나 잘 재현할 수 있는지가 핵심입니다.

304
00:13:56,420 --> 00:13:58,780
이를 수행하는 방식은 기본적으로

305
00:13:58,780 --> 00:14:02,870
돌연변이가 있는 DNA 문자열과 없는 DNA 문자열, 이렇게 두 개를 준비하는 것입니다.

306
00:14:02,870 --> 00:14:05,010
즉 기준(reference) 게놈 서열입니다.

307
00:14:05,010 --> 00:14:07,210
이를 각각 별도로 모델에 입력합니다.

308
00:14:07,210 --> 00:14:08,450
예측값을 얻습니다.

309
00:14:08,450 --> 00:14:11,570
그리고 그다음에는 기본적으로 차이를 찾습니다.

310
00:14:11,570 --> 00:14:13,750
차이를 찾아 요약합니다.

311
00:14:13,750 --> 00:14:17,770
그래서 개념적으로는 꽤 단순합니다.

312
00:14:17,770 --> 00:14:21,010
하지만 기술적으로는 끝없는 골칫거리를 만들었습니다.

313
00:14:21,010 --> 00:14:23,830
본질적으로 우리가 처음 맞닥뜨린 문제는

314
00:14:23,830 --> 00:14:24,770
사실 속도였습니다.

315
00:14:24,770 --> 00:14:27,570
모델 출력이 대략 11GB 정도였습니다.

316
00:14:27,570 --> 00:14:30,390
그리고 변이 스코어링은 악명 높을 정도로 느렸습니다.

317
00:14:30,390 --> 00:14:32,430
TOM WARD: 네, 모델에 데이터를 넣을 때와 아주 비슷하게

318
00:14:32,430 --> 00:14:35,230
다음으로 겪은 문제는

319
00:14:35,230 --> 00:14:38,150
이렇게 큰 예측 결과를 다시 받아와서

320
00:14:38,150 --> 00:14:41,630
유용한 스플라이싱 통계로 요약하려는 것이었습니다.

321
00:14:41,630 --> 00:14:43,910
이를 통해 모델이 얼마나

322
00:14:43,910 --> 00:14:45,790
특정 과제를 잘 수행하는지 평가할 수 있었습니다.

323
00:14:45,790 --> 00:14:48,055
그러다 보니 팀의 모든 사람이

324
00:14:48,055 --> 00:14:49,930
각자 나름의 방식으로 이 작업을 하고 있다는 걸 깨달았습니다.

325
00:14:49,930 --> 00:14:52,310
각자 자체적인 집계(aggregation) 전략을 만들고

326
00:14:52,310 --> 00:14:55,550
스크립트나 노트북에서 처리하고 있었습니다.

327
00:14:55,550 --> 00:14:57,350
하지만 말씀하신 대로 정말 느렸습니다.

328
00:14:57,350 --> 00:14:58,725
가끔은 몇 분씩

329
00:14:58,725 --> 00:14:59,990
이런 예측을 만드는 데 걸렸습니다.

330
00:14:59,990 --> 00:15:02,490
그래서 몇몇 엔지니어가 함께 앉아서

331
00:15:02,490 --> 00:15:04,490
어떻게 만들지 고민했고

332
00:15:04,490 --> 00:15:07,890
이런 형태의 변이 스코어링 API를 만들었습니다.

333
00:15:07,890 --> 00:15:10,850
이를 통해 변이 예측을 수행하고

334
00:15:10,850 --> 00:15:12,650
그 결과를 같은 장치에서

335
00:15:12,650 --> 00:15:14,810
모델을 학습하고 실행하던 장치에서 바로 집계할 수 있었습니다.

336
00:15:14,810 --> 00:15:17,530
그 덕분에 매우 빠르고

337
00:15:17,530 --> 00:15:20,170
효율적으로, 그리고 다양한 집계를

338
00:15:20,170 --> 00:15:21,810
병렬로 수행할 수 있었습니다.

339
00:15:21,810 --> 00:15:26,010
그래서 많은 평가를

340
00:15:26,010 --> 00:15:27,110
정말, 정말 빠르게 할 수 있었습니다.

341
00:15:27,110 --> 00:15:30,510
그리고 논문을 위해서도 꽤 많은 평가를 했습니다.

342
00:15:30,510 --> 00:15:33,010
NATASHA LATYSHEVA: 네, 평가와 벤치마크를 정말 많이 했고,

343
00:15:33,010 --> 00:15:36,468
그 벤치마크와 평가를 논문에 잔뜩 넣었습니다.

344
00:15:36,468 --> 00:15:38,010
하지만 그렇게 한 이유는

345
00:15:38,010 --> 00:15:41,430
가능한 한 포괄적으로 모델을 평가하고 싶었기 때문입니다.

346
00:15:41,430 --> 00:15:45,730
시간과 지면, 그리고 정신력의 제약 속에서 말입니다.

347
00:15:45,730 --> 00:15:48,270
사실 아주 초기에 부딪힌 한 가지 문제는

348
00:15:48,270 --> 00:15:51,090
평가를 어떻게 구조화할지

349
00:15:51,090 --> 00:15:52,170
라는 점이었습니다.

350
00:15:52,170 --> 00:15:53,930
우리가 이를

351
00:15:53,930 --> 00:15:55,930
엄밀하고 포괄적인 방식으로 수행하는지 어떻게 보장할지가 문제였습니다.

352
00:15:55,930 --> 00:15:58,150
모델이 할 수 있는 일이 너무 많다 보니

353
00:15:58,150 --> 00:16:00,510
그 모든 것을 어떻게 다룰지 고민이었습니다.

354
00:16:00,510 --> 00:16:05,030
그래서 우리가 택한 접근은, 다시 말해 병렬화였습니다.

355
00:16:05,030 --> 00:16:06,510
그래서 본질적으로

356
00:16:06,510 --> 00:16:08,640
각 개인이 한 가지

357
00:16:08,640 --> 00:16:10,910
또는 두 가지 영역, 즉 한두 개 모달리티를 맡아

358
00:16:10,910 --> 00:16:15,370
논문의 해당 섹션을 사실상 처음부터 끝까지 책임지는 방식이었습니다.

359
00:16:15,370 --> 00:16:17,770
즉 데이터를 수집하고, 평가를 설계하고,

360
00:16:17,770 --> 00:16:20,430
벤치마크를 추가하고, 논문 그림을 만드는 것이었습니다.

361
00:16:20,430 --> 00:16:22,310
그리고 이 방식이 실제로 매우 잘 작동했습니다.

362
00:16:22,310 --> 00:16:24,870
또 한 가지는 이런 평가들 중 상당수가

363
00:16:24,870 --> 00:16:28,050
연구 커뮤니티에 이미 존재하고 있었다는 점입니다.

364
00:16:28,050 --> 00:16:32,030
그래서 많은 경우에 우리는 그것들을 그대로 가져와서

365
00:16:32,030 --> 00:16:32,570
직접 사용할 수 있었습니다.

366
00:16:32,570 --> 00:16:33,898
이는 정말 큰 도움이 되었습니다.

367
00:16:33,898 --> 00:16:36,190
DHAVI HARIHARAN: 서로 다른 사람들이

368
00:16:36,190 --> 00:16:38,490
서로 다른 분야에 집중하기 시작했다고 말씀하셨는데,

369
00:16:38,490 --> 00:16:41,343
그러면 평가에도 서로 다른 범주가 있습니까?

370
00:16:41,343 --> 00:16:43,010
NATASHA LATYSHEVA: 그 부분은 Jun이 말씀해 주실 수 있습니다.

371
00:16:43,010 --> 00:16:44,052
JUN CHENG: 네, 맞습니다.

372
00:16:44,052 --> 00:16:47,430
가능한 경우마다 우리는 모델을

373
00:16:47,430 --> 00:16:48,910
여러 방식으로 평가하려고 했습니다.

374
00:16:48,910 --> 00:16:52,350
예를 들어 분자 수준에서

375
00:16:52,350 --> 00:16:56,190
실험적 측정값을 잘 재현하는지 평가하고,

376
00:16:56,190 --> 00:17:00,030
또 생물체 수준의 결과 측면에서도

377
00:17:00,030 --> 00:17:03,730
돌연변이가

378
00:17:03,730 --> 00:17:06,490
질병 위험을 높일지 여부를 잘 예측하는지 평가합니다.

379
00:17:06,490 --> 00:17:10,990
또한 가능한 한 많은 예시를 보여주려고 했고,

380
00:17:10,990 --> 00:17:13,490
모델이 잘한 사례와

381
00:17:13,490 --> 00:17:15,810
잘하지 못한 사례를 모두 포함했습니다.

382
00:17:15,810 --> 00:17:19,290
그리고 이것은 제가 특히 흥미롭다고 생각했던 한 가지 예시였습니다.

383
00:17:19,290 --> 00:17:22,250
우리가 논문에서 보여준 사례입니다.

384
00:17:22,250 --> 00:17:25,410
모델이 몇몇 암 드라이버 돌연변이를 예측하려고 했는데,

385
00:17:25,410 --> 00:17:28,650
우리는 모델이 실제로

386
00:17:28,650 --> 00:17:32,130
연구자들이 습식 실험에서 발견한 것을

387
00:17:32,130 --> 00:17:34,290
매우 잘 재현해서 정말 놀랐습니다.

388
00:17:34,290 --> 00:17:37,290
그리고 모델이

389
00:17:37,290 --> 00:17:39,490
드라이버 돌연변이를

390
00:17:39,490 --> 00:17:42,730
다른 임의의 대조군보다 훨씬 높게 순위를 매긴다는 점이 놀라웠습니다.

391
00:17:42,730 --> 00:17:45,328
그래서 우리는 꽤 만족했고, 논문에 넣었습니다.

392
00:17:45,328 --> 00:17:46,370
DHAVI HARIHARAN: 훌륭합니다.

393
00:17:46,370 --> 00:17:47,870
네, 제 생각에는 평가 이후에는

394
00:17:47,870 --> 00:17:49,992
결국 논문 쓰기로 귀결됐던 것 같습니다.

395
00:17:49,992 --> 00:17:51,950
NATASHA LATYSHEVA: 네, 그냥 논문 쓰기만 남았습니다.

396
00:17:51,950 --> 00:17:53,130
[웃음]

397
00:17:53,130 --> 00:17:56,270
DHAVI HARIHARAN: 그런데 논문이 왜 이렇게 깁니까?

398
00:17:56,270 --> 00:17:58,730
거의 소설 수준입니다.

399
00:17:58,730 --> 00:18:00,690
NATASHA LATYSHEVA: 네, 정말 길습니다.

400
00:18:00,690 --> 00:18:03,150
하지만 제 생각에는, 어쩔 수 없이, 항상

401
00:18:03,150 --> 00:18:06,730
길어질 수밖에 없었는데, 범위가 매우 방대하기 때문입니다,

402
00:18:06,730 --> 00:18:08,830
기본적으로요, 적어도 저는 그렇게 생각합니다.

403
00:18:08,830 --> 00:18:12,110
저희는 다른 모든 모델들을 공정하게 다루고 싶었습니다

404
00:18:12,110 --> 00:18:13,170
저희가 비교 대상으로 삼았던 모델들 말입니다.

405
00:18:13,170 --> 00:18:15,310
저희는 정말 가능한 한 깊이

406
00:18:15,310 --> 00:18:19,590
모든 다양한 모달리티에 대해 파고들고 싶었습니다.

407
00:18:19,590 --> 00:18:21,590
그래서 그런 것입니다.

408
00:18:21,590 --> 00:18:25,710
그리고 저희도 '한 번만 더 평가' 증후군을 조금 겪었던 것 같습니다.

409
00:18:25,710 --> 00:18:28,290
이 분야에서는 모두가 매우 들떠 있습니다.

410
00:18:28,290 --> 00:18:33,158
그리고 누군가가 새 논문이나 새 데이터셋을 보면,

411
00:18:33,158 --> 00:18:34,950
그걸 모델에 통합하고 싶어 했고

412
00:18:34,950 --> 00:18:37,390
평가 하나, 그림 하나를 더 추가하고 싶어 했습니다.

413
00:18:37,390 --> 00:18:40,450
하지만 그 덕분에 논문이 훨씬 더 탄탄해졌다고 생각합니다.

414
00:18:40,450 --> 00:18:41,730
그래서 그렇게 된 것이 기쁩니다.

415
00:18:41,730 --> 00:18:43,430
DHAVI HARIHARAN: 네, 그리고 얼마나

416
00:18:43,430 --> 00:18:44,990
이 전체 과정이 걸렸나요, 그러니까,

417
00:18:44,990 --> 00:18:48,475
초기 프로토토타입에서 논문이 나오기까지요?

418
00:18:48,475 --> 00:18:50,350
ZIGA AVSEC: 저는 팀이 꽤 오랫동안

419
00:18:50,350 --> 00:18:52,370
이 분야에서 작업해 왔다고 생각합니다.

420
00:18:52,370 --> 00:18:56,190
하지만 그 특정한 출시 논의 시점을

421
00:18:56,190 --> 00:18:58,090
논의를 시작한 때부터 논문이 출판된 때까지로 한정하면,

422
00:18:58,090 --> 00:19:00,750
2년이 채 안 걸렸습니다.

423
00:19:00,750 --> 00:19:02,410
그래서 팀이 정말

424
00:19:02,410 --> 00:19:05,010
그 지점까지 가기 위해 열심히 일했다고 생각합니다.

425
00:19:05,010 --> 00:19:07,270
어느 시점에는 모두가 한 방에 모여서,

426
00:19:07,270 --> 00:19:08,950
테이블 위에 모니터를 많이 올려두고,

427
00:19:08,950 --> 00:19:11,710
함께 이 작업을 했습니다.

428
00:19:11,710 --> 00:19:16,130
그렇게 하고 진전을 보는 것은 매우 흥분되는 시간이었습니다.

429
00:19:16,130 --> 00:19:18,210
그리고 저는 정말 설레고 매우 자랑스럽습니다

430
00:19:18,210 --> 00:19:20,450
팀이요, 저희 모두가-- 저희가 어떻게

431
00:19:20,450 --> 00:19:24,470
함께 모여 모델과 API를 출시할 수 있었던 점이요.

432
00:19:24,470 --> 00:19:27,970
[음악 재생]

433
00:19:29,508 --> 00:19:31,050
DHAVI HARIHARAN: 그래서 저는 팀에 합류했는데,

434
00:19:31,050 --> 00:19:32,982
그때는 모델이 거의 준비되어 있었고 저희가

435
00:19:32,982 --> 00:19:34,690
어떻게 이것을 공유할지

436
00:19:34,690 --> 00:19:36,730
커뮤니티와 함께 고민하기 시작하던 때였습니다.

437
00:19:36,730 --> 00:19:40,470
그리고 뭔가를 빨리 공유하고 싶다는 강한 열망이 있었고,

438
00:19:40,470 --> 00:19:44,050
동시에 더 쉽게 사용할 수 있는 방법을 찾으려 했습니다.

439
00:19:44,050 --> 00:19:47,450
TOM WARD: 네, 저희가-- 저희가 만든 것에 꽤 만족했습니다.

440
00:19:47,450 --> 00:19:50,610
우리 모델과 상호작용하기 위한 이런 모델 API를 구축한 점이요,

441
00:19:50,610 --> 00:19:53,890
예측을 하고, 결과를 평가하고 분석할 수 있게 한 점이요.

442
00:19:53,890 --> 00:19:55,450
그 결과들 말입니다.

443
00:19:55,450 --> 00:19:57,130
그리고 저희는 꽤 빠르게 깨달았습니다.

444
00:19:57,130 --> 00:20:00,450
같은 기능을 외부 사용자들도 이용할 수 있게 만들고 싶다는 것을요.

445
00:20:00,450 --> 00:20:04,070
외부에도 가능한 한 쉽고 접근하기 쉬운 방식으로 제공하면서도

446
00:20:04,070 --> 00:20:06,790
여러 가지를 할 수 있는 범용성은

447
00:20:06,790 --> 00:20:09,190
유지하고 싶었습니다.

448
00:20:09,190 --> 00:20:11,030
그래서 저희가 했던 멋진 일 중 하나는

449
00:20:11,030 --> 00:20:13,870
기본적으로 이 API를 저희 프리프린트와 거의 동시에 공개한 것이었습니다.

450
00:20:13,870 --> 00:20:15,390
프리프린트와 같은 시점에요.

451
00:20:15,390 --> 00:20:18,590
그리고 좋은 점은, 여러분이 그냥

452
00:20:18,590 --> 00:20:21,270
노트북을 열고 예측을 실행할 수 있고,

453
00:20:21,270 --> 00:20:25,030
결과를 아주 빠르게 시각화할 수 있다는 것이었습니다.

454
00:20:25,030 --> 00:20:27,910
GPU가 필요하거나 드라이버를 설치할 필요도 없이

455
00:20:27,910 --> 00:20:31,910
모델을 처음부터 로딩할 때 따라오는

456
00:20:31,910 --> 00:20:33,355
그 밖의 번거로운 작업 없이요.

457
00:20:33,355 --> 00:20:34,730
그 점이 정말 강력했다고 생각합니다.

458
00:20:34,730 --> 00:20:39,190
그래서 저희는 그걸 꼭 하고 싶었고, 사람들이--

459
00:20:39,190 --> 00:20:40,150
어떻게 사용하는지 보고 싶었습니다.

460
00:20:40,150 --> 00:20:41,910
DHAVI HARIHARAN: 간단하고 쉽게 쓸 수 있게 만드는 것처럼,

461
00:20:41,910 --> 00:20:43,530
그런 부분과 관련해

462
00:20:43,530 --> 00:20:46,710
저희 팀이 많은 시간을 들여 이야기하는 주제 중 하나는

463
00:20:46,710 --> 00:20:49,750
결국 이것이 사람들에게 실제로 무엇을

464
00:20:49,750 --> 00:20:51,870
가능하게 해 주느냐 하는 점이기도 합니다.

465
00:20:51,870 --> 00:20:54,015
준, 가장 기대되는 점이 무엇인가요?

466
00:20:54,015 --> 00:20:55,390
JUN CHENG: 네, 몇 가지

467
00:20:55,390 --> 00:20:57,870
제가 특히 기대하는 점이 있는데,

468
00:20:57,870 --> 00:20:59,950
커뮤니티가 AlphaGenome을 어떻게 활용할지입니다.

469
00:20:59,950 --> 00:21:04,450
첫 번째는 과학자들이 이를 도구로 활용해

470
00:21:04,450 --> 00:21:06,690
어떤 종류의 변이가

471
00:21:06,690 --> 00:21:09,810
인체에 해로울 수 있는지 특정하는 데 도움이 된다는 점입니다.

472
00:21:09,810 --> 00:21:13,990
또 하나는 기본 생물학을 이해하는 도구로 활용하는 것입니다.

473
00:21:13,990 --> 00:21:16,990
생물학은 생각해 보면 상당히 복잡합니다.

474
00:21:16,990 --> 00:21:19,490
그리고 이 도구로, 바라건대 과학자들은

475
00:21:19,490 --> 00:21:23,570
연구를 시작하고-- 예측을 할 수 있을 것입니다.

476
00:21:23,570 --> 00:21:26,050
게놈의 어느 부분이 기능적인지,

477
00:21:26,050 --> 00:21:29,530
또 어느 부분이

478
00:21:29,530 --> 00:21:33,790
유전자 발현을 조절하는 책임이 있는지, 그리고 어떤 세포 유형에서 활성화되는지요.

479
00:21:33,790 --> 00:21:37,090
그런 것들이요. 네, 저는 이것이 정말 훌륭한

480
00:21:37,090 --> 00:21:39,090
도구라고 생각합니다.

481
00:21:39,090 --> 00:21:42,650
우리 게놈에 대해, 바라건대 과학자들이 이를 활용하기 시작해서,

482
00:21:42,650 --> 00:21:45,770
한정된 자원과

483
00:21:45,770 --> 00:21:50,650
연구비로 최대한의 성과를 내고,

484
00:21:50,650 --> 00:21:53,570
전반적으로 과학 연구를 개선하는 데 기여하길 바랍니다.

485
00:21:53,570 --> 00:21:55,570
DHAVI HARIHARAN: 지가, 나타샤 두 분 모두

486
00:21:55,570 --> 00:21:57,678
이 분야에서 오랫동안 활동해 오셨는데요.

487
00:21:57,678 --> 00:21:59,470
지금까지 어떤 요청을 받아 왔나요?

488
00:21:59,470 --> 00:22:01,730
또 특별히 놀라웠던 점이 있었나요?

489
00:22:01,730 --> 00:22:05,190
ZIGA AVSEC: 네, 사람들은 정말 많은--

490
00:22:05,190 --> 00:22:08,070
기능 요청을 해 왔습니다.

491
00:22:08,070 --> 00:22:10,670
예를 들어 사람들이 묻는 것 중 하나는,

492
00:22:10,670 --> 00:22:12,630
게놈에서 단일 염기 변경만이 아니라

493
00:22:12,630 --> 00:22:15,270
여러 염기에 걸친 다중 변경도 할 수 있느냐는 것이었습니다.

494
00:22:15,270 --> 00:22:18,627
삽입, 결실, 혹은 큰 구조적 변이 같은 것들이요.

495
00:22:18,627 --> 00:22:20,710
그리고 인델(indels)의 경우에는, 사실 이미 지원하는 기능입니다.

496
00:22:20,710 --> 00:22:22,010
이미 구현해 두었었습니다.

497
00:22:22,010 --> 00:22:26,430
다만 퀵스타트에서 충분히 강조되지 않았을 뿐입니다.

498
00:22:26,430 --> 00:22:28,395
다만 한 사용자가 버그를 하나 발견했는데,

499
00:22:28,395 --> 00:22:30,270
이 코드의 버그가 사실 꽤 까다로운 문제였습니다.

500
00:22:30,270 --> 00:22:33,270
그리고 결국 고칠 수 있었습니다.

501
00:22:33,270 --> 00:22:37,542
그리고 또 다른 기능으로는 사람들이 이렇게 물어봤습니다,

502
00:22:37,542 --> 00:22:39,250
모델의 임베딩을 사용할 수 있나요?

503
00:22:39,250 --> 00:22:41,590
아니면 자신의 데이터로 파인튜닝할 수 있나요?

504
00:22:41,590 --> 00:22:45,370
왜냐하면 더 흥미로운 데이터가 꽤 많이 있고

505
00:22:45,370 --> 00:22:46,870
저희가 포함하지 못한 데이터셋들이

506
00:22:46,870 --> 00:22:48,322
모델에 꽤 많지요, 그렇죠 나타샤?

507
00:22:48,322 --> 00:22:50,530
NATASHA LATYSHEVA: 네, 사실 데이터 측면에서,

508
00:22:50,530 --> 00:22:53,710
흥미로웠고, 놀랍다기보다는

509
00:22:53,710 --> 00:22:56,930
추가 종에 대한 요청이 이렇게 많다는 점이

510
00:22:56,930 --> 00:23:00,430
추가 모달리티와 추가 세포 유형에 대한 요청도요.

511
00:23:00,430 --> 00:23:02,330
그래서 앞서 말씀드린 것처럼,

512
00:23:02,330 --> 00:23:06,708
모델이 꽤 괜찮은 범위를 커버하도록 노력했지만,

513
00:23:06,708 --> 00:23:07,750
종에 대해서는 그렇지 않습니다.

514
00:23:07,750 --> 00:23:10,170
지금은 아직 사람과 생쥐만 지원합니다.

515
00:23:10,170 --> 00:23:14,490
하지만 기본적으로 사람들은 한곳에서 더 많은 기능을 원합니다.

516
00:23:14,490 --> 00:23:15,790
그리고 그건 사실 당연합니다.

517
00:23:15,790 --> 00:23:17,713
저도 충분히 공감합니다.

518
00:23:17,713 --> 00:23:19,130
제가 강조하고 싶은 한 가지는

519
00:23:19,130 --> 00:23:21,730
커뮤니티에서 오는 이런 피드백 신호가

520
00:23:21,730 --> 00:23:23,390
저희에게 대단히 중요하다는 점입니다.

521
00:23:23,390 --> 00:23:26,570
이것이 다음에 무엇을 할지에 직접 반영되고

522
00:23:26,570 --> 00:23:27,830
다음에 무엇을 만들지로 이어집니다.

523
00:23:27,830 --> 00:23:31,330
[음악 재생]

524
00:23:32,630 --> 00:23:34,130
DHAVI HARIHARAN: 이제 자주 받는 질문인데요,

525
00:23:34,130 --> 00:23:36,870
늘 듣는 질문이죠, 다음은 무엇인가요?

526
00:23:36,870 --> 00:23:40,810
JUN CHENG: 그리고 저희 웹사이트에 가서 API를 보면,

527
00:23:40,810 --> 00:23:42,610
변이 하나당 수만 개의

528
00:23:42,610 --> 00:23:45,210
점수를 예측하고 있는데, 이는 당연히

529
00:23:45,210 --> 00:23:47,810
과학자들이 읽고 해석하기가 매우 어렵습니다.

530
00:23:47,810 --> 00:23:51,730
그래서 이 모든 점수를 어떻게 요약해서

531
00:23:51,730 --> 00:23:56,010
변이당 하나의 점수로 만들고, 기본적으로

532
00:23:56,010 --> 00:23:58,890
점수들을 최대한 집계하여

533
00:23:58,890 --> 00:24:03,350
사용자나 과학자들이 변이별 예측을 하고

534
00:24:03,350 --> 00:24:06,070
점수를 본 다음, 그리고 나서--

535
00:24:06,070 --> 00:24:08,270
변이 목록, 짧은 후보 목록의 우선순위를 정해서

536
00:24:08,270 --> 00:24:10,590
깊게 파고들 대상을 고를 수 있게 하려 합니다.

537
00:24:10,590 --> 00:24:13,990
그리고 나서 매우 포괄적인 예측을

538
00:24:13,990 --> 00:24:16,230
세포 유형과 조직별로 살펴보고, 그리고

539
00:24:16,230 --> 00:24:21,390
그리고 이런 질문에 답할 수 있습니다-- 이 변이의 효과가

540
00:24:21,390 --> 00:24:23,270
어느 조직에서 비롯되는지,

541
00:24:23,270 --> 00:24:27,387
또 어떤 유전자들이 [청취 불가] 활성화되는지 같은 것들이요.

542
00:24:27,387 --> 00:24:29,470
TOM WARD: 네, 그리고 또 하나 저희가 하고 싶은 것은

543
00:24:29,470 --> 00:24:32,190
정말 대규모 분석을 지원하는 것입니다,

544
00:24:32,190 --> 00:24:36,010
예를 들어 전장유전체 연관 분석 같은 것들이요.

545
00:24:36,010 --> 00:24:38,590
현재 API로도 많은--

546
00:24:38,590 --> 00:24:40,750
많은 예측을 할 수 있지만, 아마도

547
00:24:40,750 --> 00:24:48,470
그런 매우 광범위한 대규모 연구에 필요한 만큼은 아닐 수 있습니다.

548
00:24:48,470 --> 00:24:51,230
그래서 네, 기본적으로는

549
00:24:51,230 --> 00:24:54,270
가능한 한 많은 변이를 미리 계산해 두는 방안을

550
00:24:54,270 --> 00:25:00,310
사람들이 그런 대규모 분석을 훨씬 더

551
00:25:00,310 --> 00:25:01,157
쉽게 할 수 있도록 검토하고 있습니다.

552
00:25:01,157 --> 00:25:03,490
NATASHA LATYSHEVA: 그리고 모델 가중치도

553
00:25:03,490 --> 00:25:04,867
물론 공개할 예정입니다.

554
00:25:04,867 --> 00:25:05,450
TOM WARD: 네.

555
00:25:05,450 --> 00:25:06,010
NATASHA LATYSHEVA: 네, 저희는 정말

556
00:25:06,010 --> 00:25:08,330
사람들이 그것으로 무엇을 할지 기대하고 있습니다.

557
00:25:08,330 --> 00:25:09,850
그래서 임베딩을 가지고

558
00:25:09,850 --> 00:25:12,530
실험해 보거나, 파인튜닝을 하거나,

559
00:25:12,530 --> 00:25:14,370
새로운 데이터로 확장하는 등 무엇이든 될 수 있습니다.

560
00:25:14,370 --> 00:25:17,890
그리고 이 모델이 매우 많은 작업에서 성능이 좋기 때문에,

561
00:25:17,890 --> 00:25:20,310
사람들이 어디에 활용할지 정말 기대됩니다.

562
00:25:20,310 --> 00:25:23,262
바라건대 아주 다양하고

563
00:25:23,262 --> 00:25:24,970
서로 다른 문제들에 적용될 수 있을 것이고,

564
00:25:24,970 --> 00:25:26,413
그중 일부는 저희가 아마 이전엔 생각도 못 했던 것들일 겁니다.

565
00:25:26,413 --> 00:25:28,830
DHAVI HARIHARAN: 이 모든 것을 추진하고 있다니 정말 기쁩니다.

566
00:25:28,830 --> 00:25:31,330
그리고 이 이야기를 들으면 우리 과학자들 중 일부도

567
00:25:31,330 --> 00:25:32,810
기뻐하길 바랍니다.

568
00:25:32,810 --> 00:25:35,050
지가, 팀의 미션으로 돌아가서

569
00:25:35,050 --> 00:25:37,590
AlphaGenome이 그 미션을 향한 한 걸음이었다는 점을 고려할 때,

570
00:25:37,590 --> 00:25:40,465
모델의 다음 단계에 대해 어떻게 생각하시나요?

571
00:25:40,465 --> 00:25:42,090
ZIGA AVSEC: 네, 아직도

572
00:25:42,090 --> 00:25:44,270
개선 여지가 많이 남아 있다고 생각합니다,

573
00:25:44,270 --> 00:25:47,410
예측 성능 측면에서도 그렇고,

574
00:25:47,410 --> 00:25:49,050
역량 측면에서도 그렇습니다.

575
00:25:49,050 --> 00:25:50,630
예측 성능 측면에서는

576
00:25:50,630 --> 00:25:53,090
어디까지 갈 수 있을지 지켜보겠습니다.

577
00:25:53,090 --> 00:25:57,130
그리고 역량 측면에서 제가 기대하는 것 중 하나는

578
00:25:57,130 --> 00:26:02,950
이 새롭고 놀라운 단일세포 아틀라스들을 활용하는 것입니다,

579
00:26:02,950 --> 00:26:05,110
예를 들어--

580
00:26:05,110 --> 00:26:07,590
기술이 정말 빠르게 발전하고

581
00:26:07,590 --> 00:26:09,550
개선되고 있기 때문입니다.

582
00:26:09,550 --> 00:26:14,510
이 덕분에 저희는 분자 과정들을

583
00:26:14,510 --> 00:26:18,150
조직 수준뿐 아니라 개별 세포 유형

584
00:26:18,150 --> 00:26:20,270
수준에서도 조직 내에서 측정할 수 있습니다.

585
00:26:20,270 --> 00:26:23,790
그리고 이러한 것들로 모델을 확장할 수 있다면,

586
00:26:23,790 --> 00:26:27,390
질병과 관련된 변이들을 연구하는 데

587
00:26:27,390 --> 00:26:31,150
예를 들어 이런 종류의 결함이

588
00:26:31,150 --> 00:26:33,168
이 개별 세포 유형에서 발생하는 경우에 더 적용 가능해질 것이라고 생각합니다.

589
00:26:33,168 --> 00:26:34,710
DHAVI HARIHARAN: 시청해 주셔서 감사합니다.

590
00:26:34,710 --> 00:26:36,110
지금까지는

591
00:26:36,110 --> 00:26:39,190
AlphaGenome을 만들고 공개하는 과정의 주요 내용이었습니다.

592
00:26:39,190 --> 00:26:41,710
더 많은 자세한 내용은 저희 "Nature" 논문에 담겨 있습니다.

593
00:26:41,710 --> 00:26:43,590
그리고 여러분이

594
00:26:43,590 --> 00:26:46,150
모델을 탐색하고 사용하기 시작하면서

595
00:26:46,150 --> 00:26:49,430
흥미로운 사례 연구든, 빈틈이든, 아이디어든

596
00:26:49,430 --> 00:26:51,910
이 작업을 여러분에게 더 유용하게 만들 수 있는 의견을 정말 듣고 싶습니다.

597
00:26:51,910 --> 00:26:55,710
사용자 지원팀은 사실상 저희 팀 자체이므로,

598
00:26:55,710 --> 00:26:58,530
Discourse 포럼에서 꼭 연락해 주세요.

599
00:26:58,530 --> 00:27:01,880
[음악 재생 중]
