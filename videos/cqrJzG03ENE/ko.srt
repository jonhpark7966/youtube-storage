1
00:00:00,000 --> 00:00:01,840
아마도 제가 가장 놀랐던 점은

2
00:00:01,840 --> 00:00:03,980
제가 느끼기에 그 정도가

3
00:00:03,980 --> 00:00:05,060
AI 경제가

4
00:00:05,060 --> 00:00:07,220
안정화됐다는 점입니다. 모델 계층 회사들이 있고

5
00:00:07,220 --> 00:00:09,280
애플리케이션 계층 회사들도 있고

6
00:00:09,280 --> 00:00:10,960
인프라 계층 회사들도 있습니다. 모두가

7
00:00:10,960 --> 00:00:12,740
큰돈을 벌 것 같고

8
00:00:12,740 --> 00:00:14,720
AI 네이티브 회사를

9
00:00:14,720 --> 00:00:16,320
모델 위에서 어떻게 만들지에 대한

10
00:00:16,320 --> 00:00:16,940
어느 정도의 플레이북도 생긴 것 같습니다.

11
00:00:17,120 --> 00:00:18,800
몇 에피소드 전 저희가

12
00:00:18,800 --> 00:00:20,820
스타트업 아이디어를 찾아보는 일이 그 어느 때보다

13
00:00:20,820 --> 00:00:21,820
쉽게 느껴진다고 이야기한 적이 있습니다.

14
00:00:21,820 --> 00:00:23,840
왜냐하면 그저 버티기만 할 수 있다면, 그리고

15
00:00:23,840 --> 00:00:25,460
몇 달만 기다리면, 아마

16
00:00:25,460 --> 00:00:25,780
곧

17
00:00:25,780 --> 00:00:28,640
완전히 새로운 아이디어들을 가능하게 만드는

18
00:00:28,640 --> 00:00:30,420
큰 발표가 나올 가능성이 높기 때문이었습니다. 그래서

19
00:00:30,420 --> 00:00:30,620
결국

20
00:00:30,620 --> 00:00:32,720
아이디어를 찾는 일이 다시

21
00:00:32,720 --> 00:00:34,560
정상적인 난이도 수준으로 돌아가고 있는 것 같습니다.

22
00:00:42,020 --> 00:00:44,300
The Light Cone의 또 다른 에피소드에 다시 오신 것을 환영합니다.

23
00:00:44,300 --> 00:00:46,540
오늘은 2025년에 저희가 본 것들 중

24
00:00:46,540 --> 00:00:49,220
가장 놀라웠던 것들에 대해 이야기해 보겠습니다.

25
00:00:50,060 --> 00:00:53,400
Diana, 정말 놀라운 걸 하나 찾으셨더군요. 이건

26
00:00:53,400 --> 00:00:53,960
일종의

27
00:00:53,960 --> 00:00:56,460
YC 배치에서 선호되는 LLM이 누군지에 대해

28
00:00:56,460 --> 00:00:59,860
거의 판도가 바뀐 것 같은 이야기입니다.

29
00:01:00,120 --> 00:01:02,440
네. 사실 저희가 방금

30
00:01:02,440 --> 00:01:06,660
기업들을 대상으로 한 Winter 26 선발 사이클을 마무리했습니다. 그리고

31
00:01:06,660 --> 00:01:06,880
그 과정에서

32
00:01:06,880 --> 00:01:09,240
YC에 지원하는 모든 창업자분들께

33
00:01:09,240 --> 00:01:11,720
기술 스택이 무엇인지와

34
00:01:11,720 --> 00:01:13,640
선호하는 모델이 무엇인지 질문합니다.

35
00:01:14,000 --> 00:01:16,040
그런데 충격적인 점 중 하나는

36
00:01:16,040 --> 00:01:18,920
아주 오랫동안 OpenAI가

37
00:01:18,920 --> 00:01:19,540
명확한 1위였고

38
00:01:19,540 --> 00:01:22,920
작년 내내와 최근 몇 개의 배치 동안

39
00:01:22,920 --> 00:01:25,460
그 비중이 내려오고 있었다는 점입니다.

40
00:01:26,380 --> 00:01:30,520
그런데 놀랍게도 이번 배치에서 1위

41
00:01:30,520 --> 00:01:34,920
API는 실제로 Anthropic이었습니다. 약간

42
00:01:34,920 --> 00:01:35,540
OpenAI보다 더 높게 나왔는데

43
00:01:35,540 --> 00:01:37,800
누가 이런 걸 예상했겠습니까? 저희가

44
00:01:37,800 --> 00:01:40,620
이 팟캐스트 시리즈를 시작했을 때만 해도

45
00:01:40,620 --> 00:01:44,180
OpenAI가 90% 이상이었는데, 지금은

46
00:01:44,940 --> 00:01:46,620
Anthropic이라니, 누가 생각했겠습니까?

47
00:01:46,860 --> 00:01:48,620
네. 그리고 아시다시피 Anthropic은

48
00:01:48,620 --> 00:01:52,060
2024년 대부분과 2025년 초까지는

49
00:01:52,060 --> 00:01:55,980
대략 20~25% 정도에서 머물렀습니다. 그런데

50
00:01:55,980 --> 00:01:58,280
정말 최근 3~6개월 사이에

51
00:01:58,280 --> 00:02:00,740
이런 세대교체가

52
00:02:00,740 --> 00:02:01,640
실제로 일어났습니다.

53
00:02:01,640 --> 00:02:03,860
성장이 하키스틱처럼 급격히 치솟아

54
00:02:03,860 --> 00:02:06,060
52%를 넘겼습니다.

55
00:02:06,060 --> 00:02:07,420
왜 그렇다고 생각하십니까?

56
00:02:07,660 --> 00:02:09,380
기술 스택 선택 측면에서

57
00:02:09,380 --> 00:02:11,440
몇 가지 이유가 있다고 생각합니다. 올해 저희가 본 것처럼

58
00:02:11,440 --> 00:02:12,760
올해는

59
00:02:13,280 --> 00:02:16,000
바이브 코딩 도구들이 많이 성공했고

60
00:02:16,000 --> 00:02:18,220
여기저기에서 계속 만들어지고 있습니다. 그리고

61
00:02:18,220 --> 00:02:19,680
코딩 에이전트 같은 카테고리가 워낙 많아서

62
00:02:19,680 --> 00:02:22,700
결국 이 분야가 더 큰 문제 영역이 되었고

63
00:02:22,700 --> 00:02:25,740
실제로 큰 가치를 만들어내고 있습니다. 그리고

64
00:02:25,740 --> 00:02:26,240
알고 보니

65
00:02:26,240 --> 00:02:28,140
그 일을 가장 잘하는 모델이

66
00:02:28,140 --> 00:02:30,760
결국

67
00:02:30,760 --> 00:02:31,580
실제로는

68
00:02:32,580 --> 00:02:35,800
Anthropic의 모델들입니다. 그리고 저는 그게

69
00:02:35,800 --> 00:02:38,080
우연이 아니라고 생각합니다. 얼마 전

70
00:02:38,080 --> 00:02:39,780
Tom Brown과 나눴던 대화를 떠올려 보면

71
00:02:39,780 --> 00:02:41,500
그가 와서 말했듯이, 그것이

72
00:02:41,500 --> 00:02:43,180
그들의 내부 평가 중 하나였다고 합니다.

73
00:02:43,360 --> 00:02:45,940
그들은 의도적으로 그것을 자신들의 노스스타로 삼았습니다.

74
00:02:46,120 --> 00:02:47,840
그리고 그 결과가 모델에 그대로 드러납니다.

75
00:02:47,840 --> 00:02:49,220
그래서 모델 선택에서도 그런 성향이 나타납니다.

76
00:02:49,740 --> 00:02:53,060
제품을 만드는 많은 창업자들에게 어떤 모델이

77
00:02:53,060 --> 00:02:55,580
가장 좋은 선택인지 보면, Anthropic입니다.

78
00:02:55,840 --> 00:02:58,140
다만 사람들이 사용하는 유스케이스의 대다수는

79
00:02:58,140 --> 00:03:00,060
코딩이 아닙니다.

80
00:03:00,240 --> 00:03:01,000
그래서 혹시

81
00:03:01,000 --> 00:03:02,320
일종의 스필오버 효과가 있어서 사람들이

82
00:03:02,320 --> 00:03:05,420
개인 코딩에 Claude를 쓰고, 그러다

83
00:03:05,420 --> 00:03:07,680
그 결과로

84
00:03:07,680 --> 00:03:09,260
애플리케이션에서도 그 모델을 선택할 가능성이 커지는

85
00:03:09,260 --> 00:03:09,460
것 아닐까 하는데요,

86
00:03:09,460 --> 00:03:10,300
애플리케이션이 코딩을 전혀 하지 않더라도 말입니다.

87
00:03:10,300 --> 00:03:12,940
왜냐하면 그러면

88
00:03:12,940 --> 00:03:15,940
Claude Opus 같은 모델의 성격에, 또는

89
00:03:15,940 --> 00:03:17,720
자신이 쓰는 모델에 매우 익숙해지기 때문입니다. 아마 Sonnet이겠지요.

90
00:03:18,140 --> 00:03:20,440
Gemini는 어떤가요? 그런 순위에서 Gemini는

91
00:03:20,440 --> 00:03:20,720
어떻게 되고 있습니까?

92
00:03:21,060 --> 00:03:23,440
Gemini도 거의 계속해서

93
00:03:23,440 --> 00:03:25,780
꽤 높은 순위까지 올라왔습니다. 작년에는

94
00:03:25,780 --> 00:03:26,000
아마

95
00:03:26,000 --> 00:03:28,640
한 자릿수 퍼센트였거나 2%,

96
00:03:28,800 --> 00:03:32,480
3% 정도였을 텐데, 이제 Winter 26에서는

97
00:03:32,480 --> 00:03:32,660
대략

98
00:03:32,660 --> 00:03:36,320
23%입니다. 저희도 개인적으로

99
00:03:36,320 --> 00:03:38,320
Gemini 3.0을 많이 써 왔고

100
00:03:38,320 --> 00:03:39,140
정말

101
00:03:39,140 --> 00:03:42,200
품질이 인상적이었습니다. 정말,

102
00:03:42,420 --> 00:03:43,300
정말 잘 작동합니다.

103
00:03:43,540 --> 00:03:45,800
그러니까, 모델마다 성격이 다 다르지 않습니까?

104
00:03:45,800 --> 00:03:45,980
그렇지요?

105
00:03:46,160 --> 00:03:46,280
맞습니다.

106
00:03:46,560 --> 00:03:46,760
네.

107
00:03:47,300 --> 00:03:49,940
전형적인 비유로 OpenAI는

108
00:03:49,940 --> 00:03:52,740
좀 검은 고양이 같은 에너지가 있고, 거의

109
00:03:52,740 --> 00:03:53,020
반면

110
00:03:54,340 --> 00:03:55,780
Anthropic은 좀 더 낙천적이고

111
00:03:55,780 --> 00:03:58,660
아주 친절한 골든리트리버에 가깝습니다.

112
00:03:58,840 --> 00:03:59,240
적어도

113
00:03:59,240 --> 00:04:00,360
제가 그들과 이야기할 때는 그렇게

114
00:04:00,360 --> 00:04:00,520
느껴집니다.

115
00:04:00,940 --> 00:04:01,920
그럼 Gemini는 어떻습니까?

116
00:04:02,140 --> 00:04:03,220
그 중간쯤인 것 같습니다.

117
00:04:03,780 --> 00:04:05,480
Harj, 사실 Gemini를 더 선호하시잖아요.

118
00:04:05,860 --> 00:04:08,900
네, 저는 올해 Gemini로

119
00:04:08,900 --> 00:04:11,340
기본으로 쓰는 모델을 바꿨습니다. 심지어

120
00:04:11,340 --> 00:04:13,360
2.5 Pro가 나오기

121
00:04:13,360 --> 00:04:16,920
전부터도 제게는 추론이 더 잘되는 것처럼

122
00:04:16,920 --> 00:04:19,400
느껴졌고, 저는 점점 더

123
00:04:19,400 --> 00:04:20,120
제

124
00:04:20,120 --> 00:04:22,420
Google 검색을 Gemini로 대체했습니다. 그리고 저는

125
00:04:22,420 --> 00:04:24,960
구글의, 그러니까

126
00:04:24,960 --> 00:04:25,320
Grounding

127
00:04:25,320 --> 00:04:27,340
API와 실제로

128
00:04:27,340 --> 00:04:29,740
구글 인덱스를 활용해

129
00:04:29,740 --> 00:04:30,820
실시간 정보를

130
00:04:30,820 --> 00:04:32,900
정확히 제공하는 능력을 신뢰했습니다. 개인적으로는

131
00:04:33,100 --> 00:04:34,660
그런 용도에서는

132
00:04:34,660 --> 00:04:34,760
다른

133
00:04:34,760 --> 00:04:35,840
도구들보다 더 낫다고 느꼈습니다. 그리고

134
00:04:35,840 --> 00:04:37,780
그 부분에서는 Perplexity보다도 나았습니다. Perplexity는

135
00:04:37,780 --> 00:04:37,940
대체로

136
00:04:37,940 --> 00:04:40,300
빠르지만 항상 정확하진 않았습니다. 반면 Gemini는

137
00:04:40,300 --> 00:04:42,040
Perplexity만큼 빠르진 않았지만

138
00:04:42,040 --> 00:04:42,400
항상

139
00:04:42,400 --> 00:04:44,760
제가 무언가를 물어보면 대체로 꽤 정확했고

140
00:04:44,760 --> 00:04:45,940
예를 들어 오늘 일어난 일도 그랬습니다.

141
00:04:45,940 --> 00:04:47,960
Perplexity에서 추론 엔진으로 Gemini를

142
00:04:47,960 --> 00:04:49,420
쓰더라도 그렇습니까?

143
00:04:50,140 --> 00:04:51,200
저는 그렇게 해본 적이 없습니다.

144
00:04:51,440 --> 00:04:53,640
흥미롭네요. 네, 그래서

145
00:04:53,640 --> 00:04:55,020
얼마나 툴링 덕분인지,

146
00:04:55,020 --> 00:04:55,800
얼마나

147
00:04:55,800 --> 00:04:57,100
기본 LLM 덕분인지는 알기 어렵습니다.

148
00:04:57,220 --> 00:04:57,640
그 말도 맞습니다.

149
00:04:57,880 --> 00:04:59,900
네. 그러면 여러분은 어떤 도구를

150
00:04:59,900 --> 00:05:01,860
주로 쓰십니까? 저는 아직 ChatGPT에서 갈아타지 않았습니다.

151
00:05:02,000 --> 00:05:02,140
그러니까요,

152
00:05:02,260 --> 00:05:04,440
메모리가 정말 강하게 남아 있어서요. 저를

153
00:05:04,440 --> 00:05:06,400
알고, 제 성격도 알고, 제가

154
00:05:06,400 --> 00:05:06,800
생각하는

155
00:05:06,800 --> 00:05:09,620
것들까지 압니다. 그래서 저는 Perplexity를

156
00:05:09,620 --> 00:05:13,580
빠른 웹 검색이나 제가

157
00:05:13,580 --> 00:05:14,200
명확히

158
00:05:14,200 --> 00:05:16,680
리서치 과제라고 아는 일에는 쓰는데, ChatGPT는

159
00:05:16,680 --> 00:05:17,960
여전히 약간 한 걸음

160
00:05:17,960 --> 00:05:19,320
뒤처진다고 생각합니다,

161
00:05:19,320 --> 00:05:20,940
웹 검색에서는요. 모르겠습니다만, 메모리가

162
00:05:20,940 --> 00:05:25,540
사실상

163
00:05:25,540 --> 00:05:26,740
그런 소비자 경험의 진짜 해자가 되고 있다고 봅니다.

164
00:05:26,740 --> 00:05:29,340
그리고 Gemini가 결코

165
00:05:29,340 --> 00:05:32,400
ChatGPT에서 기대하는 그런 성격을 갖게 될 것 같지는 않습니다.

166
00:05:32,560 --> 00:05:34,600
그냥 다른 존재처럼 느껴집니다,

167
00:05:34,920 --> 00:05:35,140
아시겠지요?

168
00:05:35,480 --> 00:05:37,340
제가 여전히 놀라는 것은 왜

169
00:05:37,340 --> 00:05:42,380
우리가 하는 온갖 일을 둘러싼

170
00:05:42,380 --> 00:05:42,780
소비자

171
00:05:42,780 --> 00:05:44,960
앱이 더 많지 않은가 하는 점입니다. 예를 들어

172
00:05:44,960 --> 00:05:46,400
돌이켜보면, 올해 제게 큰 변화 중 하나는

173
00:05:46,400 --> 00:05:47,960
그저

174
00:05:48,840 --> 00:05:51,220
제 삶을 위해 하는 프롬프팅과 컨텍스트 엔지니어링이

175
00:05:51,220 --> 00:05:53,620
얼마나 많아졌는가입니다. 예를 들어 최근 집을 샀는데

176
00:05:53,620 --> 00:05:54,020
그 과정에서

177
00:05:54,020 --> 00:05:55,700
전체 과정 내내 저는 그냥

178
00:05:55,700 --> 00:05:59,220
아주 오래 이어진 ChatGPT 대화에 계속

179
00:05:59,220 --> 00:05:59,440
온갖

180
00:05:59,440 --> 00:06:01,980
점검 보고서 같은 컨텍스트를 채워 넣거나

181
00:06:01,980 --> 00:06:04,400
정보 비대칭을

182
00:06:04,400 --> 00:06:04,880
저와

183
00:06:04,880 --> 00:06:06,720
부동산 중개인 사이에서 줄여서 대략

184
00:06:06,720 --> 00:06:08,420
모든 역학관계와

185
00:06:08,420 --> 00:06:08,920
진행 상황을 이해하려고 했습니다.

186
00:06:09,120 --> 00:06:11,240
그러다 보니 이런 일을 해주는

187
00:06:11,240 --> 00:06:12,180
앱이 있어야 한다고 느낍니다.

188
00:06:12,180 --> 00:06:15,800
하지만 동시에, 아마 PDF들을

189
00:06:15,800 --> 00:06:18,080
그냥 Gemini에 넣고

190
00:06:18,080 --> 00:06:18,640
이렇게 말했겠지요,

191
00:06:18,640 --> 00:06:20,900
"요약해 주고 무엇이 중요한지

192
00:06:20,900 --> 00:06:21,280
알려 달라"고요.

193
00:06:21,360 --> 00:06:23,180
저는 좀 걱정이 됩니다. 예전에도 그랬고,

194
00:06:23,220 --> 00:06:25,260
지금도 모델을 충분히 신뢰하지 못해서

195
00:06:25,260 --> 00:06:25,460
프롬프팅을 많이 하지 않으면 정확하지 않을까 싶습니다. 게다가 이건

196
00:06:25,460 --> 00:06:28,160
고가의 거래입니다. 그래서

197
00:06:28,160 --> 00:06:29,820
그냥

198
00:06:29,820 --> 00:06:30,100
잘못된 데이터를 얻고 싶지 않습니다. 그래서 저는

199
00:06:30,100 --> 00:06:32,360
여전히 직접

200
00:06:32,360 --> 00:06:33,580
노력을 들여야 한다고 느끼고, 그러면서도

201
00:06:33,580 --> 00:06:34,760
모든 일을 대신해 주는 앱이

202
00:06:34,760 --> 00:06:37,360
여전히 있어야 한다고

203
00:06:37,360 --> 00:06:38,260
생각합니다.

204
00:06:38,380 --> 00:06:40,080
Karpathy가 일종의

205
00:06:40,080 --> 00:06:42,920
LLM 아레나 같은 것을 공개한 것 보셨습니까? 저는

206
00:06:42,920 --> 00:06:44,320
말하자면 그걸 손으로

207
00:06:44,320 --> 00:06:46,480
지금 탭으로 하고 있습니다. 예를 들면

208
00:06:46,480 --> 00:06:49,260
Claude를 열어두고, Gemini를 열어두고,

209
00:06:49,260 --> 00:06:50,020
ChatGPT도 열어두고,

210
00:06:50,020 --> 00:06:52,400
똑같은 과제를 줍니다. 그리고

211
00:06:52,400 --> 00:06:54,240
각각의 결과를 가져오고,

212
00:06:54,240 --> 00:06:55,440
그다음에는 보통 Claude로

213
00:06:55,440 --> 00:06:56,900
가서 이렇게 말합니다. "좋습니다,

214
00:06:57,040 --> 00:06:58,380
Claude, 다른 모델은 이렇게 말했습니다."

215
00:06:58,480 --> 00:06:59,020
"어떻게 생각하십니까?"

216
00:06:59,020 --> 00:07:01,060
이렇게 서로의 작업을 대조합니다. 저는 사실

217
00:07:01,060 --> 00:07:02,860
소비자 측에서 이런 행동이

218
00:07:03,000 --> 00:07:06,360
우리가 하는 이 수준으로 스타트업들도

219
00:07:06,360 --> 00:07:08,360
똑같이 하고 있다고 봅니다. 실제로 그들은

220
00:07:08,360 --> 00:07:09,660
여러 모델을 적극적으로 조합해 이득을 보고 있습니다. 저는

221
00:07:09,660 --> 00:07:12,320
여러 창업자들과 대화를 했는데, 예전에는

222
00:07:12,320 --> 00:07:12,620
그들이 예를 들어 OpenAI

223
00:07:12,620 --> 00:07:15,180
모델이나 Anthropic에 충성적이었을 수도 있습니다. 그런데 저는

224
00:07:15,180 --> 00:07:18,580
최근에도 그들과 대화를 했습니다. 이들은

225
00:07:18,580 --> 00:07:20,760
더 큰 회사를 운영하는 창업자들이고,

226
00:07:20,760 --> 00:07:23,380
시리즈 B 수준의 회사들입니다. AI에서는

227
00:07:23,380 --> 00:07:26,420
그들이 실제로 그런 것들을 전부 추상화해 버리고

228
00:07:26,680 --> 00:07:29,600
오케스트레이션 레이어를 구축해서, 아마도

229
00:07:29,600 --> 00:07:33,580
새 모델이 출시될 때마다

230
00:07:33,580 --> 00:07:35,620
그것들을 갈아 끼웠다 뺐다 할 수 있고, 또는

231
00:07:35,760 --> 00:07:37,980
특정 작업에 더 뛰어난 특정 모델을

232
00:07:37,980 --> 00:07:40,360
필요한 곳에

233
00:07:40,360 --> 00:07:41,440
바로 그 용도로 쓰기도 합니다. 예를 들어

234
00:07:41,440 --> 00:07:43,700
어떤 스타트업에서 들었는데요,

235
00:07:43,700 --> 00:07:47,000
Gemini 3로

236
00:07:47,000 --> 00:07:47,600
컨텍스트

237
00:07:47,600 --> 00:07:50,740
엔지니어링을 하고, 그 결과를 실제로 OpenAI에 넣어

238
00:07:50,740 --> 00:07:52,540
실행한다고 합니다. 그리고 그들은 계속

239
00:07:52,540 --> 00:07:52,960
새

240
00:07:52,960 --> 00:07:55,000
모델이 나올 때마다 바꾸며, 각

241
00:07:55,000 --> 00:07:58,600
카테고리나 에이전트 작업 유형마다

242
00:07:58,600 --> 00:07:58,960
승자가 달라진다는 것입니다.

243
00:07:59,600 --> 00:08:02,680
그리고 궁극적으로 이것이 가능한 이유는

244
00:08:02,680 --> 00:08:04,840
모든 것이 평가(evals)에 기반해 정착되어 있기 때문입니다. 또

245
00:08:04,840 --> 00:08:05,580
그 평가들은 전부

246
00:08:05,580 --> 00:08:07,820
그들만의 독점 자산인데, 그들은 버티컬 AI

247
00:08:07,820 --> 00:08:09,540
에이전트이고, 매우

248
00:08:09,540 --> 00:08:10,420
규제가 강한 산업에서만

249
00:08:10,420 --> 00:08:12,300
일하면서, 자신들에게 가장

250
00:08:12,300 --> 00:08:14,020
잘 맞는 데이터셋을 갖고 있기 때문입니다. 저는 이것이

251
00:08:14,020 --> 00:08:15,300
바로 지금의 새로운

252
00:08:15,300 --> 00:08:17,600
표준이 되었다고 생각합니다. 사람들은 이제, 네,

253
00:08:17,600 --> 00:08:20,260
모델 회사들이

254
00:08:20,260 --> 00:08:20,400
막대한 돈을

255
00:08:20,400 --> 00:08:23,960
쏟아부어 지능을 더 빠르고 더 좋게 만드는 것이 멋지고, 또

256
00:08:23,960 --> 00:08:25,240
우리 모두가 그 혜택을 볼 수 있으니, 그냥

257
00:08:25,240 --> 00:08:25,580
최선을 다하자는 것입니다.

258
00:08:26,020 --> 00:08:28,700
마치 Intel과

259
00:08:28,700 --> 00:08:31,240
AMD가 새 아키텍처를 내놓던 시기와 비슷합니다. 사람들은

260
00:08:31,240 --> 00:08:31,800
그냥

261
00:08:31,800 --> 00:08:33,380
갈아 끼울 수 있었지요, 맞습니까? 네, 최상위 수준에서는

262
00:08:33,380 --> 00:08:35,960
가치가 어디에

263
00:08:35,960 --> 00:08:36,660
쌓일지에 대한 불안이

264
00:08:36,800 --> 00:08:37,560
모델

265
00:08:37,560 --> 00:08:39,660
회사로 갈지, 아니면 애플리케이션 레이어, 즉

266
00:08:39,660 --> 00:08:40,900
스타트업으로 갈지 같은 문제는

267
00:08:40,900 --> 00:08:43,760
한 해 동안 양쪽으로

268
00:08:43,760 --> 00:08:45,200
조금씩 오르내리는 것처럼 느껴집니다. 예를 들어

269
00:08:45,200 --> 00:08:46,020
어떤 순간에는

270
00:08:46,020 --> 00:08:49,080
Claude Code가 정말 멋지게 출시되면서

271
00:08:49,080 --> 00:08:50,540
아, 그렇구나, 모델 회사들이

272
00:08:50,540 --> 00:08:50,700
실제로

273
00:08:50,700 --> 00:08:52,380
애플리케이션 레이어까지 가져가려는 것처럼 보이기도 합니다. 하지만

274
00:08:52,380 --> 00:08:53,760
적어도 제게는 결국 다 분위기(vibes)로

275
00:08:53,760 --> 00:08:54,420
결정되는 것 같습니다. 예를 들어

276
00:08:54,420 --> 00:08:56,400
특히 지난 몇 달간의 Gemini 급상승은

277
00:08:56,480 --> 00:08:57,900
우리를 다시

278
00:08:57,900 --> 00:08:58,460
그런 세계로

279
00:08:58,460 --> 00:09:00,800
되돌려 놓는 느낌입니다. 모델들은 본질적으로 모두

280
00:09:00,800 --> 00:09:02,800
서로를 상품화(커모디티화)하고 있고, 결국

281
00:09:03,520 --> 00:09:05,240
애플리케이션 레이어와 스타트업들이

282
00:09:05,240 --> 00:09:07,540
또 한 번 훌륭한 한 해를 보낼 준비가 되는 것처럼

283
00:09:07,540 --> 00:09:08,040
그런 흐름이 계속된다면 말입니다.

284
00:09:08,040 --> 00:09:10,840
Jared, 어떻게 생각하십니까? 특히

285
00:09:10,840 --> 00:09:15,700
부정적인 댓글들이 꽤 많은데,

286
00:09:15,700 --> 00:09:15,940
트위터에서요.

287
00:09:15,940 --> 00:09:17,560
이게 약간의 거품인지에 대한 이야기와 관련해

288
00:09:17,860 --> 00:09:22,020
AI 거품인지요? 네. 제가

289
00:09:22,020 --> 00:09:23,140
학부생들과 이야기하면, 이건

290
00:09:23,140 --> 00:09:25,080
제가 자주 받는 질문입니다. 예를 들면, 아,

291
00:09:25,220 --> 00:09:27,800
AI가 큰 거품이라고 들었는데

292
00:09:27,800 --> 00:09:29,180
왜냐하면

293
00:09:29,180 --> 00:09:31,320
NVIDIA와

294
00:09:31,320 --> 00:09:35,400
OpenAI 사이에서 미친 듯한 라운드트립이 일어나고, 이게 다 가짜 아닙니까?

295
00:09:35,600 --> 00:09:35,760
네.

296
00:09:35,760 --> 00:09:38,420
아니요, 이건 훌륭한 일입니다. 사람들이

297
00:09:38,420 --> 00:09:39,700
통신 버블을 보면

298
00:09:39,700 --> 00:09:39,880
그때는

299
00:09:39,920 --> 00:09:41,840
수십억 달러, 수백억 달러,

300
00:09:41,840 --> 00:09:43,400
심지어 수천억 달러가

301
00:09:43,400 --> 00:09:45,960
통신 인프라에

302
00:09:45,960 --> 00:09:48,620
90년대에 그냥 쌓여 있었습니다. 사실

303
00:09:48,680 --> 00:09:49,640
그게 YouTube가

304
00:09:49,640 --> 00:09:52,020
존재할 수 있었던 이유입니다, 맞습니까? 만약

305
00:09:52,020 --> 00:09:53,940
사용되지 않는 여분의 대역폭이 잔뜩 있고

306
00:09:53,940 --> 00:09:54,780
그리고

307
00:09:54,780 --> 00:09:56,680
그게 비교적 싸다면, 비용이 충분히 낮아져서

308
00:09:56,680 --> 00:09:58,660
YouTube 같은 서비스가 존재할 수 있습니다. 즉

309
00:09:58,660 --> 00:09:58,920
만약

310
00:09:58,920 --> 00:10:02,060
통신이 과잉 공급되지 않았다면, 아마

311
00:10:02,060 --> 00:10:03,300
유튜브는 결국 생겼겠지만 그저

312
00:10:03,300 --> 00:10:03,560
더 늦게

313
00:10:03,560 --> 00:10:05,560
일어났을 뿐입니다. 그리고 그게, 여기서 우리가 말하는 게

314
00:10:05,560 --> 00:10:07,560
바로 그런 것 아닙니까? 그러니까

315
00:10:07,560 --> 00:10:07,860
어떻게

316
00:10:07,980 --> 00:10:10,280
더 빠르게 가속해야 합니다, 맞습니까? 우리는

317
00:10:10,280 --> 00:10:12,120
지능의 시대에 살고 있고, 바위도 말하며,

318
00:10:12,120 --> 00:10:12,580
생각할 수 있고,

319
00:10:12,700 --> 00:10:13,880
일도 할 수 있는데, 여러분은 그냥

320
00:10:13,880 --> 00:10:16,100
더 많은 전력을 공급하면 되고, 그러면

321
00:10:16,100 --> 00:10:17,820
점점 더 똑똑한 것들이

322
00:10:17,820 --> 00:10:20,060
이 시점에서는 그렇습니다. 저는 대학생들에게 하는 주장이

323
00:10:20,060 --> 00:10:22,500
사실 이런 것입니다. 앞으로 과잉 공급이 생길 것이기 때문에

324
00:10:22,500 --> 00:10:22,880
과잉 공급 말입니다,

325
00:10:23,480 --> 00:10:25,460
여러분에게 기회가 생긴다는 것입니다. 그리고 만약

326
00:10:25,460 --> 00:10:27,780
과잉 공급이 없다면, 그러면

327
00:10:27,780 --> 00:10:28,160
그만큼

328
00:10:28,160 --> 00:10:31,900
경쟁이 많지 않을 것입니다. 가격은 더 높아지고, 마진은

329
00:10:31,900 --> 00:10:34,640
스택 하단에서 더 높아질 것입니다, 맞습니까?

330
00:10:35,020 --> 00:10:36,300
그리고, 아시다시피, 올해의 큰 이야기 중 하나가 무엇입니까?

331
00:10:36,300 --> 00:10:39,140
엔비디아가 갑자기 밀려나고 있다는 것입니다. 그러니까

332
00:10:39,140 --> 00:10:40,240
입지가 흔들리고 있는 것입니다. 그러니까

333
00:10:40,240 --> 00:10:41,940
오늘 주가가

334
00:10:41,940 --> 00:10:44,380
170달러대쯤인 것 같습니다. 아시다시피, 저는

335
00:10:44,380 --> 00:10:45,540
솔직히 여전히 장기적으로는

336
00:10:45,540 --> 00:10:47,780
매수 후 보유라고 생각합니다. 하지만 당장은,

337
00:10:48,000 --> 00:10:49,500
사람들이 말하기를, 아, 제미니가 너무

338
00:10:49,500 --> 00:10:49,960
좋다고 합니다.

339
00:10:49,960 --> 00:10:52,140
그리고, 아시다시피, 이제는 아무도

340
00:10:52,140 --> 00:10:55,260
엔비디아만 고집하지 않는 것 같고 모두가 AMD를

341
00:10:55,260 --> 00:10:56,040
사고 있고, 모두가,

342
00:10:56,180 --> 00:10:59,160
아시다시피, TPU도 잘 돌아갑니다. 그래서,

343
00:10:59,160 --> 00:11:01,200
아시다시피, 지금은 마치

344
00:11:01,360 --> 00:11:01,580
그러니까,

345
00:11:01,700 --> 00:11:04,680
그게 무슨 뜻입니까? 경쟁이 있다는 뜻이고

346
00:11:04,680 --> 00:11:07,920
연산 자원이 더 많아진다는 뜻입니다,

347
00:11:08,080 --> 00:11:11,200
줄어드는 것이 아니라요. 그리고 그러면 아마

348
00:11:11,200 --> 00:11:13,880
모든

349
00:11:13,880 --> 00:11:14,900
대형 LLM

350
00:11:14,900 --> 00:11:16,800
기업들, 그러니까, 아시다시피,

351
00:11:16,800 --> 00:11:19,180
AI 랩들이 조금

352
00:11:19,180 --> 00:11:19,900
힘을 얻게 되겠지만,

353
00:11:20,020 --> 00:11:22,440
아시다시피, 그들 또한 서로 경쟁하고 있습니다.

354
00:11:22,440 --> 00:11:24,200
그렇다면 그게 무슨 뜻입니까?

355
00:11:24,320 --> 00:11:24,380
그러면,

356
00:11:24,460 --> 00:11:26,260
그러면, 아시다시피, 한 단계 위로 올라가야 합니다

357
00:11:26,260 --> 00:11:28,200
이 스택에서요, 맞습니까? 즉,

358
00:11:28,200 --> 00:11:29,240
아주 많은

359
00:11:29,700 --> 00:11:32,160
AI 랩들이 치열하게 경쟁

360
00:11:32,160 --> 00:11:35,680
하고 있다면, 그러면 그것은 오히려 더 좋습니다,

361
00:11:35,680 --> 00:11:36,640
그 대학

362
00:11:36,640 --> 00:11:38,820
학생에게요. 즉, 애플리케이션 레이어에서 회사를 시작하려는

363
00:11:38,820 --> 00:11:41,160
학생에게요. 네, 저는 그게 정확히

364
00:11:41,160 --> 00:11:41,400
맞다고 생각합니다.

365
00:11:41,400 --> 00:11:43,560
사람들이 이런 질문을 합니다. 즉,

366
00:11:43,700 --> 00:11:45,840
"거품입니까?"라는 질문은 어쩌면

367
00:11:45,840 --> 00:11:46,060
정말

368
00:11:46,060 --> 00:11:47,580
적절한 질문입니다. 예컨대

369
00:11:47,580 --> 00:11:49,860
Comcast 같은 존재이거나 엔비디아라면, 그건

370
00:11:49,860 --> 00:11:50,020
매우

371
00:11:50,020 --> 00:11:52,320
중요한 질문입니다. 예를 들어 사람들이 GPU 용량을 과잉 구축하고 있습니까?

372
00:11:52,320 --> 00:11:54,660
하지만 대학생들은

373
00:11:54,660 --> 00:11:57,100
Comcast가 아닙니다. 사실 유튜브에 가깝습니다. 만약

374
00:11:57,100 --> 00:11:58,480
기숙사 방에서 스타트업을 한다면, 그것은

375
00:11:58,480 --> 00:11:58,580
마치

376
00:11:58,580 --> 00:12:00,220
AI에서 유튜브 같은 것에 해당하는 것이 있다고 하더라도

377
00:12:00,220 --> 00:12:02,380
사실 그리 중요하지 않습니다. 어쩌면

378
00:12:02,380 --> 00:12:02,800
엔비디아의

379
00:12:02,800 --> 00:12:04,700
주가가 내년에 내려갈 것이라는 얘기가 나올 수도 있습니다. 저는

380
00:12:04,700 --> 00:12:07,060
잘 모르겠습니다. 하지만 설령 그렇더라도 그것이

381
00:12:07,060 --> 00:12:07,800
곧바로

382
00:12:07,800 --> 00:12:08,900
AI 스타트업을

383
00:12:08,900 --> 00:12:10,540
하는 데 나쁜 시기라는 뜻은 아닙니다. 네, 이는

384
00:12:10,540 --> 00:12:11,220
저커버그가

385
00:12:11,220 --> 00:12:12,720
올해 초 팟캐스트에서 말한 내용과 비슷합니다, 맞지요? 요지는

386
00:12:12,720 --> 00:12:15,420
메타가 결국

387
00:12:15,420 --> 00:12:16,000
상당한

388
00:12:16,000 --> 00:12:19,620
규모로 CAPEX와 인프라에 과잉 투자하게 될 수도 있지만,

389
00:12:19,620 --> 00:12:21,360
본질적으로는 그럴 수밖에 있고, 대기업들은

390
00:12:21,360 --> 00:12:22,720
그렇게 해야 합니다. 그냥

391
00:12:22,720 --> 00:12:24,860
옆에서 지켜보고만 있을 수는 없습니다. 그리고 만약

392
00:12:24,860 --> 00:12:27,200
수요가

393
00:12:27,200 --> 00:12:29,300
어떤 이유로든 급락한다면, 그것은 그들의

394
00:12:29,300 --> 00:12:31,380
CAPEX이지 스타트업의 CAPEX가 아닙니다. 그리고 여전히

395
00:12:31,380 --> 00:12:31,780
앞으로도

396
00:12:31,780 --> 00:12:34,120
계속 만들어 갈 인프라와 아이디어가 아주 많이

397
00:12:34,120 --> 00:12:36,820
남아 있을 것입니다. 카를로타 페레즈라는

398
00:12:36,820 --> 00:12:40,380
경제학자가 쓴 책이 있는데, 그분은 많은

399
00:12:40,380 --> 00:12:43,140
기술 트렌드를 연구했고, 또 많은

400
00:12:43,140 --> 00:12:43,340
기술

401
00:12:44,220 --> 00:12:47,200
혁명도 연구했습니다. 그리고 실제로는 두 단계가 있다고

402
00:12:47,200 --> 00:12:49,840
요약합니다. 첫 번째는

403
00:12:49,840 --> 00:12:52,100
설치 단계인데, 여기서 많은

404
00:12:52,100 --> 00:12:56,180
막대한 CAPEX 투자가 들어옵니다. 그리고 다음은

405
00:12:56,180 --> 00:12:56,580
바로

406
00:12:56,580 --> 00:13:00,520
전개 단계인데, 실제로 파급이 일어나고 본격적으로 확산되며,

407
00:13:00,600 --> 00:13:03,000
풍요로움의 측면에서 모든 것이 폭발합니다.

408
00:13:03,000 --> 00:13:06,840
그리고 설치 단계의 초기에는

409
00:13:06,840 --> 00:13:08,340
거품처럼 느껴집니다. 약간의

410
00:13:08,340 --> 00:13:08,580
광풍이

411
00:13:08,580 --> 00:13:10,540
있는데, 처음에는 이런 식으로 시작합니다. 즉,

412
00:13:10,540 --> 00:13:13,040
정말 놀라운 새로운 기술이 등장하고, 이것이

413
00:13:13,040 --> 00:13:16,080
2023년의 ChatGPT 순간에서 일어났습니다. 모두가

414
00:13:16,080 --> 00:13:18,420
그 기술에 매우 흥분했고, 그러고 나서 모두가

415
00:13:18,420 --> 00:13:18,640
더

416
00:13:18,640 --> 00:13:21,800
더욱 고무되어

417
00:13:21,800 --> 00:13:23,440
인프라에 많이 투자하기 시작했고, 많은

418
00:13:23,440 --> 00:13:24,240
GPU를

419
00:13:24,240 --> 00:13:27,040
사들이며 거대한 기가와트급 데이터센터를 구축했습니다.

420
00:13:27,160 --> 00:13:28,680
그러고 나서 사람들은 묻습니다. 그러면 도대체

421
00:13:28,680 --> 00:13:29,340
수요는 무엇입니까? 어떤

422
00:13:29,340 --> 00:13:30,760
애플리케이션들이

423
00:13:30,760 --> 00:13:32,300
만들어질 것입니까? 저는 지금 우리가

424
00:13:32,300 --> 00:13:32,860
그 전환기에 있다고

425
00:13:32,880 --> 00:13:36,140
생각합니다. 그리고 이것은 사실 스타트업

426
00:13:36,140 --> 00:13:38,980
창업자들에게 매우 좋은 소식인데, 그들은

427
00:13:38,980 --> 00:13:41,280
데이터센터를 짓는 일에는 관여하지 않고,

428
00:13:41,280 --> 00:13:44,600
대신 다음 세대 애플리케이션을

429
00:13:44,600 --> 00:13:48,180
정말로 확산되는 전개 단계에서 만들 것이기 때문입니다. 그리고

430
00:13:48,180 --> 00:13:50,320
인터넷 시대에 대한 비유로 돌아가 보면,

431
00:13:50,320 --> 00:13:53,800
인터넷 시대를 보자면, 2000년 이전에는

432
00:13:53,800 --> 00:13:55,660
막대한 CAPEX

433
00:13:55,660 --> 00:13:56,740
투자가

434
00:13:56,740 --> 00:14:00,480
통신사들에 들어갔습니다. 그런 것들은

435
00:14:00,480 --> 00:14:02,800
대학생들이 관여할 만한

436
00:14:03,000 --> 00:14:05,660
프로젝트가 아니었지만, 매우 크게 투자되었습니다. 그리고

437
00:14:05,660 --> 00:14:07,740
어떤 경우에는 과잉투자이기도 했습니다. 예를 들면,

438
00:14:07,820 --> 00:14:09,660
다크 파이버 같은 것과

439
00:14:09,660 --> 00:14:11,760
사용되지 않는 일부 회선들이 있었는데, 그것은

440
00:14:11,760 --> 00:14:12,020
괜찮습니다.

441
00:14:12,260 --> 00:14:15,280
인터넷은 결국 여전히 거대한

442
00:14:15,280 --> 00:14:18,720
경제적 동력이 되었습니다. 그리고 그것이 의미하는 바는

443
00:14:18,720 --> 00:14:19,340
바로

444
00:14:19,340 --> 00:14:21,400
미래의 페이스북이나 미래의 구글 같은

445
00:14:21,400 --> 00:14:23,160
스타트업들이 아직 시작되지 않았다는 것이며, 그런 것들은

446
00:14:23,160 --> 00:14:23,780
전개

447
00:14:23,780 --> 00:14:26,440
단계에서 등장하기 때문입니다. 왜냐하면 지금은 저는

448
00:14:26,440 --> 00:14:28,440
여전히 여러 것들이 구축되고 있다고 생각합니다. 그리고

449
00:14:28,440 --> 00:14:29,100
파운데이션 모델

450
00:14:29,100 --> 00:14:31,820
기업들과 GPU는 분명히

451
00:14:31,820 --> 00:14:33,060
인프라 범주에 들어간다고 생각합니다.

452
00:14:33,500 --> 00:14:35,460
네. 그러니까, 이런 것들이 어떻게

453
00:14:35,460 --> 00:14:37,160
조금씩 진화하는지 지켜보는 것이 흥미롭습니다. 그래서

454
00:14:37,160 --> 00:14:37,540
기억하십니까,

455
00:14:37,540 --> 00:14:40,340
24년 여름에 스타클라우드라는 회사가

456
00:14:40,340 --> 00:14:42,440
등장했고, 그중에서도

457
00:14:42,440 --> 00:14:43,300
가장 먼저

458
00:14:43,300 --> 00:14:45,840
우리는 우주에 데이터센터를 만들겠다고

459
00:14:45,840 --> 00:14:48,560
말했습니다. 그리고 그때 반응이 어땠습니까, 그러니까

460
00:14:48,560 --> 00:14:48,660
아시다시피,

461
00:14:48,660 --> 00:14:50,980
사람들이 인터넷에서 그들을 비웃었죠. 네.

462
00:14:51,380 --> 00:14:52,800
그들은 "역대 가장 멍청한 아이디어"라고 말했습니다.

463
00:14:53,160 --> 00:14:55,760
그런데 18개월 뒤인 지금은 갑자기

464
00:14:55,760 --> 00:14:57,900
구글도 하고 있고, 일론도 하고 있습니다.

465
00:14:57,900 --> 00:14:59,460
그래서 이제는 모든 인터뷰에서 그것을 언급한다고

466
00:14:59,460 --> 00:15:00,040
합니다, 지금은.

467
00:15:00,220 --> 00:15:00,460
정말 그런가요?

468
00:15:00,520 --> 00:15:02,160
그분의 가장 중요한

469
00:15:02,160 --> 00:15:02,400
이야깃거리인 것 같습니다.

470
00:15:02,620 --> 00:15:04,500
네. 그런데, 그러면 왜 그런 것입니까?

471
00:15:04,700 --> 00:15:06,180
제 생각에 그 이유 중 하나는

472
00:15:06,180 --> 00:15:06,860
그러니까,

473
00:15:07,360 --> 00:15:10,200
지금 진행되는 인프라 확장의 한 부분이

474
00:15:10,200 --> 00:15:12,880
너무 격렬한 이유가, 저희가 말 그대로

475
00:15:12,880 --> 00:15:13,300
전혀

476
00:15:13,860 --> 00:15:17,620
전력 생산 능력이 없기 때문입니다. Boom Supersonic은 지금 초음속

477
00:15:17,620 --> 00:15:18,400
제트기를 만드는 대신,

478
00:15:18,600 --> 00:15:21,220
이 많은 AI 데이터

479
00:15:21,220 --> 00:15:24,260
센터들에 필요한 충분한

480
00:15:24,260 --> 00:15:25,060
전력을 만들기 위한

481
00:15:25,060 --> 00:15:28,140
프로젝트를 진행하고 있습니다. 그들은 제트 엔진을 씁니다. 그리고

482
00:15:28,140 --> 00:15:30,240
그마저도 상황이 매우 좋지 않은데,

483
00:15:30,280 --> 00:15:30,880
공급망이

484
00:15:30,880 --> 00:15:32,880
데이터센터 전력 생산용 제트 엔진에 대한

485
00:15:32,880 --> 00:15:35,100
수요로 너무 밀려 있어서,

486
00:15:35,220 --> 00:15:35,840
이것들을 확보하려면

487
00:15:35,840 --> 00:15:38,040
사실 2년

488
00:15:38,040 --> 00:15:40,420
또는 3년 전에 주문했어야 하고,

489
00:15:40,420 --> 00:15:41,660
그래야 2년이나 3년

490
00:15:41,660 --> 00:15:45,180
뒤에나 받을 수 있습니다. 이런 제약들이

491
00:15:45,420 --> 00:15:48,640
결국 꽤 직접적으로 영향을 미쳐서

492
00:15:48,640 --> 00:15:51,800
거대 기술 기업들이 무엇을 해야 하는지,

493
00:15:51,800 --> 00:15:53,520
3년이나 5년

494
00:15:53,520 --> 00:15:53,920
뒤에 게임에서 이기기 위해서입니다.

495
00:15:54,700 --> 00:15:57,940
갑자기 땅이 충분하지 않게 됩니다, 아시겠지만,

496
00:15:58,020 --> 00:16:00,380
미국에서는 짓지를 못합니다. 규제가

497
00:16:00,380 --> 00:16:00,520
너무

498
00:16:00,520 --> 00:16:02,860
강합니다. 캘리포니아에는 CEQA가 있는데, 그건

499
00:16:02,860 --> 00:16:06,140
환경 로비가 완전히 악용해서

500
00:16:06,140 --> 00:16:06,460
모든

501
00:16:06,460 --> 00:16:09,880
혁신과 주택 건설을 막는 데 씁니다. 그리고 저희는

502
00:16:09,880 --> 00:16:13,640
지상에서 그냥

503
00:16:13,640 --> 00:16:15,820
사회가 필요로 하는 일들을

504
00:16:15,820 --> 00:16:18,160
지금 당장 할 만큼의 여력이 없습니다. 그래서, 탈출구는

505
00:16:18,160 --> 00:16:18,520
그러니까,

506
00:16:18,660 --> 00:16:20,840
사실 우주에서 그냥 해버리자는 겁니다. 네.

507
00:16:20,900 --> 00:16:22,000
생각해보니, 저희가

508
00:16:22,000 --> 00:16:22,120
거의

509
00:16:22,120 --> 00:16:24,220
데이터 센터 확장 문제를 해결하는 YC 회사 삼총사를

510
00:16:24,220 --> 00:16:26,320
갖고 있는 셈이네요. 음, 필요한 건

511
00:16:26,320 --> 00:16:26,580
핵융합

512
00:16:26,580 --> 00:16:29,640
에너지죠. 네, 네. 그리고 저희에겐 그 회사가 있습니다,

513
00:16:29,640 --> 00:16:32,620
땅이 없는 문제를 해결하려고

514
00:16:32,620 --> 00:16:34,920
데이터 센터를 우주에 짓는 회사요. 또 Boom

515
00:16:34,920 --> 00:16:36,940
과 Helium이 있는데, 저희가

516
00:16:36,940 --> 00:16:37,560
에너지

517
00:16:37,560 --> 00:16:40,160
문제가 없도록 해결하고 있죠. 오늘은, 음, 우주

518
00:16:40,160 --> 00:16:43,240
핵융합 회사 하나를 찾았는데, 막 졸업한 Zephyr Fusion입니다.

519
00:16:43,460 --> 00:16:44,900
멋진 회사죠. 그리고 그들은 실제로

520
00:16:44,900 --> 00:16:46,600
데모데이 이후에 훌륭한 시드 라운드를 했습니다.

521
00:16:46,780 --> 00:16:47,640
그분들은 40대이고,

522
00:16:47,680 --> 00:16:51,140
국립 연구소 엔지니어들로서 커리어 내내

523
00:16:51,140 --> 00:16:53,620
아시겠지만 토카막 같은 것과

524
00:16:53,620 --> 00:16:56,580
핵융합 에너지를 만들던 분들입니다. 어느 날 연구소에 들어와서

525
00:16:56,580 --> 00:16:58,960
그들이 물리를 보고,

526
00:16:59,100 --> 00:17:00,120
그러니까,

527
00:17:00,120 --> 00:17:03,020
수학과 모델을 들여다보고는, 이렇게 말했죠,

528
00:17:03,020 --> 00:17:05,040
있잖아요, 이걸 우주에서 하면

529
00:17:05,340 --> 00:17:06,700
실제로 타산이 맞을 겁니다.

530
00:17:07,040 --> 00:17:08,660
그래서 그들은 일종의

531
00:17:08,660 --> 00:17:11,500
앞으로 5년, 10년짜리 거대한 퀘스트를 하고 있는데,

532
00:17:11,500 --> 00:17:13,220
그걸 실제로 구현해서,

533
00:17:13,300 --> 00:17:15,980
우주에서 진짜로 만들어내려는 겁니다, 음, 왜냐하면

534
00:17:15,980 --> 00:17:18,980
방정식이 가능하다고 말하거든요. 그리고,

535
00:17:18,980 --> 00:17:19,100
음,

536
00:17:19,180 --> 00:17:20,560
그걸 해낸다면, 그게 사실상 유일한

537
00:17:20,560 --> 00:17:23,280
기가와트급 에너지를 얻는 경로가 됩니다, 음, 저 위

538
00:17:23,280 --> 00:17:24,560
우주에서요. 그래서,

539
00:17:24,700 --> 00:17:26,300
아시겠지만, 그게 어쩌면

540
00:17:26,300 --> 00:17:28,500
곧 더 완벽한 삼총사가 될 수도 있겠네요, 음.

541
00:17:28,500 --> 00:17:30,280
네. 제가 보기엔 올해 동안 또 하나 일어난 일이 있었습니다.

542
00:17:30,280 --> 00:17:32,300
올해 한 해 동안의 흐름 중 하나가, 음,

543
00:17:32,660 --> 00:17:35,740
모델 회사를 시작하려는 관심이 커진 것 같습니다. 그러니까, 제 생각에는

544
00:17:35,740 --> 00:17:37,200
어쩌면 양쪽 끝 모두에 그런 흐름이 있는 것 같습니다만,

545
00:17:37,200 --> 00:17:39,180
자본을 조달할 수 있는 사람들은

546
00:17:39,180 --> 00:17:41,040
나가서 실제로 정면 경쟁자를

547
00:17:41,040 --> 00:17:41,800
만들어 보려고 시도해서

548
00:17:41,800 --> 00:17:43,240
OpenAI와 겨루려 하지만, 그런 사례는 정말, 정말 드뭅니다.

549
00:17:43,320 --> 00:17:46,040
예를 들면 SSI의 ILIO 같은 경우가 있을지 모르지만, 그보다는

550
00:17:46,040 --> 00:17:47,360
YC 내부에서는 오히려

551
00:17:47,680 --> 00:17:49,800
더 작은 모델을 만들려는 사람들이 더 많습니다. 음,

552
00:17:50,060 --> 00:17:51,360
저도 확실히 그런 팀을

553
00:17:51,360 --> 00:17:51,740
최근 몇

554
00:17:51,740 --> 00:17:53,720
배치에서 예전보다 더 많이 봤습니다. 예를 들면

555
00:17:53,720 --> 00:17:55,800
엣지 디바이스에서 구동되는 모델이거나

556
00:17:55,800 --> 00:17:56,460
아니면 음성

557
00:17:56,460 --> 00:17:59,520
특정 언어에 특화된 모델 같은 것들입니다. 그리고 저는

558
00:17:59,520 --> 00:18:01,640
그런 추세가 계속될지 궁금합니다, 다시

559
00:18:01,640 --> 00:18:01,860
되돌아가

560
00:18:01,860 --> 00:18:04,140
YC의 초기 시대로 보면, 사실 우리는

561
00:18:04,140 --> 00:18:06,040
스타트업이 만들어지는 폭발을

562
00:18:06,040 --> 00:18:06,700
어느 정도 목격했습니다.

563
00:18:06,700 --> 00:18:10,280
그리고 아마 특히 SaaS 스타트업이 그랬습니다. 부분적으로는, 뭐,

564
00:18:10,400 --> 00:18:13,080
음, 그걸 뒷받침한 것은 스타트업에 대한 지식이

565
00:18:13,080 --> 00:18:15,500
더 널리 퍼졌기 때문입니다. 인터넷에는 정전 같은

566
00:18:15,500 --> 00:18:17,520
자료가 거의 없었습니다. 예를 들면

567
00:18:17,520 --> 00:18:18,900
어떻게 스타트업을 시작하는지, 어떻게

568
00:18:18,900 --> 00:18:21,320
소프트웨어를 만드는지요. 그리고 약 10년에 걸쳐 그것이

569
00:18:21,320 --> 00:18:21,920
점점 더

570
00:18:21,920 --> 00:18:25,640
보편화되면서, 사회의 지식이 폭발적으로 늘었습니다.

571
00:18:25,640 --> 00:18:27,100
스타트업과 무언가를 만드는 방법에 대해서요.

572
00:18:27,440 --> 00:18:29,540
그리고 어쩌면 지금은 우리가

573
00:18:29,540 --> 00:18:31,300
AI 분야에서 그런 순간을

574
00:18:31,300 --> 00:18:32,580
연구가

575
00:18:32,580 --> 00:18:35,680
모델을 학습시키며 실제로 무언가를 만드는 일과, 그 지점에서

576
00:18:35,680 --> 00:18:37,160
만나는 과정을 확실히

577
00:18:37,160 --> 00:18:39,080
지금 겪고 있다고 생각합니다. 네. 그러니까 그게

578
00:18:39,080 --> 00:18:41,340
아주 희귀한 기술 조합에서

579
00:18:41,340 --> 00:18:42,220
더 흔한 기술 조합으로

580
00:18:42,220 --> 00:18:44,320
바뀌고 있기 때문입니다. 예를 들어 10년 전의 OpenAI는,

581
00:18:44,500 --> 00:18:45,760
정말 드문 경우였고, 그러니까 필요했던 것이,

582
00:18:45,900 --> 00:18:46,700
그러니까 그런,

583
00:18:46,700 --> 00:18:49,400
독특한 기술 조합이 필요했지요. 연구자적 사고도 필요하고

584
00:18:49,400 --> 00:18:50,800
연구자적 머리도 필요하고,

585
00:18:50,800 --> 00:18:53,340
일종의 엔지니어링 감각도 필요하고, 어쩌면

586
00:18:53,340 --> 00:18:55,560
재무나 비즈니스 감각도 필요했습니다.

587
00:18:55,880 --> 00:18:57,960
잠깐, 잠깐, 잠깐요. 그러면 방금

588
00:18:57,960 --> 00:19:00,580
일리야, 그렉, 그리고 샘을 묘사하신 건가요?

589
00:19:00,640 --> 00:19:01,060
맞습니다.

590
00:19:03,100 --> 00:19:04,960
그런 팀은 정말 희귀했지요. 그때는

591
00:19:04,960 --> 00:19:07,080
그런 팀 구성이 주변에 그리

592
00:19:07,080 --> 00:19:07,940
많지 않았습니다. 그런데 이제

593
00:19:07,940 --> 00:19:11,820
10년이 지난 지금은, 그런 배경을 가진 사람들이 아주 많습니다.

594
00:19:11,820 --> 00:19:14,260
연구 배경을 가진 사람들도 많고,

595
00:19:14,480 --> 00:19:17,940
엔지니어링 배경도 있고, 음, 스타트업 자본 조달

596
00:19:17,940 --> 00:19:19,660
음, 경험도 있거나, 적어도 그런 것들을

597
00:19:19,660 --> 00:19:20,600
하는 법을 배울 수 있습니다. 그리고 저는 그게 그냥

598
00:19:20,600 --> 00:19:22,700
그런 것들 전부를 하려면 필요한데, 그리고 저는 그것이 단지

599
00:19:22,700 --> 00:19:23,820
더 많이 보게 된다는 뜻인지 궁금합니다.

600
00:19:24,960 --> 00:19:28,180
적용형 AI 회사를 더 많이 시작하게 되는 것인지, 그리고 어쩌면

601
00:19:28,180 --> 00:19:30,440
다양한 특정 과업을 위해 선택할 수 있는 모델도 더 많아질지요.

602
00:19:30,440 --> 00:19:30,540
모든

603
00:19:30,540 --> 00:19:32,560
여러 특정 과업에서요. 저도 그렇게 생각합니다. 또

604
00:19:32,560 --> 00:19:34,880
하나 더 기여하면서 이것을 더

605
00:19:34,880 --> 00:19:35,480
큰 눈덩이로

606
00:19:35,480 --> 00:19:39,260
만드는 이유는 바로

607
00:19:39,260 --> 00:19:41,620
RL 때문입니다. 새로운 오픈

608
00:19:41,620 --> 00:19:43,120
소스 모델들이 있고,

609
00:19:43,120 --> 00:19:46,060
사람들이 그 위에 파인튜닝을

610
00:19:46,060 --> 00:19:48,980
특정 RL 환경과

611
00:19:48,980 --> 00:19:51,060
과업에 맞춰서 하고 있으니, 그러므로 충분히

612
00:19:51,060 --> 00:19:55,280
가능합니다, 최고의 도메인

613
00:19:55,280 --> 00:19:59,220
특화, 이를테면 헬스케어 모델을, 어떤

614
00:19:59,220 --> 00:20:02,020
그냥 무난하게만 해도 범용 오픈소스 모델은

615
00:20:02,020 --> 00:20:04,960
거기에 파인튜닝과 RL을 하면, 그것이

616
00:20:04,960 --> 00:20:06,260
일반적인 대형 모델을 이깁니다.

617
00:20:06,260 --> 00:20:08,380
사실 저는 여러 사례를 듣고 직접 본 적도 있는데,

618
00:20:08,380 --> 00:20:11,900
도메인 특화 모델이, 어, 이기는 스타트업들이

619
00:20:12,300 --> 00:20:12,500
오픈

620
00:20:12,500 --> 00:20:14,540
AI를 예컨대 헬스케어 분야에서 이깁니다. 특히 어떤

621
00:20:14,540 --> 00:20:16,740
YC 스타트업이 저에게, 그들이 모은 것이

622
00:20:16,740 --> 00:20:17,180
최고의

623
00:20:17,180 --> 00:20:20,520
헬스케어용 데이터셋이었고, 결국

624
00:20:20,520 --> 00:20:22,620
OpenAI보다 더 나은 성능을 보였으며

625
00:20:22,620 --> 00:20:22,840
여러

626
00:20:22,840 --> 00:20:25,580
헬스케어 벤치마크에서도 파라미터가 80억 개뿐인데도

627
00:20:25,580 --> 00:20:27,620
그랬다고 했습니다. 재미있는 점은, 어, 결국

628
00:20:27,620 --> 00:20:27,920
필요한 것이

629
00:20:27,920 --> 00:20:30,360
사후 학습 인프라라는 점입니다. 아시다시피,

630
00:20:30,400 --> 00:20:32,940
저희도 YC 회사들 중에, 어, 그들이

631
00:20:32,940 --> 00:20:33,560
어떤 것으로

632
00:20:33,560 --> 00:20:36,060
OpenAI, 그러니까 GPT-3

633
00:20:36,060 --> 00:20:38,500
.5를 이겼고 RL로 파인튜닝을 하고 있었던

634
00:20:38,500 --> 00:20:42,360
경우가 있었습니다. 그런데, 어, 네, GPT-4.5가

635
00:20:42,360 --> 00:20:42,600
그리고

636
00:20:42,600 --> 00:20:45,920
그다음 5.1이 나오면서, 어, 그들의

637
00:20:45,920 --> 00:20:48,000
파인튜닝이 사실상 완전히

638
00:20:48,000 --> 00:20:49,240
무력화되었습니다. 계속

639
00:20:49,240 --> 00:20:51,160
해 나가야 합니다. 네. 네. 계속해야 합니다. 네.

640
00:20:51,240 --> 00:20:53,260
그러니까 실제로는 계속해서

641
00:20:53,260 --> 00:20:54,560
어, 최전선까지

642
00:20:54,560 --> 00:20:57,260
도달해야 합니다. 또 다른 것으로, 어, 지난 1년 동안

643
00:20:57,260 --> 00:21:00,060
정말 두드러졌던 것이

644
00:21:00,060 --> 00:21:00,500
떠오르시나요?

645
00:21:00,500 --> 00:21:02,640
어, 재미있습니다. 저희는 한 해를

646
00:21:02,640 --> 00:21:04,640
조회수가 많이 나온 에피소드 중 하나로

647
00:21:04,640 --> 00:21:05,460
바로

648
00:21:05,460 --> 00:21:07,760
바이브 코딩을 다뤘습니다. 당시에는

649
00:21:07,760 --> 00:21:10,060
발생하던 행동을 관찰하는 정도로

650
00:21:10,060 --> 00:21:10,400
이야기하고

651
00:21:10,400 --> 00:21:13,560
있었습니다. 그런데 저는

652
00:21:13,560 --> 00:21:16,220
이것이 거대한 카테고리가 된 것을 보고 놀랐습니다.

653
00:21:16,400 --> 00:21:16,560
그리고

654
00:21:16,560 --> 00:21:19,460
이기고 있는 회사가 정말 많습니다. 예를 들어,

655
00:21:19,540 --> 00:21:22,600
Replit도 있고 Emergence도 있고, 그 외에도

656
00:21:22,600 --> 00:21:22,900
여러 곳이 있습니다.

657
00:21:22,900 --> 00:21:25,540
Varun Mohan은 Google로 갔고,

658
00:21:25,540 --> 00:21:28,340
anti-gravity를 공개했습니다. 그리고, 어, 여러분은

659
00:21:28,340 --> 00:21:28,960
그 영상을 보셨나요?

660
00:21:29,200 --> 00:21:30,640
저는 사실 그들이

661
00:21:30,640 --> 00:21:33,300
nano banana나 이런

662
00:21:33,300 --> 00:21:33,860
영상

663
00:21:33,860 --> 00:21:36,160
생성 도구를 실제로 썼는지 궁금합니다. 약간 너무

664
00:21:36,160 --> 00:21:38,180
완벽해 보이는데, Google은

665
00:21:38,180 --> 00:21:38,640
높은 수준의

666
00:21:38,640 --> 00:21:41,380
제작비 영상을 만들 예산이 있습니다. 그런데 영상에는 Varun이

667
00:21:41,380 --> 00:21:43,460
키보드 앞에 있고, 또

668
00:21:43,940 --> 00:21:46,120
Sergey가 바로 뒤에 서 있는 듯합니다. 그래서

669
00:21:46,120 --> 00:21:48,120
매우 시네마틱하다고 느꼈습니다. 어쨌든 저는

670
00:21:48,120 --> 00:21:49,280
Sundar도, 어,

671
00:21:49,280 --> 00:21:51,800
아시다시피, 음, 우주 데이터 센터뿐 아니라

672
00:21:52,600 --> 00:21:55,680
그것에 대해서 이야기했을 뿐만 아니라, 또한

673
00:21:55,680 --> 00:21:56,180
바이브

674
00:21:56,180 --> 00:21:58,280
코딩에 대해서도 말하고 있었다고 봅니다. 그리고 저는 제가

675
00:21:58,280 --> 00:22:00,980
약간 되받아치는 농담을 하고 있다는 것을 알지만, 우리가

676
00:22:00,980 --> 00:22:02,600
아는 바를 생각하면, 그러니까 네, 바이브

677
00:22:02,600 --> 00:22:06,620
코딩은 완전히 사용할 수 있고

678
00:22:06,620 --> 00:22:09,700
신뢰할 수 있는 것이, 어, 100%는 아닙니다.

679
00:22:09,700 --> 00:22:10,380
여러분의

680
00:22:10,380 --> 00:22:13,520
코딩 기간 전체에 대해서 말입니다. 그러니까, 아시다시피,

681
00:22:13,520 --> 00:22:16,560
바로 출시할 수 있다는 말이

682
00:22:16,560 --> 00:22:17,780
100%, 그러니까 100%로

683
00:22:17,780 --> 00:22:21,600
완전히 견고한 프로덕션 코드를 오늘 당장, 2020년 기준으로도

684
00:22:21,600 --> 00:22:22,540
2025년 말 기준으로도 가능하다는 것은 사실이 아닙니다.

685
00:22:23,120 --> 00:22:24,580
네. 저는 2025년에 저를 놀라게 했던 것들을

686
00:22:24,580 --> 00:22:26,960
생각해 보고 있었습니다. 그리고 아마도

687
00:22:26,960 --> 00:22:27,440
가장

688
00:22:27,440 --> 00:22:29,680
놀라웠던 것은 제가

689
00:22:29,680 --> 00:22:32,480
AI 경제가 안정화되었다고 느끼는 정도입니다. 그러니까

690
00:22:32,480 --> 00:22:33,120
저는 우리가

691
00:22:33,120 --> 00:22:35,300
2024년 말에 이 에피소드를 했을 때는

692
00:22:35,300 --> 00:22:36,600
여전히 한가운데에

693
00:22:36,600 --> 00:22:37,520
믿을 수 없을 만큼

694
00:22:37,520 --> 00:22:39,060
급격한 변화의 시기였고, 발밑이

695
00:22:39,060 --> 00:22:41,300
흔들리는 듯했으며, 누구도

696
00:22:41,300 --> 00:22:41,660
다음 충격이

697
00:22:41,660 --> 00:22:43,640
언제 올지, 그리고 정확히 무엇이

698
00:22:43,640 --> 00:22:45,140
스타트업과 AI, 그리고

699
00:22:45,140 --> 00:22:46,140
경제에 어떤 영향을 줄지 몰랐습니다. 지금은 저는

700
00:22:46,140 --> 00:22:48,240
우리가 비교적

701
00:22:48,240 --> 00:22:50,380
안정적인 AI 경제로 어느 정도 자리 잡았다고 느끼며,

702
00:22:50,380 --> 00:22:50,760
모델 레이어

703
00:22:50,760 --> 00:22:52,980
회사들과 애플리케이션 레이어 회사들이 있고,

704
00:22:53,140 --> 00:22:54,420
인프라스트럭처 레이어 회사들도 있으며,

705
00:22:54,580 --> 00:22:55,600
모두가

706
00:22:55,600 --> 00:22:57,540
많은 돈을 벌게 될 것 같고, 어느 정도

707
00:22:57,540 --> 00:22:58,860
상대적으로 표준적인 플레이북이

708
00:22:58,860 --> 00:23:00,540
AI 네이티브 회사를

709
00:23:00,540 --> 00:23:02,100
모델 위에서 어떻게 만들지에 대해 생긴 것 같습니다. 저는

710
00:23:02,100 --> 00:23:03,440
여러 면에서 정말로 성숙해졌다고

711
00:23:03,440 --> 00:23:05,080
느낍니다. 이는 결국

712
00:23:05,080 --> 00:23:07,560
모델 자체가 올해 점진적으로

713
00:23:07,560 --> 00:23:09,740
개선되기는 했지만,

714
00:23:09,740 --> 00:23:12,040
모든 것을 뒤흔들 만한 큰 도약은 없었다는 점에서

715
00:23:12,040 --> 00:23:13,820
비롯된 것 같습니다. 그 결과로, 몇

716
00:23:13,820 --> 00:23:15,420
에피소드 전에는

717
00:23:15,420 --> 00:23:16,600
그 어느 때보다도

718
00:23:16,600 --> 00:23:18,280
피벗하고 스타트업 아이디어를 찾기가 쉬웠다고 이야기했습니다.

719
00:23:18,480 --> 00:23:20,300
왜냐하면 버티기만 하면,

720
00:23:20,300 --> 00:23:20,980
몇

721
00:23:20,980 --> 00:23:22,520
달만 기다려도 아마도

722
00:23:22,520 --> 00:23:25,180
완전히 새로운

723
00:23:25,180 --> 00:23:25,440
아이디어들의

724
00:23:25,440 --> 00:23:28,020
가능성을 열고 더 많은 기회를

725
00:23:28,020 --> 00:23:30,540
만들어 줄 큰 발표가 있었기 때문입니다. 확실히 그런 속도는

726
00:23:30,540 --> 00:23:32,900
느려진 듯합니다. 그래서 아이디어를 찾는 일이

727
00:23:32,900 --> 00:23:35,380
어느 정도 정상적인 난이도 수준으로

728
00:23:35,380 --> 00:23:35,920
돌아가고 있는 것 같고,

729
00:23:35,920 --> 00:23:37,680
제 경험상 그렇습니다. 저도 동의합니다.

730
00:23:37,880 --> 00:23:40,180
놀랍지 않은 이야기도 말씀드리겠습니다. 혹시

731
00:23:40,180 --> 00:23:40,520
기억하시나요,

732
00:23:40,520 --> 00:23:43,580
AI 2027이라는 보고서가 있었는데, 그것은

733
00:23:43,580 --> 00:23:45,460
일종의 종말론적 글로서

734
00:23:45,460 --> 00:23:46,220
그러니까, 음,

735
00:23:46,380 --> 00:23:47,960
사회가

736
00:23:47,960 --> 00:23:50,300
2027년에 무너져 내리기 시작할 것이라고 했습니다. 그런데 어느 시점에

737
00:23:50,300 --> 00:23:51,500
조용히 내용을 수정해서

738
00:23:51,500 --> 00:23:53,820
2027년이 아니라고 했지만,

739
00:23:53,820 --> 00:23:55,760
제목은 그대로 두었습니다. 어쩌면 이것도 놀랄 일은 아닙니다.

740
00:23:56,020 --> 00:23:57,000
저는 원래부터

741
00:23:57,000 --> 00:23:59,740
이런

742
00:23:59,740 --> 00:24:03,360
패스트 테이크오프 논증과 관련해, 스케일링

743
00:24:03,360 --> 00:24:04,340
법칙이 있더라도,

744
00:24:04,340 --> 00:24:09,000
그 성장은 로그-선형입니다. 그래서 더 느리고,

745
00:24:09,000 --> 00:24:12,140
예를 들어 컴퓨팅이 10배 더 필요하며, 그래도

746
00:24:12,140 --> 00:24:13,040
말하자면,

747
00:24:13,180 --> 00:24:16,040
한계에 다다르는 것입니다. 그리고 이것이 한 가지 형태의

748
00:24:16,040 --> 00:24:18,520
좋은 소식입니다. 또 다른 형태로는 이것을

749
00:24:18,520 --> 00:24:19,100
좋은 소식이라고 부르기엔 이상하지만,

750
00:24:19,100 --> 00:24:23,280
소위 '좋은 소식'이 하나 더 있는데, 인간은 변화를 좋아하지 않습니다.

751
00:24:23,280 --> 00:24:25,220
지난 에피소드에서 저희가

752
00:24:25,220 --> 00:24:25,740
그

753
00:24:26,340 --> 00:24:28,620
MIT 보고서를 다뤘는데, 거기서는 98

754
00:24:28,620 --> 00:24:32,520
퍼센트 또는 90퍼센트의 기업 AI 프로젝트가

755
00:24:32,520 --> 00:24:33,880
실패한다고 했습니다. 그런데 알고 보니

756
00:24:33,880 --> 00:24:37,400
기업의 90퍼센트는

757
00:24:37,400 --> 00:24:40,540
IT조차 제대로 못하며, AI는 더더욱 그렇습니다.

758
00:24:40,540 --> 00:24:41,280
이게

759
00:24:41,280 --> 00:24:42,780
좋은 일이라고 말하기는 이상하지만, 패스트 테이크오프 맥락에서는

760
00:24:42,780 --> 00:24:44,780
이것이 실제로

761
00:24:44,780 --> 00:24:46,940
이 새롭고 믿기 어려울 정도로 강력한 기술이

762
00:24:46,940 --> 00:24:50,480
실제로 사회에 스며드는 것을

763
00:24:50,480 --> 00:24:53,300
가로막는 큰 제동이 됩니다. 저는 가속을 좋아하지만,

764
00:24:53,400 --> 00:24:55,580
이 경우에는 '사실은'

765
00:24:55,660 --> 00:24:57,080
그게 좋은 일일지도 모른다고 말하는 것이

766
00:24:57,220 --> 00:24:57,640
이상하기는 합니다.

767
00:24:57,640 --> 00:25:01,680
정말 놀라울 정도로 강력한 기술입니다. 하지만

768
00:25:01,680 --> 00:25:03,760
아시다시피, 로그-선형 스케일링이라는 점과

769
00:25:04,020 --> 00:25:07,620
인간은 변화를 정말 좋아하지 않으며,

770
00:25:07,620 --> 00:25:10,980
조직적으로 말하면 사회가

771
00:25:10,980 --> 00:25:14,160
이 기술을 흡수할 것이고, 모두가 충분한 시간을 갖고

772
00:25:14,160 --> 00:25:16,880
어느 정도 이를 소화할 시간이 생기고, 문화도 따라잡을

773
00:25:16,880 --> 00:25:17,240
것입니다.

774
00:25:17,420 --> 00:25:19,620
정부도 이에 대응할 수 있을 것입니다.

775
00:25:19,860 --> 00:25:23,120
허둥대는 SB 1047 같은

776
00:25:23,120 --> 00:25:24,320
그런 식이 아니라,

777
00:25:24,320 --> 00:25:26,220
‘10의 26제곱을 넘는 컴퓨팅은 전부 멈추자’ 같은,

778
00:25:26,220 --> 00:25:28,700
그렇지요? 이런 반사적인

779
00:25:28,700 --> 00:25:29,400
대응들

780
00:25:29,980 --> 00:25:33,860
기술에 대한 대응입니다. 저희는 Arc AGI

781
00:25:33,860 --> 00:25:36,340
프라이즈가, 아시다시피, 들어와서

782
00:25:36,340 --> 00:25:36,760
그

783
00:25:36,760 --> 00:25:39,580
Winter 26 배치를 비영리로 진행할 거라는 점이 기대됩니다. 재미있는

784
00:25:39,580 --> 00:25:41,620
점은, 네, 어쩌면 지금

785
00:25:42,160 --> 00:25:45,060
Arc AGI 리더보드를

786
00:25:45,060 --> 00:25:47,680
올라가고 있는 팀이 있고, 그들이

787
00:25:47,680 --> 00:25:48,400
이걸

788
00:25:48,400 --> 00:25:48,880
또다시 가속화할지도 모른다는 것입니다.

789
00:25:48,880 --> 00:25:50,840
그와 관련해서 제게 놀라웠던 점은

790
00:25:50,840 --> 00:25:52,300
스타트업 쪽에서, 제가 이쯤

791
00:25:52,300 --> 00:25:52,580
작년

792
00:25:52,580 --> 00:25:54,580
이 시기에, 회사들이 어떻게

793
00:25:54,580 --> 00:25:56,240
연간 반복 매출(ARR) 100만 달러에 도달하고

794
00:25:56,240 --> 00:25:56,560
시리즈

795
00:25:56,560 --> 00:25:58,720
A를 채용 없이도 받는다는 얘기를 했다는 것입니다, 어떤 경우엔 채용을

796
00:25:58,720 --> 00:26:00,980
아무도 채용하지 않고 창업자들만 있거나, 한 명만 채용하기도 했습니다,

797
00:26:00,980 --> 00:26:04,040
그게 정말 이례적으로 느껴졌습니다. 그런데

798
00:26:04,040 --> 00:26:08,560
1년이 지난 지금, 그게 ‘좋아, 그러면’으로 이어지지는 않았고,

799
00:26:08,640 --> 00:26:10,100
그 다음에

800
00:26:10,100 --> 00:26:13,320
ARR 1,000만 달러를 찍었거나, 사람을

801
00:26:13,320 --> 00:26:14,120
더 늘리지 않고도 스케일했다로 이어지지는 않았습니다.

802
00:26:14,120 --> 00:26:16,980
아니요, 그들은 돌아서서

803
00:26:16,980 --> 00:26:17,500
실제 팀을 채용하기 시작했습니다.

804
00:26:17,720 --> 00:26:20,540
네. 시리즈 A 이후에는, 사실 대부분

805
00:26:20,540 --> 00:26:23,680
플레이북은 같고

806
00:26:23,680 --> 00:26:24,640
회사들은

807
00:26:24,640 --> 00:26:26,760
같은

808
00:26:26,760 --> 00:26:29,560
매출 규모 대비 더 작을 수 있지만, 그건 전적으로 그들이

809
00:26:29,560 --> 00:26:29,880
매출을

810
00:26:29,880 --> 00:26:32,060
너무 빨리 달성했고, 여전히 병목이

811
00:26:32,060 --> 00:26:33,480
사람을 채용하는 데 걸리는 시간에 있어서

812
00:26:33,480 --> 00:26:34,400
있기 때문이지, 그들이

813
00:26:34,400 --> 00:26:35,600
더 적은 인력을 필요로 해서가 아닙니다.

814
00:26:35,800 --> 00:26:37,500
저는 여전히,

815
00:26:37,580 --> 00:26:39,920
어떤 효과는 있다고 보지만, 완전히

816
00:26:39,920 --> 00:26:41,540
명확한 건 아닙니다. 여러분이

817
00:26:41,540 --> 00:26:43,840
더 이상 임원을 채용하지 않아도 된다는 뜻은 아닙니다. 저는

818
00:26:43,840 --> 00:26:45,720
그런 경우가 있을 수도 있다고

819
00:26:45,720 --> 00:26:46,780
푸아그라 스타트업 두

820
00:26:46,780 --> 00:26:49,720
곳이 있는데, 하나는 Harvey이고 다른 하나는

821
00:26:49,720 --> 00:26:52,020
Open Evidence입니다. Harvey는,

822
00:26:52,300 --> 00:26:55,200
창업자들이 대단합니다. 아주 일찍 시작했습니다.

823
00:26:55,200 --> 00:26:57,480
그리고 또 이런 생각이 있습니다.

824
00:26:57,480 --> 00:26:57,740
그러니까,

825
00:26:58,000 --> 00:26:59,920
VC 입장에서는 Sand

826
00:26:59,920 --> 00:27:02,100
Hill Road를 쭉 돌면서, 승부가 이미 정해져 있는 것처럼

827
00:27:02,100 --> 00:27:03,260
그들을 전부

828
00:27:03,260 --> 00:27:04,800
그냥 차단해 버릴 수 있다는 것입니다. 그리고 그 사람들,

829
00:27:05,000 --> 00:27:07,420
아마 30명 정도가

830
00:27:07,420 --> 00:27:08,860
1,000만 달러에서

831
00:27:08,860 --> 00:27:10,480
1억 달러 규모의 수표를 쓸 수 있습니다. 그리고 그들의 돈을

832
00:27:10,480 --> 00:27:12,260
전부 끌어모으면,

833
00:27:12,260 --> 00:27:12,980
실제로

834
00:27:12,980 --> 00:27:15,260
다음 시리즈 A에 들어와서 투자할 수 있는 사람이

835
00:27:15,260 --> 00:27:17,440
남지 않게 되고, 그러면 기본적으로 여러분은

836
00:27:17,440 --> 00:27:17,980
안전해집니다. 그러니까

837
00:27:17,980 --> 00:27:20,060
자본을 곤봉처럼 휘두르는 것, 그 경우 자본은

838
00:27:20,060 --> 00:27:21,980
그 경우 자본은 해자 역할을 합니다. 그래서

839
00:27:21,980 --> 00:27:22,960
네, Harvey는 흥미로운데

840
00:27:22,960 --> 00:27:25,380
Lagora가 빠르게 그들을 추격하고 있고

841
00:27:25,380 --> 00:27:27,900
있기 때문입니다. 그리고 당연히 저희는 Lagora에 어느 정도 이해관계가

842
00:27:27,900 --> 00:27:28,280
있지만

843
00:27:28,280 --> 00:27:30,000
저희는 그들이,

844
00:27:30,100 --> 00:27:32,120
어, 누구 못지않게 가능성이 있다고 봅니다, 저는

845
00:27:32,120 --> 00:27:33,160
제가 보기엔 저희가 본 한 가지 트렌드는

846
00:27:33,160 --> 00:27:34,720
2025년에 본 트렌드 중 하나는

847
00:27:34,720 --> 00:27:37,000
AI 기업들에 대한 첫 번째 물결의 일종의 AI 혐오가

848
00:27:37,000 --> 00:27:37,840
Harvey 같은 회사들에 대한 첫 번째 물결의 일종의 AI 혐오였다는 것입니다.

849
00:27:38,160 --> 00:27:39,480
실제로 파인튜닝에

850
00:27:39,480 --> 00:27:40,420
돈을 많이 낭비했을 수도 있습니다.

851
00:27:40,980 --> 00:27:42,960
맞습니다. 그게 2023년에

852
00:27:42,960 --> 00:27:45,240
정말 크게 터졌고, 일종의 승리 선언을

853
00:27:45,240 --> 00:27:45,680
했습니다. 그러니까,

854
00:27:45,780 --> 00:27:47,640
"우리가 이 분야를 먹었다"라고 말한 것입니다. 그리고 이제는

855
00:27:47,640 --> 00:27:49,660
Lagora 같은 회사들의 두 번째 물결과

856
00:27:49,660 --> 00:27:50,300
Giga 같은 회사들을 보고 있습니다.

857
00:27:50,400 --> 00:27:51,780
그리고 알고 보니, 그러니까, 사실

858
00:27:51,780 --> 00:27:53,940
그게 그렇게 단순하지는 않다는 것입니다.

859
00:27:54,180 --> 00:27:56,860
네. 결국 수혜자는, 음, 그러니까,

860
00:27:57,100 --> 00:28:00,720
자본 구조의 적지 않은 두 자릿수 비율을

861
00:28:00,720 --> 00:28:03,640
파인튜닝에 태워서 얻는 것은,

862
00:28:03,640 --> 00:28:06,220
그러니까 그 ‘우위’의 수혜자는 사실상 투자자들이고

863
00:28:06,220 --> 00:28:07,840
거기서 이기는 쪽은 그들뿐인 게,

864
00:28:07,840 --> 00:28:09,140
결국 여러분 회사의 지분을 더 많이 갖게 되기 때문입니다, 그렇지요?

865
00:28:09,600 --> 00:28:10,740
네. 그래서 적어도 이것은

866
00:28:10,740 --> 00:28:12,760
채용과 팀 규모 문제와는 연결되는 것 같습니다.

867
00:28:12,760 --> 00:28:13,160
그러니까

868
00:28:13,160 --> 00:28:15,960
두 진영이 있는데, 하나는 AI가

869
00:28:15,960 --> 00:28:17,100
모든 것을 더 효율적으로 만들어서 여러분은

870
00:28:17,100 --> 00:28:17,500
더 적은

871
00:28:17,500 --> 00:28:19,840
사람만 필요해질 거라는 쪽이고, 다른 하나는 AI가

872
00:28:19,840 --> 00:28:21,960
뭔가를 만드는 데 걸리는 시간, 즉 생산 비용을

873
00:28:21,960 --> 00:28:22,580
낮춰 줄 거라는 쪽입니다.

874
00:28:22,740 --> 00:28:25,040
그러면 사용자와

875
00:28:25,040 --> 00:28:26,560
고객의 기대치가 계속 올라가고, 여러분은

876
00:28:26,560 --> 00:28:26,760
그래서

877
00:28:26,760 --> 00:28:28,680
그 늘어나는 기대를 충족하려고 더 많은 사람을

878
00:28:28,680 --> 00:28:29,560
계속 채용해야 하게 됩니다.

879
00:28:29,560 --> 00:28:31,640
제 느낌엔 올해는 더

880
00:28:31,640 --> 00:28:33,740
그 두 번째 진영에 가까웠던 것 같습니다. 그리고 저는

881
00:28:33,740 --> 00:28:34,880
그게 이런 사실을 설명한다고 봅니다.

882
00:28:34,880 --> 00:28:36,380
기업들이 여전히

883
00:28:36,380 --> 00:28:38,840
AI 이전과 비슷한 수준으로 계속 사람을 뽑고 있다는 점입니다. 다만

884
00:28:38,840 --> 00:28:39,480
기준이, 그러니까

885
00:28:39,480 --> 00:28:41,320
소프트웨어에서 고객이 기대하는 수준의 문턱이 올라갔을 뿐입니다.

886
00:28:41,760 --> 00:28:42,900
그리고 다들, 그러니까

887
00:28:42,900 --> 00:28:43,660
Lagora는

888
00:28:43,660 --> 00:28:46,620
Harvey와 경쟁하고, Giga는 Sierra와 경쟁하듯이,

889
00:28:46,620 --> 00:28:49,140
모두가 여전히 같은 고객군을 놓고

890
00:28:49,140 --> 00:28:49,240
서로

891
00:28:49,240 --> 00:28:51,720
경쟁하고 있고, 결국 병목은 여전히

892
00:28:51,720 --> 00:28:54,940
사람입니다. 저는 누구도

893
00:28:54,940 --> 00:28:56,700
아이디어 때문에 병목이 생긴다고는 생각하지 않지만, 정말 잘 실행할 수 있는

894
00:28:56,700 --> 00:28:58,140
사람 때문에 병목이 생깁니다.

895
00:28:58,140 --> 00:28:59,560
모르겠습니다. 제 생각엔 그래서

896
00:28:59,560 --> 00:29:01,260
흥미롭습니다. 흥미로운 국면인 것 같습니다.

897
00:29:01,420 --> 00:29:04,240
저도 동의합니다. 1명이

898
00:29:04,240 --> 00:29:07,340
1조 달러 규모의

899
00:29:07,340 --> 00:29:08,340
회사를 운영하는 시대는

900
00:29:08,340 --> 00:29:09,200
아직은 아닙니다. 아직은요.

901
00:29:09,460 --> 00:29:10,980
네. 하지만 결국 그쪽으로

902
00:29:10,980 --> 00:29:13,320
흘러갈 거라고 생각합니다. 정말 엄청난 시기가 되겠지요.

903
00:29:13,640 --> 00:29:14,040
어쩌면 그게

904
00:29:14,040 --> 00:29:15,600
예측일 수도 있겠네요... 내년에 대해서요?

905
00:29:15,680 --> 00:29:16,600
...2026년이요. 네.

906
00:29:16,720 --> 00:29:17,300
그게 올 거라고 보십니까?

907
00:29:17,300 --> 00:29:18,660
그러니까 제 생각엔

908
00:29:18,660 --> 00:29:20,900
솔직히 2026년에도 일어나지는 않을 것 같습니다. 제 말은, 저는

909
00:29:20,900 --> 00:29:21,400
앞으로

910
00:29:21,400 --> 00:29:25,260
그러니까 100명 미만으로 운영되면서

911
00:29:25,420 --> 00:29:27,360
수억 달러를 벌어들이는

912
00:29:27,360 --> 00:29:27,560
기업들의

913
00:29:27,560 --> 00:29:28,600
많은 사례가 나올 거라고 생각합니다. 네.

914
00:29:28,600 --> 00:29:31,060
그래서, 그러니까 Gamma가 흥미로웠습니다.

915
00:29:31,200 --> 00:29:33,200
예를 들면 그들이

916
00:29:33,200 --> 00:29:34,060
출시 때 말한 것들 중 가장 큰 것 하나가

917
00:29:34,060 --> 00:29:35,680
제 생각엔 아주 좋은 트렌드였는데,

918
00:29:35,680 --> 00:29:37,300
그들이

919
00:29:37,300 --> 00:29:40,120
ARR 1억 달러에

920
00:29:40,120 --> 00:29:42,660
직원 50명만으로 도달했다고 했습니다. 그래서, 그건 정말 다릅니다.

921
00:29:42,940 --> 00:29:44,800
그러니까 완전히 역전이죠, 그렇지요? 보통은

922
00:29:44,800 --> 00:29:47,400
큰 배너가 있고

923
00:29:47,400 --> 00:29:49,840
작은 X 같은 것, 그러니까 이미지가 있고, 그리고

924
00:29:49,840 --> 00:29:50,660
‘아, 맞아,’

925
00:29:50,800 --> 00:29:52,700
‘우리가 이렇게 많은 돈을 모았고, 그리고’

926
00:29:52,700 --> 00:29:54,240
‘우리 회사에 일하는 사람이 이렇게 많다’라고 하지요.

927
00:29:54,240 --> 00:29:56,500
그 반대로 자랑하는 흐름이 좋은데,

928
00:29:56,500 --> 00:29:58,220
즉, ‘이 매출을 봐라, 그리고’

929
00:29:58,220 --> 00:29:59,360
‘얼마나 적은 사람이 일하는지’를

930
00:29:59,360 --> 00:30:01,340
‘봐라’라는 겁니다. 자, 이번에는 여기까지입니다.

931
00:30:01,340 --> 00:30:03,520
이번에는 시간이 여기까지였습니다. 저희는 그저

932
00:30:03,520 --> 00:30:04,060
여러분께

933
00:30:04,060 --> 00:30:06,220
즐거운 연말연시와 새해 복 많이 받으시길

934
00:30:06,220 --> 00:30:08,180
저희 모두를 대표해 여러분과 가족분들께 전해 드리고 싶었습니다.

935
00:30:08,460 --> 00:30:09,260
다음에 또 뵙겠습니다.
