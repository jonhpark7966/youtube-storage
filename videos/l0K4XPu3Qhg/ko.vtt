WEBVTT

00:00:25.316 --> 00:00:27.652
그렇다면 알트먼은 여기서 왜 이렇게 화가 난 것처럼 보일까요?

00:00:27.652 --> 00:00:28.570
어쨌든 이 인터뷰어는

00:00:28.570 --> 00:00:33.158
OpenAI가 1조 달러가 넘는 돈을 쓰겠다고 약속했다는 기본적인 사실을 지적했을 뿐인데요,

00:00:33.158 --> 00:00:36.995
향후 8년 동안 AI 인프라에, 그럼에도 불구하고 겨우

00:00:36.995 --> 00:00:40.915
연간 반복 매출이 약 130억 달러 수준인데도 말입니다,

00:00:40.915 --> 00:00:44.044
약속한 지출액의 1%도 안 되는 수준입니다.

00:00:44.294 --> 00:00:47.172
저는 돈의 천재가 아니고, 개인적으로는 정말

00:00:47.172 --> 00:00:50.175
예산을 짜는 데도 서툴지만, 그래도 그건 좋아 보이지 않습니다.

00:00:50.258 --> 00:00:52.302
2025년에 미국

00:00:52.302 --> 00:00:55.889
경제가 성장한 것처럼 보였던 대부분은 AI 투자 때문에 생긴 것이었습니다.

00:00:56.139 --> 00:01:00.435
그것은 샘 알트먼이 이끄는 업계가 내놓는 약속의 일부입니다,

00:01:00.810 --> 00:01:04.439
머신러닝 지능이 일정 수준에 도달하면,

00:01:04.647 --> 00:01:06.357
우리의 모든 문제가 해결될 것이라는 약속 말입니다.

00:01:06.608 --> 00:01:07.442
주거 위기,

00:01:07.442 --> 00:01:07.901
암,

00:01:07.901 --> 00:01:08.443
빈곤,

00:01:08.443 --> 00:01:09.027
기후변화,

00:01:09.027 --> 00:01:09.527
정신 건강,

00:01:09.527 --> 00:01:10.153
민주주의,

00:01:10.195 --> 00:01:12.822
보편적 기본소득, 돌봄, 온갖 질병들, 이 암

00:01:12.822 --> 00:01:14.074
저 암, 그리고 심장병까지,

00:01:14.074 --> 00:01:16.618
목표를 이루고 최고의 모습이 되도록 돕는 것까지요.

00:01:16.618 --> 00:01:17.702
아주 높은 수준의 의료 서비스도요.

00:01:17.702 --> 00:01:19.370
중요한 새로운 과학적 발견들,

00:01:19.370 --> 00:01:21.998
에너지의 한계비용은 빠르게 0에 가까워질 것이라고 합니다.

00:01:21.998 --> 00:01:24.542
더 평등한 세상, 모두를 위한 보편적 최고 수준의 건강도요.

00:01:24.918 --> 00:01:26.294
그 모든 것의 대가로

00:01:26.294 --> 00:01:30.215
알트먼은 사회 전체가 우리의 모든 달걀, 즉 우리의 데이터

00:01:30.381 --> 00:01:35.261
우리 경제, 물과 자원... 모든 것을 한 바구니에 담으라고 요구합니다:

00:01:35.762 --> 00:01:38.348
바로 그의 바구니에요. 그는 우리에게 하나의 거대한,

00:01:40.308 --> 00:01:42.060
그렇다면 우리는 알트먼을 믿어야 할까요?

00:01:42.060 --> 00:01:43.603
그의 거래를 받아들여야 할까요?

00:01:43.603 --> 00:01:45.730
그게 과연 우리의 선택이기나 할까요?

00:01:45.730 --> 00:01:48.108
알트먼은 기술자도 과학자도 아닙니다,

00:01:48.108 --> 00:01:52.737
그는 투자자이자 협상가이고, 그 일을 아주 잘한다고들 합니다... 아마도요.

00:01:52.904 --> 00:01:56.324
하지만 그의 커리어 전체는 '그냥 믿어라, 형' 같은 순간들의 연속입니다.

00:01:56.741 --> 00:01:58.118
그럼 그가 제안하는 거래를

00:01:58.118 --> 00:01:59.702
우리 모두에게 무엇을 내놓고 있는지 살펴보겠습니다.

00:01:59.702 --> 00:02:01.830
샘 알트먼의 약속을 믿어야 할까요?

00:02:01.830 --> 00:02:05.625
그리고 그 약속들이

00:02:05.625 --> 00:02:08.628
거짓으로 드러난다면... 우리 모두가 치를 대가는 무엇일까요?

00:02:10.380 --> 00:02:11.965
그럼 다시 돌아가서

00:02:11.965 --> 00:02:14.968
알트먼의 기술 업계 초기 시절을 더 자세히 보겠습니다.

00:02:15.176 --> 00:02:18.221
알트먼의 첫 번째 큰 거래는 첫 회사를 파는 것이었습니다,

00:02:18.513 --> 00:02:21.933
친구의 위치를 찾는 서비스인 Loopt였죠.

00:02:22.100 --> 00:02:26.020
그런 서비스는 본질적으로 이용자가 많아야 작동하고, 아니면 그저

00:02:26.146 --> 00:02:27.438
자기 자신만 찾게 됩니다.

00:02:27.605 --> 00:02:29.774
핵심 아이디어는 어디에나 존재하는, 즉 보편성이었던 것 같습니다.

00:02:29.774 --> 00:02:33.736
그러니까 상상할 수 있는 것보다 훨씬 더 많은 방식으로 퍼뜨리라는 뜻입니다.

00:02:37.532 --> 00:02:39.742
그 기간 내내 Loopt는 이용자가 몇 명인지 말하기를 거부했습니다.

00:02:40.034 --> 00:02:42.912
알트먼은 그저 "훨씬

00:02:42.912 --> 00:02:45.915
더 많은 이용자"가 다른 비슷한 서비스들보다 있다고 주장했을 뿐입니다.

00:02:45.957 --> 00:02:50.837
하지만 결국 밝혀진 바에 따르면, 말기에는 Loopt의 이용자가 겨우 500명뿐이었습니다.

00:02:51.129 --> 00:02:54.883
로이터가 이를 보도하자, 알트먼은 실제로는 "100배"라고

00:02:54.883 --> 00:02:58.553
더 많고 증거를 내놓겠다고 주장했지만... 끝내 내놓지 않았습니다.

00:02:58.803 --> 00:03:00.847
그냥 믿어라, 형.

00:03:00.847 --> 00:03:03.349
Loopt는 Green Dot Corporation에 매각됐고,

00:03:03.349 --> 00:03:06.895
그들은 즉시 서비스를 종료했고 기술은 한 번도 쓰지 않았습니다.

00:03:07.187 --> 00:03:10.857
Green Dot의 투자자들은 이것이 부를 불리기 위해 벌어진 더러운 거래였다고 주장합니다,

00:03:10.857 --> 00:03:14.652
Loopt에 지분을 가진 VC인 Sequoia Capital을

00:03:14.819 --> 00:03:18.948
그리고 거래 승인에 관여한 Green Dot 이사회 멤버 두 명을 위해서였다는 것입니다.

00:03:19.240 --> 00:03:21.951
알트먼은 법적으로 가능해지자마자 Green Dot을 떠났고,

00:03:21.951 --> 00:03:26.706
어떤 형태로도 더 이상 존재하지 않는 앱을 만든 대가로 수백만 달러를 챙겨 떠났습니다.

00:03:26.998 --> 00:03:30.001
그리고 알트먼에게는 운 좋게도 그에게서 무엇인가를 본 사람이 있었습니다.

00:03:30.126 --> 00:03:34.464
피터 틸입니다. 틸은 한때 알트먼을

00:03:34.672 --> 00:03:37.842
"메시아에 더 가까운 인물"로 대해야 한다고 말했고, 알트먼에게 수백만 달러를

00:03:37.842 --> 00:03:40.887
그의 VC 회사인 Hydrazine Capital을 시작하라고 건넸습니다.

00:03:41.763 --> 00:03:44.098
그리고 알트먼이 통제하던 자본은 그것만이 아니었습니다.

00:03:44.098 --> 00:03:47.936
그는 영향력 있는 벤처캐피털이자 스타트업 인큐베이터인 Y Combinator, 즉 YC의 대표로도 영입되었습니다,

00:03:47.936 --> 00:03:51.898
영향력 있는 벤처캐피털이자 스타트업 인큐베이터 말입니다,

00:03:51.898 --> 00:03:55.568
Loopt가 처음 자금을 받은 곳이기도 하죠. "YC의 대표는

00:03:55.777 --> 00:03:58.321
스타트업 운동의 비공식적 리더 같은 존재"라고 생각합니다."

00:03:58.321 --> 00:04:01.324
그리고 알트먼은 그 영향력을 개인적으로 활용했습니다.

00:04:01.366 --> 00:04:04.953
더 뉴요커는 Hydrazine

00:04:05.036 --> 00:04:08.039
Capital의 최대 75%가 YC 기업들에 투자됐다고 보도했습니다.

00:04:08.039 --> 00:04:11.292
알트먼은 내부에서 보는 시각을 이용해

00:04:11.292 --> 00:04:12.085
YC의 힘에서 몫을 챙긴 것입니다.

00:04:12.085 --> 00:04:16.172
알트먼은 YC 기업들에 교차 투자하지 않겠다고 약속했음에도요.

00:04:16.798 --> 00:04:20.176
지금까지 큰 거짓말이 두 가지입니다: 사용자 수가 있어야 존재할 수 있는 LOOPT의

00:04:20.176 --> 00:04:23.972
사용자 기반에 대한 거짓말, 그리고 그의 투자에 대한 거짓말입니다.

00:04:24.264 --> 00:04:28.977
2015년, 알트먼은 YC를 이끌고 여러분이 그를 가장 잘 아는 투자로 나아갑니다:

00:04:29.352 --> 00:04:34.023
"일종의 반은 회사이고 반은 비영리인 형태로, AI 안전 연구를 하는 곳"입니다.

00:04:34.107 --> 00:04:39.362
OpenAI는 소위 비영리인 OpenAI Foundation으로 출범했고, 헌장에는

00:04:39.362 --> 00:04:43.783
수많은 고상한 목표들이 담겼습니다, "인류에 대한 1차적 신인의무"가 있고

00:04:43.783 --> 00:04:47.161
그리고 "인류에 해를 끼치거나 권력을 과도하게 집중시키는 AI 또는 AGI의

00:04:47.161 --> 00:04:50.164
활용을 가능하게 하지 않기"도 포함되며, 또한

00:04:50.331 --> 00:04:54.252
"직원과 이해관계자 사이의 이해상충을 최소화하기" 위해 행동한다고 했습니다.

00:04:54.794 --> 00:04:57.880
그런 일을 할 거라는 증거요? "그냥 믿으라니까요."

00:04:58.631 --> 00:05:00.258
OpenAI의 주요 재정적 후원자는

00:05:00.258 --> 00:05:03.428
Altman 같은 기술 분야 억만장자와 백만장자들이었고,

00:05:03.428 --> 00:05:07.015
Peter Thiel, Reid Hoffman, Elon Musk도 포함됐습니다.

00:05:07.140 --> 00:05:10.893
또 Amazon Web Services와 Infosys 같은 기술 기업들도 있었습니다.

00:05:11.269 --> 00:05:14.522
저희는 인류의 최선의 이익을 마음에 두고 이것을 만들고 싶었습니다.

00:05:14.522 --> 00:05:17.025
하지만 그 대가로 OpenAI는 많은 것을 요구하고 있습니다…

00:05:17.025 --> 00:05:20.361
말하자면 사회의 모든 계란을 한 바구니에 담는 셈입니다.

00:05:20.361 --> 00:05:24.866
그들은 전기, 물, 기반시설을 원합니다…

00:05:25.366 --> 00:05:26.284
자본도요…

00:05:26.284 --> 00:05:29.120
당신의 데이터… 당신의 글… 당신의 예술…

00:05:29.120 --> 00:05:32.290
그리고 인류가 일자리 상실에 적응하고,

00:05:32.290 --> 00:05:35.251
딥페이크와 그 밖의 모든 것에 적응하길 원합니다.

00:05:35.335 --> 00:05:40.381
모든 것을 해결해 준다는 미래 기술의 약속과 맞바꾸면서 말입니다.

00:05:40.631 --> 00:05:43.259
그렇다면 우리가 이 모든 것을 그에게 맡기고 믿어도 될까요?

00:05:43.259 --> 00:05:45.345
그의 가장 큰 발언들 몇 가지와

00:05:45.345 --> 00:05:50.308
약속들을 살펴보며 그것들이 이 '한 바구니의 계란들'과 어떻게 연결되는지 보겠습니다.

00:05:50.725 --> 00:05:53.770
Altman은 자신이 OpenAI의 어떤 지분도 소유하지

00:05:53.770 --> 00:05:56.314
않고 급여도 거의 받지 않는다고 주장합니다.

00:05:56.314 --> 00:05:58.691
저는 건강보험을 유지할 정도만 받습니다. OpenAI 지분은 없습니다.

00:05:58.691 --> 00:05:59.859
저는 이 일을 사랑해서 하고 있습니다.

00:05:59.942 --> 00:06:02.403
하지만 그는 이미 부자라는 사실을 숨기지 않으며

00:06:02.403 --> 00:06:05.531
돈으로 선을 행하는 부자 배트맨 같은 일을 하려는 겁니다.

00:06:05.823 --> 00:06:07.325
그 배트맨 말입니다.

00:06:07.325 --> 00:06:09.285
정말 훌륭한 사람이죠.

00:06:09.285 --> 00:06:10.953
저는 그럴 자격이 없습니다.

00:06:10.953 --> 00:06:13.206
하지만 우리 백만장자들은 당신은 그럴 자격이 있다고 결정했습니다.

00:06:13.748 --> 00:06:16.751
하지만 이것이 그의 정직성 문제의 일부인 이유를 보겠습니다.

00:06:16.834 --> 00:06:20.463
그리고 이것은 '한 바구니의 계란들'과도 연결되는데, Altman이 투자하고 있기 때문입니다.

00:06:20.463 --> 00:06:23.841
OpenAI를 만드는 데 필요한 모든 것에 말입니다.

00:06:24.050 --> 00:06:27.261
OpenAI가 필요로 하는 '계란' 중 하나는 방대한 데이터입니다:

00:06:27.470 --> 00:06:31.265
언어의 예시 없이는 대규모 언어 모델을 만들 수 없고,

00:06:31.265 --> 00:06:34.977
그 데이터의 한 출처가 Reddit입니다.

00:06:35.311 --> 00:06:35.978
Altman은

00:06:35.978 --> 00:06:40.733
그 소셜 네트워킹 사이트의 큰 지분을 보유했고 2022년까지 이사회에 있었습니다.

00:06:40.900 --> 00:06:44.695
Reddit은 Loopt와 같은 첫 번째 Y Combinator 기수에서 시작했습니다.

00:06:45.113 --> 00:06:49.826
2005년에 Reddit 공동창업자 Aaron Swartz 옆에 서 있는 Altman이 여기 있습니다.

00:06:50.159 --> 00:06:54.747
Swartz는 2013년에 형사 기소를 당한 뒤 스스로 목숨을 끊었습니다.

00:06:54.747 --> 00:07:00.044
학술 논문을 온라인에 복제해 올리고 저작권법을 위반했다는 이유였습니다.

00:07:00.086 --> 00:07:04.048
2015년에 Altman은 Reddit과 거래를 맺어 OpenAI가 "기본적으로

00:07:04.048 --> 00:07:08.636
사이트에 올라온 모든 것을 공격적으로 긁어 모으도록" 허용해 OpenAI 기술에 먹였습니다.

00:07:08.845 --> 00:07:13.307
Reddit 공동창업자 Alex Ohanian은 그 거래가 잘못됐다는 걸 "뼛속으로" 느꼈다고 했습니다.

00:07:13.558 --> 00:07:16.436
이는 Reddit 공동창업자

00:07:16.436 --> 00:07:19.522
Aaron Swartz가 법 집행기관의 표적이 됐던 일의, 덜 숭고한 버전입니다.

00:07:19.856 --> 00:07:22.859
Swartz는 지식을 모든 사람에게 열어두길 원했습니다.

00:07:22.900 --> 00:07:25.903
Altman은 그것을 자신의 제품에 넣고 싶어 했습니다.

00:07:26.446 --> 00:07:29.449
2014년에 Altman은 자신과 다른 투자자들이

00:07:29.449 --> 00:07:33.286
Reddit 가치의 10%를 Reddit 커뮤니티에 돌려주겠다고 약속했습니다.

00:07:33.494 --> 00:07:37.248
하지만 "규제 문제" 때문에 그것은 결코 이행되지 않았습니다.

00:07:37.582 --> 00:07:41.419
하지만 Reddit의 데이터가 OpenAI로 넘어가는 것처럼, Altman의 자산이 투자된 분야를 보면

00:07:41.419 --> 00:07:42.712
그의 부가 투자된 곳들은

00:07:42.712 --> 00:07:46.090
조직의 다른 필요들과도 깊게 연결돼 있음을 보여줍니다.

00:07:46.424 --> 00:07:51.345
그는 AI 네트워킹 장비 회사, 열 배터리 회사에 투자했고,

00:07:51.345 --> 00:07:55.766
서버 팜에 필요한 희토류 금속을 채굴하는 회사에도 투자했습니다.

00:07:56.267 --> 00:08:01.689
그리고 모든 것이 지어진 뒤에는, Altman이 AI가 만들어내는 문제들로부터 이익을 보게 될 것입니다.

00:08:02.064 --> 00:08:05.818
저희는 세 가지에 집중하겠습니다: 증가하는 에너지 수요와 비용.

00:08:06.027 --> 00:08:08.696
사기와 딥페이크 같은 악용.

00:08:08.696 --> 00:08:10.990
그리고 일자리 상실과 경제 붕괴입니다.

00:08:12.700 --> 00:08:13.576
Altman은

00:08:13.576 --> 00:08:17.497
OpenAI에 더 많은 전력이 필요하다고 거듭거듭 말합니다.

00:08:17.497 --> 00:08:20.875
"대담한 장기 목표는

00:08:20.875 --> 00:08:24.504
2033년까지 250GW의 설비 용량을 구축하는 것입니다."

00:08:24.670 --> 00:08:28.049
그만한 연산은 15억

00:08:28.174 --> 00:08:31.761
명 인구가 쓰는 전기, 즉 인도 전체 인구와 맞먹는 전력을 필요로 합니다.

00:08:32.345 --> 00:08:36.224
하지만 Altman에게는 해법이 있습니다: 2000년대 초에 처음 만난 이후로,

00:08:36.349 --> 00:08:39.268
Peter Thiel과 Sam Altman은 공통된 관심사를 공유해 왔습니다.

00:08:39.268 --> 00:08:42.647
원자력에 투자하는 것인데, 그것 자체가 본질적으로 나쁜 것은 아닙니다.

00:08:42.688 --> 00:08:45.024
물론 원자력은 매우 효율적이고

00:08:45.024 --> 00:08:48.861
깨끗한 에너지원이 될 수 있지만, Thiel과 Altman은 그것을 소유하고 싶어 합니다.

00:08:49.237 --> 00:08:51.989
Altman은 Helion과 Oklo에 투자하고 있습니다.

00:08:51.989 --> 00:08:55.910
Helion은 사상 최초의 핵융합 발전소를 만들려고 하고 있는데,

00:08:55.910 --> 00:08:59.705
많은 과학자들은 이런 방식의 에너지 생산이 작동하지 않을 것이라고 말합니다.

00:09:00.081 --> 00:09:01.332
그리고 Oklo는

00:09:01.332 --> 00:09:05.211
마이크로 원자로, 말 그대로 트럭 크기의 원자로를 만들고 있는데,

00:09:05.253 --> 00:09:08.923
이 투자 전략을 생각하면 다소 우려스럽습니다.

00:09:09.131 --> 00:09:13.302
"우리 모델의 일부는 실수의 비용을 정말 낮게 만들고,

00:09:13.594 --> 00:09:15.263
그다음 실수를 많이 하는 것입니다."

00:09:15.263 --> 00:09:18.307
하지만 지금까지 Oklo는 아직 원자로를 제대로 완성하지 못했고,

00:09:18.307 --> 00:09:21.561
자신들이 했던 약속을 맞추려고 가스를 쓰고 있을 뿐입니다.

00:09:21.644 --> 00:09:25.231
원자력 스타트업 Oklo와 천연가스 회사 Liberty Energy가 오늘

00:09:25.231 --> 00:09:28.734
대규모 고객에게 에너지를 공급하기 위한 파트너십을 발표했습니다.

00:09:30.069 --> 00:09:30.736
알트만은 또한

00:09:30.736 --> 00:09:34.115
AI 악성 행위자로부터 보호를 제공하는 여러 회사에 투자했으며,

00:09:34.115 --> 00:09:38.578
딥페이크를 막기 위한 신원 인증 솔루션, 그리고 심지어

00:09:38.578 --> 00:09:42.415
AI 사기와 해킹으로 인한 손실을 보장하는 보험을 제공하는 회사에도 투자했습니다.

00:09:42.748 --> 00:09:46.168
이는 배트맨이 범죄 퇴치로는 돈을 한 푼도 벌지 않다가,

00:09:46.210 --> 00:09:49.755
그러면서 '배트모빌이 우리 집에 들이받았습니다' 보험을 팔고,

00:09:50.381 --> 00:09:54.427
한편으로는 리들러가 쓰는 부하용 우버 스타트업을 운영하며,

00:09:54.427 --> 00:09:57.430
조커에게 하얀 분장용 화장품까지 파는 것과 같습니다.

00:10:00.057 --> 00:10:00.683
또 한 가지

00:10:00.683 --> 00:10:04.520
알트만이 내세우는 큰 약속은, 그가 불가피하다고 보는 AI가

00:10:04.520 --> 00:10:05.479
많은 일자리를

00:10:05.479 --> 00:10:09.317
쓸모없게 만들더라도, 엄청난 부를 만들어 모두와 나눌 수 있다는 것입니다.

00:10:09.317 --> 00:10:14.071
레딧에서 했던 더 작은 규모의 약속이 결국 헛소리였던 것과 마찬가지입니다.

00:10:14.780 --> 00:10:18.159
그리고 2024년에 그는, 그 공유된 풍요를 제공할 것이라던

00:10:18.159 --> 00:10:20.411
제품을 발표했습니다.

00:10:20.494 --> 00:10:23.289
월드코인입니다.

00:10:23.289 --> 00:10:26.667
월드코인은 기술 기업이자 암호화폐 프로젝트로,

00:10:26.667 --> 00:10:30.296
테크노 파시즘의 늘 보던 그 후원자들이 자금을 댄 프로젝트입니다.

00:10:30.630 --> 00:10:33.674
월드코인의 후원자들은 이것이

00:10:33.674 --> 00:10:35.426
일종의 보편적 기본소득을 지급하는 방법이 될 수 있다고 말합니다.

00:10:35.426 --> 00:10:38.054
AI가 일자리를 대체하기 시작하면,

00:10:38.054 --> 00:10:42.308
저는 정부 어느 곳의 통제도 받지 않는

00:10:42.308 --> 00:10:45.311
글로벌 통화가 있다는 발상이

00:10:45.311 --> 00:10:50.399
기술 트리에서 매우 논리적이고 중요한 다음 단계라고 생각합니다.

00:10:50.524 --> 00:10:53.027
하지만 이것은 또한

00:10:53.027 --> 00:10:57.073
AI가 만들어낸 신원 인증 문제의 해결책이라고 스스로를 포장합니다.

00:10:57.615 --> 00:11:02.244
그들은 이 오브를 신뢰할 수 있는 신원 확인 방법으로 쓰려 하고,

00:11:02.453 --> 00:11:05.581
보편적 기본소득을 받으려면

00:11:05.790 --> 00:11:08.751
오브에 눈을 스캔해야 받을 수 있습니다.

00:11:09.085 --> 00:11:12.296
그리고 Loopt부터 ChatGPT까지 알트만의 다른 프로젝트들처럼,

00:11:12.296 --> 00:11:17.093
사업적으로 쓸모가 있으려면 전 세계적 채택이 필요합니다.

00:11:17.176 --> 00:11:21.138
다른 사람들이 함께

00:11:21.138 --> 00:11:24.100
사용하지 않으면, 통화와 신원 확인 시스템은 쓸모가 없습니다.

00:11:24.100 --> 00:11:27.520
그러니 다시 말해, 우리에게 신원을 주면 암호화폐를 주겠다는 것입니다.

00:11:27.770 --> 00:11:29.647
전형적인 알트만식 거래입니다.

00:11:29.647 --> 00:11:32.525
당신이 모든 것을 양도하면, 저는 모든 것을 고쳐드리겠습니다.

00:11:32.525 --> 00:11:34.151
그냥 저를 믿어주십시오.

00:11:34.151 --> 00:11:37.988
마치 알트만이 아예 다른 경제를 만들려는 것 같습니다.

00:11:38.030 --> 00:11:40.991
지금 우리가 가진 경제가 무너질 경우에 대비해서 말입니다.

00:11:40.991 --> 00:11:41.992
뭐, 그 얘기는 곧 하겠습니다.

00:11:41.992 --> 00:11:45.621
2019년에 OpenAI는

00:11:45.621 --> 00:11:49.333
비영리라는 겉치레를 완전히 버리고 영리 부문을 시작했습니다.

00:11:49.583 --> 00:11:53.838
그리고 2024년에 그 영리 부문을 별도의 법인으로 분리했습니다.

00:11:54.171 --> 00:11:57.717
그 영리 조직은 비영리 조직과 같은 법적 책임을 지지 않았고,

00:11:57.717 --> 00:12:01.637
그 대신 Microsoft 같은 새로운 투자자들을 끌어들였습니다.

00:12:01.637 --> 00:12:05.182
Microsoft는 130억 달러를 투자했는데,

00:12:05.391 --> 00:12:09.103
OpenAI는 그 돈의 대부분을 Microsoft 제품에 썼습니다.

00:12:09.562 --> 00:12:13.482
Microsoft만이 아닙니다. 엔비디아는 향후 몇 년간 1,000억 달러를

00:12:13.482 --> 00:12:17.695
OpenAI에 투자하겠다고 약속했고, OpenAI는 그 돈으로

00:12:17.695 --> 00:12:19.238
엔비디아 칩을 사게 될 겁니다.

00:12:19.238 --> 00:12:22.241
OpenAI는 AMD와도 비슷한 순환 거래를 맺고 있으며,

00:12:22.575 --> 00:12:26.078
카타르 정부, 그리고 래리 엘리슨의 오라클과도 그렇습니다.

00:12:26.287 --> 00:12:29.874
내가 빌려준 20달러는 어쩌고요? 전 10달러밖에 없으니 10달러 드리고 10달러는 빚진 것으로 하겠습니다.

00:12:29.874 --> 00:12:32.001
모, 제게 20달러 빚지셨죠.

00:12:32.084 --> 00:12:34.253
그럼 여기 10달러 드리고 10달러는 빚지겠습니다. 그런데 당신도 제게 20달러 빚졌지요.

00:12:34.253 --> 00:12:35.045
여기 10달러 드리겠습니다. 10달러는 빚진 것으로 하겠습니다.

00:12:35.045 --> 00:12:36.756
여기 제가 빚진 10달러입니다.

00:12:36.756 --> 00:12:37.882
좋습니다. 이제 우리 모두 빚이 없습니다.

00:12:39.091 --> 00:12:39.759
경제 전체가

00:12:39.759 --> 00:12:43.137
알트만의 프로젝트 성공에 묶여 있습니다.

00:12:43.554 --> 00:12:46.682
"우리가 망칠 수도 있습니다. 이게 우리가 거는 베팅이고,

00:12:46.682 --> 00:12:50.394
그에 따른 위험도 감수합니다." 그런데 그 베팅을 하는 '우리'는 누구입니까?

00:12:50.561 --> 00:12:52.772
OpenAI의 CFO를 들어보겠습니다.

00:12:52.772 --> 00:12:55.775
은행, 프라이빗 에쿼티, 어쩌면,

00:12:56.442 --> 00:12:59.445
정부도요,

00:12:59.487 --> 00:13:02.656
정부가 개입할 수 있는 방식들, 예를 들면 연방 보조금 같은 것들, 또는,

00:13:03.115 --> 00:13:05.576
그러니까, 우선은, 그,

00:13:05.576 --> 00:13:09.288
금융이 성사되도록 하는 안전망과 보증 같은 것들입니다.

00:13:09.747 --> 00:13:10.873
그 모든 더듬거림 속에서도

00:13:10.873 --> 00:13:14.627
OpenAI의 CFO가 말하려는 요점은 분명합니다.

00:13:14.794 --> 00:13:19.840
정부, 즉 여러분의 세금이 AI 프로젝트를 구할 책임을 지게 된다는 겁니다.

00:13:20.132 --> 00:13:22.927
그건 더 많은 계란을

00:13:22.927 --> 00:13:24.386
바구니에 담는 일입니다.

00:13:24.386 --> 00:13:27.681
그리고 그 바구니는 샘 알트만의 약속 위에 놓여 있는데,

00:13:27.681 --> 00:13:31.101
우리가 봤듯이 그는 거짓말을 하고 약속을 자주 어깁니다.

00:13:32.311 --> 00:13:34.772
그러니 우리가 정말로

00:13:34.772 --> 00:13:36.065
그 바구니를 들여다본다면,

00:13:36.065 --> 00:13:39.068
그 안에 그렇게 많은 계란을 담지 말았어야 했는지도 모릅니다.

00:13:39.401 --> 00:13:40.528
그리고 상황은 더 나빠집니다.

00:13:40.528 --> 00:13:45.574
우리가 이 영상을 편집하던 중, OpenAI가 7,500억 달러의

00:13:45.574 --> 00:13:48.786
가치 평가를 추진 중이며 Amazon과

00:13:48.786 --> 00:13:51.789
100억 달러 투자를 두고 논의 중이라는 소식이 나왔습니다.

00:13:52.039 --> 00:13:54.834
그 돈은 OpenAI가

00:13:54.834 --> 00:13:57.837
아마존 인프라에 쓰게 될 돈입니다. 그래서

00:13:58.587 --> 00:14:00.130
계란이 더 필요하겠습니다.
