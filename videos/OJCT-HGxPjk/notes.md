# Training General Robots for Any Task: Physical Intelligence’s Karol Hausman and Tobi Springenberg

1. 로보틱스의 병목은 하드웨어가 아니라 “지능”이며, 파운데이션 모델/엔드투엔드 학습이 이를 풀 열쇠라는 관점을 제시한다.
2. 핵심 난제는 일반화와 성능(긴 꼬리)이고, 이를 위해 배포를 통한 데이터 루프와 “경험으로부터의 학습(RL)”을 강조한다.
3. VLM+액션 모델로 시작해 데이터 스케일링·가치 함수·지속적(에 가까운) 학습으로 확장하며, 특정 앱 회사로 수렴하는 함정을 피하려 한다.

## Chapter 1: 지능 병목과 파운데이션 모델 미션 (00:00-04:50)
- [00:00] 범용 학습 알고리즘에 데이터를 넣으면 “어째서인지” 이해하고 이전 방식보다 더 잘해내는 현상이 놀랍다고 언급.
- [00:17] 이 현상이 로봇뿐 아니라 비전·언어·소리 등 다양한 모달리티 전반에서 관찰된다고 강조.
- [00:25] “실제로 작동한다”는 사실 자체가 충격적이라고 말함.
> "[00:29] 그리고 실제로 작동한다는 것 자체가 정말로 충격적일 정도입니다" — (발언자 미상)
- [00:49] 카롤·토비(Physical Intelligence)와 함께 로보틱스를 위한 파운데이션 모델을 만드는 접근을 다룬다고 소개.
- [00:56] 로보틱스를 인식·계획·제어로 나누는 고전적 접근이 왜 근본적으로 잘못됐는지 논의 예고.
- [01:03] 엔드투엔드 강화학습 기반 학습이 실제 배치를 가능하게 만든다는 주장 예고.
- [01:09] 로봇이 13시간 커피를 만들게 한 사례, 전혀 다른 과업으로의 일반화, 수술 로봇·드론 비행까지의 확장 가능성을 언급.
- [01:20] `π*0.6`의 기술적 통찰(“경험으로부터 학습”, RL 활용)을 예고.
- [01:43] 회사 미션: “어떤 로봇이든 어떤 과업이든 수행”할 수 있는 로보틱 파운데이션 모델 개발.
- [01:57] 지난 약 1년 반 동안 구축을 시작했고, 확장 가능한 올바른 구성요소들을 마련했다고 설명.
- [02:09] 다양한 로봇 폼팩터를 제어 가능함을 보였고, 새로운 환경으로 가져가도 일반화가 가능함을 시연했다고 말함.
- [02:22] `π*0.6`이 배포 가능한 수준으로 성능을 끌어올리는 방법을 보여준다고 강조.
- [02:38] 로봇 행동 데이터는 인터넷처럼 “무료 데이터” 혜택을 누리기 어려워 데이터셋을 직접 만들어야 한다는 제약을 설명.
- [03:22] 로봇공학의 병목은 하드웨어가 아니라 “지능”이었다는 관점을 제시(인간이 뒤에 있으면 하드웨어는 이미 많은 일을 할 수 있었다는 주장).
- [03:47] “원격 조종일 때”가 단서: 인간 두뇌가 붙으면 하드웨어가 다양한 일을 해낸다는 점을 강조.
- [04:02] 기존 회사들이 특정 로봇을 특정 작업/응용에 맞춰 설계해 왔다고 지적.
- [04:10] 병목(지능)에 집중해 이를 해결해야 로봇이 현실화된다고 주장.
- [04:36] 지능 병목이 풀리면 가정·산업 등 사실상 어디에든 배포될 것이라고 전망.
- [04:50] 옵티머스 손이 “예술 작품” 같을 정도로 정교하다고 언급하며 하드웨어 화제로 전환 예고.

## Chapter 2: 일반화·배포와 데이터 경제성 (06:59-12:22)
- [06:59] 앞에서 보여준 내용은 “기본적으로 가능하다”는 점을 시사한다고 정리.
- [07:02] 어떤 작업이든 어떤 로봇이든 데이터를 수집할 수만 있다면 자동화·학습이 가능하다고 전제.
- [07:10] 다음 과제는 일반화이며 아직 열린 문제라고 강조.
- [07:14] 목표: 로봇이 제로샷으로 새 집 같은 낯선 환경에서도 바로 작동하는 수준.
- [07:25] 새 집 일반화에 필요한 요소(물건 위치, 다른 조리대/조명 등)가 많아 매우 어렵다고 재강조.
- [07:35] “해결됐다”고는 말하지 않지만, 어떻게 풀지/어떻게 스케일되는지 감을 잡기 시작했다고 말함.
- [07:43] 일반화의 핵심 가설로 데이터 다양성을 제시하고, 다양한 데이터셋을 많이 보면 유사 환경으로 일반화해야 한다고 설명.
> "[07:43] 머신러닝에서 일반화에 대한 유일한 해답은 결국 데이터의 다양성입니다." — (발화자 미상)
- [07:55] `π0.5`(4월 공개)에서 이 가설을 확인했다고 언급.
- [08:00] 로봇을 완전히 새로운 집으로 데려가도 실제로 작동할 수 있는 수준까지 왔다고 말함(완벽하진 않음).
- [08:12] 남은 마지막 과제는 “아직 완전히 해결되지 않은 성능 문제”이며, 배포 가능한 성능까지 끌어올리는 것이 목표.
- [08:22] 배포의 중요성: 데이터를 계속 모아야 하며, 배포가 가장 확장 가능한 데이터 수집 방법이 될 것이라고 봄.
- [08:32] 배포가 데이터 수집을 경제적으로 바꾸는 논리(가치 있는 일을 하며 데이터가 쌓이면 수집 비용이 사실상 ‘마이너스’가 됨).
> "[08:37] 그 데이터 수집 비용은 사실상 마이너스가 되며," — (발화자 미상)
- [09:12] 로봇 배포가 “꽤 가까워졌다”고 평가하며 실제 배포를 시작했다고 말함.
- [09:21] 상업 환경 배포까지 5년쯤 걸릴 줄 알았는데 “두 달 전쯤 이미 해냈다”고 언급.
- [09:37] 모델이 유용하고 성능이 충분히 좋고 다양한 작업을 수행할 수 있어 “실제로 쓸 만한 수준”이 됐다고 표현.
- [09:53] 다만 적용 범위는 아직 더 지켜봐야 하며, 실패가 치명적인 작업이나 가정 배포(프라이버시/안전)는 초기 배포처로 최적이 아닐 수 있다고 언급.
- [10:27] 파운데이션 모델은 역량을 사전에 예측하기 어렵고, 결국 실제로 테스트해야 한다고 설명.
> "[10:52] 실제로 테스트를 해봐야 하고," — (발언자 미상)
- [10:56] 오픈소스 공개 이유: 자신들만 테스트하며 병목이 되지 않게 하고, 예상보다 다양한 응용이 나올 수 있다고 봄.
- [11:34] 적용 범위의 출발점은 넓지만, 사람들이 일상적으로 쓰려면 성능은 아직 할 일이 많다고 말함.
- [12:00] `π*0.6`에서 “경험으로부터 학습”에 진전이 있었고, 배포된 상태에서도 개선이 이뤄졌음을 시사.
- [12:12] 근본적 어려움으로 긴 꼬리(long tail) 문제를 들며, 완전한 해결에 대한 이해가 아직 부족하다고 솔직히 말함.

## Chapter 3: 현재 아키텍처와 스케일링(데이터/모델) (12:27-16:03)
- [12:27] 질문: 아키텍처가 거의 굳었는지, 데이터만 더 모으면 되는지, 아키텍처 변화가 필요한지.
- [12:55] 답변: 둘 다 열려 있으며, 현재 상태를 설명한 뒤 변화 가능성을 이야기하겠다고 함.
- [13:04] 현재 아키텍처는 VLM 구축 방식과 매우 유사하다고 설명.
- [13:23] 인터넷 규모 데이터로 학습된 모델을 바탕으로 이미지·텍스트를 받고, 여기에 로보틱스 데이터를 추가(현재는 대부분 직접 수집한 로봇 데이터).
- [13:41] 구성: 비전-언어 모델(VLM) + 옆에 액션 모델/액션 익스퍼트(로봇 구동 부분)를 더하는 형태.
- [14:00] 입력(이미지+지시)을 받아 작업을 수행하고 로봇에 행동 명령을 출력해야 한다고 설명.
- [14:05] 전반적으로 트랜스포머 기반의 큰 모델이며, 수십억 파라미터까지 사용한다고 언급.
- [14:12] 사전학습 후 로보틱스+인터넷 데이터로 학습하며, 초기에는 인간 시연(원격조작) 데이터로 학습한다고 설명.
- [14:32] 스케일링 성과는 주로 데이터 규모를 키우는 데서 나온다고 봄.
- [14:39] 향후 아키텍처 변화는 열린 질문이며, 더 많은 컨텍스트/카메라/물리 세계 이해 등 확장 기회가 많다고 말함.
- [15:22] 5~6년 뒤에는 모델 백본이 지금의 VLM 계열에서 다른 것으로 진화했을 수 있지만, 데이터 기반과 “데이터를 모델에 넣는 방식”은 비슷하게 남을 수 있다고 전망.
- [15:50] “픽셀/신호 입력 → 행동 출력” 관점에서 하나의 큰 신경망이 입력(이미지/텍스트)을 받아 출력(텍스트/행동)을 내는 형태로 정리.
> "[14:43] 열린 질문이라고 생각합니다." — (화자 미상)  
> "[15:23] 5~6년쯤 후에 우리가 돌아보며 '아, 아마 그때의 모델 백본이 … 이미 바뀌었을지도'…" — (화자 미상)

## Chapter 4: 전통적 로봇 스택(인지·계획·제어)과 그 한계 (16:05-18:12)
- [16:05] 질문: 이동과 조작을 구분한 별도 스택이 있는지, 로보틱스 학습의 역사적 흐름이 현재 스택과 어떻게 연결되는지.
- [16:21] 과거에는 엔지니어가 충분히 코드를 쓰면 로봇이 무엇이든 하게 만들 수 있다고 생각해 왔다고 설명.
- [16:43] 현실 세계는 너무 복잡해 모든 경우를 코드로 열거하는 방식은 작동하지 않았다고 말함.
- [16:57] 그 결과 문제를 인지/제어/계획 같은 더 작은 하위 문제로 쪼개는 접근이 등장했고, 각 분야가 별도 커뮤니티로 분화했다고 언급.
- [17:21] 이후 “데이터로부터 학습”으로 이동했지만, 여전히 하위 요소를 분리해 각각 학습하는 방식이 주로 시도됐고 한계가 드러났다고 말함.
- [17:58] 인간은 “인지→계획→제어”를 단계적으로 의식하지 않고 바로 행동한다는 비유로, 파이프라인 인터페이스가 무너지는 지점을 설명.
> "[16:43] 결국 세상은 너무나 복잡하다는 것이 드러났습니다." — (화자 미상)  
> "[18:00] 제가 이 잔을 집어 들려고 할 때 저는 그것을 인지하고 그다음 계획하고 그다음 제어한다고 생각하지 않고, 그냥 바로 손을 뻗어서 잔을 집어 듭니다." — (화자 미상)

## Chapter 5: 작업 분해(플래닝)와 물리적 계획 감각 (20:59-22:40)
- [20:59] 상위 지시(예: “부엌을 청소해”)를 받으면 첫 하위 과제를 고르고 필요한 행동을 순서대로 떠올리는 분해가 이미 가능하다고 봄.
- [21:06] 예: 카운터로 이동 → 유리컵 집기 → 싱크대로 옮기기처럼 구체 행동을 단계화.
- [21:20] 상위 과제를 스스로 부여하고, 짧은 행동 지평(몇 단계)을 예측하는 형태로 이해할 수 있다고 설명.
- [21:31] “추론을 위한 학습” 등 최근 발전이 로보틱스에도 유입되며 이런 능력이 강화될 것으로 기대.
> "[21:01] 예를 들어 ‘부엌을 청소해’라고 시키면" — 화자  
> "[21:08] 카운터로 이동해야 하고… 유리컵을 집어 싱크대로 옮겨야 한다" — 화자
- [21:46] 수학 같은 텍스트 기반 RL과 로보틱스/물리적 지능은 성격이 다를 수 있다고 봄.
- [21:52] 텍스트 문제는 인간에게 쉬워 텍스트로 조작(공식 변형 등)하기 편하지만,
- [22:07] 물리적 지능은 텍스트적 사고보다 “동작 자체”를 떠올리는 쪽에 가깝다고 설명.
- [22:14] 새 스포츠(테니스 등)를 배울 때 문장형 계획보다 몸의 움직임/감각 중심으로 사고한다는 예를 듦.
- [22:33] 물체의 궤적이 주변에서 어떻게 움직일지 머릿속으로 그리며 계획하는 느낌에 가깝다고 말함.
- [22:40] 시간이 지나며 이런 동작·궤적 중심 계획 방식이 모델에도 더 반영될 것으로 전망.

## Chapter 6: 멀티-스페이스 추론, 데이터 정의, RL로의 전환 (22:47-25:59)
- [22:47] 지금은 VLM에서 큰 혜택을 보지만 장기적으로는 흐름이 “거꾸로” 될 수 있다고 전망.
- [22:58] 오늘날 LLM 한계 일부가 수학·코딩 같은 텍스트 문제 중심 최적화와 연관될 수 있다고 봄.
- [23:10] 로보틱스가 “추론을 어떻게 생각할지”를 다시 고민하게 만들 것이라 주장.
- [23:14] 추론은 단일 텍스트 공간이 아니라 여러 추상 공간(텍스트/이미지/궤적 등)을 오가며 이뤄질 수 있다고 설명.
- [23:28] 로보틱스는 물리 세계 기반의 좋은 테스트베드지만, 데이터가 아직 충분치 않아 어려움이 따른다고 언급.
- [23:45] 이 과정의 발견이 다시 LLM 세계에도 재적용될 수 있다고 봄.
- [23:49] 데이터 규모 측정/현재 수집량/향후 수집 계획을 어떻게 보느냐는 질문이 나옴.
- [24:08] 데이터는 단순 “양”만의 문제가 아니며, 품질·다양성이 중요하지만 로봇 데이터에서 이를 엄밀히 정의하기 어렵다고 지적.
- [24:26] 같은 작업을 10가지 방식으로 한 다양성과, 10개의 다른 컵을 집는 다양성을 어떻게 비교할지 불명확하다고 예시.
- [24:37] 커뮤니티 차원에서 데이터 특성화(다양성·품질 기술) 방법을 아직 완전히 이해하지 못했다고 말함.
- [24:59] 어떤 작업은 일정 수준 이후 “데이터 양만 늘려도” 계속 좋아지지 않는 정체 구간이 있다고 설명.
- [25:04] 같은 방식으로 더 수집해도 성능이 더 이상 개선되지 않았다고 함.
- [25:08] `π`와 `π*0.6` 릴리스를 위해 3가지 과제로 작업하며 이를 초반부터 체감했다고 언급.
- [25:22] 새로운 방식으로 데이터를 수집하거나 “어떤 데이터가 더 나은 성능으로 이어지는지”로 사고를 전환해야 한다고 말함.
- [25:31] 이 지점에서 강화학습(RL) 같은 접근이 큰 도움이 된다고 연결.
- [25:40] `π*` 명명 의미(Q* 연상/최적 정책 의미 등)를 질문하는 흐름이 나오고,
- [25:51] `π*0.6`에서 무엇을 하는지 한마디로 설명해 달라는 요청으로 구간이 넘어감.

## Chapter 7: 배포 요구, 배포 데이터, ‘Age of Experience’와 지속적 학습 (34:59-39:34)
- [34:59] 커피 제조 모델을 고객 현장에 안정적으로 배포 가능하게 만든 것이 배포 혁신인지 근본 역량 혁신인지(혹은 둘 다인지) 질문.
- [35:20] 답변: 둘 다라는 입장(배포 가능성 자체가 역량과 연결됨).
- [35:26] “정말 원하는 로봇”: 집에서 세탁/설거지/요리, 돌아다니며 운전까지 하는 범용 로봇을 언급.
- [35:34] 소규모 사업장에서도 실제 문제를 해결하는 로봇 수요가 있다고 말함.
- [35:40] 전통적 자동화를 원치 않는 이유는 비용이 너무 비싸기 때문이라고 설명(예: 초콜릿 상자 만들기).
- [35:44] 이런 과업은 신뢰성·성능·새 과업 일반화 역량이 필요하다고 강조.
> "[35:40] 전통적인 방식으로 자동화하고 싶지 않은데, 그 이유는 그것이 너무 비싸기 때문입니다." — (발언자 미상)  
> "[35:48] 초기 훈련에서 보지 못한 새로운 과업을 해낼 수 있는 역량도 필요합니다." — (발언자 미상)
- [35:54] 인간 데이터만 더 모으고 모델을 더 키우는 것만으로는 비현실적이라는 견해(데이터 상한, 초기 정책 품질 한계).
- [36:11] 앞으로 몇 년은 배포로부터 얻는 데이터가 사전학습 원천으로 매우 가치 있어질 것이라고 전망.
- [36:28] 시간이 갈수록 자율 데이터 수집에 더 의존하게 될 것으로 보고, “볼록 껍질(컨벡스 헐)” 같은 방대한 데이터로 과업을 수행·보간하는 새 역량을 기대.
> "[36:21] 이 배포를 하게 되고 그 데이터가 실제로 아주 가치 있어질 것이라고 생각합니다. 모델을 더 좋게 만드는 사전학습의 원천으로서요." — (발언자 미상)  
> "[36:37] 우리가 로봇이 결국 하길 원하는 모든 과업의 볼록 껍질(컨벡스 헐)이 되는 방대한 데이터를 구축해서," — (발언자 미상)
- [36:52] 로봇이 자기 경험으로부터 배우는 방법을 완전히 알아내지 못했고, 규모 있게 배포 가능한 결과를 본 적이 없다고 인정.
- [37:07] 이번 결과는 자기 경험 학습으로 가는 중요한 “첫걸음”을 보여준 것이라고 평가.
- [37:13] 인간 학습 비유: 결국 현장에서 직접 해보고, 행동이 목표에 미치는 피드백을 관찰하며 스스로 결론 내리고 다시 시도한다고 설명.
> "[37:23] 어느 시점에는 결국 현장에서 배우셔야 하고, 직접 그 일을 해 보셔야 하며," — (발언자 미상)
- [37:36] ‘Age of Experience’ 맥락에서 이것이 로보틱스의 지속적 학습을 가능하게 하는지 질문.
- [37:49] 정의에 따라 다르지만, 이전보다 더 지속적이라는 건 맞다고 답변(과거 산출물 모델은 완성 후 바꾸기 어려움).
- [38:13] 지향은 더 “살아 있는” 시스템: 배포 후에도 계속 학습하며 자기 경험에서 배우는 방식.
- [38:43] 추론도 전 과정에서 가능해질 수 있고 “직무 중 얼마나 학습하느냐”는 스펙트럼이 있다고 언급.
- [38:57] 다른 발언자: 고전적 의미의 continual learning과는 다르지만 첫걸음이며, 사람의 수정만으로도 성능이 개선되는 점을 강조하려는 흐름.
> "[38:21] 배포하고 나면 계속 학습하잖아요, 그래서 훨씬 그 의미에서 더 지속적이고," — (발언자 미상)  
> "[39:03] 고전적 의미의 지속적 학습은 확실히 아닙니다." — (발언자 미상)

## Chapter 8: 배포 루프, RL 피드백, 가치 함수(value function) (41:58-46:19)
- [41:58] 제로샷 성능이 나타나지만 계속 개선 중이라고 언급.
- [42:04] 일정 주기로 사전학습 런을 반복하며, 매번 더 많은 데이터와 개선으로 모델이 좋아짐을 관찰.
- [42:18] 모델을 더 많이 배포할수록 데이터가 되돌아와 일반화가 늘어나는 선순환(배포→데이터 회수→개선→더 많은 배포)을 강조.
> “[42:31] 여러분이 이 모델들을 배포하면, 그 데이터가 돌아오고 모델은 더 좋아져서, 여러분은 더 많이 배포할 수 있으며… 이런 식입니다.” — (화자 미상)
- [42:47] “5~6단계 레시피”의 디테일: 모델이 두 부분으로 구성됨(정책과 RL 피드백을 얻는 메커니즘).
- [43:02] 인간 교정과 RL 피드백은 성격이 다르며, RL 피드백은 어느 정도 일반화 성격을 이미 가진다고 봄.
- [43:15] RL 피드백 수집: 각 에피소드 성공/실패 라벨을 사람에게 받아,
- [43:29] 라벨된 에피소드로 가치 함수를 학습.
- [43:32] 가치 함수는 현재 상태에서 성공/실패 가능성을 예측하고, 학습에서 기준선처럼 “무엇을 올릴지/내릴지” 판단에 활용.
- [44:02] 정책과 유사한 백본에서 파생되지만 정책 학습 전에 가치 함수를 먼저 사전학습한다고 설명.
- [44:15] 서로 다른 작업 데이터가 가치 함수 성능을 개선하며, 일부 작업에선 실패를 미리 감지 가능하다고 언급.
- [44:30] 포터필터를 커피 머신에 끼우는 예: 잘못된 각도로 실패할 것을 30~40스텝 전에 가치 함수 예측 하락으로 감지.
- [44:54] “좋지 않은” 에피소드를 데이터에 포함하지 않는 의사결정으로 이어진다고 설명.
- [45:00] 과제/데이터 다양성이 커질수록 가치 함수가 좋아지는 점을 흥미로운 대조로 언급(카르파티 ‘빨대로 조금씩’ 비유 연결).
- [45:20] RL을 특정 알고리즘(정책 그래디언트/온-폴리시)로만 보지 않고 “문제 정의”에 가깝다고 설명.
- [45:39] 보상이 끝에서만 주어지는 긴 지평 과제는 그대로 확장 불가하므로, 가치 함수·TD 학습 등 연속 예측으로 푸는 접근을 듦.
- [46:02] 로봇은 언어처럼 완벽한 시뮬레이터에서 무한 시뮬레이션을 돌릴 수 없어 실제 세계에서 더 효율적인 방법이 필요하고, 이런 접근이 다른 분야에도 가치가 있을 수 있다고 주장.
- [46:19] 인터넷 비디오가 레시피 일부지만 큰 초점은 아닌 듯한데, 그 안의 ‘금(gold)’을 어떻게 보는지 질문이 이어짐.

## Chapter 9: 상용화/전략, ‘앱 회사’ 함정, 신뢰도와 타임라인 (48:59-53:44)
- [48:59] 여러 접근법이 근본적으로 비슷한 문제를 겨냥하고 있으며 다양한 방법을 탐색 중이라고 설명.
- [49:06] 반사실(카운터팩추얼) 문제를 실제로 어떻게 풀지 핵심 난제로 남아 있고, 정답이 있다고 말하긴 어렵다고 언급.
- [49:14] 그럼에도 RL 쪽에서 진전이 있었고 `π*`/`π*0.6`에서도 확인했다고 말함.
- [49:28] 부트스트랩을 넘어 고객 배포 시 “무엇을 가져가고 무엇을 판매하는지” GTM/상용화 형태를 질문.
- [49:45] 답변: 진짜 답은 아직 모르며 알아가는 중이고 기술적으로도 초기 단계라고 솔직히 말함.
- [49:56] 배포 가능 임계치에 도달해 배포를 시작할 수 있게 됐다고 설명.
- [50:03] 우선순위는 기술을 정말 쉽게 배포 가능한 수준까지 끌어올리고 적용 범위를 확장하는 것.
- [50:12] 전형적 스타트업 경로(범용 비전→특정 앱 선택→특수 목적 최적화→앱 회사)가 되는 것을 경계.
- [50:45] 창고 피킹&플레이스에만 매몰되는 미래를 예로 들며 피하고 싶다고 말함.
- [50:53] “물리적 지능” 자체를 해결할 기회가 있고 가치가 단일 애플리케이션보다 훨씬 크다고 주장.
- [51:03] 기술을 범용적·배포 용이·적용 범위 최대화에 맞춘 뒤 상용화를 고민하겠다고 함.
- [51:15] 모델 제공자/수직 통합/로봇 판매 등 여러 상용화 방식이 가능하나 지금 답하기엔 이르다고 말함.
- [52:06] 자율주행 사례를 들어 일반화와 성능의 타임라인 감각을 얼마나 길게 보느냐 질문.
- [53:09] 어떤 면은 자율주행보다 쉽고 어떤 면은 더 어렵다고 전제.
- [53:17] 더 쉬운 점: 100% 신뢰할 수 있을 때만 배포할 필요는 없다고 설명.
- [53:23] 신뢰도 95%만으로도 유용한 작업이 많다고 말함(예: 빨래 개기에서 100번 중 1번 실패는 치명적이지 않음).
- [53:44] 자율주행은 100번 중 1번 치명적 실패가 큰 문제라 요구치가 훨씬 엄격하다고 대비.
> "[49:45] 진짜 답은 저희가 아직 모른다는 것입니다." — (발언자 미상)  
> "[53:21] 우리가 100% 신뢰할 수 있을 때만 배포할 필요는 없다는 점입니다." — (발언자 미상)

## Chapter 10: 마무리 메모 — 범용 학습, 쪼개기 vs 통합, 경험에서 배우기 (55:59-60:26)
- [55:59] 최근 모델 성과가 놀랍고, 여기까지 왔다는 사실 자체가 경이롭다고 말함.
- [56:15] 단순한 다음 토큰 예측에서 이렇게 지능적으로 보이는 모델이 나온다는 게 아직도 믿기지 않는다고 강조.
- [56:24] IMO 우승, 수학 챌린지 우승, 과학에서의 발견 등 작은 진전 하나하나가 충격적이라고 언급.
- [56:41] 연초엔 사전학습 비즈니스가 시들해지는 듯했지만 지금은 두 번째 숨결/신선한 공기가 들어오는 느낌이라고 함.
- [56:54] 무엇보다 “이 모든 게 실제로 작동한다”는 사실이 충격적이라고 반복.
> "[56:56] 이 모든 게 실제로 작동한다는 사실 자체가 정말 충격적입니다." — (화자 미상)
- [57:05] 뇌에서 느슨하게 영감 받은 시스템에 범용 학습 알고리즘과 데이터를 주면, 어떤 식으로든 이해해 이전보다 더 잘해낸다고 설명.
- [57:17] 이 접근이 로봇/시각/언어/소리 등 다양한 영역에 적용된다고 말함.
- [57:33] 로봇이 처음 가본 집에서 무엇을 해야 하는지 알거나 13시간 커피를 내리는 일이 가능해진다고 예시.
- [57:48] 이런 능력이 완전히 엔드투엔드 학습에서 나오며, 완전히 이해하진 못하지만 이해하기 시작하는 듯 보인다고 말함.
- [57:57] “우리는 시뮬레이션 속에 살고 있다”는 발언과 함께 소냐가 시뮬레이션을 믿는다는 언급을 덧붙임.
> "[57:57] 우리는 시뮬레이션 속에 살고 있습니다." — (화자 미상)
- [58:05] 큰 문제를 더 작은 문제로 쪼개라는 전통이 있지만, 기계/로봇 훈련의 최선이 아닐 수 있다는 깨달음이 나온다고 설명.
- [58:17] ML/AI도 오랫동안 개별 문제를 깊게 파고드는 “같은 실수”를 어느 정도 저질렀다고 자기비판.
- [58:32] 멀티태스크를 일반적 사전학습 목표로 바꾸자 많은 것들이 “저절로 따라 나온다”는 점이 놀랍다고 강조.
- [58:47] 쪼개기↔통합을 아코디언처럼 오가게 되는지 질문에,
- [59:00] 다시 쪼개기 중심으로 돌아가진 않을 것 같다고 단언.
- [59:05] 이미 아는 규칙(뉴턴 역학 등)을 가중치에 통합해 “양쪽 장점”을 가져오자는 주장에 대해, 지금까지 본 바로는 잘 되지 않는다고 반박.
- [59:25] 규칙을 억지로 넣으면 새로운 것을 배우는 능력을 제한하기 쉽고, “양쪽 장점”은 없으며 끝까지 학습으로 가야 한다고 주장.
- [59:35] 이런 관점이 인간 학습과 비슷하다고 연결(진화가 미리 구워 넣을 수 있었다면 했을 것, 인간은 발달 단계가 있고 경험에서 배워야 함).
- [60:00] 인간은 처음부터 완성된 지능이 아니라 자기 경험으로부터 배워야 한다고 설명.
- [60:12] 어느 정도는 스스로 쟁취해야 하며 그 점에 의미가 있다고 봄.
- [60:20] 결국 “세상을 경험하고 거기서 배워야 한다”는 것이 교훈이라고 정리.
- [60:26] ML/AI도 우리가 사고를 안다고 착각하지만 실제로는 모르니, 알고리즘이 데이터에서 배우게 해야 한다고 말함(아이를 키우는 것에 비유).