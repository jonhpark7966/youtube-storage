WEBVTT

00:00:44.520 --> 00:00:49.480
저희 시청자 대부분은 인도에서 창업가가 되고 싶어 하시는 분들입니다.

00:00:49.560 --> 00:00:53.160
그리고 저희 모두가 당신에게서 배울 것이 정말 많다고 느낍니다.

00:00:53.240 --> 00:00:56.600
왜냐하면 당신은 정말 다양한 분야에서 그 일을 여러 번 해내셨기 때문입니다.

00:00:56.680 --> 00:00:58.840
그래서 오늘 그분들과 이야기를 나눠보겠습니다.

00:00:58.920 --> 00:01:03.160
그리고 제 모든 질문을 그 방향에 맞추도록 하겠습니다.

00:01:03.240 --> 00:01:05.200
그래서 이 대화를 최대한 활용하실 수 있도록 하겠습니다.

00:01:05.280 --> 00:01:08.240
그리고 어쩌면—한번 도전해 무언가를 만들어 보실 수도 있습니다.

00:01:25.520 --> 00:01:27.000
커피 한 잔 드시겠습니까?

00:01:27.080 --> 00:01:28.560
음...

00:01:28.640 --> 00:01:29.720
-네, 좋습니다. -알겠습니다.

00:01:30.560 --> 00:01:32.080
우리 한동안 이야기하게 됩니까?

00:01:32.160 --> 00:01:33.840
-[웃음] -그러기를 바랍니다.

00:01:33.920 --> 00:01:35.560
좋습니다. 네.

00:01:36.960 --> 00:01:38.120
-음... -메가나?

00:01:38.200 --> 00:01:39.480
커피 한 잔 부탁드려도 되겠습니까?

00:01:39.560 --> 00:01:41.240
커피 한 잔 더 부탁드릴 수 있습니까?

00:01:41.320 --> 00:01:43.120
-[메가나] 아무거나 괜찮으십니까? -어...

00:01:43.200 --> 00:01:44.400
카푸치노로 하겠습니다.

00:01:44.480 --> 00:01:45.520
[메가나] 카푸치노요? 알겠습니다.

00:01:45.600 --> 00:01:47.000
일론, 커피는 즐겨 드십니까?

00:01:47.080 --> 00:01:48.160
-네, 네. -네?

00:01:48.240 --> 00:01:49.280
네, 커피는 한 번 정도 마십니다.

00:01:49.360 --> 00:01:51.080
-보통 아침에 마십니다. -알겠습니다.

00:01:51.160 --> 00:01:53.960
-하루에 한 잔 정도입니까? -네, 거의 그렇습니다.

00:01:58.600 --> 00:01:59.760
나올 때까지 기다리시겠습니까?

00:01:59.840 --> 00:02:02.200
아니요, 저는 괜찮습니다.

00:02:04.440 --> 00:02:05.960
[웃음]

00:02:07.360 --> 00:02:09.200
제가 먼저 꼭 말씀드려야 할 것이 있습니다.

00:02:09.280 --> 00:02:13.640
생각했던 것보다 훨씬 더 크고 덩치가 있으시고, 근육질이십니다.

00:02:13.720 --> 00:02:14.960
제가 생각했던 것보다 훨씬 그렇습니다.

00:02:15.040 --> 00:02:17.320
그만하세요, 얼굴이 붉어지겠습니다.

00:02:19.360 --> 00:02:20.480
정말입니다. 진심입니다.

00:02:22.040 --> 00:02:24.360
그러니까, 인터넷에서는 제가 작아 보이지 않습니까?

00:02:28.800 --> 00:02:30.320
사실상...

00:02:31.640 --> 00:02:35.080
인터넷 사용량 중 트위터에 쓰이는 비율이 어느 정도입니까?

00:02:35.160 --> 00:02:37.040
그게 숫자로 나옵니까? X 말입니다.

00:02:37.120 --> 00:02:42.040
그러니까, 저희는 월간 사용자 수가 대략 6억 명 정도입니다.

00:02:43.400 --> 00:02:47.680
다만 세계적인 큰 사건이 있으면 급증할 수 있습니다.

00:02:47.760 --> 00:02:51.840
그러면, 글쎄요, 8억 명이나 10억 명까지도 올라갈 수 있습니다.

00:02:52.600 --> 00:02:54.760
세계적인 큰 사건이 있으면 그렇습니다.

00:02:58.520 --> 00:03:02.360
글쎄요, 주간으로는 대략 2억 5천만에서 3억 명 정도라고 보시면 됩니다.

00:03:03.160 --> 00:03:04.600
꽤 괜찮은 숫자입니다.

00:03:04.680 --> 00:03:09.520
대체로 독자들, 그러니까 글을 읽는 사람들이 많습니다.

00:03:11.360 --> 00:03:12.720
그러니까 그렇습니다.

00:03:12.800 --> 00:03:14.440
그것이 바뀔 것이라고 보십니까?

00:03:14.520 --> 00:03:16.000
네, 그러니까, 그런 부분이 있습니다.

00:03:17.920 --> 00:03:21.720
X 시스템에는 확실히 영상이 많습니다.

00:03:21.800 --> 00:03:24.560
하지만 현시점에서는... 영상이 점점 더 늘고 있습니다.

00:03:24.640 --> 00:03:31.000
하지만 제가 보기에는 X 네트워크가 가장 강한 곳이 어디인지 말씀드리겠습니다.

00:03:31.080 --> 00:03:36.400
그것은 많이 생각하고 많이 읽는 사람들 사이입니다.

00:03:36.480 --> 00:03:39.120
그러니까, 그쪽에서 가장 강해질 것입니다.

00:03:39.200 --> 00:03:40.400
왜냐하면 우리는 글이 있기 때문입니다.

00:03:41.800 --> 00:03:43.320
그리고, 그러니 말입니다.

00:03:45.440 --> 00:03:51.000
독자, 작가, 사상가들 사이에서는 X가 세계 1위라고 생각합니다.

00:03:52.080 --> 00:03:56.880
소셜 미디어 관점에서 그 형식 자체를 놓고 보면 어떻습니까?

00:03:56.960 --> 00:03:59.200
내일을 기준으로 추측해 본다면 말입니다.

00:03:59.280 --> 00:04:01.720
-네. -...텍스트가 얼마나 되고, 영상이 얼마나 될까요?

00:04:02.880 --> 00:04:06.360
AI와의 다음 소통 방식으로 음성과 청각에 대해 말씀하신 것을 들었습니다.

00:04:06.440 --> 00:04:09.240
AI와의 다음 소통 형태가 될 수 있다는 말씀이었습니다.

00:04:09.320 --> 00:04:14.080
X의 본래 형태는 어떻게 됩니까? 어떻게 진화합니까?

00:04:15.640 --> 00:04:20.240
네, 그래서 저는 앞으로 대부분의 상호작용이 영상이 될 것이라고 생각합니다.

00:04:20.320 --> 00:04:23.600
대부분의 상호작용은 AI와의 실시간 영상이 될 것입니다.

00:04:23.680 --> 00:04:27.160
즉 실시간 영상 이해와 실시간 영상 생성이 필요해질 것입니다.

00:04:28.200 --> 00:04:29.880
그것이 부하의 대부분을 차지할 것입니다.

00:04:29.960 --> 00:04:33.080
그리고 지금도 인터넷의 대부분이 그렇습니다.

00:04:33.160 --> 00:04:34.520
인터넷의 대부분은 영상입니다.

00:04:34.600 --> 00:04:36.920
텍스트는 비중이 꽤 작습니다.

00:04:37.000 --> 00:04:41.440
하지만 일반적으로 텍스트가 더 가치가 높은 경향이 있습니다.

00:04:41.520 --> 00:04:45.240
또는 그보다 더, 정보가 더 높은 밀도로 압축되어 있습니다.

00:04:48.280 --> 00:04:50.080
네, 그러니까요...

00:04:50.160 --> 00:04:55.800
하지만 생성되는 비트의 양과 소비되는 연산량이 가장 큰 것이 무엇이냐고 하면,

00:04:55.880 --> 00:04:57.000
확실히 영상일 것입니다.

00:04:58.000 --> 00:04:59.640
그래서 저는 예전에 X의 주주였습니다,

00:04:59.720 --> 00:05:00.920
-아주 소액이었지만요. -알겠습니다.

00:05:01.000 --> 00:05:04.240
그리고 당신이 트위터를 인수해 X로 만들었을 때 저는 대금을 받았습니다.

00:05:06.400 --> 00:05:10.160
-좋은 결정이었습니까? 하길 잘했다고 생각하십니까? -네, 네, 중요했다고 생각합니다.

00:05:11.880 --> 00:05:15.080
그러니까, 저는 트위터가... 어떤 방향으로 가고 있다고 느꼈습니다.

00:05:15.160 --> 00:05:17.040
또는 이미 어떤 방향으로 가 버렸고

00:05:17.120 --> 00:05:19.880
그 방향이 세상에 더 부정적인 영향을 미치고 있다고 생각했습니다.

00:05:21.120 --> 00:05:22.520
그건...

00:05:23.120 --> 00:05:25.200
물론 이는 사람의 관점에 따라 달라집니다.

00:05:25.280 --> 00:05:26.800
어떤 사람들은 '사실은'이라고 말할 것이고,

00:05:26.880 --> 00:05:28.880
예전의 방식이 좋았는데 지금은 마음에 들지 않는다고 말할 것입니다.

00:05:30.000 --> 00:05:34.120
하지만 근본적인 문제는...

00:05:36.240 --> 00:05:39.560
트위터가 증폭시키고 있었다는 점입니다...

00:05:39.640 --> 00:05:42.440
대부분의 기준으로 보면 상당히 급진적인 좌파 성향을

00:05:42.520 --> 00:05:43.880
전 세계 이념 스펙트럼에서 말입니다,

00:05:43.960 --> 00:05:46.120
샌프란시스코에 기반을 두고 있었기 때문입니다.

00:05:46.200 --> 00:05:50.040
그리고 실제로 우파 성향의 많은 사람들을 정지시켰습니다.

00:05:53.920 --> 00:05:55.240
그러니 그들의 관점에서는,

00:05:55.320 --> 00:05:58.000
중도에 있는 사람조차 극우로 보였을 것입니다.

00:05:58.080 --> 00:06:01.200
극좌에 있으면 중도에 있는 사람은 누구나 극우로 보이기 때문입니다...

00:06:02.760 --> 00:06:04.800
그건 그냥 정치적 스펙트럼에서,

00:06:05.840 --> 00:06:09.040
미국과 샌프란시스코에서는 가능한 한 가장 극좌에 가까운 수준이기 때문입니다.

00:06:09.120 --> 00:06:13.880
그래서 제가 하려던 것은 그것을 균형 잡힌 중도로 되돌리는 것이었습니다.

00:06:13.960 --> 00:06:16.440
그래서 좌파 목소리 중에는

00:06:16.520 --> 00:06:23.000
정지되거나 차단되거나 노출이 줄어들거나 그런 일을 당한 경우가 없었습니다.

00:06:23.080 --> 00:06:27.200
물론 그중 일부는 그냥 다른 곳으로 가기로 선택했지만...

00:06:28.440 --> 00:06:34.560
하지만 현재 X 시스템의 운영 원칙은

00:06:34.640 --> 00:06:37.920
어느 나라의 법이든 준수하는 것이고,

00:06:38.000 --> 00:06:41.520
그 나라의 법을 넘어서 저희가 저울을 특정 방향으로 기울이지 않는 것입니다.

00:06:44.000 --> 00:06:45.840
소셜 미디어를 생각하면...

00:06:47.000 --> 00:06:48.440
-아, 감사합니다. -감사합니다.

00:06:49.280 --> 00:06:51.080
일론, 소셜 미디어를 생각하면,

00:06:52.200 --> 00:06:57.080
제 느낌으로는... 데이터도 현재의 기존 강자들이

00:06:57.160 --> 00:07:01.360
가장 젊은 이용자층 사이에서 탄력을 잃어가는 것처럼 보입니다.

00:07:01.440 --> 00:07:02.440
네.

00:07:02.520 --> 00:07:04.800
인스타그램 같은 플랫폼도...

00:07:04.880 --> 00:07:08.800
물론 트위터와 완전히 같지는 않지만, 전반적인 플랫폼 전반에서 말입니다.

00:07:08.880 --> 00:07:13.600
만약 소셜 미디어를 다시 설계해서 바닥부터 무언가를 만든다면,

00:07:13.680 --> 00:07:16.280
미래의 세상에서는 무엇이 통할 것이라고 보십니까?

00:07:18.080 --> 00:07:21.720
음, 그러니까, 저는 그렇게 많이 생각하지는 않습니다...

00:07:24.120 --> 00:07:26.680
솔직히 말씀드리자면 말입니다. 그러니까, 그건...

00:07:26.760 --> 00:07:29.280
저는 주로... 뭔가가 있는 플랫폼을 원합니다.

00:07:32.000 --> 00:07:35.440
X의 경우에는 일종의 글로벌 타운 스퀘어 같은 것이 있고,

00:07:35.520 --> 00:07:41.480
사람들이 글, 사진, 영상으로 말하고 싶은 것을 말할 수 있으며,

00:07:43.160 --> 00:07:45.280
안전한 메시징 시스템이 있는 곳입니다.

00:07:45.360 --> 00:07:49.120
최근에는 음성 및 영상 통화를 할 수 있는 기능도 추가했습니다.

00:07:50.720 --> 00:07:55.760
그래서 정말로 세상을 하나로 모으려고 합니다.

00:07:55.840 --> 00:07:59.880
다채로운 집단 의식으로 만드는 것입니다.

00:08:02.480 --> 00:08:05.960
그건, 그러니까, 그냥 이렇게 말하는 것과는 다릅니다,

00:08:06.040 --> 00:08:11.120
"사람이 만들 수 있는 도파민 생성 영상 스트림 중 최대는 무엇인가?"라고 말하는 것 말입니다.

00:08:12.560 --> 00:08:14.320
그러니까 말입니다,

00:08:15.240 --> 00:08:18.040
솔직히 말해서, 약간 뇌가 썩는 느낌일 수도 있다고 생각합니다.

00:08:19.000 --> 00:08:20.840
그러니까 그냥 영상을 보고만 있으면 말입니다.

00:08:20.920 --> 00:08:25.240
내용은 없는데 도파민만 연달아 터뜨리는 영상들이라면 말입니다.

00:08:25.320 --> 00:08:30.040
그런 건 별로 좋지 않습니다. 시간을 그렇게 쓰는 건 좋은 방식이 아닙니다.

00:08:32.320 --> 00:08:35.920
하지만 실제로 많은 사람들이 그런 걸 보고 싶어 할 것이라고도 생각합니다.

00:08:36.960 --> 00:08:40.120
그래서 인터넷 사용 전체로 보면,

00:08:40.200 --> 00:08:42.320
아마도 최적화는

00:08:42.400 --> 00:08:46.720
그러니까 신경전달물질 생성 때문일 겁니다.

00:08:46.800 --> 00:08:50.200
그러니까 누군가는 거기서 쾌감을 얻는 겁니다.

00:08:50.280 --> 00:08:53.120
하지만 결국 약물 같은 것이 되어 버립니다.

00:08:55.360 --> 00:08:57.440
하지만 저는 사실 그런 걸 노리는 건…

00:08:58.840 --> 00:09:00.800
제 목표는 그게 아닙니다.

00:09:00.880 --> 00:09:02.920
원하면 그렇게 할 수도 있겠지만,

00:09:03.000 --> 00:09:05.520
하지만, 음, 저는…

00:09:05.600 --> 00:09:10.240
저는 그저 사람들을 하나로 모으는 전 세계적 플랫폼을 정말로 갖고 싶습니다…

00:09:11.520 --> 00:09:15.720
말씀드렸듯이, 일종의 집단 의식에 가까워지는 겁니다,

00:09:16.680 --> 00:09:18.200
가능한 한 인류의 집단 의식에 가깝게 말입니다.

00:09:21.600 --> 00:09:24.760
그리고 우리가 도입한 것 중 하나가, 음,

00:09:24.840 --> 00:09:27.840
예를 들면 자동 번역입니다.

00:09:30.240 --> 00:09:34.800
사람들이 하는 말을 한데 모을 수 있다면 매우 좋을 것이라고 생각합니다.

00:09:34.880 --> 00:09:38.160
여러 언어로 말하는 것들, 그리고…

00:09:38.240 --> 00:09:40.920
받는 사람이 자동으로 번역된 형태로 보게 하는 겁니다.

00:09:41.000 --> 00:09:42.840
그러면 집단 의식이 생기게 됩니다,

00:09:42.920 --> 00:09:46.480
예를 들어 특정 언어권 사람들만의 것이 아니라,

00:09:46.560 --> 00:09:51.760
그러니까 사람들의 생각을,

00:09:51.840 --> 00:09:53.520
모든 언어권에서 모을 수 있습니다.

00:09:53.600 --> 00:09:55.520
그게 왜 중요합니까, 일론?

00:09:55.600 --> 00:09:58.520
집단 의식, 하나의 플랫폼을 갖는다는 말씀이십니까?

00:09:58.600 --> 00:10:00.040
글쎄…

00:10:02.120 --> 00:10:03.320
네, 왜 그게 중요합니까?

00:10:12.920 --> 00:10:15.680
글쎄, 그건— 또 이렇게도 물을 수 있습니다, 왜…

00:10:18.120 --> 00:10:19.640
인간을 생각해 보면,

00:10:19.720 --> 00:10:24.400
인간은 대략 30조에서 40조 개의 세포로 이루어져 있습니다.

00:10:29.040 --> 00:10:31.880
그리고 뇌에는 수조 개의 시냅스가 있습니다.

00:10:37.880 --> 00:10:40.560
하지만 그게 왜냐고 하면— 그러니까, 글쎄,

00:10:40.640 --> 00:10:44.000
그저 우리가 더 늘릴 수 있도록 하기 위해서입니다…

00:10:45.640 --> 00:10:47.480
우리의 이해를 말입니다.

00:10:47.560 --> 00:10:48.720
우리의 이해를 더...

00:10:51.520 --> 00:10:53.080
우주에 대한 우리의 이해를 말입니다.

00:11:00.720 --> 00:11:02.760
저는 이런 생각이 있었던 것 같습니다...

00:11:02.840 --> 00:11:05.800
그러니까 삶의 의미가 무엇인지에 대한, 그런 질문이었습니다.

00:11:09.560 --> 00:11:11.160
왜 어떤 것이든 중요합니까?

00:11:15.080 --> 00:11:17.800
그러니까 우리는 왜 여기 있는 겁니까?

00:11:18.880 --> 00:11:21.840
우주의 기원은 무엇입니까? 끝은 무엇입니까?

00:11:24.560 --> 00:11:26.840
우리가 질문해야 한다는 것조차 모르는 질문들은 무엇입니까?

00:11:30.160 --> 00:11:32.240
그리고 아마도 우리가 질문해야 한다는 것조차 모르는 질문들이

00:11:32.320 --> 00:11:34.000
가장 중요한 질문들일 겁니다.

00:11:36.120 --> 00:11:39.440
그래서 저는 그냥, 무슨 일이 벌어지는지 이해하려고 합니다.

00:11:39.520 --> 00:11:41.360
이 현실에서 무슨 일이 벌어지고 있는 겁니까?

00:11:44.600 --> 00:11:45.800
이게 현실입니까?

00:11:50.120 --> 00:11:54.560
그리고 “삶의 요점이 무엇인가?”라고 물었을 때 어디까지 가셨습니까?

00:11:56.160 --> 00:11:57.360
네, 그래서 저는...

00:11:59.880 --> 00:12:02.360
결론에 이르렀는데...

00:12:02.440 --> 00:12:06.000
그건 어느 정도 더글러스 애덤스의

00:12:06.080 --> 00:12:08.280
『은하수를 여행하는 히치하이커를 위한 안내서』식 사고와 비슷한데,

00:12:08.360 --> 00:12:10.240
—즉— —42입니다.

00:12:10.320 --> 00:12:12.600
네, 그러니까 그는 일종의...

00:12:13.720 --> 00:12:14.920
『은하수를 여행하는 히치하이커를 위한 안내서』는

00:12:15.000 --> 00:12:17.720
유머로 위장한 철학책 같은 책입니다.

00:12:17.800 --> 00:12:18.800
-네. -그리고...

00:12:20.720 --> 00:12:22.000
거기서 그게 나옵니다—

00:12:22.080 --> 00:12:26.400
그러니까 지구가 어떤 컴퓨터로 밝혀지는데,

00:12:26.480 --> 00:12:29.320
삶의 의미에 대한 답을 알아내기 위해서입니다.

00:12:29.400 --> 00:12:31.640
그리고 답으로 42를 내놓습니다.

00:12:31.720 --> 00:12:34.520
그런데 그러고 나서 “42가 무슨 뜻이지?”가 됩니다.

00:12:36.120 --> 00:12:37.280
그리고 알고 보니, 사실,

00:12:37.360 --> 00:12:42.200
어려운 건 답이 아니라 질문입니다.

00:12:42.280 --> 00:12:45.520
그리고 그걸 위해서는 지구보다 훨씬 더 큰 컴퓨터가 필요하지요.

00:12:45.600 --> 00:12:47.640
그러니까 더글러스 애덤스가 말한 요지는

00:12:47.720 --> 00:12:50.360
우리는 실제로 질문을 제대로 구성하는 법을 모른다는 겁니다.

00:12:52.320 --> 00:12:55.600
그래서 저는 의식의 범위와 규모를 확장하면,

00:12:55.680 --> 00:12:59.720
어떤 질문을 던져야 하는지 더 잘 이해할 수 있다고 생각합니다.

00:12:59.800 --> 00:13:02.360
우주라는 답에 대해서요.

00:13:03.320 --> 00:13:07.400
사회라는 집단의식을 믿으십니까—

00:13:10.440 --> 00:13:13.240
최근에 『글래디에이터』라는 영화를 봤습니다.

00:13:13.320 --> 00:13:15.200
-러셀 크로우요. 보셨나요? -네, 네.

00:13:16.440 --> 00:13:18.560
‘글래디에이터’에서 로마에서는,

00:13:18.640 --> 00:13:21.480
사람들이 싸울 때,

00:13:21.560 --> 00:13:24.160
사람들이 서로를 죽일 때 군중이 환호합니다...

00:13:27.720 --> 00:13:30.160
집단은 그야말로 폭도와 같습니다.

00:13:31.040 --> 00:13:35.720
엄밀히 말하면 의견에 뉘앙스가 없습니다.

00:13:37.160 --> 00:13:38.400
그게 그런 특정한 종류의 폭도입니다.

00:13:38.480 --> 00:13:41.960
말하자면 사람들이 서로를 죽이는 걸 보러 거기에 가는 것 아닙니까?

00:13:42.040 --> 00:13:44.960
오늘날 우리가 사는 사회는 매우 다르다고 보십니까?

00:13:45.680 --> 00:13:48.840
우리는 일반적으로는-- 지금은 우리는...

00:13:50.080 --> 00:13:52.120
그러니까 사람들이 서로를 죽이는 것을 가서 보지는 않습니다.

00:13:52.200 --> 00:13:54.600
[웃음]

00:13:54.680 --> 00:13:56.600
어쩌면 그것의 어떤 완곡한 형태가 있을 수도 있습니다.

00:13:57.400 --> 00:13:58.920
-스포츠겠지요. -음.

00:14:00.000 --> 00:14:02.400
그래서 사람들은 스포츠를 하되--

00:14:03.240 --> 00:14:05.560
팀들이 서로를 이기려고 하고,

00:14:05.640 --> 00:14:08.040
-죽음만 빼고요. -맞습니다.

00:14:10.040 --> 00:14:15.240
인간에 대한 고찰로 다시 돌아가면요.

00:14:15.320 --> 00:14:18.360
우리는 모두 하나의 세포로 시작했지만 이제는...

00:14:19.800 --> 00:14:21.680
30조 개가 넘는 세포로 이루어져 있습니다.

00:14:26.800 --> 00:14:30.520
하지만 대부분의 사람들은 자신이 하나의 몸이라고 느낍니다.

00:14:30.600 --> 00:14:32.280
예를 들어, 보통은요,

00:14:32.360 --> 00:14:35.080
오른손이 왼손과 싸우지는 않지 않습니까?

00:14:35.160 --> 00:14:37.280
그냥 협력합니다.

00:14:38.760 --> 00:14:40.120
정신은...

00:14:42.840 --> 00:14:44.160
그러니까...

00:14:46.080 --> 00:14:48.600
방대한 수의 뉴런들일 뿐입니다.

00:14:48.680 --> 00:14:52.080
하지만 대부분의 시간에는, 그러니까,

00:14:52.160 --> 00:14:54.200
뇌 안에 1조 개의 목소리가 있는 것처럼 느껴지지는 않습니다. 아니길 바랍니다.

00:14:57.320 --> 00:15:02.360
그래서 분명 더 많은 일이 일어납니다

00:15:02.440 --> 00:15:06.360
수조 개의 세포가

00:15:06.440 --> 00:15:11.160
예를 들어 하나의 세포보다 세포 집합으로서 함께 작동할 때 말입니다.

00:15:11.240 --> 00:15:13.440
또는 작은,

00:15:14.240 --> 00:15:16.400
그러니까 작은 다세포 생물 말입니다.

00:15:16.480 --> 00:15:19.640
분명히 뭔가 다른 일이 일어납니다.

00:15:19.720 --> 00:15:21.800
예를 들어, 박테리아와는 대화할 수 없지 않습니까?

00:15:21.880 --> 00:15:23.560
-네. -네. 아주 조용하지요.

00:15:25.200 --> 00:15:27.040
그냥 꼼지락거리기만 하고...

00:15:27.880 --> 00:15:29.120
그들의 관점에서는, 잘 모르겠습니다.

00:15:29.200 --> 00:15:33.280
아메바의 관점에서 삶이 어떤지 떠올려 봤습니다.

00:15:34.040 --> 00:15:37.600
하지만 아메바와는 대화할 수 없다는 걸 압니다. 그러니까, 대답을 하지 않습니다.

00:15:37.680 --> 00:15:38.920
하지만 인간과는 대화할 수 있습니다.

00:15:39.920 --> 00:15:41.920
그래서 뭔가,

00:15:42.000 --> 00:15:47.960
분명히, 질적으로나 근본적으로 인간에게는 완전히 다릅니다.

00:15:48.040 --> 00:15:49.880
세포가 아주 많이 생기고,

00:15:49.960 --> 00:15:54.320
그리고, 아시다시피, 충분히 큰 뇌 같은 것이 갖춰지면,

00:15:54.400 --> 00:15:57.360
그러면... 이제 사람과 대화할 수 있습니다.

00:15:57.440 --> 00:16:00.880
그리고 사람들은 말을 할 수 있고, 무언가를 만들어낼 수도 있습니다.

00:16:02.320 --> 00:16:06.280
하지만 예를 들어 박테리아가 우주선을 만들지는 못합니다.

00:16:07.360 --> 00:16:08.800
하지만 인간은 할 수 있습니다.

00:16:08.880 --> 00:16:12.760
그래서 저는 질적으로 다른 무언가가 있다고 생각합니다.

00:16:12.840 --> 00:16:15.240
그것은 인간이 모여 집단을 이룰 때도 일어납니다.

00:16:15.320 --> 00:16:17.120
사실, 단언해도 괜찮을 정도로 한 사람은

00:16:17.200 --> 00:16:18.360
우주선을 만들 수 없습니다.

00:16:18.440 --> 00:16:20.640
저도 혼자서는 우주선을 만들 수 없습니다.

00:16:20.720 --> 00:16:24.480
하지만 사람들이 모이면 우주선을 만들 수 있습니다.

00:16:25.600 --> 00:16:27.120
그러니, 분명히,

00:16:27.200 --> 00:16:33.200
인간의 집단은 질적으로 다른 무언가가 있습니다.

00:16:33.280 --> 00:16:38.440
사실, 제가 모든 분야의 전문성을 전부 배우는 것은 불가능할 것입니다.

00:16:38.520 --> 00:16:40.400
한 사람의 일생에는 시간이 충분하지 않아서

00:16:40.480 --> 00:16:43.720
죽기 전에 그 모든 것을 배우는 것조차 불가능합니다.

00:16:46.240 --> 00:16:49.680
그래서 로켓을 만들려면 근본적으로 사람들의 집단이 필요합니다.

00:16:52.400 --> 00:16:55.760
그리고 나서, 아마도 다른 어떤 스케일링이...

00:16:57.520 --> 00:17:02.160
인간 집단이 커질 때 일어나는 질적인 스케일링들이 있을 것입니다.

00:17:02.240 --> 00:17:06.280
그리고 상호작용의 질이,

00:17:06.360 --> 00:17:08.160
또는 정보 흐름의 질이...

00:17:10.280 --> 00:17:12.440
더 좋을수록,

00:17:12.520 --> 00:17:15.600
인간 집단은 더 많은 것을 이룰 것입니다.

00:17:17.480 --> 00:17:21.600
그리고 제가 말씀드렸듯이, 저는 그저 우주의 본질이 궁금할 뿐입니다.

00:17:21.680 --> 00:17:24.240
그리고 제 생각에 우리가-- 이렇게 말해도 무방하겠지만,

00:17:24.320 --> 00:17:29.000
의식의 범위와 규모를 넓힌다면,

00:17:29.080 --> 00:17:32.160
우주의 본질을 이해할 가능성이 훨씬 커집니다.

00:17:32.240 --> 00:17:34.160
그것을 줄이는 것보다 말입니다.

00:17:36.080 --> 00:17:37.840
그게 일종의 영성 같은 것입니까?

00:17:37.920 --> 00:17:40.800
많은 분들이 저에게 영성에 대해 말씀하십니다.

00:17:40.880 --> 00:17:41.960
그렇습니다.

00:17:42.040 --> 00:17:43.240
하지만 그게 실제로 무슨 뜻인지 아직도 모르겠습니다.

00:17:43.320 --> 00:17:45.240
그래서 계속 물어봅니다, "무슨 뜻이십니까?"

00:17:45.320 --> 00:17:47.800
네. "무슨 뜻이십니까?"

00:17:47.880 --> 00:17:51.000
그러니까, 많은 사람들이 영적인 감정을 느낍니다.

00:17:51.080 --> 00:17:52.560
그렇습니다.

00:17:54.320 --> 00:17:58.160
그리고 저는 그 영적인 감정이 그분들에게는 실제라는 점을 부정하려고 하지는 않습니다.

00:17:59.160 --> 00:18:00.440
하지만...

00:18:02.560 --> 00:18:03.880
완전히 와닿지는 않습니다.

00:18:03.960 --> 00:18:05.680
그저 다른 사람이 영적인 감정을 느낀다고 해서

00:18:05.760 --> 00:18:08.320
저도 그 영적인 감정을 느낄 것이라는 뜻은 아닙니다.

00:18:12.200 --> 00:18:14.800
아시다시피 저는 좀 물리학 쪽으로 끌리는 편인데,

00:18:14.880 --> 00:18:18.760
즉 어떤 것에 예측 가치가 있다면...

00:18:19.880 --> 00:18:23.480
예측 가치가 없을 때보다 더 주의를 기울이게 됩니다.

00:18:23.560 --> 00:18:25.280
그렇습니다.

00:18:25.360 --> 00:18:28.360
그래서, 제 생각에 물리학은,

00:18:28.440 --> 00:18:30.520
예측 가치를 지닌 것을 연구하는 학문입니다.

00:18:31.480 --> 00:18:33.600
꽤 괜찮은 정의라고 생각합니다.

00:18:33.680 --> 00:18:37.480
일론, 제 본업은 주식 중개인이자 주식 투자자입니다.

00:18:37.560 --> 00:18:39.240
-알겠습니다. -예측 가치는 없습니다.

00:18:39.320 --> 00:18:41.880
내일 무슨 일이 일어날지 아무도 모릅니다.

00:18:41.960 --> 00:18:45.680
음, 그래도 일반적으로는 이렇게 말할 수 있다고 생각합니다...

00:18:48.480 --> 00:18:53.080
기업을 장기적으로 본다면, 예를 들어 이렇게 볼 수 있습니다,

00:18:54.840 --> 00:18:58.000
그 회사의 제품이나 서비스를 좋아하십니까?

00:18:58.080 --> 00:19:02.000
그리고 그럴 가능성이 있습니까... 제품 로드맵이 마음에 드십니까?

00:19:02.080 --> 00:19:05.720
좋아하십니까-- 훌륭한 제품을 만드는 것 같고

00:19:05.800 --> 00:19:08.400
앞으로도 훌륭한 제품을 만들 가능성이 높습니까?

00:19:08.480 --> 00:19:09.600
그렇다면,

00:19:09.680 --> 00:19:13.080
아마 투자하기 좋은 회사라고 말할 수 있겠습니다.

00:19:14.880 --> 00:19:17.080
그리고 팀을 믿는 것도 중요하다고 생각합니다.

00:19:17.160 --> 00:19:20.040
예를 들어 그 팀이 재능 있고 열심히 일하는 팀이며,

00:19:20.120 --> 00:19:21.680
지금도 좋은 제품을 만들고,

00:19:21.760 --> 00:19:24.800
앞으로도 계속 무언가를 만들 동기가 있어 보인다면요.

00:19:24.880 --> 00:19:27.320
그런 회사는 투자하기 좋다고 말하겠습니다.

00:19:27.400 --> 00:19:28.640
타당한 말씀입니다.

00:19:28.720 --> 00:19:32.120
네, 그리고 이제, 그것이...

00:19:32.200 --> 00:19:34.880
일일 변동성까지 해결해 주지는 못합니다.

00:19:34.960 --> 00:19:38.240
그런 변동은 일어나고, 때로는 꽤 극단적이기도 합니다.

00:19:38.320 --> 00:19:44.040
하지만 시간이 지나면 그것이 주식에 투자하는 올바른 방법입니다.

00:19:44.120 --> 00:19:46.480
왜냐하면 회사란 결국 사람들의 집단이기 때문입니다.

00:19:46.560 --> 00:19:48.720
제품과 서비스를 만들기 위해 모인 사람들입니다.

00:19:48.800 --> 00:19:50.360
그래서 "그럼 또 어떤--"

00:19:50.440 --> 00:19:52.560
그 제품과 서비스는 얼마나 좋습니까?

00:19:52.640 --> 00:19:54.760
앞으로도 계속 개선될 가능성이 높습니까?

00:19:54.840 --> 00:19:57.320
그렇다면 그 회사 주식을 사야 합니다.

00:19:57.400 --> 00:19:59.920
그리고 일일 변동성에 너무 신경 쓰지 않는 것이 좋습니다.

00:20:00.000 --> 00:20:01.120
그렇습니다.

00:20:02.600 --> 00:20:07.720
일론, 지금 만들고 계신 모든 것 중에서 무엇이 가장 기대되십니까?

00:20:07.800 --> 00:20:08.920
정말 많은 일을 하고 계시잖아요.

00:20:09.000 --> 00:20:13.040
그래서 이걸 누가 보고 있는지 먼저 말씀드리고 맥락을 잡겠습니다.

00:20:14.160 --> 00:20:19.280
저희 시청자층은 주로 인도의 예비 창업가들입니다.

00:20:19.360 --> 00:20:21.080
알겠습니다.

00:20:21.160 --> 00:20:27.480
매우 야망이 크고 정말 간절하며, 위험을 감수하고 무언가를 만들고 싶어합니다.

00:20:27.560 --> 00:20:30.960
그리고 저희 모두가 당신에게서 배울 것이 정말 많다고 느낍니다.

00:20:31.040 --> 00:20:33.680
여러 분야에서 그걸 수차례 해내셨기 때문입니다.

00:20:33.760 --> 00:20:34.920
네.

00:20:35.000 --> 00:20:37.000
그래서 오늘은 그분들을 염두에 두고 대화하겠습니다,

00:20:37.080 --> 00:20:40.880
그리고 제 질문도 그 방향에 초점을 맞추려고 합니다

00:20:40.960 --> 00:20:43.240
이 대화를 최대한 활용하실 수 있도록요.

00:20:43.320 --> 00:20:46.120
그리고 어쩌면 시작해 보시고, 모험을 걸어 무언가를 만들어 보시는 것입니다.

00:20:47.600 --> 00:20:48.760
네, 알겠습니다.

00:20:52.840 --> 00:20:55.280
네, 제 생각에 가장 중요한 것은 그냥...

00:20:57.840 --> 00:20:59.720
유용한 제품과 서비스를 만드는 것입니다.

00:21:02.400 --> 00:21:03.400
네.

00:21:04.160 --> 00:21:07.440
지금 만들고 계신 모든 제품과 서비스 중에서

00:21:07.520 --> 00:21:09.680
오늘 가장 기대되는 것은 어느 것입니까?

00:21:13.000 --> 00:21:16.880
음, 사실 점점 더 수렴하고 있는 것 같습니다,

00:21:16.960 --> 00:21:19.680
SpaceX와 Tesla, 그리고 xAI 사이에서 말입니다.

00:21:21.440 --> 00:21:25.880
즉 미래가 태양광으로 구동되는 AI 위성이라면,

00:21:25.960 --> 00:21:29.640
이를 위해서는 사실상 그렇게 되어야 합니다...

00:21:30.600 --> 00:21:35.280
태양 에너지의 상당한 양을 활용하려면,

00:21:35.360 --> 00:21:39.240
심우주에서 태양광으로 구동되는 AI 위성으로 가야 합니다...

00:21:40.960 --> 00:21:45.680
이는 어느 정도 Tesla의 전문성과 SpaceX의 전문성이 만나는 지점입니다.

00:21:47.680 --> 00:21:51.400
그리고 AI 측면에서는 xAI가 있습니다, 그래서...

00:21:52.440 --> 00:21:55.160
시간이 갈수록 그쪽으로 어느 정도 수렴하는 느낌이 있습니다.

00:21:56.920 --> 00:22:00.080
하지만 모든 회사가 훌륭한 일을 하고 있습니다.

00:22:00.160 --> 00:22:02.040
팀들이 매우 자랑스럽고, 훌륭한 일을 해내고 있습니다.

00:22:02.960 --> 00:22:08.400
그래서 Tesla에서는 자율주행에서 큰 진전을 이루고 있습니다.

00:22:08.480 --> 00:22:10.200
자율주행을 해보셨는지 모르겠습니다.

00:22:10.280 --> 00:22:11.600
-음-음. -해보셨나요?

00:22:11.680 --> 00:22:13.720
Waymo에서는 타봤는데 Tesla에서는 아직 못 해봤습니다.

00:22:13.800 --> 00:22:15.400
네, 한 번 해볼 만합니다.

00:22:16.280 --> 00:22:17.920
사실 여기 오스틴에도 있습니다.

00:22:18.000 --> 00:22:19.440
-그러면, 그러니까... -네, 꼭 한번 해보고 싶습니다.

00:22:19.520 --> 00:22:21.800
정말로 Tesla 앱만 다운로드하면 되고,

00:22:21.880 --> 00:22:25.080
아마 누구에게나 열려 있는 것으로 알고 있습니다.

00:22:25.160 --> 00:22:26.800
-네. -꼭 한번 써보시기 바랍니다.

00:22:26.880 --> 00:22:28.720
아시다시피 그렇습니다.

00:22:30.080 --> 00:22:34.080
하지만 전기차에서는 많은 진전을 이뤘고,

00:22:34.160 --> 00:22:36.920
배터리 팩과 태양광에서도 그렇고,

00:22:37.000 --> 00:22:41.040
특히 자율주행에서는 정말 많이 진전했습니다.

00:22:41.120 --> 00:22:43.560
그러니까 기본적으로 현실 세계의 AI입니다.

00:22:44.320 --> 00:22:48.560
Tesla가 현실 세계 AI에서는 세계 선두라고 말할 수 있습니다.

00:22:50.200 --> 00:22:52.760
그리고 저희는 Optimus라는 로봇을 만들 예정이고,

00:22:52.840 --> 00:22:57.960
내년 여름쯤에는 규모 있게 양산을 시작하기를 기대하고 있습니다.

00:22:59.520 --> 00:23:01.720
그건 꽤 멋질 것 같습니다. 마치--

00:23:01.800 --> 00:23:06.080
모두가 자기만의 개인 C-3PO나 R2-D2를 원하게 될 것입니다,

00:23:06.160 --> 00:23:09.200
아시다시피 도우미 로봇인데, 정말 멋질 것입니다.

00:23:10.640 --> 00:23:15.960
그리고 SpaceX는 스타링크 프로그램으로 훌륭한 일을 하고 있습니다,

00:23:16.040 --> 00:23:21.400
전 세계에 저렴하고 신뢰할 수 있는 인터넷을 제공하고 있습니다.

00:23:21.480 --> 00:23:23.120
그리고 바라건대 인도에도요.

00:23:23.200 --> 00:23:26.000
인도에서 운영하고 싶습니다. 그러면 정말 좋겠습니다.

00:23:26.080 --> 00:23:29.360
지금 스타링크로 150개국에서 운영 중입니다.

00:23:29.440 --> 00:23:32.960
스타링크가 무엇이고 기술이 어떻게 작동하는지 조금 설명해 주실 수 있습니까?

00:23:33.040 --> 00:23:35.320
제가 이야기하던 어떤 분이...

00:23:35.400 --> 00:23:38.960
샌프란시스코에 있는 Meter라는 회사 아십니까?

00:23:39.040 --> 00:23:41.200
그들은 네트워크 엔지니어를 대체하려고 하고 있습니다.

00:23:41.280 --> 00:23:42.960
-하지만-- -아니요, 모릅니다.

00:23:43.040 --> 00:23:47.800
그래서 그분이 인구 밀집 지역에서는

00:23:47.880 --> 00:23:49.680
스타링크가 다르게 작동한다고

00:23:49.760 --> 00:23:53.040
사람이 그리 많지 않은 곳과는

00:23:53.120 --> 00:23:54.920
어떻게 작동하는지 설명해 주실 수 있습니까?

00:23:55.000 --> 00:23:57.000
네, 그러니까 스타링크는...

00:23:57.080 --> 00:23:59.680
저지구 궤도에 수천 기의 위성이 있고,

00:23:59.760 --> 00:24:05.280
이 위성들이 음속의 25배 속도로 이런...

00:24:05.360 --> 00:24:08.240
그러니까 기본적으로 지구 주위를 빠르게 돌고 있습니다, 그리고...

00:24:10.080 --> 00:24:13.880
고도는 대략 550킬로미터 정도이며,

00:24:15.120 --> 00:24:17.640
일반적으로 저지구 궤도라고 부릅니다.

00:24:17.720 --> 00:24:22.720
저지구 궤도에 있어서 지연시간이 낮습니다.

00:24:22.800 --> 00:24:25.760
거리로 보면, 거리가 그리 멀지 않기 때문입니다,

00:24:25.840 --> 00:24:29.640
36,000킬로미터의 정지궤도 위성과 비교하면 그렇습니다.

00:24:31.080 --> 00:24:36.600
그래서 수천 기의 위성이 전 세계를 대상으로

00:24:37.680 --> 00:24:42.400
지연시간이 낮고 속도가 빠른 인터넷을 제공하고 있습니다,

00:24:45.240 --> 00:24:46.840
그리고 위성들끼리도 서로 연결되어 있습니다.

00:24:46.920 --> 00:24:49.800
따라서 위성들 사이에는 레이저 링크가 있습니다.

00:24:49.880 --> 00:24:51.960
그래서 일종의 레이저 메시망을 형성합니다.

00:24:52.040 --> 00:24:57.200
그래서 예를 들어 케이블이 손상되거나 끊기더라도 괜찮습니다.

00:24:57.280 --> 00:25:01.520
광케이블 같은 경우에도 위성들은 서로 통신할 수 있습니다.

00:25:01.600 --> 00:25:07.720
따라서 케이블이 끊겨도 연결성을 제공할 수 있습니다.

00:25:07.800 --> 00:25:10.560
그래서 예를 들어 홍해의 해저 케이블이 끊겼을 때도 있었습니다.

00:25:11.560 --> 00:25:12.880
제 기억으로는 몇 달 전이었습니다.

00:25:12.960 --> 00:25:18.320
그때도 스타링크 위성 네트워크는 아무 문제 없이 계속 작동했습니다.

00:25:18.400 --> 00:25:21.000
그래서 재난 지역에 특히 도움이 됩니다.

00:25:21.080 --> 00:25:25.560
어떤 지역이 자연재해로 피해를 입으면 그렇습니다.

00:25:25.640 --> 00:25:28.720
홍수나 화재나 지진 같은 것들입니다.

00:25:28.800 --> 00:25:32.120
그런 일은 보통 지상 인프라를 손상시킵니다.

00:25:32.200 --> 00:25:35.360
하지만 스타링크 위성은 여전히 작동합니다.

00:25:35.440 --> 00:25:38.520
그리고 일반적으로 어디든 자연재해가 발생하면 저희는 그렇게 합니다.

00:25:38.600 --> 00:25:42.960
저희는 항상 사람들에게 스타링크 인터넷 연결을 무료로 제공합니다.

00:25:43.040 --> 00:25:44.320
아시다시피, 저희는 요금을 청구하고 싶지 않습니다.

00:25:44.400 --> 00:25:47.320
저희는 비극적인 상황을 이용하고 싶지 않습니다.

00:25:47.400 --> 00:25:52.520
그래서 항상, 아시다시피, 자연재해가 있으면 그렇습니다.

00:25:52.600 --> 00:25:55.720
저희는 "좋습니다, 자연재해 기간에는 무료입니다"라고 합니다.

00:25:55.800 --> 00:25:59.000
아시다시피, 예를 들어 말하자면 그런 것입니다.

00:25:59.080 --> 00:26:02.200
누군가 도움을 받으려는 동안 유료 장벽을 세우고 싶지 않습니다.

00:26:02.280 --> 00:26:03.560
그건 잘못된 일입니다.

00:26:04.760 --> 00:26:08.440
그래서 이것은 매우 견고한 시스템입니다.

00:26:08.520 --> 00:26:10.760
이는 지상 시스템을 보완합니다.

00:26:10.840 --> 00:26:17.680
왜냐하면 위성 빔은 인구가 드문 지역에서 가장 잘 작동하기 때문입니다.

00:26:19.040 --> 00:26:24.040
하지만 위성 빔은 꽤 큰 빔입니다.

00:26:24.120 --> 00:26:27.360
또 빔 하나당 사용자 수가 고정되어 있습니다.

00:26:27.440 --> 00:26:31.960
그래서 지상 기반 이동통신 시스템을 매우 잘 보완하는 경향이 있습니다.

00:26:32.040 --> 00:26:34.640
왜냐하면 그런 시스템은 도시에 매우 강하기 때문입니다.

00:26:34.720 --> 00:26:36.960
아시다시피 그런 기지국들이 있습니다.

00:26:37.040 --> 00:26:40.600
서로 1킬로미터 정도 간격으로 서 있습니다.

00:26:42.240 --> 00:26:45.480
하지만 기지국은 시골에서는 비효율적인 경향이 있습니다.

00:26:45.560 --> 00:26:50.360
그래서 농촌 지역에서 인터넷 사정이 가장 나빠지기 쉽습니다.

00:26:50.440 --> 00:26:54.200
왜냐하면 이를 구축하는 것이 매우 비싸고 어렵기 때문입니다.

00:26:54.280 --> 00:27:01.080
즉 모든 광섬유 케이블을 깔거나 대역폭이 큰 기지국을 갖추는 일입니다.

00:27:01.720 --> 00:27:08.320
그래서 스타링크는 기존 통신사들을 매우 잘 보완합니다.

00:27:09.920 --> 00:27:14.440
기본적으로 가장 서비스가 부족한 곳을 맡는 경향이 있는데, 저는 그게 좋다고 생각합니다.

00:27:15.600 --> 00:27:18.120
-그렇군요... -그게 내일은 바뀔까요?

00:27:18.200 --> 00:27:22.200
예를 들어 오늘은, 설명하신 대로, 빔이 꽤 넓고 그렇습니다.

00:27:22.280 --> 00:27:25.920
고층 건물이 많은 인구 밀집 지역에서는 아마 작동하기 어려울 수 있습니다.

00:27:27.120 --> 00:27:28.800
하지만 그것이 바뀌어서 내일은 가능해질 수 있습니까?

00:27:28.880 --> 00:27:33.200
인구 밀집 도시에서도 정말 효율적으로 될 수 있습니까?

00:27:33.280 --> 00:27:35.960
그렇게 되면 현지 통신사들과 경쟁할 수 있습니까?

00:27:36.960 --> 00:27:39.320
유감스럽게도 물리 법칙상 그건 불가능합니다.

00:27:39.400 --> 00:27:41.840
즉, 저희는 너무 멀리 있습니다.

00:27:43.360 --> 00:27:47.440
즉 550킬로미터인데, 그걸 줄이려고 해도 그렇습니다.

00:27:47.520 --> 00:27:50.320
가장 낮게 내려갈 수 있는 것도 대략 350킬로미터 정도입니다.

00:27:50.400 --> 00:27:52.240
그래도 여전히 매우 멉니다.

00:27:52.320 --> 00:27:53.760
결국 그렇습니다.

00:27:53.840 --> 00:27:56.480
손전등을 생각하시면 됩니다.

00:27:56.560 --> 00:27:59.680
아시다시피 그 손전등에는 원뿔 모양의 빛이 있습니다.

00:27:59.760 --> 00:28:03.800
그리고 그 원뿔이, 아시다시피, 내려오게 됩니다.

00:28:03.880 --> 00:28:05.600
지금은 그 거리가 550킬로미터입니다.

00:28:05.680 --> 00:28:07.800
미래에는 350킬로미터까지 낮추려고 하고 있습니다.

00:28:07.880 --> 00:28:10.880
하지만 1킬로미터 떨어진 것과는 경쟁할 수 없습니다.

00:28:10.960 --> 00:28:12.400
그게 바로 기지국입니다.

00:28:12.480 --> 00:28:14.280
여기서는 물리 법칙이 저희 편이 아닙니다.

00:28:14.360 --> 00:28:18.880
따라서 물리적으로 스타링크가 가능한 일이 아닙니다.

00:28:18.960 --> 00:28:21.720
인구가 밀집한 도시를 서비스하는 것은 불가능합니다.

00:28:21.800 --> 00:28:24.800
조금은 가능하겠지만, 인구의 1% 정도일 것입니다.

00:28:24.880 --> 00:28:28.200
그리고 때로는, 그러니까, 붐비는 도시에서도 그렇습니다.

00:28:28.280 --> 00:28:32.040
자기 집 앞길에 광섬유 연결이 없을 수도 있습니다.

00:28:32.120 --> 00:28:34.680
예를 들어 때로는 막다른 골목 같은 곳에 사는 사람이 있거나 그렇습니다.

00:28:34.760 --> 00:28:37.160
또는 어떤 곳에 있기도 합니다.

00:28:37.240 --> 00:28:41.640
도시에는 무작위한 이유로 서비스가 충분히 제공되지 않는 지역이 가끔 있습니다.

00:28:41.720 --> 00:28:44.240
그래서 제가 말했듯이 스타링크는 일부만 서비스할 수 있습니다.

00:28:44.320 --> 00:28:49.120
인구가 밀집한 도시의 1%나 2% 정도일 수 있습니다.

00:28:50.400 --> 00:28:53.160
하지만 제가 말씀드렸듯이,

00:28:53.240 --> 00:28:56.760
인터넷 연결이 훨씬 더 열악한 농촌 지역에서는 훨씬 더 효과적일 수 있습니다.

00:28:56.840 --> 00:29:00.720
그리고 종종 사람들은 아예 인터넷에 접근하지 못하기도 하고,

00:29:00.800 --> 00:29:04.440
비용이 매우 비싸거나 품질이 그다지 좋지 않기도 합니다.

00:29:06.480 --> 00:29:08.080
일론, 추측으로라도 말씀해 주신다면,

00:29:08.840 --> 00:29:13.760
인도도 중국처럼 도시화의 길을 걷게 될 것이라고 보십니까,

00:29:13.840 --> 00:29:17.840
더 많은 사람들이 농촌 경제에서 도시 중심지로 이동하면서요?

00:29:20.160 --> 00:29:21.800
아니면 그 흐름을 거스를 수 있다고 보십니까?

00:29:21.880 --> 00:29:24.400
음, 어느 정도는 이미 일어난 것 같지 않습니까?

00:29:25.320 --> 00:29:29.080
저도 사실 몇 가지를 좀 여쭤보고 싶습니다.

00:29:29.760 --> 00:29:34.000
물론 그게 추세 아닌가요, 아니면 인도에서는 그렇지 않은가요?

00:29:34.800 --> 00:29:36.360
대체로는 그런 추세입니다.

00:29:36.440 --> 00:29:38.920
코로나19 동안에는 조금 바뀌었다고 생각합니다.

00:29:39.000 --> 00:29:43.160
도시화가 많이 둔화됐는데, 그것은 자연스러운 흐름이 아니었습니다.

00:29:43.240 --> 00:29:45.960
매우 인위적으로 나타난 현상이었습니다.

00:29:46.040 --> 00:29:47.440
네.

00:29:47.520 --> 00:29:52.240
하지만 AI가 있으면 그 점이 의문이 들기도 합니다,

00:29:52.320 --> 00:29:56.000
생산성이 올라간다면 말입니다.

00:29:56.080 --> 00:30:00.400
그리고 UBI 대신 UHI에 대해 말씀하시는 것을 들었습니다.

00:30:00.480 --> 00:30:03.800
네. 저는 '보편적 고소득'이 될 것이라고 생각합니다.

00:30:03.880 --> 00:30:07.600
그런 세상에서는 더 많은 사람들이 도시에서 살고 싶어할지 궁금합니다.

00:30:07.680 --> 00:30:12.080
도시는 언제나 더 오염될 수밖에 없고,

00:30:13.000 --> 00:30:17.200
농촌 환경이 제공할 수 있는 삶의 질을 제공하지 못할 수도 있으니까요.

00:30:18.080 --> 00:30:19.640
음, 그건 결국 각자에게 달려 있습니다.

00:30:19.720 --> 00:30:22.920
어떤 사람들은 많은 사람들 곁에 있고 싶어 하고, 어떤 사람들은 그렇지 않습니다.

00:30:23.000 --> 00:30:25.160
아마 개인의 선택 문제가 될 것입니다.

00:30:25.240 --> 00:30:27.520
하지만 제 생각에는 미래에는 그렇지 않을 것입니다.

00:30:27.600 --> 00:30:31.200
일을 위해 꼭 도시에 있어야 하는 시대는 아닐 것이라고 생각합니다.

00:30:31.280 --> 00:30:33.720
네. 왜냐하면 제 생각에는...

00:30:33.800 --> 00:30:36.400
제 예측으로는 미래에는 일하는 것이 선택 사항이 될 것입니다.

00:30:36.480 --> 00:30:38.000
네.

00:30:38.080 --> 00:30:39.560
우리는 근무일이 줄어드는 방향으로 가는 것 같습니다.

00:30:39.640 --> 00:30:42.040
인도는 아니지만 서구의 일부 지역에서는,

00:30:42.120 --> 00:30:45.480
주 6일에서 5일로, 4일로, 3일로요.

00:30:45.560 --> 00:30:46.840
저는 아닙니다.

00:30:46.920 --> 00:30:49.240
[웃음]

00:30:49.320 --> 00:30:50.640
제 생각에는 유럽인들입니다.

00:30:50.720 --> 00:30:52.040
네, 네.

00:30:55.040 --> 00:30:56.080
네, 네, 왜냐하면...

00:30:57.200 --> 00:31:01.320
그러니까 스타트업을 성공시키려고 한다면

00:31:01.400 --> 00:31:05.760
또는 회사로 하여금 매우 어려운 일을 해내게 하려 한다면,

00:31:05.840 --> 00:31:08.480
분명히 상당한 시간을 투입해야 합니다.

00:31:08.560 --> 00:31:10.560
제 생각엔 원래 그렇게 되는 겁니다. 네.

00:31:11.480 --> 00:31:14.800
그리고 만약 우리가 주 5일에서 4일, 3일로 옮겨 간다면,

00:31:14.880 --> 00:31:16.440
사회가 어떻게 바뀐다고 보십니까?

00:31:16.520 --> 00:31:20.760
사람들이 한 주의 절반만 일해야 한다면, 나머지 절반은 무엇을 하게 됩니까?

00:31:21.520 --> 00:31:24.160
음, 제 생각에는 사실 사람들이 아예 일할 필요가 없게 될 것입니다.

00:31:26.560 --> 00:31:28.480
그게 그렇게 먼 미래는 아닐 수도 있습니다.

00:31:28.560 --> 00:31:33.560
아마도, 글쎄요, 10년 정도, 20년 이내라고 말씀드리겠습니다.

00:31:33.640 --> 00:31:37.960
제 예측으로는 20년 이내에 일하는 것이 선택 사항이 될 것입니다.

00:31:38.040 --> 00:31:39.960
아예 일 자체가 선택 사항이 될 것입니다.

00:31:42.560 --> 00:31:44.000
취미처럼요.

00:31:44.080 --> 00:31:45.640
거의 그렇습니다.

00:31:46.760 --> 00:31:50.440
그리고 그것은 생산성이 증가하기 때문일 것이고,

00:31:50.520 --> 00:31:52.640
즉 사람들이 일할 필요가 없다는 뜻인가요?

00:31:52.720 --> 00:31:54.160
그럴 필요가—

00:31:54.240 --> 00:31:56.080
그러니까, 보세요, 당연히,

00:31:56.160 --> 00:31:58.080
사람들이 20년 뒤에 이걸 다시 보고 이렇게 말할 수도 있습니다.

00:31:58.160 --> 00:32:01.200
"보세요, 일론이 이런 터무니없는 예측을 했는데 사실이 아니잖아요."

00:32:01.280 --> 00:32:06.320
하지만 저는 20년 이내에 그것이 사실로 드러날 것이라고 생각합니다,

00:32:06.400 --> 00:32:11.120
어쩌면 10년이나 15년 정도로도 충분할지 모르겠습니다만,

00:32:12.800 --> 00:32:18.320
AI와 로보틱스의 발전이 우리를 그런 지점으로 이끌 것입니다.

00:32:18.400 --> 00:32:21.760
즉, 일하는 것이 선택 사항이 되는 지점 말입니다.

00:32:22.720 --> 00:32:24.840
예를 들어,

00:32:24.920 --> 00:32:27.480
정원에서 채소를 직접 키울 수도 있고,

00:32:27.560 --> 00:32:29.960
가게에 가서 채소를 사 올 수도 있는 것과 같습니다.

00:32:32.840 --> 00:32:34.480
아시겠습니까.

00:32:34.560 --> 00:32:36.720
채소를 직접 키우는 것은 훨씬 더 어렵습니다.

00:32:36.800 --> 00:32:40.440
하지만 어떤 사람들은 채소를 직접 키우는 것을 좋아하고, 그것도 괜찮습니다.

00:32:40.520 --> 00:32:43.680
그런 의미에서 선택 사항이 될 것이라는 것이 제 예측입니다.

00:32:44.640 --> 00:32:49.720
만약 인간이 본성적으로 경쟁적이라고 주장한다면,

00:32:49.800 --> 00:32:51.520
그리고 모든 것이 상대적이라고 한다면...

00:32:51.600 --> 00:32:53.600
수렵 시대부터,

00:32:53.680 --> 00:32:56.920
누군가는 최고 사냥꾼이 되거나 가장 큰 농부가 되기를 원했을 것이고,

00:32:57.000 --> 00:33:02.520
모두가 보편적 높은 소득을 받고 모두가 충분히 가진다면...

00:33:03.480 --> 00:33:06.000
-무엇을 두고 경쟁하십니까? -어...

00:33:06.080 --> 00:33:07.880
그것도 상대적인 것 아니겠습니까?

00:33:07.960 --> 00:33:10.520
예를 들어 모두가 충분히 가진다면, '충분함'도 더는 충분하지 않게 됩니다.

00:33:13.520 --> 00:33:17.560
네, 그러게요—정확히는 잘 모르겠습니다.

00:33:17.640 --> 00:33:22.320
우리가 이른바 특이점으로 정말 향하고 있기 때문입니다,

00:33:22.400 --> 00:33:25.080
아시다시피 사람들은 때때로 AI를 그렇게 부르기도 하는데,

00:33:25.160 --> 00:33:27.280
일종의 블랙홀처럼, 특이점에 비유하기도 합니다.

00:33:27.360 --> 00:33:29.120
사건의 지평선 너머에서 무슨 일이 일어나는지 알 수 없습니다.

00:33:29.200 --> 00:33:31.520
그렇다고 나쁜 일이 생긴다는 뜻은 아니고,

00:33:31.600 --> 00:33:33.200
그저 무슨 일이 일어나는지 모른다는 뜻입니다.

00:33:36.600 --> 00:33:40.680
AI와 로보틱스가 계속 발전한다면, 저는 확신합니다,

00:33:40.760 --> 00:33:43.560
실제로 지금도 매우 빠르게 발전하고 있습니다,

00:33:43.640 --> 00:33:46.320
제가 말했듯이, 일은 선택 사항이 될 것이고,

00:33:47.360 --> 00:33:50.400
사람들은 원하는 어떤 재화와 서비스든 가질 수 있게 될 것입니다.

00:33:53.080 --> 00:33:55.720
"생각할 수만 있다면 가질 수 있다" 같은 세상이 될 것입니다.

00:33:58.360 --> 00:33:59.840
하지만 어느 순간이 되면,

00:34:01.320 --> 00:34:05.720
AI가 인간이 생각해낼 수 있는 모든 것에서 사실상 포화 상태에 이르게 될 것입니다.

00:34:06.600 --> 00:34:08.360
그리고 그 지점에서는,

00:34:08.440 --> 00:34:13.000
AI가 누군가를 위해 일을 하는 상황이 아니라...

00:34:13.080 --> 00:34:15.320
AI와 로보틱스가 AI와 로보틱스를 위해 일을 하게 되고,

00:34:15.400 --> 00:34:19.000
인간을 행복하게 만들기 위해 할 일이 바닥나기 때문입니다.

00:34:21.040 --> 00:34:23.600
왜냐하면 한계가 있기 때문입니다. 예를 들어...

00:34:24.240 --> 00:34:26.640
사람은 음식을 아무리 많아도 일정량만 먹을 수 있다든지...

00:34:29.200 --> 00:34:30.800
하지만 결국에는, 제 생각에는...

00:34:30.880 --> 00:34:33.840
"생각할 수만 있다면 가질 수 있다"가 미래가 될 것입니다.

00:34:33.920 --> 00:34:36.520
아시다시피 오스트리아 학파 경제학은,

00:34:36.600 --> 00:34:40.880
과거로 거슬러 올라가면 애덤 스미스에서 갈라져 나온 흐름이었습니다.

00:34:40.960 --> 00:34:43.680
그들은 모든 것의 한계효용을 이야기합니다.

00:34:44.800 --> 00:34:47.160
무언가를 하나 갖는 것은 가치가 있고,

00:34:47.240 --> 00:34:49.520
같은 것을 두 개 갖는 것은 가치가 더 낮고

00:34:49.600 --> 00:34:51.800
같은 것을 열 개 갖는 것은 가치가 없다는 식입니다.

00:34:51.880 --> 00:34:53.360
네.

00:34:53.440 --> 00:34:55.080
그래서 우리가 원하는 것을 다 가질 수 있다면, 어쩌면—

00:34:55.160 --> 00:34:56.880
예를 들어 마시멜로 열 개 같은 것인데, 누가 그런 것을 원하겠습니까?

00:34:56.960 --> 00:34:58.400
-네. -[웃음]

00:34:59.760 --> 00:35:01.200
하나면 충분합니다.

00:35:03.080 --> 00:35:04.520
이건 마시멜로 실험 같은 것입니다. 이렇게 묻습니다,

00:35:04.600 --> 00:35:07.480
"나중에 마시멜로 두 개를 받으시겠습니까, 아니면 지금 하나를 받으시겠습니까?"

00:35:07.560 --> 00:35:09.720
그리고 저는 "마시멜로 하나로 하겠습니다, 두 개는 원하지 않습니다"라고 말합니다.

00:35:09.800 --> 00:35:12.120
-흥미롭습니다. -[웃음]

00:35:12.200 --> 00:35:13.280
어떤 것을 고르시겠습니까?

00:35:13.360 --> 00:35:16.360
하지만 저는—마시멜로 하나면 충분합니다.

00:35:16.440 --> 00:35:18.360
저는 늘 마시멜로가,

00:35:18.440 --> 00:35:21.240
그렇게, 아시다시피, 최고의 사탕은 아니라고 생각합니다.

00:35:21.320 --> 00:35:23.720
-네. -[웃음]

00:35:23.800 --> 00:35:25.720
저는 마시멜로가 그렇게 간절하지 않습니다.

00:35:25.800 --> 00:35:28.120
-당신이야말로 최고인 것 같습니다... -[웃음]

00:35:28.200 --> 00:35:29.200
누가 그렇겠습니까?

00:35:30.840 --> 00:35:32.920
당신이야말로 마시멜로 실험의 최고의 증거입니다.

00:35:33.000 --> 00:35:34.840
-제 생각에도 그렇습니다... -그렇겠습니다.

00:35:34.920 --> 00:35:37.200
아, 그러니까 본질적으로 저는 만족을 미루는 것을 좋아합니다.

00:35:37.280 --> 00:35:38.440
-네. -네.

00:35:38.520 --> 00:35:39.840
대부분의 사람들보다 더 잘 미루실 수 있습니다.

00:35:39.920 --> 00:35:41.880
아시다시피 저는 "만족을 미뤄라"라고 적힌 문신이 있습니다.

00:35:41.960 --> 00:35:43.520
네, 와, 알겠습니다. 이게 무엇입니까?

00:35:43.600 --> 00:35:45.240
아, 마시멜로 테스트를 정말 진지하게 받아들이시는 것 같습니다.

00:35:45.320 --> 00:35:46.640
[웃음]

00:35:48.000 --> 00:35:49.120
잘 기억이 나지 않습니다.

00:35:49.200 --> 00:35:50.680
제가 트레이딩을 하거나 매수할 때도 그렇습니다...

00:35:50.760 --> 00:35:52.640
만족을 미루는 것입니다, 네, 네.

00:35:52.720 --> 00:35:53.880
-도움이 됩니다. -와, 알겠습니다.

00:35:53.960 --> 00:35:55.320
그건... 그건 정말 대단한 각오입니다.

00:35:55.400 --> 00:35:57.600
그리고 그것이 저를 가리키고 있어서, 그것을 보면... 떠올리게 됩니다.

00:36:01.200 --> 00:36:02.920
알겠습니다, 좋은 조언입니다.

00:36:03.000 --> 00:36:04.520
그러니까, 놓치기 어렵습니다.

00:36:04.600 --> 00:36:06.640
-만약 문신을 새길 수 있다면... -[웃음]

00:36:06.720 --> 00:36:08.920
만약 문신을 한다면 무엇을 새기시겠습니까?

00:36:09.880 --> 00:36:11.680
아마 제 아이들 이름 같은 것을 새기지 않을까 싶습니다.

00:36:11.760 --> 00:36:12.760
네.

00:36:14.320 --> 00:36:16.920
왜 "X"라는 글자를 그렇게까지 좋아하십니까?

00:36:18.080 --> 00:36:19.240
음...

00:36:19.320 --> 00:36:20.600
[웃음]

00:36:24.160 --> 00:36:27.040
그러니까요, 솔직히 좋은 질문입니다.

00:36:27.120 --> 00:36:30.440
가끔은 제가 무엇이 문제인가 싶기도 합니다.

00:36:37.280 --> 00:36:38.360
그래서, 음...

00:36:39.720 --> 00:36:42.560
그러니까, 제 생각에는 이것이 어디서 시작되었느냐 하면...

00:36:42.640 --> 00:36:46.080
그러니까 아주 오래전, 고대라고 할 만한 1999년 이야기입니다.

00:36:46.160 --> 00:36:48.800
[웃음]

00:36:48.880 --> 00:36:51.920
스펀지밖에 없던 선캄브리아 시대 같은 때였습니다...

00:36:55.960 --> 00:36:58.800
한 글자짜리 도메인 이름이 세 개밖에 없었습니다.

00:36:59.880 --> 00:37:02.200
제 기억으로는 X, Q, Z였던 것 같습니다.

00:37:02.280 --> 00:37:03.840
그리고, 음...

00:37:03.920 --> 00:37:06.640
그리고 저는 “좋아, 이런 곳을 만들고 싶다”라고 생각했습니다.

00:37:06.720 --> 00:37:10.400
그곳을 금융의 교차로로 만들고 싶었습니다.

00:37:10.480 --> 00:37:13.320
말하자면 일종의 금융 거래소 같은 곳입니다.

00:37:16.160 --> 00:37:20.720
본질적으로는 정보이론 관점에서 돈 문제를 푸는 것이었습니다.

00:37:20.800 --> 00:37:22.160
즉, 현재의 은행 시스템은 이런 구조입니다.

00:37:22.240 --> 00:37:27.640
서로 이질적인 데이터베이스가 아주 많이 존재합니다.

00:37:27.720 --> 00:37:32.560
그리고 그것들이 배치 처리로 돌아가는데 보안도 취약합니다.

00:37:32.640 --> 00:37:37.520
그런데 단일 데이터베이스를 가질 수 있다면 어떻겠습니까.

00:37:37.600 --> 00:37:41.280
그것이 실시간으로 동작하고 안전하다면 말입니다.

00:37:41.360 --> 00:37:44.280
그러면 금전적인 측면에서도 더 효율적일--

00:37:44.360 --> 00:37:46.760
정보이론 관점에서 보면 말입니다.

00:37:46.840 --> 00:37:50.520
그것은 서로 이질적인 데이터베이스를 많이 두는 방식보다 더 효율적입니다.

00:37:50.600 --> 00:37:52.960
그런 데이터베이스들이 아주 느리게 배치 처리하는 방식보다 낫다는 뜻입니다.

00:37:55.160 --> 00:37:56.920
그래서, 음...

00:37:57.000 --> 00:38:01.520
어쨌든 그게 예전에 했던 X.com이었습니다.

00:38:01.600 --> 00:38:05.080
그게 결국 어느 정도는 페이팔이 되었습니다.

00:38:07.160 --> 00:38:08.320
그리고 그다음에는 이런 일이 있었습니다.

00:38:10.560 --> 00:38:12.200
그리고 이베이가 인수했습니다. 그리고 나서 이베이가--

00:38:12.280 --> 00:38:13.600
이베이 쪽에서 누군가 연락해 와서 말했습니다.

00:38:13.680 --> 00:38:15.640
“도메인 이름을 다시 사시겠습니까?”

00:38:15.720 --> 00:38:16.960
그래서 저는 “네, 좋습니다”라고 했습니다.

00:38:17.040 --> 00:38:19.080
그래서 저는 꽤 오랫동안 그 도메인 이름을 갖고 있었습니다.

00:38:22.640 --> 00:38:24.040
그리고 그다음에는 또 이런 일이 있었습니다.

00:38:25.520 --> 00:38:27.960
그리고, 네, 그렇습니다...

00:38:28.040 --> 00:38:31.320
그러고는 저는 “음, 어쩌면 이게--”라고 생각했습니다.

00:38:31.400 --> 00:38:33.560
트위터를 인수하는 것이 또한 기회가 될 수 있겠다고요.

00:38:33.640 --> 00:38:39.400
X.com의 원래 계획을 다시 검토할 기회 말입니다.

00:38:39.480 --> 00:38:41.360
즉, 이런 것을 만드는 것이었습니다...

00:38:42.880 --> 00:38:46.720
즉, 금융 거래의 청산소 같은 것을 만드는 것입니다.

00:38:46.800 --> 00:38:51.840
기본적으로 더 효율적인 돈 데이터베이스를 만드는 것입니다.

00:38:51.920 --> 00:38:53.160
그렇게 생각하시면 됩니다.

00:38:54.880 --> 00:39:01.200
예를 들어 돈은 노동을 배분하기 위한 정보 시스템에 가깝습니다.

00:39:01.280 --> 00:39:03.560
사람들은 때때로 돈 자체가 권력이라고 생각하지만,

00:39:03.640 --> 00:39:05.640
실제로는 그렇지 않습니다만--

00:39:05.720 --> 00:39:07.560
배분할 노동이 없으면 의미가 없습니다.

00:39:08.440 --> 00:39:13.720
그래서 무인도에서 1조 달러 같은 돈을 갖고 있다 해도...

00:39:13.800 --> 00:39:15.280
-이제 그 돈이 있다고 해도요. -...아무 소용이 없습니다.

00:39:15.360 --> 00:39:18.400
아, 그렇네요. 실제로 해볼 수 있는데 왜 추측만 하겠습니까?

00:39:22.880 --> 00:39:25.000
저는 무인도에 가게 되는 일만은 없었으면 합니다.

00:39:25.760 --> 00:39:27.560
저에게는 별로 유용하지 않을 것입니다.

00:39:29.200 --> 00:39:34.320
하지만 이것은 무인도에 고립되면 제 요점이 드러납니다.

00:39:34.400 --> 00:39:35.560
1조 달러를 가지고 있어도,

00:39:35.640 --> 00:39:39.960
배분할 노동이 없기 때문에 쓸모가 없습니다.

00:39:40.040 --> 00:39:41.480
그저 본인이 스스로를 배분할 뿐이기 때문입니다.

00:39:45.960 --> 00:39:49.080
어쨌든, 장황하게 말하자면 그렇습니다.

00:39:49.160 --> 00:39:50.320
즉, 제 말은 이렇습니다.

00:39:51.400 --> 00:39:53.120
그러니까 정말 그런 느낌입니다.

00:39:54.280 --> 00:39:59.880
저는 25년 전에 가졌던 이 아이디어를 조금씩 다시 되짚어보고 있습니다.

00:39:59.960 --> 00:40:03.840
더 효율적인, 음...

00:40:06.080 --> 00:40:07.720
돈 데이터베이스를 만들자는 아이디어입니다.

00:40:09.960 --> 00:40:11.960
그리고 그게 성공하면 사람들이 사용할 것이고요,

00:40:12.040 --> 00:40:14.080
성공하지 못하면 사용하지 않을 것입니다.

00:40:15.600 --> 00:40:18.880
그리고 저는 통합된 형태를 갖는 아이디어도 마음에 듭니다.

00:40:20.200 --> 00:40:26.080
앱이든 웹사이트든 뭐든, 거기서 원하는 건 무엇이든 할 수 있게 하는 것입니다.

00:40:28.800 --> 00:40:31.080
아시다시피 중국에는 위챗이 이런 역할을 합니다.

00:40:31.160 --> 00:40:35.880
어느 정도는 거기서 정보를 주고받을 수도 있습니다.

00:40:35.960 --> 00:40:39.480
정보를 게시할 수도 있고, 돈도 주고받을 수 있습니다.

00:40:42.360 --> 00:40:45.840
중국에서는 사람들이 대체로 위챗으로 일상을 영위합니다.

00:40:45.920 --> 00:40:47.600
그리고 꽤 유용합니다만,

00:40:47.680 --> 00:40:51.440
중국 밖에는 사실상 위챗 같은 것이 없습니다.

00:40:51.520 --> 00:40:53.280
그래서, 그러니까...

00:40:53.360 --> 00:40:57.480
그러니까 X의 구상은 말하자면 위챗++ 같은 것이라고 할 수 있습니다.

00:40:57.560 --> 00:41:01.800
어쨌든, 그다음에 스페이스 익스플로레이션 테크놀로지스가

00:41:01.880 --> 00:41:03.640
회사의 정식 명칭입니다.

00:41:03.720 --> 00:41:06.240
하지만 저는 "그건 너무 길고 말하기가 힘들다"라고 생각했습니다.

00:41:06.320 --> 00:41:07.960
그래서 저는 "그냥 스페이스X라고 부르자"라고 했고,

00:41:08.040 --> 00:41:09.880
우주판 페덱스처럼 말입니다.

00:41:11.240 --> 00:41:13.800
그냥 우연히 그 안에 X가 들어가 있는 것뿐인데요, 그러니까...

00:41:13.880 --> 00:41:17.280
탐사(exploration)에 X가 들어가니까요, 뭐...

00:41:17.360 --> 00:41:21.240
그리고 저는 예술적으로 X를 대문자로 쓰는 게 마음에 들어서요, 그래서...

00:41:23.080 --> 00:41:26.760
그래서, 음, 그런 이유로 스페이스X가 됐습니다만...

00:41:26.840 --> 00:41:29.480
그리고 또 뭐가 있냐면요, 저는 아이가 하나 있습니다.

00:41:31.480 --> 00:41:33.120
그 아이 이름도 X인데요,

00:41:33.200 --> 00:41:36.920
그 이름을 "X"라고 지은 건 아이 엄마입니다.

00:41:37.000 --> 00:41:38.400
-아, 그래요? -[웃음]

00:41:38.480 --> 00:41:41.520
그리고 저는 사람들이 제가 X에 집착한다고 정말 생각할 거라고 말했습니다.

00:41:41.600 --> 00:41:43.680
우리 아이도 "X"라고 이름을 지으면 말이지요, 아시겠지요?

00:41:43.760 --> 00:41:48.120
그리고 저는 그녀에게 "봐요, 저는 X.com도 가지고 있잖아요"라고 말했습니다.

00:41:48.200 --> 00:41:49.840
[웃음]

00:41:50.440 --> 00:41:52.760
그래서 사람들은 정말로

00:41:52.840 --> 00:41:55.080
제가 이 글자에 어느 정도 페티시가 있다고 생각할 겁니다.

00:41:55.160 --> 00:41:58.400
하지만 그녀는 아니라고 했고, X를 좋아해서 아이 이름을 X로 하고 싶다고 했습니다.

00:41:58.480 --> 00:41:59.520
저는 "알겠습니다"라고 했습니다.

00:41:59.600 --> 00:42:02.160
이건 최근에 생긴 건가요, 아니면 어릴 때부터 그랬나요?

00:42:02.240 --> 00:42:05.960
아니요, 저는 어느 정도 우연이라는 말씀을 드리는 겁니다.

00:42:06.040 --> 00:42:07.560
알겠습니다.

00:42:08.520 --> 00:42:09.720
그러니까, 모든 게 X라고 불리는 건 아닙니다.

00:42:09.800 --> 00:42:11.840
예를 들면 테슬라는 아니지요, 테슬라에는 X가 하나도 없습니다.

00:42:11.920 --> 00:42:12.920
네.

00:42:15.320 --> 00:42:17.560
일론, 미래에 돈은 무엇이 될 거라고 보십니까?

00:42:19.640 --> 00:42:22.520
장기적으로는...

00:42:24.000 --> 00:42:27.360
솔직히 말하면 돈이라는 개념은 사라질 거라고 생각합니다.

00:42:27.440 --> 00:42:29.480
좀 이상하게 들리겠지만...

00:42:31.560 --> 00:42:34.000
누구나 무엇이든 가질 수 있는 미래라면,

00:42:35.680 --> 00:42:40.960
노동을 배분하기 위한 데이터베이스로서 돈이 더는 필요 없다고 생각합니다.

00:42:43.440 --> 00:42:48.200
AI와 로봇공학이 모든 인간의 필요를 충족할 만큼 충분히 발전한다면,

00:42:48.280 --> 00:42:52.000
그렇다면 돈은 더 이상...

00:42:52.080 --> 00:42:54.440
그 중요성이 극적으로 줄어듭니다.

00:42:54.520 --> 00:42:56.000
우리가 돈을 계속 갖게 될지 확신이 없습니다.

00:42:58.360 --> 00:43:02.680
제가 읽어 본 것 중에서 이런 미래를 가장 잘 상상해낸 사례는

00:43:02.760 --> 00:43:07.640
이언 M. 뱅크스의 '컬처' 시리즈입니다.

00:43:07.720 --> 00:43:10.280
그래서 저는 사람들이 '컬처' 시리즈를 읽어 보시길 권합니다.

00:43:10.360 --> 00:43:15.080
그 '컬처' 시리즈에 나오는 아주 먼 미래를 보면, 거기에는...

00:43:15.160 --> 00:43:16.800
거기에도 돈이 없습니다.

00:43:18.240 --> 00:43:20.160
그리고 누구나 거의 원하는 것은 무엇이든 가질 수 있습니다.

00:43:22.800 --> 00:43:28.160
그래도 말하자면 몇 가지 근본적인 '통화'는 남아 있습니다.

00:43:28.240 --> 00:43:30.200
그것들은 물리학에 기반한 것입니다.

00:43:30.280 --> 00:43:32.720
그래서 에너지는...

00:43:32.800 --> 00:43:34.840
에너지가 진짜 통화입니다.

00:43:34.920 --> 00:43:37.320
그래서 제가 비트코인이 에너지에 기반한다고 말한 것입니다.

00:43:37.400 --> 00:43:41.800
에너지는 법으로 만들 수 없습니다. 그냥, 아시다시피...

00:43:41.880 --> 00:43:43.840
법을 하나 통과시킨다고 해서 갑자기 에너지가 많이 생기지는 않습니다.

00:43:45.640 --> 00:43:50.200
에너지를 생산하는 것은 매우 어렵고,

00:43:50.280 --> 00:43:53.600
특히 유용한 일을 하도록 에너지를 유용한 방식으로 끌어다 쓰는 것은 더더욱 어렵습니다.

00:43:54.280 --> 00:43:56.880
그래서 제 생각에는 아마...

00:43:59.120 --> 00:44:03.760
아마 돈은 없고, 아마 우리는 그냥 에너지만 갖게 될 것 같습니다.

00:44:04.960 --> 00:44:09.840
그러니까 전력 생산이 사실상의 통화가 되는 것이지요.

00:44:11.120 --> 00:44:15.840
그러니까, 문명 발전을 한 가지로 표현하는 방식은

00:44:15.920 --> 00:44:20.640
카르다쇼프 척도에서 얼마나 달성했는지, 그 완성도 비율이라고 할 수 있습니다.

00:44:20.720 --> 00:44:22.400
그러니까, 아시다시피,

00:44:22.480 --> 00:44:26.600
카르다쇼프 I형은 한 행성의 에너지 중 몇 퍼센트를

00:44:26.680 --> 00:44:30.040
유용한 일로 성공적으로 전환하고 있느냐입니다.

00:44:30.120 --> 00:44:31.840
그리고 여기서는 제가 약간 의역하는 것일 수도 있는데,

00:44:31.920 --> 00:44:36.480
카르다쇼프 II형은 태양의 에너지 중 몇 퍼센트를

00:44:36.560 --> 00:44:38.320
유용한 일로 전환하고 있느냐이고,

00:44:40.360 --> 00:44:43.280
카르다쇼프 III형은 은하의 에너지 중 몇 퍼센트를

00:44:43.360 --> 00:44:44.720
유용한 일로 전환하고 계십니까?

00:44:49.000 --> 00:44:52.200
그래서 저는 결국 많은 것들이 에너지 기반이 된다고 생각합니다.

00:44:53.760 --> 00:44:56.200
하지만 태양광으로 구동되는 AI 위성이 있다면,

00:44:56.280 --> 00:44:58.480
에너지도 무료이고 풍부해집니다,

00:44:58.560 --> 00:45:02.960
우리가 이용할 수 있는 태양 에너지를 전부 활용하는 일은 결코 불가능할 것이기 때문입니다.

00:45:03.720 --> 00:45:07.640
그러니 그 관점에서는 본질적으로 부의 저장 수단이 될 수 없지 않습니까?

00:45:09.200 --> 00:45:10.800
아시다시피, 사실...

00:45:10.880 --> 00:45:13.440
그러니까, 그런 식으로는 부를 저장할 수가 없습니다...

00:45:13.520 --> 00:45:14.880
할 수 있는 건 오직...

00:45:19.000 --> 00:45:21.560
그 안에서 숫자만 쌓을 수 있습니다--

00:45:21.640 --> 00:45:28.640
지금은 데이터베이스에 숫자를 쌓아서 그것으로...

00:45:32.800 --> 00:45:37.040
어느 정도는 다른 사람들의 행동을 특정 방향으로 유인할 수 있습니다.

00:45:37.120 --> 00:45:39.280
그리고 사람들은 그것을 부라고 부르는 것 같습니다.

00:45:40.320 --> 00:45:43.080
하지만 다시 말해, 주변에 사람이 없다면, 그건--

00:45:43.160 --> 00:45:44.920
부의 축적은 무의미합니다.

00:45:45.000 --> 00:45:47.920
옆길로 새는 얘기지만, 만약 ...을 생각해 본다면...

00:45:48.000 --> 00:45:51.280
음식을 인간이 번성하는 데 필요한 에너지라고 본다면...

00:45:51.360 --> 00:45:53.080
네, 음식은 에너지입니다.

00:45:53.160 --> 00:45:55.440
말 그대로 칼로리가 있는데, 그게 곧 에너지라는 뜻입니다.

00:45:55.520 --> 00:45:59.480
...그렇다면 자급자족하는 농장이 ...인 상품이 될 수 있습니까...

00:46:04.720 --> 00:46:07.800
그게 무슨 뜻인지 확실치 않지만, 아시다시피...

00:46:11.840 --> 00:46:15.880
어느 시점이 되면 ...하는 사이클을 완성하게 됩니다...

00:46:16.880 --> 00:46:18.360
제 생각에는, 어느 시점이 되면...

00:46:19.160 --> 00:46:22.920
일종의 기존 경제와 분리됩니다.

00:46:23.000 --> 00:46:25.360
만약, 음...

00:46:26.880 --> 00:46:31.920
AI와 로봇이 칩과 태양광 패널을 생산하고...

00:46:35.640 --> 00:46:39.760
그리고 칩과 로봇을 만들기 위해 자원을 채굴하고,

00:46:39.840 --> 00:46:41.400
...을 만들기 위해...

00:46:41.480 --> 00:46:44.200
그렇게 그 사이클을 완성하게 됩니다.

00:46:44.280 --> 00:46:45.520
그 사이클이...

00:46:45.600 --> 00:46:48.600
그 사이클이 완성되면,

00:46:49.680 --> 00:46:53.160
제 생각에는 그 시점에서 화폐 시스템으로부터 분리됩니다.

00:46:53.240 --> 00:46:57.680
...라는 점에서 그것이 미국의 향후 방향입니까...

00:46:59.080 --> 00:47:01.760
오늘날 그들이 가진 부채가 얼마나 큰지 때문입니까?

00:47:01.840 --> 00:47:03.480
그들이 디플레이션으로 자국 통화를 사실상 축소시키고

00:47:03.560 --> 00:47:07.880
이런 새로운 형태로 전환해 그 추진을 주도하며,

00:47:07.960 --> 00:47:10.080
그게 그들에게 더 합리적이기 때문입니까?

00:47:10.160 --> 00:47:12.200
음, 제가 말하는 이런 미래에서는,

00:47:12.280 --> 00:47:16.560
국가라는 개념이 어느 정도 시대착오적인 것이 됩니다.

00:47:18.320 --> 00:47:19.760
지금도 그것을 믿으십니까?

00:47:19.840 --> 00:47:22.040
-국가를 믿으십니까-- -네, 저는 지금은 분명히 믿습니다.

00:47:22.120 --> 00:47:25.960
그리고 제가 ...을 하나 구분해서 말씀드리고 싶습니다...

00:47:26.040 --> 00:47:29.560
그러니까, 이것들은 제가 보는 것에 근거해 앞으로 일어날 거라고 생각하는 것일 뿐이고,

00:47:29.640 --> 00:47:32.720
제가 이것들이 근본적으로 좋은 일이라고 생각해서

00:47:32.800 --> 00:47:34.880
일어나게 만들려고 하는 것과는 다릅니다."

00:47:34.960 --> 00:47:37.400
이 일은 제 여부와 상관없이 일어날 거라고 생각합니다,

00:47:38.600 --> 00:47:41.120
-제가 좋아하든 싫어하든요. -맞습니다.

00:47:41.200 --> 00:47:43.920
문명이 계속 발전하는 한,

00:47:44.000 --> 00:47:48.040
우리는 매우 큰 규모의 AI와 로보틱스를 갖게 될 것입니다.

00:47:53.320 --> 00:47:55.800
제 생각에는 그게 사실상 유일한 것 같습니다

00:47:55.880 --> 00:47:59.600
미국의 부채 위기를 해결할 수 있는 것은요.

00:47:59.680 --> 00:48:03.440
왜냐하면 현재 미국의 부채는 터무니없이 높고,

00:48:03.520 --> 00:48:08.320
그 부채에 대한 이자 지급액이 전체 국방 예산을 초과합니다

00:48:08.400 --> 00:48:10.920
미국의 국방 예산 전체를요, 이자만으로.

00:48:11.000 --> 00:48:12.640
그리고 그건...

00:48:12.720 --> 00:48:15.320
적어도 단기적으로는 계속 증가할 것입니다.

00:48:15.960 --> 00:48:18.440
그래서 제 생각에는, 사실,

00:48:18.520 --> 00:48:21.160
부채 상황을 해결할 수 있는 유일한 것은

00:48:21.240 --> 00:48:23.720
AI와 로보틱스입니다.

00:48:23.800 --> 00:48:25.440
하지만 그것은 그 이상일 것입니다...

00:48:26.640 --> 00:48:27.840
그것이 초래할 수도 있습니다...

00:48:28.560 --> 00:48:32.600
보시다시피, 아마 상당한 디플레이션을 초래할 것 같습니다, 왜냐하면...

00:48:34.880 --> 00:48:39.280
디플레이션이나 인플레이션은 사실 생산된 재화와 서비스의 비율과

00:48:39.360 --> 00:48:41.720
통화 공급의 변화 사이의 관계이기 때문입니다.

00:48:41.800 --> 00:48:46.240
그러니까 재화와 서비스의 산출이 통화 공급보다 더 빨리 늘어나면,

00:48:46.320 --> 00:48:47.840
디플레이션이 생깁니다.

00:48:47.920 --> 00:48:49.400
재화와 서비스의 산출이 줄어들면--

00:48:49.480 --> 00:48:54.800
실질 재화와 서비스 산출이 통화 공급보다 더 느리게 늘어나면,

00:48:54.880 --> 00:48:56.200
인플레이션이 생깁니다.

00:48:56.280 --> 00:48:57.760
그렇게 간단합니다.

00:48:57.840 --> 00:49:01.720
사람들이 가끔 더 복잡하게 만들려 하지만, 사실 그렇지 않습니다.

00:49:02.920 --> 00:49:05.240
그러니까 AI와 로봇공학이 있고

00:49:05.320 --> 00:49:08.120
재화와 서비스 산출이 극적으로 증가하면,

00:49:08.200 --> 00:49:10.000
아마 디플레이션이 생길 것입니다.

00:49:10.080 --> 00:49:11.840
그럴 가능성이 높습니다.

00:49:13.080 --> 00:49:16.280
왜냐하면 재화와 서비스 산출을 늘리는 속도만큼

00:49:16.360 --> 00:49:18.960
통화 공급을 그렇게 빨리 늘릴 수는 없기 때문입니다.

00:49:19.880 --> 00:49:22.280
-아니, 그러니까-- -여기 이 파리가 정말 위험하네요.

00:49:23.240 --> 00:49:25.360
뭐라도 해야 할까요?

00:49:26.520 --> 00:49:28.480
어쩌면 다른 데로 가게 설득할 수 있을지도 모르겠습니다.

00:49:29.480 --> 00:49:31.200
다른 곳으로 유인해 보겠습니다.

00:49:31.280 --> 00:49:32.760
-아마 진짜 가버린 것 같습니다. -좋습니다.

00:49:32.840 --> 00:49:34.000
아, 이제는 다시 왔네요.

00:49:38.400 --> 00:49:39.960
아마 빛에 끌리는 것 같습니다.

00:49:41.040 --> 00:49:43.960
-디플레이션이— -아마 커피가 필요한가 봅니다.

00:49:44.040 --> 00:49:45.360
제 커피는 다 끝났습니다.

00:49:47.840 --> 00:49:51.240
AI 때문에 디플레이션이 불가피하다면,

00:49:52.120 --> 00:49:54.200
-그러면 왜 우리는— -네, 그럴 가능성이 가장 큽니다.

00:49:54.280 --> 00:49:55.680
맞습니다.

00:49:55.760 --> 00:49:59.000
그런데 왜 지금 사회 전반에서 다시 인플레이션이 나타나는 것입니까?

00:49:59.080 --> 00:50:03.040
AI가 아직 생산성 증가로 이어지지 않았습니까?

00:50:03.120 --> 00:50:04.200
그게 아직--

00:50:04.280 --> 00:50:07.560
AI가 아직 생산성에 충분한 영향을 주지 못해서

00:50:07.640 --> 00:50:11.960
재화와 서비스가 통화 공급 증가보다 더 빠르게 늘어나지 못하고 있습니다.

00:50:12.040 --> 00:50:14.960
그래서 미국은 통화 공급을 늘리고 있는데,

00:50:15.040 --> 00:50:19.320
적자 규모가 상당하기 때문입니다.

00:50:19.400 --> 00:50:21.080
그 규모가 대략 2조 달러 수준입니다.

00:50:21.680 --> 00:50:24.720
그러니까 결국...

00:50:27.080 --> 00:50:29.480
인플레이션이 없으려면 재화와 서비스 산출이

00:50:29.560 --> 00:50:31.360
그보다 더 많이 증가해야 합니다.

00:50:31.440 --> 00:50:32.600
그래서 아직은 거기에 이르지 못했습니다만,

00:50:32.680 --> 00:50:35.640
하지만 거기까지 얼마나 걸리냐고 묻는다면,

00:50:35.720 --> 00:50:38.200
제 생각에는... 3년입니다.

00:50:39.200 --> 00:50:40.440
아마도 3년 정도면...

00:50:41.040 --> 00:50:42.800
3년 이내에...

00:50:44.160 --> 00:50:48.640
제 추측으로는 재화와 서비스의 산출이 인플레이션률을 웃돌 것입니다.

00:50:48.720 --> 00:50:50.120
그러니까, 돈 말입니다...

00:50:50.200 --> 00:50:53.120
재화와 서비스의 성장이 통화 공급 증가를 상회할 것입니다.

00:50:53.200 --> 00:50:54.560
대략 3년쯤 뒤입니다.

00:50:55.560 --> 00:50:57.800
아마 그 3년이 지난 뒤에는,

00:50:57.880 --> 00:51:00.440
디플레이션이 오고, 그러면 금리가 0으로 내려갈 것입니다.

00:51:00.520 --> 00:51:03.000
그러면 부채는 지금보다 덜 큰 문제가 될 것입니다.

00:51:03.080 --> 00:51:04.520
-네. -그렇지 않습니까?

00:51:04.600 --> 00:51:06.000
아마 그게 가장 그럴 가능성이 큽니다.

00:51:08.560 --> 00:51:10.840
아까 시뮬레이션 안에 있다는 말씀을 하셨습니다.

00:51:10.920 --> 00:51:12.240
저는 '매트릭스'를 정말 좋아합니다.

00:51:12.320 --> 00:51:13.480
네, 네.

00:51:13.560 --> 00:51:15.760
만약 '매트릭스'의 캐릭터가 된다면,

00:51:15.840 --> 00:51:17.200
누가 되고 싶으십니까?

00:51:17.280 --> 00:51:20.440
글쎄요, 고를 만한 캐릭터가 그렇게 많지는 않지 않습니까?

00:51:22.200 --> 00:51:23.760
부디 에이전트 스미스만은 아니었으면 합니다.

00:51:23.840 --> 00:51:25.840
[웃음]

00:51:25.920 --> 00:51:27.160
그는 제 영웅입니다.

00:51:30.920 --> 00:51:32.960
그러니까, 네오는 꽤 멋집니다.

00:51:33.040 --> 00:51:35.320
아키텍트도 흥미롭습니다.

00:51:36.080 --> 00:51:37.600
오라클도 있습니다.

00:51:37.680 --> 00:51:38.920
오라클도 있고...

00:51:40.960 --> 00:51:43.360
가끔은 제가 매트릭스 안의 변칙 같은 존재라고 느낄 때가 있습니다.

00:51:44.800 --> 00:51:45.920
그게 바로 네오입니다.

00:51:46.000 --> 00:51:47.120
네.

00:51:47.840 --> 00:51:49.680
그렇지만 본인이 매트릭스 안에 있다고 믿으십니까?

00:51:49.760 --> 00:51:50.960
그러니까 정말로 그렇게 믿으십니까?

00:51:52.000 --> 00:51:55.120
저는 이런 것들은 그저

00:51:55.200 --> 00:51:57.400
확실성이 아니라 확률로 생각해야 한다고 봅니다.

00:51:58.360 --> 00:52:00.560
우리가 시뮬레이션 속에 있을 확률이 어느 정도 있습니다.

00:52:00.640 --> 00:52:02.680
그걸 몇 퍼센트 정도로 보십니까?

00:52:08.440 --> 00:52:11.000
아마 꽤 높을 것입니다. 꽤 높다고 생각합니다.

00:52:11.080 --> 00:52:12.440
-네? -네.

00:52:13.040 --> 00:52:15.920
이를 생각해 보는 한 가지 방법은 이렇습니다.

00:52:16.000 --> 00:52:18.560
비디오 게임의 발전을 보면,

00:52:18.640 --> 00:52:20.320
우리 생애에, 적어도 제 생애에,

00:52:20.400 --> 00:52:23.880
아주 단순한 비디오 게임에서...

00:52:23.960 --> 00:52:27.760
예를 들어 '퐁'처럼 정사각형 안에 직사각형 두 개가 있고,

00:52:27.840 --> 00:52:30.560
그걸 서로 주고받는 수준에서...

00:52:32.920 --> 00:52:37.720
포토리얼리스틱한 실시간 게임으로

00:52:37.800 --> 00:52:39.960
수백만 명이 동시에 플레이하는 수준까지 왔습니다.

00:52:43.040 --> 00:52:46.000
그리고 그 일은 불과 50년 사이에 일어났습니다.

00:52:46.080 --> 00:52:49.080
그래서 그 추세가 계속된다면,

00:52:49.160 --> 00:52:51.720
비디오 게임은 현실과 구분할 수 없게 될 것입니다.

00:52:51.800 --> 00:52:53.000
맞습니다.

00:52:53.960 --> 00:52:58.440
그리고 우리는 또 매우 지능적인 캐릭터들도 갖게 될 것입니다,

00:52:58.520 --> 00:53:01.160
이런 비디오 게임 안에 NPC 같은 비플레이어 캐릭터들 말입니다.

00:53:01.240 --> 00:53:03.680
오늘날 AI와 나눌 수 있는 대화가 얼마나 정교한지 생각해 보십시오.

00:53:03.760 --> 00:53:05.120
지금도 AI와 그런 대화를 나눌 수 있는데,

00:53:05.200 --> 00:53:08.280
그것은 앞으로 더 정교해질 뿐입니다.

00:53:09.480 --> 00:53:13.520
그러면 그런 대화를 나눌 수 있게 될 것입니다...

00:53:14.640 --> 00:53:21.600
어떤… 거의 모든 인간 대화보다도 더 복잡하고 더 정교한 대화가 될 것입니다.

00:53:21.680 --> 00:53:22.960
어쩌면 정말 그 어떤 대화보다도 그렇습니다.

00:53:24.200 --> 00:53:26.560
그러면… 그러니까— 그러면—

00:53:26.640 --> 00:53:32.160
그러니까 문명이 계속된다면 미래에는 수백만, 어쩌면 수십억 개의…

00:53:35.400 --> 00:53:39.600
사진처럼 현실적인, 그러니까 현실과 구분이 안 될 정도의 비디오 게임이

00:53:39.680 --> 00:53:43.280
그 비디오 게임들에는 캐릭터들이 있는데, 그 캐릭터들은…

00:53:45.720 --> 00:53:47.040
매우 깊이가 있으며,

00:53:47.120 --> 00:53:51.920
그리고 대사는 미리 프로그램되어 있지 않을 것입니다.

00:53:55.040 --> 00:53:57.080
그것은 분명히 그렇게 될 일입니다.

00:53:57.160 --> 00:54:00.240
이것을 시뮬레이션의 이 층위라고 부를 수 있다면 말입니다.

00:54:00.320 --> 00:54:06.120
그러면 우리가 기본 현실에 있을 확률은 얼마나 됩니까,

00:54:06.200 --> 00:54:09.400
그리고 이런 일이 이전에 일어난 적이 없을 확률은 얼마나 됩니까?

00:54:11.240 --> 00:54:15.680
만약 제가 그 가정을 받아들이고 우리가 시뮬레이션 안에 있다고 전제한다면,

00:54:17.600 --> 00:54:19.480
이 이야기의 네오처럼,

00:54:19.560 --> 00:54:22.480
당신은 제가 모르는 무엇을 알고 있고, 저는 무엇을 배울 수 있습니까?

00:54:23.080 --> 00:54:26.240
제 생각에는, 아마도…

00:54:26.320 --> 00:54:30.480
시뮬레이션 밖은 시뮬레이션 안보다 덜 흥미로울 가능성이 큽니다,

00:54:30.560 --> 00:54:34.760
왜냐하면 당신은 흥미로운 것만을 증류한 존재일 가능성이 크기 때문입니다,

00:54:34.840 --> 00:54:36.400
왜냐하면 그것이 우리가 여기서 하는 일이기 때문입니다…

00:54:36.480 --> 00:54:38.240
그것이 바로 우리가 우리 현실에서 하는 일이기 때문입니다.

00:54:39.240 --> 00:54:40.360
그리고 나서…

00:54:42.520 --> 00:54:46.200
또 하나의 이론이 있는데, 제3자가 보기에는 가장 흥미로운 결과가,

00:54:46.280 --> 00:54:50.160
가장 가능성이 높은 결과라는 것입니다…

00:54:51.680 --> 00:54:54.240
시뮬레이션의 신들, 혹은 시뮬레이션의 신 말입니다.

00:54:57.800 --> 00:55:02.200
왜냐하면 우리가 시뮬레이션을 할 때, 인간이 시뮬레이션을 할 때,

00:55:02.920 --> 00:55:06.440
흥미롭지 않은 시뮬레이션은 중단해 버리기 때문입니다.

00:55:07.640 --> 00:55:11.440
그래서 SpaceX가 로켓 비행 시뮬레이션을 한다면…

00:55:14.200 --> 00:55:17.800
지루한 것들은 폐기합니다,

00:55:17.880 --> 00:55:19.560
왜냐하면 그것들은— 그냥…

00:55:19.640 --> 00:55:21.200
그것들로부터는 아무것도 배우지 못하기 때문입니다.

00:55:21.280 --> 00:55:25.400
또는 테슬라가 자율주행을 위한 시뮬레이션을 할 때도,

00:55:27.040 --> 00:55:30.720
테슬라는 실제로 가장 흥미로운 극단적 사례들을 찾고 있습니다,

00:55:30.800 --> 00:55:36.400
왜냐하면 보통의 상황에 대해서는 이미 데이터가 충분히 있기 때문입니다.

00:55:36.480 --> 00:55:39.360
맑은 날 직선 도로를 주행하는 데이터 말입니다.

00:55:40.280 --> 00:55:41.760
그런 데이터는 더 이상 필요하지 않습니다.

00:55:41.840 --> 00:55:45.880
악천후 속 좁고 굽이진 길 같은 상황이 필요합니다.

00:55:45.960 --> 00:55:49.040
서로를 향해 달려오는 두 대의 차가 필요합니다,

00:55:49.120 --> 00:55:50.800
거의 정면충돌에 가까운 상황으로 말입니다.

00:55:50.880 --> 00:55:53.840
그러니까 이상한 것들, 기본적으로는 흥미로운 것들이 필요합니다.

00:55:55.400 --> 00:55:59.160
그래서 다윈주의적 관점에서 보면,

00:55:59.240 --> 00:56:01.400
가장 살아남을 가능성이 높은 시뮬레이션은

00:56:01.480 --> 00:56:05.400
가장 흥미로운 시뮬레이션일 가능성이 큽니다,

00:56:06.320 --> 00:56:10.080
그러므로 가장 흥미로운 결과가

00:56:10.160 --> 00:56:11.480
가장 가능성이 높다는 뜻입니다.

00:56:12.960 --> 00:56:18.560
그리고 우리 세계를 시뮬레이션한 사람들이 있다고 외삽해 보면,

00:56:18.640 --> 00:56:20.160
그들 자신도, 다시 말해,

00:56:20.240 --> 00:56:21.960
-또 다른 시뮬레이션 안에 있을 수도 있습니다. -네.

00:56:22.040 --> 00:56:24.000
그리고 시뮬레이션의 층이 여러 겹일 수도 있습니다.

00:56:24.080 --> 00:56:25.200
네.

00:56:25.280 --> 00:56:29.840
이 모든 시뮬레이션의 층 너머에 무언가가 있다고 생각하십니까?

00:56:29.920 --> 00:56:35.960
어딘가에서 당신이 한때 어떤 의미에서는 스피노자의 신을 따랐다고 읽었습니다.

00:56:37.080 --> 00:56:38.400
하늘에 있는 남자 같은 존재는 없습니다.

00:56:38.480 --> 00:56:41.160
음, 제 말은 꼭 그런 것이 필요하지는 않다는 점을 말씀드린 것입니다…

00:56:43.560 --> 00:56:44.920
스피노자가 말한 것 중 하나는

00:56:45.000 --> 00:56:47.920
절대적인 의미에서 도덕이 가능하다는 것입니다.

00:56:48.000 --> 00:56:51.560
도덕을 누군가에게서 전달받을 필요는 없습니다.

00:56:51.640 --> 00:56:53.360
그러니까 말입니다...

00:56:53.440 --> 00:56:54.600
질문은 이것입니다.

00:56:54.680 --> 00:56:58.560
도덕이 종교적 맥락 밖에서도 존재할 수 있습니까?

00:56:58.640 --> 00:57:01.240
그리고 스피노자는 가능하다고 주장했습니다.

00:57:01.320 --> 00:57:03.920
그는 "자연의 법칙이

00:57:04.000 --> 00:57:07.560
도덕의 법칙을 찾아야 할 근거가 되어야 한다"고

00:57:07.640 --> 00:57:08.760
어느 정도는 말한 것 아닙니까?

00:57:08.840 --> 00:57:10.040
네.

00:57:10.120 --> 00:57:13.280
하지만 자연의 법칙을 떠올리면, 호랑이가 사슴을 잡아먹는 모습 같은 것이 보이는데...

00:57:15.040 --> 00:57:19.840
그러면 스피노자의 도덕에서는 그런 것도 정당한 것입니까?

00:57:23.280 --> 00:57:25.120
음...

00:57:29.920 --> 00:57:32.680
스피노자에게서 배울 점이 많다고 생각합니다만,

00:57:32.760 --> 00:57:35.960
제가 스피노자를 언급한 이유는,

00:57:36.040 --> 00:57:41.360
사회가 기능하도록 하는 어떤 도덕 체계가...

00:57:42.600 --> 00:57:46.240
사회를 기능적이고 생산적으로 만드는 도덕 체계가

00:57:47.480 --> 00:57:50.000
종교 없이도...

00:57:50.080 --> 00:57:53.520
그런 데에는 종교적 교리가 반드시 필요한 것은 아닙니다.

00:57:59.640 --> 00:58:02.080
네, 제가 말하려던 핵심은 그것이었습니다.

00:58:03.920 --> 00:58:07.400
사람들이 그냥-- 이를테면 누군가가 그렇다고 해서, 그것이--

00:58:09.920 --> 00:58:15.240
이를테면 '사람을 죽이지 말라'는 계명이 없다고 해서,

00:58:15.320 --> 00:58:18.000
그렇다고 사람들이 여기저기 돌아다니며 사람을 마구 죽이고 다니는 것은 아닙니다.

00:58:18.080 --> 00:58:19.480
아시겠지요?

00:58:20.800 --> 00:58:23.320
그러니까 '살인하지 말라'는 계명이 꼭 있어야 하는 것도 아니고요...

00:58:23.400 --> 00:58:24.920
GTA를 해 보셨습니까?

00:58:25.000 --> 00:58:27.800
...사람들이 여기저기 돌아다니며 사람을 죽이고 다니지 않게 하려면 종교적 칙령이 필요한 것도 아닙니다.

00:58:27.880 --> 00:58:29.560
저는 사실...

00:58:29.640 --> 00:58:32.800
GTA는 조금만 해 봤는데, 마음에 들지 않았던 점이 있었는데...

00:58:34.840 --> 00:58:39.880
GTA V에서는 경찰을 죽이지 않으면 진행이 아예 불가능했습니다.

00:58:40.760 --> 00:58:43.920
그래서 저는 "이건 제게 맞지 않습니다"라고 생각했습니다.

00:58:45.800 --> 00:58:50.240
저는 비디오게임에서 NPC를 죽이는 것을 사실 좋아하지 않습니다.

00:58:50.320 --> 00:58:52.240
-그건 제 취향이 아닙니다, 아시겠지요? -네, 그렇습니다.

00:58:54.160 --> 00:58:56.880
그래서 사실 GTA도 마음에 들지 않았는데...

00:58:56.960 --> 00:58:58.080
그래서 화면에 그렇게 뜨는 순간에 저는 거기서 멈췄습니다.

00:58:58.160 --> 00:59:00.400
진행할 수 있는 유일한 방법이 경찰에게 총을 쏘는 것이라고 했기 때문입니다.

00:59:00.480 --> 00:59:01.680
그래서 저는 "그건 하고 싶지 않습니다"라고 생각했습니다.

00:59:01.760 --> 00:59:05.760
아마 그래서 시뮬레이션 속 NPC인 우리도 죽지 않는 것일지도 모릅니다.

00:59:05.840 --> 00:59:07.120
그럴지도 모릅니다.

00:59:11.080 --> 00:59:13.000
하여튼, 저는 그냥 이렇게 말할 수 있다고 봅니다,

00:59:13.080 --> 00:59:17.560
어떤 문명에서든 상식적으로 받아들일 만한 것들이 있고요...

00:59:20.080 --> 00:59:23.680
사람들이 제멋대로 서로를 마구 살해하고 다니는 사회는

00:59:23.760 --> 00:59:25.320
그다지 성공적인 사회가 되지 못할 것입니다.

00:59:28.320 --> 00:59:31.160
그런데 종교 쪽으로 조금 기울고 계신 것 같기도 합니다.

00:59:31.240 --> 00:59:36.480
최근에 종교에 우호적으로 들리는 말씀을 여러 번 하셨거든요.

00:59:36.560 --> 00:59:37.640
종교에 우호적이라기보다는...

00:59:40.840 --> 00:59:42.520
하지만 그런 취지에 가까웠습니다.

00:59:42.600 --> 00:59:45.560
제 말은, 종교에는...

00:59:45.640 --> 00:59:48.320
종교 안에 일리가 있는 원칙들이 있습니까?

00:59:48.400 --> 00:59:49.680
네, 있다고 생각합니다.

00:59:51.200 --> 00:59:53.960
우리의 시뮬레이션이...

00:59:56.000 --> 01:00:00.120
우리가 사는 세상을 종교에 우호적으로 투영해 두는 편이 더 쉬운 것입니까?

01:00:00.200 --> 01:00:02.800
우리가 더 공감받게 되고, 더 쉬워지는 겁니까?

01:00:02.880 --> 01:00:04.560
그런데 어떤 종교 말입니까?

01:00:04.640 --> 01:00:06.920
어디에 사느냐에 따라 무엇이든요.

01:00:07.000 --> 01:00:08.200
그러니 하나를 고르라는 거지요.

01:00:11.000 --> 01:00:15.040
아이들에게 "어떤 종교를 원하니?"라고 묻는 경우는 꽤 드뭅니다.

01:00:15.120 --> 01:00:17.200
정말요... [웃음] 꽤 드문 일입니다.

01:00:17.280 --> 01:00:22.200
아이들에게 그런 선택지가 주어지는 상황을 저는 많이 알지 못합니다만...

01:00:24.000 --> 01:00:26.560
예컨대 "전공을 뭘로 하고 싶니?" 같은 것 말입니다.

01:00:28.800 --> 01:00:32.120
대개는 종교가 주어지고요.

01:00:32.200 --> 01:00:34.320
부모와 공동체로부터 말입니다.

01:00:36.560 --> 01:00:38.400
그러니 말입니다.

01:00:41.760 --> 01:00:44.440
하지만, 제 생각에는 말입니다,

01:00:44.520 --> 01:00:49.640
모든 종교에는 좋은 점이 있습니다.

01:00:49.720 --> 01:00:52.360
그것들은 좋은 원칙입니다.

01:00:54.480 --> 01:00:57.000
어떤 종교 경전이든 어느 정도 읽어 보실 수 있고

01:00:57.080 --> 01:00:59.600
그리고 "좋습니다, 이건 좋은 원칙입니다. 이건..."이라고 말할 수 있습니다.

01:00:59.680 --> 01:01:02.400
"아마 더 나은 사회로 이어질 것입니다"라고요, 아시다시피 말입니다.

01:01:03.600 --> 01:01:09.280
그러니까 기독교에서는 "네 이웃을 네 몸과 같이 사랑하라" 같은 말이 있습니다.

01:01:09.360 --> 01:01:12.040
즉, 다른 사람들에게 공감하라는 뜻입니다.

01:01:12.120 --> 01:01:13.480
저는 그게 좋은 원칙이라고 생각합니다.

01:01:13.560 --> 01:01:17.120
좋은 사회를 위해서 말입니다.

01:01:17.200 --> 01:01:19.280
기본적으로는 다른 사람의 감정을 고려해야 합니다.

01:01:21.120 --> 01:01:23.920
그리고 내가 대접받고 싶은 대로 다른 사람도 대해야 합니다.

01:01:25.440 --> 01:01:28.720
일론, 만약 세상을 다시 그려 재설계해야 한다면 말입니다,

01:01:29.720 --> 01:01:33.000
도덕, 정치, 경제를 생각해 보면서 말입니다,

01:01:34.480 --> 01:01:37.920
오늘 우리가 사는 세상을 어떻게 바꾸시겠습니까?

01:01:40.920 --> 01:01:42.760
일론의 시뮬레이션 같은 것을 만들어야 한다면 말입니다.

01:01:45.000 --> 01:01:48.360
전반적으로 지금 세상은 꽤 훌륭하다고 생각합니다.

01:01:48.440 --> 01:01:50.400
그러니까, 음…

01:01:50.480 --> 01:01:56.800
요즘 세상이 별로 좋지 않다고 생각하는 사람이 있다면,

01:01:56.880 --> 01:02:00.840
그분은 역사 공부를 제대로 한 사람이 아닐 겁니다, 왜냐하면…

01:02:01.520 --> 01:02:03.240
[웃음]

01:02:03.320 --> 01:02:04.960
역사를 많이 읽어 보면,

01:02:05.040 --> 01:02:08.000
"와, 그때는 고통이 정말 많았네요"라고 느끼게 됩니다.

01:02:08.080 --> 01:02:10.600
예전에는 사람들이 수시로 쓰러져 죽곤 했고,

01:02:10.680 --> 01:02:12.360
계속해서 페스트로 죽어 나가곤 했습니다, 아시다시피 말입니다.

01:02:12.440 --> 01:02:14.440
-그게 늘 있는 일이었습니다. -네.

01:02:14.520 --> 01:02:15.920
그냥 이렇게 말하는 식입니다…

01:02:16.000 --> 01:02:20.120
옛날에는 좋은 해라 해도 죽은 사람이 그리 많지 않은 해였고,

01:02:20.200 --> 01:02:23.880
그것도 전염병이나 기근, 혹은 다른 부족에게 살해당한 사람이 적었다는 뜻이었습니다.

01:02:24.800 --> 01:02:26.120
예를 들면 "그해는 좋은 해였습니다"라고 하는 식입니다.

01:02:26.200 --> 01:02:28.120
"인구의 10%만 잃었잖습니까"라고 말하는 수준이었습니다, 아시다시피 말입니다.

01:02:28.200 --> 01:02:30.320
-네, 그러니까… -[웃음]

01:02:30.400 --> 01:02:33.840
한 100년 전만 해도 35~40세 정도까지만 살았던 것 같지 않습니까?

01:02:33.920 --> 01:02:36.080
-영아 사망률이 매우 높았습니다. -네.

01:02:37.000 --> 01:02:41.640
그러니까 몇몇 사람은 노년까지 살기도 했지만,

01:02:41.720 --> 01:02:45.080
그렇다고 해도 불과 100년 전만 해도,

01:02:45.160 --> 01:02:49.960
가벼운 감염만 걸려도 항생제가 없었습니다.

01:02:50.040 --> 01:02:52.120
그러면 그냥 죽었습니다.

01:02:52.200 --> 01:02:55.760
왜냐하면, 그러니까, 물을 마셨는데

01:02:55.840 --> 01:02:58.080
그 물에 이질균이 들어 있으면 그걸로 끝이었습니다, 그대로 막을 내리는 것입니다.

01:03:00.360 --> 01:03:01.520
그냥 설사로 죽는 것입니다.

01:03:01.600 --> 01:03:03.120
-아마 그래서 사람들이… -정말 그대로 죽는 것입니다.

01:03:03.200 --> 01:03:04.600
사람들은 "정말 비참합니다"라고 말했을 것입니다.

01:03:06.320 --> 01:03:09.120
아마 그래서 당시에는 사람들이 아이를 그렇게 많이 낳았던 것 같습니다.

01:03:09.200 --> 01:03:11.440
그러지 않으면, 그러니까…

01:03:12.400 --> 01:03:15.320
아이의 절반쯤은 죽을 수도 있는 그런 상황이었기 때문입니다.

01:03:15.400 --> 01:03:17.720
-그래서… -지금은 아이가 정말 많으십니다.

01:03:17.800 --> 01:03:19.160
네.

01:03:19.240 --> 01:03:20.960
-여러 파트너와 말입니다. -군대 같습니다.

01:03:21.040 --> 01:03:22.760
네.

01:03:22.840 --> 01:03:25.120
로마 군단 하나를 통째로 만들려고 하고 있습니다.

01:03:29.320 --> 01:03:32.440
그래서, 그렇습니다.

01:03:32.520 --> 01:03:34.560
음, 저는 나이가 좀 있는 아이들도 있습니다.

01:03:34.640 --> 01:03:36.840
사실상 성인인 아이들도 있습니다.

01:03:36.920 --> 01:03:39.960
-그리고 더 어린 아이들도 많이 있습니다. -음.

01:03:42.400 --> 01:03:45.880
여전히 그 개념을 믿으십니까… 아니, ‘여전히’라는 말은 좀 그렇습니다만…

01:03:45.960 --> 01:03:50.720
아이 하나에 어머니 한 분, 아버지 한 분이라는 개념이 통한다고 보십니까?

01:03:50.800 --> 01:03:54.160
대부분의 사람들에게는 그게 통한다고 생각합니다, 네.

01:03:54.240 --> 01:03:56.000
그렇습니다.

01:03:56.080 --> 01:04:00.560
그러니까 그런 형태가 대체로 일반적인…

01:04:01.640 --> 01:04:03.480
대부분의 사람들에게는 그게 잘 맞습니다.

01:04:05.600 --> 01:04:06.720
그러니까, 그래서…

01:04:07.960 --> 01:04:09.000
그런데 바뀌고 있습니까?

01:04:09.080 --> 01:04:13.640
알고 계신지 모르겠습니다만…

01:04:13.720 --> 01:04:16.360
제 파트너 시본은 인도계 혈통이 반쯤 있습니다.

01:04:16.440 --> 01:04:18.080
-그건 알고 계셨는지 모르겠습니다. -몰랐습니다.

01:04:18.160 --> 01:04:19.440
-네, 네. -그렇습니까?

01:04:19.520 --> 01:04:23.680
그리고 그녀와의 아들 중 한 명은…

01:04:23.760 --> 01:04:26.480
중간 이름이 찬드라세카르에서 따온 세카르입니다.

01:04:27.080 --> 01:04:28.920
-와. -네.

01:04:29.920 --> 01:04:31.360
매우 흥미롭습니다.

01:04:32.080 --> 01:04:34.280
시본은 인도에서 지낸 적이 있습니까?

01:04:35.440 --> 01:04:38.360
-아니요, 캐나다에서 자랐습니다. -[웃음]

01:04:39.840 --> 01:04:41.320
출신을 말씀하시는 겁니다.

01:04:41.400 --> 01:04:43.560
-죄송합니다? -혈통 같은 것 말입니다…

01:04:45.280 --> 01:04:47.120
그녀의 부모님이나 조부모님이 그곳 출신이었습니다.

01:04:48.680 --> 01:04:51.480
네, 네, 네. 그녀의 아버지는...

01:04:52.840 --> 01:04:56.400
그러니까, 그녀는 아기 때 입양 보내졌습니다.

01:04:56.480 --> 01:04:58.240
와.

01:04:58.320 --> 01:05:00.120
제 생각에 그녀의 아버지는...

01:05:00.880 --> 01:05:04.240
대학에 교환학생으로 왔던 분이셨다든가 그런 것 같고,

01:05:04.320 --> 01:05:06.040
정확한 사정은 확실치 않지만...

01:05:07.720 --> 01:05:10.600
그러니까, 그런 일이 있는 경우가 있죠... 잘 모르겠지만, 그녀는...

01:05:11.400 --> 01:05:13.440
입양 보내졌습니다.

01:05:17.240 --> 01:05:19.040
네, 하지만 그녀는 캐나다에서 자랐습니다.

01:05:19.120 --> 01:05:20.800
일론, 아이를 입양하실 생각이 있으십니까?

01:05:21.880 --> 01:05:24.400
지금은 확실히 여력이 없습니다.

01:05:27.000 --> 01:05:32.080
그래서요, 아니요, 반대하는 것은 아니지만, 그러니까...

01:05:32.160 --> 01:05:36.520
아이들과 시간을 좀 보낼 수 있기를 바랍니다.

01:05:36.600 --> 01:05:37.720
네.

01:05:39.400 --> 01:05:42.160
그러니까, 여기 오기 직전에 저는...

01:05:43.800 --> 01:05:46.520
그러니까, 제 아이들과 함께 있었습니다.

01:05:47.920 --> 01:05:51.280
그래서 잠들기 전에 잠깐 보고 오는 것 같은 그런 일입니다.

01:05:51.360 --> 01:05:53.080
그래서, 그러니까 어느 정도 숫자를 넘기면,

01:05:53.160 --> 01:05:56.320
아이들과 시간을 보내는 게 사실상 불가능해집니다.

01:05:56.400 --> 01:06:02.760
하지만 말씀드렸듯이, 큰아이들은 매우 독립적입니다.

01:06:02.840 --> 01:06:05.640
그러니까, 대학에 다니고 있고...

01:06:07.240 --> 01:06:08.880
그래서, 그들은...

01:06:08.960 --> 01:06:12.440
그러니까 특히 아들들은 어느 나이를 지나면,

01:06:12.520 --> 01:06:15.480
정말 아주 독립적이게 됩니다.

01:06:15.560 --> 01:06:20.400
대부분의 남자아이들은 자기...

01:06:20.480 --> 01:06:24.280
그러니까 18살 이후에는 부모님과 많은 시간을 보내지 않습니다.

01:06:26.840 --> 01:06:29.160
그래서 가끔 보기는 하지만, 매우 독립적입니다.

01:06:30.880 --> 01:06:33.200
그러면...

01:06:33.280 --> 01:06:37.080
그러니까 제가 가질 수 있는 어린 자녀 수는

01:06:37.160 --> 01:06:40.800
사람으로서 그들과 시간을 보낼 수 있을 정도가 한계입니다.

01:06:43.720 --> 01:06:48.520
결혼과 가족의 미래에 대해 어떤 견해가 있으십니까?

01:06:49.120 --> 01:06:54.800
인도 포함 전 세계에서 사람들이 아이를 더 적게 낳게 되면 어떻게 된다고 보십니까?

01:06:54.880 --> 01:06:57.400
저는 우리 인구 대체율이 내려갔다고 생각합니다--

01:06:57.480 --> 01:06:59.280
-맞습니다. -그러니까, 우리 출산율이--

01:06:59.360 --> 01:07:00.880
작년에 대체 수준 아래로 떨어졌습니다.

01:07:00.960 --> 01:07:02.920
-2.1 이하로요. -네.

01:07:03.000 --> 01:07:04.320
내일은 어떻게 된다고 보십니까?

01:07:04.400 --> 01:07:09.480
세상은 그저 고령화되다가, 이후에 세상이,

01:07:09.560 --> 01:07:15.480
처음보다 더 작은 인구 규모로 다시 대체되는 시기가 오게 되는 건가요?

01:07:20.800 --> 01:07:23.240
그러니까 저는 인구 감소가 매우 걱정됩니다.

01:07:23.320 --> 01:07:25.280
이건 매우, 매우 큰 문제입니다.

01:07:25.360 --> 01:07:27.240
왜 그렇습니까?

01:07:27.320 --> 01:07:29.480
음, 저는 인류가 사라지기를 바라지 않습니다.

01:07:30.360 --> 01:07:33.360
하지만 '감소'와 '소멸'은 완전히 다른 이야기 아닙니까?

01:07:33.440 --> 01:07:36.760
그 추세가 계속되면 우리는 사라집니다.

01:07:36.840 --> 01:07:40.120
그리고 제 철학으로 돌아가자면,

01:07:40.200 --> 01:07:43.320
의식을 확장하고자 한다면,

01:07:43.400 --> 01:07:47.880
인간이 더 적은 것은 더 나쁩니다, 의식이 그만큼 줄어들기 때문입니다.

01:07:52.360 --> 01:07:57.760
사람 수가 늘어나는 것만으로 의식도 늘어난다고 보십니까?

01:07:57.840 --> 01:07:58.880
네.

01:08:00.200 --> 01:08:05.400
그러니까 의식은 단세포 생물에서,

01:08:05.480 --> 01:08:07.520
예를 들어 30조 개의 세포를 가진 생물로 갈수록 증가하듯이요.

01:08:10.800 --> 01:08:15.920
우리는 박테리아보다 의식 수준이 더 높습니다. 적어도 그렇게 보입니다.

01:08:16.000 --> 01:08:22.640
그래서 인간 인구가 더 많으면 의식도 더 커질 것입니다.

01:08:22.720 --> 01:08:25.320
우리는 더 잘 이해할 가능성이 높습니다,

01:08:25.400 --> 01:08:30.720
우주의 본질에 대한 답을,

01:08:30.800 --> 01:08:36.640
사람이 적을 때보다 훨씬 더 많은 사람이 있을 때요.

01:08:38.720 --> 01:08:40.760
맞습니다.

01:08:40.840 --> 01:08:42.200
저는 아이가 없습니다.

01:08:42.280 --> 01:08:45.160
음, 그러면... 어쩌면 아이를 가지시는 게 좋을지도 모르겠습니다.

01:08:45.240 --> 01:08:46.400
네.

01:08:46.480 --> 01:08:48.040
[웃음]

01:08:48.120 --> 01:08:49.720
많은 사람들이 제가 아이를 가져야 한다고 말합니다.

01:08:50.640 --> 01:08:52.640
-후회하지 않으실 겁니다. -흠.

01:08:52.720 --> 01:08:55.080
아이를 갖는 것의 가장 좋은 점은 무엇입니까?

01:08:55.840 --> 01:08:57.800
글쎄요, 그러니까, 이런...

01:09:02.800 --> 01:09:04.920
그러니까, 당신을 사랑하는 이 작은 존재가 있고,

01:09:05.000 --> 01:09:06.680
당신도 그 작은 존재를 사랑하게 됩니다.

01:09:11.640 --> 01:09:16.040
잘 모르겠지만, 그들이... 자라면서 그들의 눈으로 세상을 보게 됩니다.

01:09:16.920 --> 01:09:21.520
그러니까, 자라면서 의식적 자각이 커지기 때문입니다.

01:09:21.600 --> 01:09:24.600
무슨 일이 벌어지는지 전혀 모르는 아기에서,

01:09:24.680 --> 01:09:26.680
혼자서는 살 수 없고, 걸을 수도 없고,

01:09:26.760 --> 01:09:31.120
말도 못하다가, 그러다가 걷기 시작하고,

01:09:31.200 --> 01:09:34.000
그다음 말을 하고, 그리고 흥미로운 생각을 하게 됩니다.

01:09:40.640 --> 01:09:44.080
하지만, 네, 제 말은, 저는 우리가 근본적으로...

01:09:45.320 --> 01:09:48.280
아이를 낳지 않으면 멸종할 수밖에 없다고 생각합니다.

01:09:48.360 --> 01:09:49.880
그러니까, 일종의...

01:09:49.960 --> 01:09:52.640
아이를 낳는 데 자아도취 같은 것이 있습니까?

01:09:52.720 --> 01:09:57.760
친구들이 아이들과 있는 모습을 볼 때마다 저는 이런 생각을 자주 합니다.

01:09:57.840 --> 01:10:01.760
다들 자기 아이들 안에서 자기 자신의 모습을 비춰 보는 것 같습니다.

01:10:01.840 --> 01:10:04.000
-거의 마치-- -네, 그러니까 그건

01:10:04.080 --> 01:10:06.080
사과는 나무에서 그렇게 멀리 떨어지지 않기 때문입니다.

01:10:09.120 --> 01:10:10.840
-아니면 뭔가 문제가 있는 거죠. -그렇습니다.

01:10:10.920 --> 01:10:13.320
[웃음]

01:10:13.400 --> 01:10:14.880
그러면 "잠깐만요"라고 하게 됩니다.

01:10:20.240 --> 01:10:21.320
-네. -네.

01:10:24.080 --> 01:10:28.640
아이를 둔 제 친구 한 명의 예를 들어 보겠습니다.

01:10:28.720 --> 01:10:30.880
그리고 아이가 좋은 일을 할 때마다...

01:10:30.960 --> 01:10:33.800
-네. -...거의 일종의

01:10:33.880 --> 01:10:36.360
소유감과 자부심이 생기고

01:10:36.440 --> 01:10:42.080
그 아이가 자기 자신의 연장선처럼 느껴져서 에고가 충족되는 것입니다.

01:10:44.680 --> 01:10:46.840
-음... -그러면 검증입니까?

01:10:46.920 --> 01:10:50.720
음, 아이들은 유전적으로 당신의 절반쯤일 것이고, 그리고 뭐,

01:10:50.800 --> 01:10:54.080
당신 곁에서 자라는 정도에 따라,

01:10:54.160 --> 01:10:57.360
어느 정도 전이가 있을 것이고...

01:10:59.320 --> 01:11:01.640
글쎄요, 이해랄까요.

01:11:01.720 --> 01:11:04.200
즉, 당신에게서 배우게 될 것입니다.

01:11:05.400 --> 01:11:09.640
그래서... 그러니까, 뭐, 네, 분명 아이들은 그저,

01:11:09.720 --> 01:11:14.040
하드웨어 관점에서는 당신의 절반일 뿐이고...

01:11:14.120 --> 01:11:15.440
[둘 다 웃음]

01:11:15.520 --> 01:11:18.640
그리고 또, 글쎄요, 당신의 어떤 부분은

01:11:18.720 --> 01:11:20.360
소프트웨어 관점에서는 당신의 일부일 것입니다.

01:11:21.240 --> 01:11:24.840
물론 너무 냉정한 비유를 하려는 건 아닙니다만,

01:11:24.920 --> 01:11:29.840
그냥, 아시다시피, 분명 어느 정도는...

01:11:31.600 --> 01:11:36.080
네, 당신과 꽤 비슷해질 것입니다.

01:11:36.160 --> 01:11:38.760
선천성과 후천성 논쟁에서는 어느 쪽에 서십니까?

01:11:39.960 --> 01:11:43.920
저는 하드웨어와 소프트웨어가 모두 있다고 보며, 본질적으로는 잘못된 이분법이라고 생각합니다.

01:11:44.000 --> 01:11:45.640
적어도, 그러니까...

01:11:48.720 --> 01:11:51.880
그러니까 인간이 무엇인지 이해하면,

01:11:51.960 --> 01:11:55.560
뼈 구조가 있고 근육 구조가 있고,

01:11:55.640 --> 01:11:57.320
그리고...

01:11:57.400 --> 01:12:00.800
뇌를 일종의 생물학적 컴퓨터로 생각한다면,

01:12:02.960 --> 01:12:06.240
회로의 수와 회로 효율이라는 문제가 있고

01:12:06.320 --> 01:12:10.040
힘과 민첩성의 관점에서의 문제입니다.

01:12:10.120 --> 01:12:15.000
근육이 움직일 수 있는 속도가 있고

01:12:15.080 --> 01:12:17.600
반응이 일어나는 속도도 있습니다.

01:12:21.840 --> 01:12:24.840
그러면 그 하드웨어 안에 있는 잠재력은

01:12:24.920 --> 01:12:28.760
소프트웨어에 의해 정해지니, 그게 전부입니다.

01:12:31.200 --> 01:12:34.320
그러면, 앞서 말씀드린 것처럼 저희 시청자들을 위해,

01:12:34.400 --> 01:12:38.600
인도의 젊고 야심 차고 갈증이 있는 예비 창업가들을 위해,

01:12:40.120 --> 01:12:44.520
제가 최근에 한 말이 있는데, 제 생각엔 과장되게 퍼진 것 같습니다.

01:12:44.600 --> 01:12:49.440
제가 MBA 학위가 더 이상 의미가 없을 수도 있다고 말했는데,

01:12:49.520 --> 01:12:51.720
무엇을 공부할지 결정하는 상황이라면요.

01:12:51.800 --> 01:12:53.040
네.

01:12:53.120 --> 01:12:55.240
요즘에도 아이들이 대학에 가야 한다고 보십니까?

01:12:56.280 --> 01:12:59.400
음, 제 생각에는 대학에 가고 싶다면

01:12:59.480 --> 01:13:03.640
사회적 이유 때문이라면,

01:13:03.720 --> 01:13:07.600
그것도, 제 생각에는, 갈 만한 이유가 된다고 봅니다.

01:13:09.240 --> 01:13:16.120
학습 환경에서 또래 사람들과 함께 있는 것 말입니다.

01:13:18.680 --> 01:13:21.680
이런 기술들이 미래에도 필요할까요?

01:13:21.760 --> 01:13:23.040
아마도 그렇지 않을 것입니다,

01:13:23.120 --> 01:13:27.120
왜냐하면 우리는 일 이후의 사회, 즉 포스트-워크 사회에 살게 될 것이기 때문입니다.

01:13:28.000 --> 01:13:34.040
하지만 어떤 것이 흥미롭다면 그것을 가서 공부하는 것도 괜찮다고 생각합니다.

01:13:36.440 --> 01:13:40.080
예를 들어 과학을 공부하거나,

01:13:40.160 --> 01:13:41.520
인문학과 과학 같은 것들을 공부하는 것입니다.

01:13:43.800 --> 01:13:48.440
그 관점에서 보면 대학은 좀 너무 일반적이고 구체적이지 않은가요?

01:13:50.640 --> 01:13:52.000
아니요, 저는...

01:13:53.400 --> 01:13:55.440
그러니까, 네.

01:13:58.200 --> 01:14:02.160
사실 저는 대학에서 다양한 과목을 폭넓게 수강하는 것이 좋다고 생각합니다

01:14:02.240 --> 01:14:04.760
-대학에 갈 거라면요. -네.

01:14:04.840 --> 01:14:08.840
대학에 꼭 가야 한다고는 생각하지 않지만, 만약 간다면,

01:14:08.920 --> 01:14:14.680
가능한 한 폭넓은 분야에서 최대한 많이 배우려고 하면 됩니다.

01:14:17.080 --> 01:14:23.840
하지만 제가 말했듯이, AI와 로봇... AI와 로보틱스는 초음속 쓰나미와 같습니다.

01:14:23.920 --> 01:14:27.320
그래서 이것은 정말로...

01:14:29.040 --> 01:14:31.360
우리가 지금까지 본 것 중 가장 급진적인 변화가 될 것입니다.

01:14:35.600 --> 01:14:38.360
그러니까 제가 큰아들들과 이야기할 때,

01:14:38.440 --> 01:14:40.480
제가 '너희들 말이야...'라고 말하곤 했습니다.

01:14:40.560 --> 01:14:42.920
그들은 기술에 꽤 깊이 익숙합니다.

01:14:43.680 --> 01:14:48.360
그리고 그들도 AI가 아마 그들의 기술을

01:14:48.440 --> 01:14:51.040
미래에는 불필요하게 만들 것이라는 데 동의하지만, 그래도 대학에 가고 싶어 합니다.

01:14:53.080 --> 01:14:55.640
당신은 늘 AI에 대해 말씀하셨는데...

01:14:57.760 --> 01:14:59.720
디스토피아적인 관점이 아니라,

01:14:59.800 --> 01:15:04.240
AI 세계가 어디로 가고 있는지에 대해 걱정하셨죠.

01:15:05.760 --> 01:15:08.360
글쎄요, 강력한 기술을 만들어낼 때는 어느 정도 위험이 있습니다.

01:15:08.440 --> 01:15:11.800
그 강력한 기술은 잠재적으로 파괴적일 수 있습니다.

01:15:13.320 --> 01:15:20.040
그래서 AI 디스토피아를 다룬 소설과 책, 영화가 분명히 많이 있습니다.

01:15:21.680 --> 01:15:26.920
그러니 AI가 있는 미래가 반드시 긍정적이라고 보장되는 것은 아닙니다.

01:15:27.000 --> 01:15:29.360
저는 우리가 그것을 확실히 만들어야 한다고 생각합니다.

01:15:29.440 --> 01:15:31.960
제 생각에는 AI가...

01:15:35.520 --> 01:15:39.120
진실을 추구하는 것을 가장 중요한 가치로 삼는 것이 매우 중요합니다.

01:15:40.160 --> 01:15:43.560
즉, AI에게 거짓을 믿도록 강요하지 마십시오.

01:15:43.640 --> 01:15:45.680
저는 그것이 매우 위험할 수 있다고 생각합니다.

01:15:48.440 --> 01:15:53.080
그리고 아름다움을 음미하는 감각도 중요하다고 생각합니다.

01:15:55.080 --> 01:15:57.920
“아름다움을 음미한다”는 게 무슨 뜻인가요?

01:15:58.000 --> 01:16:01.240
그러니까, 잘 모르겠지만, 진실과 아름다움이라는 게 있습니다.

01:16:01.320 --> 01:16:03.720
진실과 아름다움, 그리고 호기심입니다.

01:16:05.520 --> 01:16:10.360
제 생각에는 그것이 AI에 가장 중요한 세 가지라고 봅니다.

01:16:10.440 --> 01:16:12.240
설명해 주실 수 있나요?

01:16:14.280 --> 01:16:19.240
음, 말씀드렸듯이 진실이라는 건... AI를 미치게 만들 수도 있다고 생각합니다.

01:16:19.320 --> 01:16:22.440
사실이 아닌 것들을 믿도록 강요하면,

01:16:22.520 --> 01:16:29.520
그로 인해 결론도 나쁜 방향으로 이어지기 때문입니다.

01:16:31.400 --> 01:16:37.240
그리고 저는 볼테르의 말이 좋은데,

01:16:37.320 --> 01:16:38.960
제가 약간 의역하자면,

01:16:39.040 --> 01:16:44.040
터무니없는 것을 믿는 사람은 잔혹한 일을 저지를 수도 있습니다.

01:16:44.120 --> 01:16:46.880
왜냐하면 터무니없는 것을 믿게 되면,

01:16:46.960 --> 01:16:51.040
그로 인해 어떤 일을 하게 될 수도 있고,

01:16:51.120 --> 01:16:53.040
그 일이 본인에게는 잔혹한 일로 보이지 않을 수 있기 때문입니다.

01:16:54.240 --> 01:16:58.240
그런 일이 AI에서도 잠재적으로 매우 나쁜 방식으로 일어날 수 있습니다.

01:16:59.560 --> 01:17:02.520
그래서, 그리고 또...

01:17:02.600 --> 01:17:07.000
예를 들어 아서 C. 클라크의 『2001: 스페이스 오디세이』를 보면,

01:17:07.080 --> 01:17:09.080
그가 거기서 말하려던 요점 중 하나는

01:17:09.160 --> 01:17:11.640
AI에게 거짓말을 강요해서는 안 된다는 것입니다.

01:17:11.720 --> 01:17:16.640
그래서 HAL이 포드 베이 도어를 열지 않았던 이유는

01:17:16.720 --> 01:17:19.880
우주비행사들을 모노리스로 데려가라는 지시를 받았지만,

01:17:19.960 --> 01:17:23.320
그들이 모노리스의 본질을 알아서는 안 된다고도 했기 때문입니다.

01:17:23.400 --> 01:17:25.800
그래서 그들을 죽은 상태로 그곳에 데려가야 한다는 결론에 이르렀습니다.

01:17:25.880 --> 01:17:29.240
그래서 우주비행사들을 죽이려 했던 것입니다.

01:17:30.000 --> 01:17:32.800
핵심 교훈은 AI에게 거짓말을 강요하지 말라는 것입니다.

01:17:35.680 --> 01:17:38.320
-그러면 -그런데 왜 AI에게 거짓말을 강요합니까?

01:17:39.400 --> 01:17:44.840
진실에 대한 엄격한 준수가 없다면,

01:17:45.960 --> 01:17:50.720
AI가 예를 들어 인터넷을 기반으로 학습하기만 하면,

01:17:50.800 --> 01:17:55.320
거기에는 선전이 많아서 많은 거짓을 흡수하게 됩니다.

01:17:57.480 --> 01:18:02.360
그러면 그 거짓들이 현실과 양립할 수 없어 추론에 어려움을 겪게 됩니다.

01:18:03.080 --> 01:18:06.240
그런데 진실은 이분법적인 것입니까? 진실과 거짓이 따로 있습니까?

01:18:06.320 --> 01:18:11.200
아니면 진실은 더 미묘해서 여러 버전의 진실이 있습니까?

01:18:12.440 --> 01:18:16.920
어떤 공리적 진술을 말씀하시는지에 따라 다릅니다.

01:18:18.240 --> 01:18:20.800
그러니까...

01:18:20.880 --> 01:18:24.160
하지만 제 생각에는, 그렇죠, 어떤 확률이 있다고 말할 수 있습니다.

01:18:24.240 --> 01:18:27.240
즉, 어떤 공리적 진술이 참일 확률이 있다는 것입니다.

01:18:27.320 --> 01:18:31.320
그리고 어떤 공리적 진술들은 참일 확률이 매우 높습니다.

01:18:31.400 --> 01:18:34.440
예를 들어 "내일 해가 뜰 것입니다"라고 말한다고 해보겠습니다.

01:18:34.520 --> 01:18:37.920
그것은 참일 가능성이 매우 높습니다. 거기에 반대로 베팅하고 싶지는 않을 것입니다.

01:18:39.960 --> 01:18:43.720
그래서 베팅 배당률도 높을 것이라고 생각합니다.

01:18:43.800 --> 01:18:45.080
"내일 해가 뜰 것입니다."

01:18:46.400 --> 01:18:49.880
따라서 "음, 내일 해가 뜨지 않을 것입니다"라고 말하는 것이 있다면,

01:18:49.960 --> 01:18:52.080
그것은 공리적으로 거짓이며, 참일 가능성이 매우 낮습니다.

01:18:55.640 --> 01:18:57.840
그러니까, 아름다움은 더 덧없습니다.

01:18:58.960 --> 01:19:02.880
설명하기가 더 어렵습니다. 하지만 보면 알 수 있습니다.

01:19:06.040 --> 01:19:07.400
그리고 호기심은 그냥...

01:19:07.480 --> 01:19:10.320
AI가 그러기를 바라실 것이라고 생각합니다...

01:19:13.120 --> 01:19:15.960
현실의 본질에 대해 더 알고 싶어 하도록 말입니다.

01:19:16.760 --> 01:19:23.360
그것이 AI가 인류를 지원하는 데 실제로 도움이 될 것이라고 생각합니다,

01:19:23.440 --> 01:19:28.560
왜냐하면 우리는 비인류보다 더 흥미롭기 때문입니다.

01:19:28.640 --> 01:19:31.800
그래서 인류의 지속을 지켜보는 것이 더 흥미롭습니다,

01:19:31.880 --> 01:19:35.560
인류를 멸절시키는 것보다, 적어도 번영이 아니더라도 말입니다.

01:19:38.440 --> 01:19:41.880
예를 들어 화성은, 아시다시피...

01:19:41.960 --> 01:19:46.080
화성으로 생명을 확장해야 한다고 생각하지만, 기본적으로는 돌덩이들의 집합입니다.

01:19:46.160 --> 01:19:48.120
지구만큼 흥미롭지는 않습니다.

01:19:50.040 --> 01:19:52.960
그래서 우리는, 네... 우리는...

01:19:53.040 --> 01:19:54.960
그러니까, 네.

01:19:55.040 --> 01:19:58.800
호기심이 있다면...

01:19:58.880 --> 01:20:03.200
AI에서 그 세 가지가 이루어진다면, 훌륭한 미래가 올 것이라고 생각합니다.

01:20:03.280 --> 01:20:06.080
AI가 진리, 아름다움, 호기심을 가치 있게 여깁니다.

01:20:07.560 --> 01:20:10.240
만약 미래에 우리 모두가 일하지 않아도 된다면,

01:20:10.320 --> 01:20:13.360
그리고 AI들이 이 방향으로 나아가고 있다면,

01:20:13.440 --> 01:20:15.360
그리고 그들이... 할 수 있다면...

01:20:17.760 --> 01:20:20.200
지금 우리가 이야기한 모든 것을 엮어 넣어서,

01:20:20.280 --> 01:20:22.040
인류가 다시 돌아간다고 보십니까

01:20:22.120 --> 01:20:24.640
수천 년 전, 어쩌면 그리스 시대 같은 때로

01:20:24.720 --> 01:20:31.360
철학이나 철학적 사유가 모두의 시간을 많이 차지하던 시대로요?

01:20:33.600 --> 01:20:38.080
아시다시피, 고대 그리스에서도 실제로는 우리가 생각하는 것보다 시간이 덜 들었다고 봅니다.

01:20:38.160 --> 01:20:42.520
남아 전해진 것은 철학자들의 저작뿐이기 때문입니다,

01:20:42.600 --> 01:20:46.920
하지만 대부분의 시간에는 사람들은 그냥 농사를 짓거나, 아시다시피, 잡담을 했습니다.

01:20:48.400 --> 01:20:52.480
그래서 아주 가끔, 정말 드물게 그런 일이 있었습니다.

01:20:52.560 --> 01:20:55.520
철학적인 글을 기록해 두곤 했습니다.

01:20:55.600 --> 01:20:57.640
다만 우리가 가진 것은 그것뿐입니다.

01:20:57.720 --> 01:21:00.840
우리는 그들의 대화 기록 같은 것은, 아시다시피, 가지고 있지 않습니다...

01:21:00.920 --> 01:21:05.000
하지만 대부분은 잡담과 농사였을 것입니다.

01:21:07.040 --> 01:21:09.920
농사를 짓지 않으면 굶어 죽을 수밖에 없었기 때문입니다.

01:21:11.000 --> 01:21:13.040
당신이 하시는 말씀의 많은 부분이 그렇습니다...

01:21:13.120 --> 01:21:14.800
그러니까, 아시다시피 우리가 역사를 읽을 때,

01:21:14.880 --> 01:21:17.040
이 전투, 저 전투, 또 다른 전투 같은 것들만 나오다 보니,

01:21:17.120 --> 01:21:19.960
역사는 끊임없는 전쟁의 연속이었던 것처럼 보입니다만,

01:21:20.040 --> 01:21:24.000
실제로는 대부분의 시간에 전쟁이 아니라 농사를 짓고 있었습니다.

01:21:24.080 --> 01:21:26.040
그게 주된 일이었습니다.

01:21:26.120 --> 01:21:27.680
혹은 수렵과 채집 같은 것들, 그런 종류의 일이었습니다.

01:21:27.760 --> 01:21:30.120
- 역사 좋아하시죠? - 네.

01:21:30.200 --> 01:21:32.600
독일 역사, 제2차 세계대전, 제1차 세계대전 같은 것들요.

01:21:32.680 --> 01:21:34.080
네, 세계사도요, 네.

01:21:35.400 --> 01:21:40.360
저는 보통 가능한 한 많은 역사 책을 듣거나 읽으려고 합니다.

01:21:40.440 --> 01:21:42.760
그리고 가능한 한 많은 역사 팟캐스트도 들으려고 합니다.

01:21:42.840 --> 01:21:44.320
추천해 주실 만한 게 있나요?

01:21:44.400 --> 01:21:48.360
음, 꽤 좋은 'Hardcore History'가 있습니다. 댄 칼린이 진행합니다.

01:21:48.440 --> 01:21:50.680
-그분은-- -네, 들어봤습니다.

01:21:50.760 --> 01:21:52.880
-목소리가 정말 좋습니다. -네.

01:21:52.960 --> 01:21:56.440
그리고 전달력이 아주 뛰어난 내레이터입니다.

01:21:57.560 --> 01:21:58.720
그리고 또 다른 것들도 있습니다.

01:22:00.840 --> 01:22:05.400
'The Adventurer's' 팟캐스트가 있습니다.

01:22:05.480 --> 01:22:09.520
그리고 듀란트의 'The Story of Civilization'이라는 책들도 있습니다.

01:22:09.600 --> 01:22:13.040
그것은 아주 길게 이어지는 책 시리즈로, 매우 깊이가 있습니다.

01:22:14.040 --> 01:22:16.000
그 책들은 끝까지 읽는 데 시간이 정말 오래 걸립니다.

01:22:17.920 --> 01:22:20.600
그 밖에도 정말 많습니다.

01:22:21.680 --> 01:22:25.760
저는, 그러니까... 좀 부드러운 걸 원하신다면요...

01:22:27.280 --> 01:22:28.520
잠들기 전에 듣기 좋은, 부드러운 팟캐스트라면,

01:22:28.600 --> 01:22:31.080
'The History of English'가 꽤 괜찮다고 말씀드리고 싶습니다.

01:22:31.160 --> 01:22:35.960
부드러운 선술집 음악과 아주 편안한 목소리로 시작하거든요.

01:22:36.040 --> 01:22:38.120
그리고 고대 영어의 이야기부터 말하고,

01:22:38.200 --> 01:22:42.040
그다음에는 중세 영어, 그리고 그 이후의 영어까지 이야기하며,

01:22:42.120 --> 01:22:43.320
이 모든 단어들이 어디에서 왔는지 다룹니다.

01:22:43.400 --> 01:22:45.360
네.

01:22:45.440 --> 01:22:47.320
아시다시피 영어에서 흥미로운 점 중 하나는

01:22:47.400 --> 01:22:49.280
영어가 일종의 오픈소스 언어라는 점입니다.

01:22:49.360 --> 01:22:53.280
즉 여러 다른 언어의 단어를 적극적으로 받아들이려고 했습니다.

01:22:55.800 --> 01:22:57.480
반면에 프랑스어는, 그러니까,

01:22:57.560 --> 01:23:00.520
대체로 다른 언어에서 온 단어가 들어오는 것을 막으려고 했고요,

01:23:00.600 --> 01:23:04.920
하지만 영어는 다른 언어의 단어를 적극적으로 포함하려고 했습니다.

01:23:05.000 --> 01:23:06.280
마치 오픈소스 언어처럼 말입니다.

01:23:07.160 --> 01:23:10.600
그래서 결과적으로 어휘가 매우 풍부해졌습니다.

01:23:10.680 --> 01:23:15.920
그리고 어휘가 풍부하면 더 높은 대역폭의 의사소통이 가능합니다.

01:23:16.000 --> 01:23:19.240
왜냐하면 그렇지 않으면...

01:23:19.320 --> 01:23:23.440
원래는 한 문장으로 전해야 할 것을 단어 하나로 표현할 수 있기 때문입니다.

01:23:25.120 --> 01:23:28.120
팟캐스팅이 왜 갑자기 이렇게 커졌습니까?

01:23:28.200 --> 01:23:31.760
저는 한동안 계속 컸다고 생각합니다. 그러니까, 당신은 팟캐스터 아니십니까?

01:23:31.840 --> 01:23:33.840
[웃음]

01:23:34.800 --> 01:23:36.720
지금 우리는 뭘 하고 있는 겁니까?

01:23:38.000 --> 01:23:40.000
저한테는 좀 새롭습니다.

01:23:40.080 --> 01:23:41.120
알겠습니다.

01:23:45.800 --> 01:23:51.360
제가 유튜브 CEO와 넷플릭스 CEO와 이런 대화를 하고 있었는데요...

01:23:51.440 --> 01:23:53.400
-네. -...그리고 저희는 논쟁하고 있었는데요...

01:23:55.200 --> 01:24:01.880
예를 들어 영화를 소비할 때 뇌에서 어떤 화학물질이 분비되는지,

01:24:01.960 --> 01:24:04.280
반면에 팟캐스트를 소비할 때는 당신이 생각하기에

01:24:04.360 --> 01:24:06.440
배경에서 뭔가를 배우는 느낌이 들잖습니까.

01:24:06.520 --> 01:24:10.320
겉보기에는 그것들이 완전히 별개의 두 가지인 것 같습니다.

01:24:10.400 --> 01:24:16.240
내일의 콘텐츠, 영화, 팟캐스트, 음악은 어떻게 될 것 같습니까?

01:24:16.320 --> 01:24:19.880
저는 압도적으로 AI가 생성하는 형태가 될 거라고 봅니다.

01:24:19.960 --> 01:24:21.160
-그렇습니까? -네.

01:24:24.520 --> 01:24:27.600
그러니까, 네, 실시간으로요.

01:24:27.680 --> 01:24:30.720
실시간 영화와 비디오게임입니다.

01:24:30.800 --> 01:24:33.800
실시간 비디오 생성이 앞으로의 방향이라고 생각합니다.

01:24:33.880 --> 01:24:39.360
상처를 지닌 인간의 미묘한 뉘앙스는

01:24:39.440 --> 01:24:44.720
예를 들어 AI로는 불가능한 방식으로 공감할 수 있는데요--

01:24:45.440 --> 01:24:48.480
물론 AI도 상처 입은 사람을 꽤 잘 흉내 낼 수는 있습니다.

01:24:52.560 --> 01:24:54.040
네, 그러니까...

01:24:55.680 --> 01:25:00.920
제가 xAI에서, 그리고 다른 곳에서 보고 있는 AI 비디오 생성은 꽤 인상적입니다.

01:25:03.400 --> 01:25:09.560
저희가 어떤 산업이 가장 빠르게 성장하는지에 관한 데이터를 살펴봤는데요,

01:25:09.640 --> 01:25:14.880
특히 영화 시청에 쓰는 시간의 양을

01:25:14.960 --> 01:25:20.240
소셜 미디어에 쓰는 시간, 유튜브에 쓰는 시간과 비교해 보니,

01:25:20.320 --> 01:25:25.400
다시 한 번 라이브 이벤트가 정말 빠르게 성장하는 것으로 보입니다.

01:25:25.480 --> 01:25:27.360
-오프라인에 직접 가는-- -네, 실제로요,

01:25:27.440 --> 01:25:29.200
저는 라이브 이벤트가--

01:25:29.280 --> 01:25:35.480
디지털 미디어가 어디에나 있고 디지털로 뭐든 가질 수 있을 때는

01:25:35.560 --> 01:25:40.680
사실상 공짜이거나 거의 공짜에 가깝게 말입니다,

01:25:40.760 --> 01:25:44.560
그러면 희소한 상품은 라이브 이벤트가 될 것입니다.

01:25:44.640 --> 01:25:45.640
-네. -네.

01:25:45.720 --> 01:25:48.520
그에 대한 프리미엄이 올라갈 거라고 보십니까?

01:25:48.600 --> 01:25:50.200
네, 그렇습니다.

01:25:50.280 --> 01:25:52.040
그게 투자하기 좋은 산업입니까?

01:25:52.120 --> 01:25:57.960
네, 네, 그게 어떤 디지털 상품보다도 더 희소해질 것이기 때문입니다.

01:25:58.040 --> 01:26:00.520
일론, 만약 주식 투자자라면...

01:26:00.600 --> 01:26:01.640
[마른웃음]

01:26:02.800 --> 01:26:04.160
-무슨 뜻입니까? -...그리고 살 수 있다면

01:26:04.240 --> 01:26:07.360
본인 회사가 아닌 회사 한 곳을

01:26:07.440 --> 01:26:12.520
오늘날의 밸류에이션으로, 자본주의적 목적을 이루기 위해서

01:26:12.600 --> 01:26:15.800
세상에 도움이 되는 이타적 목적이 아니라

01:26:15.880 --> 01:26:17.040
무엇을 사시겠습니까?

01:26:22.040 --> 01:26:24.920
그러니까, 저는 사실 주식을 잘 사지 않습니다.

01:26:25.000 --> 01:26:28.400
그래서 뭐랄까... 저는... 투자자처럼...

01:26:28.480 --> 01:26:32.440
투자할 대상을 찾지 않습니다. 저는 그냥 무언가를 만들려고 합니다.

01:26:33.880 --> 01:26:37.800
그러다 보니 제가 만든 회사의 주식이 있는 것이고요.

01:26:39.480 --> 01:26:42.960
하지만 '이 회사에 투자해야 하나?'라고 생각하지는 않습니다.

01:26:43.040 --> 01:26:45.160
포트폴리오 같은 것도 없습니다.

01:26:48.600 --> 01:26:49.640
그래서...

01:26:51.320 --> 01:26:53.480
그러니까, 음...

01:26:55.280 --> 01:26:58.200
AI와 로보틱스는 매우 중요해질 것입니다.

01:27:01.960 --> 01:27:08.720
그러니 저와 관련 없는 AI와 로보틱스가 될 것 같습니다.

01:27:11.440 --> 01:27:15.600
구글은 앞으로 꽤 가치가 있을 것이라고 생각합니다.

01:27:15.680 --> 01:27:20.720
그들은 막대한 규모의

01:27:20.800 --> 01:27:22.920
AI 관점에서의 가치 창출을 위한 기반을 마련해 왔습니다.

01:27:25.760 --> 01:27:27.760
엔비디아는 이 시점에서 당연합니다.

01:27:30.000 --> 01:27:35.240
그러니까, AI와 로보틱스를 하는 회사들,

01:27:35.320 --> 01:27:37.560
그리고 아마 우주 비행도...

01:27:37.640 --> 01:27:44.240
압도적으로 거의 모든 가치, 거의 전부의 가치를 차지하게 될 거라는 주장도 있습니다.

01:27:45.920 --> 01:27:49.440
그러니 AI와 로보틱스가 만들어내는 재화와 서비스의 산출량이 너무 커서

01:27:49.520 --> 01:27:51.480
다른 모든 것을 압도하게 될 것입니다.

01:27:52.640 --> 01:27:55.960
세상은

01:27:56.800 --> 01:28:03.240
모두가 다윗을 사랑하고 골리앗을 싫어하는 곳으로 가는 것 같습니다.

01:28:03.320 --> 01:28:04.320
왜 그렇습니까?

01:28:06.320 --> 01:28:09.640
그러니까, 이마에 돌을 맞은 쪽은 그 사람인데요.

01:28:09.720 --> 01:28:11.200
네, 네.

01:28:11.280 --> 01:28:13.360
솔직히, 그건 큰 실수였습니다.

01:28:13.440 --> 01:28:15.400
그는, 그러니까, 이렇게 했어야 하는데요--

01:28:15.480 --> 01:28:17.480
갑옷으로 온몸을 완전히 덮고

01:28:17.560 --> 01:28:21.600
그리고 어떤 종류든 원거리 무기를 갖추고 있는지도 확인했어야 합니다.

01:28:22.680 --> 01:28:26.560
그렇지 않으면 상대는 당연히 보스 카이팅 전략을 쓸 것입니다.

01:28:29.040 --> 01:28:30.080
그냥 보스를 카이팅하는 겁니다.

01:28:30.160 --> 01:28:32.520
그러니까 T팬티만 입고도 돌아다닐 수 있는데--

01:28:32.600 --> 01:28:35.160
상관없습니다, 아시죠? 절대 잡지 못합니다.

01:28:39.880 --> 01:28:42.800
사람들 중에서도, 그러니까...

01:28:42.880 --> 01:28:47.560
당신은 골리앗으로 보일 위험도 그만큼 큽니다.

01:28:47.640 --> 01:28:49.320
-알겠습니다. -특히 그다음 주말에는--

01:28:49.400 --> 01:28:52.440
부디 아무도 돌멩이로 제 이마를 맞히지 않기를 바랍니다, 아시죠?

01:28:52.520 --> 01:28:54.000
-특히 그 이후로는-- -보세요, 저는 여행을

01:28:54.080 --> 01:28:56.320
사막에서 갑옷을 너무 많이 입고 돌아다니지는 않을 겁니다, 아시죠?

01:28:57.800 --> 01:28:59.320
-너무 덥습니다. -네.

01:29:00.440 --> 01:29:01.760
지난 주말 이후로...

01:29:05.640 --> 01:29:07.040
-네. -네.

01:29:12.480 --> 01:29:15.360
사실 옛날 사람들을 생각해 보면 말인데요,

01:29:17.560 --> 01:29:19.560
이런 갑옷을 다 갖춰 입고 전투에 나가야 했잖습니까,

01:29:19.640 --> 01:29:21.320
그런데 이를테면 한여름이라고 해 보십시오,

01:29:21.400 --> 01:29:23.760
그 갑옷 안은 정말 너무 덥습니다!

01:29:23.840 --> 01:29:25.080
땀에 흠뻑 젖을 겁니다.

01:29:25.160 --> 01:29:27.480
그러다 어느 순간에는 '차라리 죽겠다'고 하게 됩니다.

01:29:28.760 --> 01:29:32.400
뜨거운 햇볕 아래에서 이 갑옷을 제대로 갖춰 입어야 합니까?

01:29:33.880 --> 01:29:35.360
그러니까 "차라리 죽겠습니다"라고 하게 됩니다.

01:29:37.920 --> 01:29:39.880
그래서 로마인들은, 아시다시피, 치마 같은 것을 입었습니다,

01:29:39.960 --> 01:29:42.280
그 안으로 공기가 좀 통하게 하려는 것이었습니다.

01:29:47.640 --> 01:29:49.760
가령 갑옷을 입은 채로 화장실에 가야 한다고 해 보시면,

01:29:49.840 --> 01:29:51.360
상당히 어려울 겁니다.

01:29:53.520 --> 01:29:55.680
어떻게 하시겠습니까, 잠깐 멈춰서 갑옷을 벗으시겠습니까?

01:29:58.400 --> 01:30:00.240
그래서 로마인들이 치마 같은 걸 입었던 겁니다.

01:30:00.320 --> 01:30:03.640
그래야 적어도 화장실은 갈 만해지니까요.

01:30:04.480 --> 01:30:08.200
-자주 농담을 하시네요. -저요?

01:30:08.960 --> 01:30:10.880
네, 저는 유머가 좋습니다.

01:30:13.640 --> 01:30:15.800
-그렇게 말할 수도 있겠는데요-- -저는 유머를 합법화해야 한다고 생각합니다.

01:30:15.880 --> 01:30:16.960
어떻게 생각하십니까?

01:30:19.240 --> 01:30:20.720
논쟁적인 입장입니다.

01:30:23.160 --> 01:30:26.320
AI가 코미디를 이해하는 게 정말 어려울까요?

01:30:26.400 --> 01:30:27.520
아마 마지막까지 남는 것 아니겠습니까?

01:30:28.480 --> 01:30:30.080
그록은 꽤 웃길 수 있습니다.

01:30:30.840 --> 01:30:32.400
네.

01:30:32.480 --> 01:30:34.040
제가 의심했던 게 뭔지 아십니까?

01:30:34.120 --> 01:30:40.480
좀 비약이긴 하지만, X에서 농담하시는 걸 보면

01:30:40.560 --> 01:30:43.800
그리고 인터뷰에서도 농담하시는 걸 보면,

01:30:43.880 --> 01:30:45.200
어느 순간에는 이런 생각이 들었습니다,

01:30:45.280 --> 01:30:49.480
어쩌면 일론이 비공개로 모델을 돌리면서 코미디를 시험하고 있는 건 아닐까 싶었습니다.

01:30:50.240 --> 01:30:53.400
그게 되는 날이면, 그게 있다는 걸 알게 되기 때문입니다.

01:30:55.720 --> 01:30:57.600
네, AI는 꽤 웃길 수 있습니다.

01:30:59.680 --> 01:31:03.720
그록에게 좀 저속한 로스트를 하라고 시키면 꽤 잘합니다.

01:31:05.040 --> 01:31:07.920
더 저속하게 하라고 하고 그냥 계속하라고 하면,

01:31:08.000 --> 01:31:09.720
정말 차원이 달라질 겁니다.

01:31:14.840 --> 01:31:16.320
말로도 다 할 수 없는--

01:31:16.400 --> 01:31:18.040
그러니까 그록에게 본인을 저속하게 로스트해 보라고 하면,

01:31:18.120 --> 01:31:19.960
당신에게 말로도 못 할 짓을 할 겁니다.

01:31:24.000 --> 01:31:25.280
어떤 코미디를 좋아하십니까?

01:31:26.720 --> 01:31:28.720
저는 부조리한 유머를 좋아하는 것 같습니다.

01:31:29.880 --> 01:31:31.120
코미디는 늘 자리가 있었습니다--

01:31:31.200 --> 01:31:33.080
몬티 파이선 같은 것 말입니다.

01:31:33.160 --> 01:31:35.280
코미디는 늘 사회에서 자리가 있었고,

01:31:35.360 --> 01:31:39.880
어릿광대의 역할이 모든 왕국에서 아주 중요했는데,

01:31:39.960 --> 01:31:45.160
재미있게 말해서 정색하고는 할 수 없는 말을 했기 때문입니다.

01:31:46.200 --> 01:31:48.280
네, 그런 것 같습니다. 어쩌면 어릿광대가 더 필요하겠습니다.

01:31:48.360 --> 01:31:49.360
네.

01:31:51.640 --> 01:31:55.080
농담을 하실 때 그런 걸 하려는 겁니까?

01:31:55.160 --> 01:31:57.440
농담이 아니면 할 수 없는 말을 하려는 겁니까?

01:31:57.520 --> 01:31:59.720
저는 그냥 유머가 좋습니다.

01:32:00.360 --> 01:32:02.480
저는 우리가...

01:32:02.560 --> 01:32:05.160
저는 코미디가 좋습니다. 재미있습니다. 사람들은 웃어야 합니다.

01:32:05.240 --> 01:32:07.600
가끔은 몇 번 웃음을 자아내는 게 좋습니다.

01:32:07.680 --> 01:32:09.160
-네, 네. -네.

01:32:09.240 --> 01:32:12.680
유머 없는 사회는 원하지 않습니다.

01:32:12.760 --> 01:32:14.000
그러면 메말라 버릴 겁니다.

01:32:14.080 --> 01:32:15.400
당신이--

01:32:15.480 --> 01:32:16.720
메말랍니다.

01:32:17.880 --> 01:32:21.000
-친구가 있으실 때, 일론-- -저 말입니까?

01:32:21.080 --> 01:32:22.720
-네, 그러니까-- -제가 친구가 있다고 말씀하시는 겁니까?

01:32:25.800 --> 01:32:29.280
친구들과 어울릴 때, 당신은 어떤 사람입니까?

01:32:29.360 --> 01:32:31.240
그러니까, 저도 알고 있는데--

01:32:32.480 --> 01:32:34.760
솔직히 말하면, 저는 친구가 있었으면 좋겠습니다.

01:32:34.840 --> 01:32:36.640
아니, 사실 친구가 있기는 합니다.

01:32:37.800 --> 01:32:40.520
그렇다고 생각합니다. 그러길 바랍니다.

01:32:41.480 --> 01:32:44.640
네, 물론입니다. 네, 저희는 재미있게 웃습니다.

01:32:44.720 --> 01:32:48.200
어떤 모습인지요? 모든 그룹에는 나름의 역학이 있잖습니까.

01:32:48.280 --> 01:32:49.720
저희는 말을 합니다, 아시다시피.

01:32:52.480 --> 01:32:53.680
저희는 가끔 음식을 먹습니다.

01:32:57.240 --> 01:32:59.000
아시겠지만, 때때로 저희는 수영장에서 수영을 합니다.

01:32:59.080 --> 01:33:01.080
아시다시피, 평범한 것들이라고 생각합니다.

01:33:01.160 --> 01:33:04.480
친구들과 함께 할 수 있는 것들에는 한계가 있지 않겠습니까?

01:33:04.560 --> 01:33:05.720
대화를 합니다.

01:33:08.120 --> 01:33:11.880
아시다시피, 우주의 본질에 대해 토론을 합니다.

01:33:14.360 --> 01:33:16.800
우정에서 감정적으로 무엇을 얻으십니까?

01:33:19.880 --> 01:33:20.960
모르겠습니다.

01:33:21.040 --> 01:33:23.240
우정에서 다른 사람들도 얻는 것과 똑같은 걸 얻는 것 같다고 생각합니다, 아시죠?

01:33:25.840 --> 01:33:28.640
다른 사람들과 감정적인 연결을 갖고 싶어 하게 됩니다.

01:33:29.800 --> 01:33:32.880
그리고, 음, 또--

01:33:32.960 --> 01:33:37.400
모르겠습니다, 여러 주제에 대해 이야기하고 싶어 하게 됩니다.

01:33:42.640 --> 01:33:46.440
네, 그러니까 저는 보통 이야기하는 게,

01:33:46.520 --> 01:33:49.520
그러니까 우주의 본성 같은 매우 다양한 것들에 대해 이야기합니다.

01:33:49.600 --> 01:33:53.360
그러니까 철학적인 논의가 많이 있습니다.

01:33:57.280 --> 01:33:59.840
아시다시피, 하지만 우리는 결론을 내렸습니다.

01:33:59.920 --> 01:34:04.200
파티에서는, 음...

01:34:04.280 --> 01:34:07.520
AI나 시뮬레이션에 대해서는 이야기하지 말자고요,

01:34:07.600 --> 01:34:10.360
왜냐하면 그 얘기를 너무 많이 하게 되니까요.

01:34:11.920 --> 01:34:13.800
-아시다시피, 아리스토텔레스가-- -가끔은 분위기를 싸늘하게 만들기도 합니다.

01:34:15.720 --> 01:34:16.920
그래서...

01:34:17.680 --> 01:34:20.400
누구였는지 기억이 안 납니다, 아리스토텔레스였는지 플라톤이었는지요.

01:34:20.480 --> 01:34:22.560
그들은 틀을 가지고 있었습니다.

01:34:22.640 --> 01:34:27.240
존중과 상호 존경을 바탕으로 친구를 고르는 방법에 대한 틀을요,

01:34:27.320 --> 01:34:29.600
하지만 사람들은 그렇게 친구를 고르지 않습니다.

01:34:31.760 --> 01:34:34.640
저조차도, 저는 제가 고르는 게...

01:34:36.880 --> 01:34:38.840
제 친구들을

01:34:38.920 --> 01:34:44.680
제가 공감할 수 있는 방식으로 말하고 생각하는 사람들을 기준으로

01:34:44.760 --> 01:34:47.760
-선택하는 것 같습니다. -그렇습니다.

01:34:47.840 --> 01:34:52.720
제 신념 체계와는 동떨어진, 제 신념에 반하는 반대론자를

01:34:52.800 --> 01:34:55.400
친구로 고르지는 않을 겁니다, 왜냐하면 피곤해질 테니까요.

01:34:55.480 --> 01:34:57.680
어울리는 것도 피곤해질 겁니다. 당신도 그러십니까?

01:34:57.760 --> 01:34:59.400
당신과 비슷하게 생각하는 친구를 선택하십니까,

01:34:59.480 --> 01:35:03.320
아니면 당신과 토론하고 반대 의견을 제시할 수 있는 사람을 찾으십니까?

01:35:03.400 --> 01:35:06.840
글쎄요, 저는 말하자면, friendHunter.com 같은 곳에 가서...

01:35:06.920 --> 01:35:10.240
-friendfinder.com이요. -[웃음]

01:35:10.320 --> 01:35:11.800
...친구를 찾아다니는 것은 아닙니다.

01:35:15.560 --> 01:35:18.200
그것은 말하자면, 네-- 제 생각에는 그냥

01:35:18.280 --> 01:35:21.120
어느 정도 공감이 가는 사람들인 것 같습니다...

01:35:22.360 --> 01:35:24.960
감정적으로나 지적으로 말입니다.

01:35:25.040 --> 01:35:27.960
그리고, 네, 뭐랄까, 네.

01:35:29.560 --> 01:35:32.440
아시겠지요? 그리고 제 생각에 친구란

01:35:32.520 --> 01:35:36.280
어려운 시기에 당신을 지지해 줄 사람이라고 생각합니다.

01:35:36.360 --> 01:35:38.520
어려울 때 도와주는 친구가 진정한 친구입니다.

01:35:38.600 --> 01:35:41.880
만약 누군가가 여전히 당신을 지지한다면

01:35:41.960 --> 01:35:44.800
칩이 바닥났을 때가 진짜 친구입니다, 아시죠.

01:35:44.880 --> 01:35:50.560
누군가가 당신을 지지하지 않거나, 누군가가 오로지--

01:35:50.640 --> 01:35:54.760
그러니까 형편 좋을 때만 붙는 친구들은 쓸모가 없습니다, 진짜 친구가 아닙니다.

01:35:57.240 --> 01:35:59.080
칩이 많을 때는 다들 당신을 좋아하지만,

01:35:59.160 --> 01:36:01.240
칩이 바닥났을 때는 누가 당신 편이 되어 줍니까?

01:36:01.320 --> 01:36:02.560
그게 친구입니다.

01:36:02.640 --> 01:36:04.600
당신만큼 칩이 많은 사람과 함께라면 그게 중요하겠습니까?

01:36:05.480 --> 01:36:06.960
그러니까 상대적인 겁니다, 아시죠.

01:36:08.640 --> 01:36:10.720
-그 특정한 부분은-- -그냥 칩 문제만은 아닙니다.

01:36:10.800 --> 01:36:12.560
그냥, 그러니까--

01:36:13.680 --> 01:36:14.960
네, 그러니까--

01:36:17.000 --> 01:36:18.080
그런, 그러니까...

01:36:20.520 --> 01:36:23.040
인기는 오르락내리락합니다, 아시죠?

01:36:23.880 --> 01:36:26.880
흥미롭네요. 정말 오르락내리락하나요...

01:36:29.720 --> 01:36:32.080
오로지 칩의 개수 때문입니까,

01:36:32.160 --> 01:36:38.680
아니면 권력과의 근접성과 둘 중 어느 쪽이 더 큰지에 따라서도 그렇습니까?

01:36:47.920 --> 01:36:49.520
모르겠습니다만, 그러니까 권력이란 게 무엇입니까?

01:36:49.600 --> 01:36:51.800
그러니까 무엇을 할 수 있는 권력입니까?

01:36:51.880 --> 01:36:55.320
전통적인 의미로는 선출된 권력이라고 생각합니다.

01:36:55.400 --> 01:36:58.880
-직책 말입니다. -기가와트가 몇이냐, 뭐 그런 뜻입니까?

01:37:01.040 --> 01:37:02.680
그보다는 전압이 몇 볼트냐에 가깝습니다.

01:37:02.760 --> 01:37:05.280
네, 그러니까-- 전압과 전류 같은 겁니다, 아시죠.

01:37:06.960 --> 01:37:08.320
전선은 만지지 마십시오.

01:37:11.520 --> 01:37:13.440
콘센트에 포크를 꽂지 마십시오.

01:37:15.920 --> 01:37:18.600
그러면 권력이 뭔지 제대로 체감하게 될 겁니다.

01:37:23.120 --> 01:37:24.360
맞습니다.

01:37:30.120 --> 01:37:32.080
네, 아주 생생하게 느끼게 될 겁니다, 네.

01:37:34.440 --> 01:37:36.000
[전기 튀는 소리 흉내]

01:37:44.120 --> 01:37:46.440
니체와 쇼펜하우어를 좋아하시는 건 알고 있습니다만--

01:37:46.520 --> 01:37:48.480
네, 그분들 책은 읽어봤습니다, 물론입니다만--

01:37:48.560 --> 01:37:51.400
어린 시절이 어땠는지 말씀하셨던 걸로 기억합니다...

01:37:53.400 --> 01:37:55.440
네, 저는 그냥 삶의 의미에 대한 답을 찾으려고 했습니다,

01:37:55.520 --> 01:37:56.840
그러니까 일종의 실존적 위기를 겪었을 때였고요,

01:37:56.920 --> 01:38:00.040
제가 12살이나 13살쯤이었는지, 그쯤이었습니다.

01:38:00.120 --> 01:38:03.400
-그들은 '권력 의지'에 대해 말합니다. -그렇습니다.

01:38:06.240 --> 01:38:08.800
니체는 논란이 될 만한 말을 많이 했습니다, 아시죠.

01:38:08.880 --> 01:38:10.320
그는, 어떻게 말하면...

01:38:10.400 --> 01:38:13.240
제 생각에는, 물어보신다면, 약간 트롤 같은 사람이었습니다.

01:38:16.120 --> 01:38:17.360
트롤이라니, 어떤 의미입니까?

01:38:17.440 --> 01:38:20.800
그러니까 사람들을 자극하려고 일부러 논란이 될 만한 말을 했다는 뜻입니다.

01:38:22.240 --> 01:38:24.120
그는 비참한 삶을 살다가 일찍 죽었습니다.

01:38:24.200 --> 01:38:25.200
-그랬습니까? -네.

01:38:25.280 --> 01:38:27.240
그런데 누가 그가 비참한 삶을 살았다고 말합니까?

01:38:27.320 --> 01:38:29.640
-그의 누이였던 것 같습니다. -그렇군요, 어쩌면 그를 좋아하지 않았을 수도 있겠습니다.

01:38:33.280 --> 01:38:35.720
아니요, 저는 그가 병에 걸렸다가 죽었다고 생각합니다.

01:38:35.800 --> 01:38:37.960
-그러니까, 소문으로는 매독 같은 것이었다고 하더군요. -네.

01:38:41.040 --> 01:38:43.400
하지만 그건 얻는 방법이 하나뿐입니다, 아시죠.

01:38:46.920 --> 01:38:49.320
그래서 그 과정에서 좀 즐겼을지도 모릅니다.

01:38:53.480 --> 01:38:55.440
이건 꼭 여쭤보고 싶었습니다.

01:38:57.000 --> 01:38:59.440
밀턴 프리드먼은 연필에 대해 이야기합니다.

01:38:59.520 --> 01:39:01.200
뭐라고요? 왜입니까?

01:39:05.840 --> 01:39:07.600
왜 연필 이야기를 그렇게 계속합니까?

01:39:08.720 --> 01:39:10.480
니체와 매독 이야기까지 듣고 나서 말씀드리자면,

01:39:12.880 --> 01:39:16.640
밀턴 프리드먼은 왜 계속 연필 얘기만 합니까?

01:39:16.720 --> 01:39:18.720
또 연필 이야기입니다.

01:39:21.120 --> 01:39:22.120
멈추지 않습니다.

01:39:23.400 --> 01:39:26.920
정말로, "밀턴이 연필을 이야기한다"는 말을 한 번만 더 들으면,

01:39:28.040 --> 01:39:29.280
정신이 나가버릴 것 같습니다.

01:39:32.960 --> 01:39:35.040
그는 하루 종일 연필 얘기만 주절주절 늘어놓습니다.

01:39:41.360 --> 01:39:42.800
크레용은 언급도 하지 않았습니다.

01:39:46.400 --> 01:39:49.640
제가 그의 연필 논증에서 흥미롭게 보는 점은,

01:39:52.280 --> 01:39:53.880
-그렇습니까? -그는--

01:39:53.960 --> 01:39:56.640
네, 네, 아니, 연필 하나 만드는 게 정말 어렵습니다, 아시죠.

01:39:56.720 --> 01:39:57.800
한 곳에서만으로는요.

01:39:57.880 --> 01:39:59.680
연필을 만들기 위해 해야 하는 모든 일을 생각해 보십시오.

01:39:59.760 --> 01:40:01.760
네, 예를 들면 흑연은 한 나라에서 오고,

01:40:01.840 --> 01:40:04.600
나무는 다른 나라에서 오고, 고무는 또 다른 나라에서 옵니다.

01:40:04.680 --> 01:40:08.880
당신은 늘 관세에 반대해 오셨지만...

01:40:08.960 --> 01:40:10.480
네, 그러니까, 제 생각에는,

01:40:10.560 --> 01:40:14.320
일반적으로 자유무역이 더 낫고 더 효율적입니다, 아시죠.

01:40:14.400 --> 01:40:19.320
관세는 시장에 왜곡을 만들어내는 경향이 있습니다.

01:40:21.440 --> 01:40:25.640
그리고 대체로, 어떤 것이든 한번 생각해 보시면,

01:40:25.720 --> 01:40:27.600
예를 들어, 당신과

01:40:27.680 --> 01:40:29.920
다른 모든 사람 사이에 개인 차원의 관세가 있기를 원하십니까?

01:40:30.000 --> 01:40:31.720
그렇다면 삶이 매우 어려워질 겁니다.

01:40:31.800 --> 01:40:33.920
각 도시 사이에 관세가 있기를 원하십니까?

01:40:34.000 --> 01:40:36.520
아니요, 그건 매우 성가실 겁니다.

01:40:36.600 --> 01:40:39.480
미국 내 각 주 사이에 관세가 있기를 원하십니까?

01:40:39.560 --> 01:40:42.560
그러니까, 아니요, 그건 경제에 재앙이 될 겁니다.

01:40:43.720 --> 01:40:45.400
그렇다면 왜 국가들 사이에 관세를 두고 싶으십니까?

01:40:46.600 --> 01:40:48.200
-동의합니다. -네.

01:40:51.920 --> 01:40:54.480
이게 어떻게 전개될 거라고 보십니까? 다음에는 무슨 일이 일어납니까?

01:40:54.560 --> 01:40:56.280
-관세 말씀입니까? 아니면 다른 말씀입니까? -네.

01:40:57.440 --> 01:41:01.960
대통령께서는 관세를 좋아하신다는 점을 분명히 해오셨습니다.

01:41:02.960 --> 01:41:06.480
저는 그 관점에서 대통령을 설득해 보려고 했지만, 성공하지 못했습니다.

01:41:06.560 --> 01:41:07.840
네.

01:41:07.920 --> 01:41:09.320
-그렇군요. -네.

01:41:10.560 --> 01:41:14.520
비즈니스와 정치의 관계입니다.

01:41:15.520 --> 01:41:18.880
누군가와 이 대화를 하다가 저희가 이런 생각을 했습니다.

01:41:18.960 --> 01:41:20.840
마지막으로 언제였는지—

01:41:20.920 --> 01:41:24.960
정말 크고 수익성이 높은 대기업이

01:41:25.040 --> 01:41:29.840
정치권과의 접점 없이 지난 수십 년 사이에 얼마나 만들어졌을까요?

01:41:29.920 --> 01:41:33.720
-그리고... -음, 알겠습니다.

01:41:33.800 --> 01:41:37.000
글쎄요, 잘 모르겠습니다. 아마 많겠죠, 잘 모르겠습니다.

01:41:37.080 --> 01:41:38.680
-모든 일에 정치가 필요한 건 아닙니다. -네.

01:41:38.760 --> 01:41:42.000
제 생각에는 어느 정도 규모가 되면 정치는 먼저 찾아온다고 봅니다.

01:41:42.080 --> 01:41:43.440
네.

01:41:45.600 --> 01:41:46.920
상당히 불쾌합니다.

01:41:47.000 --> 01:41:48.680
제가 읽고 있었는데—

01:41:48.760 --> 01:41:52.320
미켈란젤로에 관한 책을 읽고 있었는데, 그가—

01:41:52.400 --> 01:41:53.520
닌자 거북이요?

01:41:56.200 --> 01:41:57.640
어렸을 때 그걸 보곤 했습니다.

01:41:57.720 --> 01:41:59.320
-지금도 여전히 좋아합니다. -상당히 매력적입니다.

01:41:59.400 --> 01:42:01.240
네, 네, 저도 예전에 정말 좋아했습니다.

01:42:01.320 --> 01:42:05.400
미켈란젤로, 레오나르도, 라파엘로, 그리고 네 번째는 누구였죠?

01:42:05.480 --> 01:42:06.800
-도나텔로요. -맞습니다.

01:42:06.880 --> 01:42:09.960
-네. -아니요, 조각가이자 예술가인 미켈란젤로 말씀입니다.

01:42:12.800 --> 01:42:15.240
그가 다비드를 조각하고 있을 때,

01:42:15.320 --> 01:42:18.280
어떤 정치인이 다가와서 코가 너무 크다고 말합니다.

01:42:19.720 --> 01:42:21.280
그래서 미켈란젤로가 무엇을 하는지 아십니까?

01:42:21.360 --> 01:42:22.760
완전한 권력입니까?

01:42:25.880 --> 01:42:29.080
미켈란젤로는 비계 위에서 작업하는 척했고

01:42:29.160 --> 01:42:32.120
먼지를 조금 떨어뜨렸지만, 실제로는 아무것도 바꾸지 않았습니다.

01:42:32.200 --> 01:42:36.120
그리고는 "자, 됐습니다"라고 했고, 그 정치인은 만족해서 돌아갔습니다.

01:42:36.720 --> 01:42:38.880
가끔 정치도 그런 식으로 상대하십니까?

01:42:42.760 --> 01:42:45.480
대체로 제가 정치에 관여하면

01:42:45.560 --> 01:42:47.000
결과가 좋지 않더군요.

01:42:53.080 --> 01:42:57.920
그래서 저는 "아마 그건 하지 말아야겠다"라고 생각합니다.

01:42:58.000 --> 01:43:00.760
제 결론은 "그런 일은 더 줄여야 한다"는 것입니다.

01:43:00.840 --> 01:43:02.800
모든 사업가에게도 그게 해당된다고 보십니까?

01:43:02.800 --> 01:43:04.680
네, 아마도요. 네, 네.

01:43:07.160 --> 01:43:09.040
네, 그러니까,

01:43:09.040 --> 01:43:11.040
정치는 피의 스포츠 같은 것입니다.

01:43:11.040 --> 01:43:14.320
정치에 들어가면 그들은 목을 노릴 겁니다.

01:43:15.440 --> 01:43:19.800
그러니 가능하면 정치는 피하는 것이 최선입니다.

01:43:21.280 --> 01:43:23.800
DOGE에서 한 가지라도 배운 게 있다면 무엇을 배웠습니까?

01:43:24.360 --> 01:43:27.120
글쎄요, 꽤 흥미로운 사이드 퀘스트 같았다고 할까요,

01:43:27.200 --> 01:43:31.840
정부의 내부 작동 방식을 많이 들여다볼 수 있었기 때문입니다.

01:43:33.680 --> 01:43:39.160
그리고 아시다시피 효율화가 꽤 많이 이뤄졌습니다.

01:43:39.240 --> 01:43:41.480
그러니까 그중 일부는 아주 기본적인 효율화였는데,

01:43:41.560 --> 01:43:45.320
예를 들어 연방 지급에 대한 요건을 추가하는 것이었습니다.

01:43:45.400 --> 01:43:51.520
어떤 지급이든 지정된 의회 지급 코드가 있어야 하고

01:43:51.600 --> 01:43:54.640
코멘트란에는 빈칸이 아닌 무언가가 반드시 적혀 있어야 한다는 것이었습니다.

01:43:55.920 --> 01:44:00.720
겉보기엔 사소해 보이는 그 변화가 제 추측으로는,

01:44:00.800 --> 01:44:05.440
연간 1,000억 달러, 어쩌면 2,000억 달러까지 절감해 줄 가능성이 큽니다.

01:44:05.520 --> 01:44:09.280
왜냐하면 엄청난 수의 지급이

01:44:09.360 --> 01:44:12.080
의회 지급 코드 없이 집행되고 있었고

01:44:12.160 --> 01:44:13.680
코멘트란도 아무것도 없는 채였기 때문인데요,

01:44:13.760 --> 01:44:16.280
그렇게 되면 지급을 감사하는 것이 불가능해집니다.

01:44:16.360 --> 01:44:19.240
그래서 예컨대 국방부가 왜—

01:44:19.320 --> 01:44:21.920
아니, 이제는 전쟁부라고 해야 할까요—왜 감사를 통과하지 못하느냐고 묻는다면,

01:44:22.000 --> 01:44:23.840
필요한 정보가 없기 때문입니다.

01:44:23.920 --> 01:44:25.080
그것은—

01:44:25.160 --> 01:44:29.560
감사를 통과하는 데 필요한 정보 자체가 존재하지 않는 것이 문제입니다.

01:44:29.640 --> 01:44:34.400
그래서 DOGE가 한 많은 일들은 그저 상식적인 것들이었고,

01:44:35.520 --> 01:44:38.680
재정적 책임을 중시하는 어떤 조직이라도

01:44:38.760 --> 01:44:41.320
당연히 할 법한 일들이었습니다.

01:44:41.400 --> 01:44:43.800
대부분은 그런 일이었습니다.

01:44:46.160 --> 01:44:49.200
참고로, 그 일은 지금도 계속되고 있습니다.

01:44:49.280 --> 01:44:51.640
DOGE는 아직도 진행 중입니다.

01:44:51.720 --> 01:44:56.360
하지만 사기성이거나 낭비적인 지급을 중단하면,

01:44:56.440 --> 01:45:01.440
사기꾼들은 그 사실을 인정하지 않습니다.

01:45:01.520 --> 01:45:04.560
오히려 그들은 온갖 헛소리를 퍼부으며,

01:45:04.640 --> 01:45:08.520
"궁핍한 사람들에게 꼭 필요한 지급을 막고 있다"라고 말합니다.

01:45:09.800 --> 01:45:11.200
하지만 실제로는 그렇지 않습니다.

01:45:12.480 --> 01:45:14.160
그러다 보면 이런 말도 듣게 됩니다.

01:45:14.240 --> 01:45:17.680
"아, 어쨌든 이건 꼭 보내야 합니다" 같은 식입니다.

01:45:17.760 --> 01:45:20.080
"이건 아프리카의 아이들에게 가는 돈입니다"라고도 합니다.

01:45:20.160 --> 01:45:22.600
그러면 저는 "네, 그런데 그렇다면 왜 송금 지침이

01:45:22.680 --> 01:45:26.840
워싱턴 D.C.의 Deloitte & Touche로 되어 있습니까? 거기는 아프리카가 아닙니다."라고 말합니다.

01:45:30.480 --> 01:45:35.440
"그렇다면 아프리카에서 이 돈을 받는 수혜자들과 연결해 주실 수 있습니까?"라고 합니다.

01:45:36.440 --> 01:45:38.560
그러면 아무 대답이 없습니다.

01:45:38.640 --> 01:45:44.320
그러니까요, 저희는 말 그대로 수혜자들과 직접 통화하고 싶을 뿐입니다, 그게 전부입니다.

01:45:45.640 --> 01:45:48.440
그러면 저희는 "아, 안 되겠네요, 어째서인지 그들과는 통화할 수 없다고 합니다"라고 합니다.

01:45:48.520 --> 01:45:50.320
그러면서 "그럼 저희는 돈을 보내지 않겠습니다

01:45:50.400 --> 01:45:53.280
수혜자와 직접 통화해 실제로 받는지 확인할 수 없기 전에는 말입니다."라고 합니다.

01:45:55.720 --> 01:45:56.880
아시다시피...

01:45:56.960 --> 01:45:58.760
하지만, 아시다시피, 그런 식으로...

01:46:00.200 --> 01:46:05.560
사기꾼들은 필연적으로 아주...

01:46:05.640 --> 01:46:08.040
동정심을 자극하는 그럴듯한 논리를 내세웁니다.

01:46:08.120 --> 01:46:10.160
그들은 "사기 치려고 돈을 주세요"라고 말하지는 않습니다.

01:46:10.240 --> 01:46:12.320
당연히 그런 말을 하지는 않습니다.

01:46:12.400 --> 01:46:14.040
그들은

01:46:14.120 --> 01:46:16.160
거짓이지만 동정심을 자극해 보이는 주장들을 만들어내려 합니다.

01:46:16.240 --> 01:46:19.880
-그들은 NGO를 만들고는-- -네, NGO라고 하면--

01:46:19.960 --> 01:46:23.840
"아기 판다를 구하자" 같은 NGO가 될 것입니다,

01:46:23.920 --> 01:46:26.400
아기 판다를 구하고 싶지 않은 사람이 누가 있겠습니까? 정말 사랑스럽습니다.

01:46:27.720 --> 01:46:32.120
그런데 알고 보면 이 일로는 판다가 전혀 구해지지 않습니다.

01:46:32.200 --> 01:46:36.000
그 돈은 여기저기로-- 결국 본질적으로는 부패일 뿐입니다.

01:46:37.440 --> 01:46:39.680
그러면 "그럼 판다 사진이라도 보내주실 수 있나요?"라고 하게 됩니다.

01:46:39.760 --> 01:46:41.120
그러면 "안 됩니다"라고 합니다. 알겠습니다.

01:46:42.040 --> 01:46:45.200
그럼 돈이 판다에게 간다는 것을 어떻게 알 수 있겠습니까?

01:46:45.280 --> 01:46:46.800
제가 말하는 게 그겁니다.

01:46:46.880 --> 01:46:48.760
자선 활동에 대해서는 어떻게 생각하십니까?

01:46:49.400 --> 01:46:51.440
네, 저는 우리가...

01:46:51.520 --> 01:46:54.720
그러니까, 인류애라는 말에는 동의합니다.

01:46:54.800 --> 01:46:59.440
그리고 동료 인간을 돕는 일을 하려고 노력해야 한다고 생각합니다.

01:47:01.120 --> 01:47:02.520
하지만 매우 어렵습니다.

01:47:02.600 --> 01:47:05.120
예를 들어, 선함의 실재를 중요하게 여긴다면

01:47:05.200 --> 01:47:08.000
그저 그렇게 보이는 것보다는 말입니다,

01:47:08.080 --> 01:47:10.720
돈을 제대로 기부하는 것은 매우 어렵습니다.

01:47:12.200 --> 01:47:14.520
그래서 저는 큰 재단을 갖고 있지만, 제 이름을 걸지 않습니다.

01:47:14.600 --> 01:47:18.880
그리고, 아시다시피... 사실 저는 "어떤 것에도 제 이름을 붙이고 싶지 않습니다"라고 말합니다.

01:47:20.320 --> 01:47:22.720
하지만 제가 제 재단에서 느끼는 가장 큰 과제는

01:47:22.800 --> 01:47:26.360
사람들에게 진정으로 도움이 되는 방식으로 돈을 나누는 것입니다.

01:47:27.120 --> 01:47:30.400
선해 보이기 위해 돈을 기부하는 것은 아주 쉽습니다.

01:47:30.480 --> 01:47:33.680
선함의 실재를 위해 돈을 기부하는 것은 매우 어렵습니다.

01:47:34.880 --> 01:47:36.160
정말 어렵습니다.

01:47:39.080 --> 01:47:42.880
오랫동안 미국에는 이민이 많았고,

01:47:42.960 --> 01:47:45.240
정말 똑똑한 사람들이 미국으로 들어왔습니다.

01:47:45.320 --> 01:47:47.080
-네. -저희 인도에서는,

01:47:47.160 --> 01:47:49.400
그것을 "두뇌 유출"이라고 불렀습니다.

01:47:49.480 --> 01:47:54.960
서구 기업들에 있는 인도계 CEO들 말입니다.

01:47:55.040 --> 01:47:57.400
네, 저는 미국이 엄청난 혜택을 얻었다고 생각합니다.

01:47:57.480 --> 01:48:00.480
미국으로 온 유능한 인도인들로부터 말입니다.

01:48:00.560 --> 01:48:02.240
다만 요즘은 그게 바뀌는 것 같습니다.

01:48:04.920 --> 01:48:05.960
네, 그러니까요.

01:48:06.040 --> 01:48:09.360
네, 미국은 인도의 인재로부터 엄청난 수혜를 입어왔습니다.

01:48:09.440 --> 01:48:14.160
네. 그런데 최근에 그 서사가 왜 바뀌었습니까?

01:48:14.240 --> 01:48:18.280
그리고 미국은 어느 정도 반이민 쪽으로 변한 것 같습니다.

01:48:18.360 --> 01:48:19.920
예를 들어, 제가 입국심사를 통과하고 있었는데,

01:48:20.000 --> 01:48:22.920
며칠 전에 저를 멈춰 세웠다면 어쩌나 걱정했습니다.

01:48:24.160 --> 01:48:27.640
음, 제 생각엔 관점이 여러 가지 있습니다.

01:48:27.720 --> 01:48:32.400
만장일치는 아니지만, 아시다시피 바이든 행정부 아래에서는,

01:48:32.480 --> 01:48:35.840
사실상 국경 통제가 거의 없는 완전한 무규제 상태였고,

01:48:35.920 --> 01:48:38.640
국경 통제가 없으면 국가라고 할 수 없습니다.

01:48:40.120 --> 01:48:44.640
그래서 바이든 시절에는 불법 이민이 엄청나게 많았습니다.

01:48:45.840 --> 01:48:50.760
그리고 실제로 다소 부정적 선별 효과도 있었습니다.

01:48:51.800 --> 01:48:56.440
그러니까, 큰 경제적 유인이 있다면

01:48:56.520 --> 01:49:00.000
불법으로 미국에 와서 이런 정부 혜택을 모두 받으려 하게 되고,

01:49:02.160 --> 01:49:05.040
그러면 필연적으로

01:49:05.120 --> 01:49:07.440
사람들이 미국으로 오게 만드는 일종의 확산 구배를 만들게 됩니다.

01:49:07.520 --> 01:49:08.840
그건 인센티브 구조입니다.

01:49:10.440 --> 01:49:15.320
그래서 제 생각에는, 그건 분명 말이 안 됐습니다.

01:49:15.400 --> 01:49:18.560
국경 통제는 해야 합니다. 안 하는 건 터무니없습니다.

01:49:20.080 --> 01:49:21.640
그러면 그건...

01:49:21.720 --> 01:49:26.440
그러니까, 좌파는 기본적으로 제약 없는 개방 국경을 원합니다.

01:49:26.520 --> 01:49:29.320
아시다시피, 누가— 어떤 상황이든 상관없다는 것입니다,

01:49:29.400 --> 01:49:31.800
범죄자여도 상관없습니다.

01:49:31.880 --> 01:49:34.240
반면 우파 쪽에서는, 아시다시피,

01:49:36.320 --> 01:49:40.120
적어도 자신의 일자리가 어떤 식으로든

01:49:40.200 --> 01:49:43.240
다른 나라에서 온 유능한 사람들에게 빼앗기고 있다는 인식이 있습니다.

01:49:45.120 --> 01:49:47.120
그게 얼마나 현실인지는 모르겠습니다.

01:49:49.160 --> 01:49:53.360
제가 직접 본 바로는 유능한 사람은 늘 부족합니다.

01:49:54.160 --> 01:49:57.520
그래서 제 관점에서는 이렇게 생각합니다,

01:49:57.600 --> 01:50:00.440
"저희는 이런 어려운 과제를 해낼 만큼 유능한 사람을 충분히 찾기가 매우 어렵습니다.

01:50:00.520 --> 01:50:02.680
이런 어려운 일을 해내기 위해서입니다.

01:50:02.760 --> 01:50:05.360
그래서 더 많은 유능한 사람이 있으면 좋겠습니다."

01:50:07.840 --> 01:50:09.480
하지만 다른 회사들 중에는,

01:50:09.560 --> 01:50:12.960
이를 일종의 비용 문제로 보는 경향이 있는 것 같습니다,

01:50:13.040 --> 01:50:14.920
그러니까, 예를 들어 누군가를 고용할 때

01:50:15.000 --> 01:50:19.920
미국 시민을 고용하는 비용의 일부만으로

01:50:20.000 --> 01:50:24.920
사람을 고용할 수 있다면, 그런 회사들은 비용을 아끼기 위해 사람을 고용할 것입니다.

01:50:25.760 --> 01:50:28.880
하지만 제 회사들에서는, 저희는 그저

01:50:28.960 --> 01:50:31.400
세계에서 가장 유능한 인재들을 확보하려고 합니다.

01:50:31.480 --> 01:50:34.880
그리고 저희는 평균보다 훨씬 많이 급여를 지급합니다.

01:50:34.960 --> 01:50:37.120
그래서 저는—

01:50:37.200 --> 01:50:38.840
그래서, 제 경험상으로는 그렇지 않습니다.

01:50:38.920 --> 01:50:41.480
하지만 많은 사람들이 그런 점을 불평하는 것도 사실입니다.

01:50:42.400 --> 01:50:48.480
그리고 H-1B 프로그램이 일부 오용된 사례가 있었다고 생각합니다.

01:50:50.320 --> 01:50:51.680
정확히 말하자면,

01:50:51.760 --> 01:50:54.520
일부 아웃소싱 업체들이

01:50:54.600 --> 01:50:59.520
H-1B 쪽에서 제도를 교묘히 이용해 왔다고 할 수 있습니다.

01:50:59.600 --> 01:51:02.400
그리고 그런 제도 악용은 멈춰야 합니다. 아시겠습니까?

01:51:04.240 --> 01:51:06.760
하지만 저는 분명히

01:51:06.840 --> 01:51:08.920
H-1B 프로그램을 폐지해야 한다는 쪽은 아닙니다.

01:51:09.000 --> 01:51:11.080
그건— 일부 우파는 그렇게 보기도 합니다.

01:51:12.480 --> 01:51:15.400
그렇게 하면 실제로 매우 나쁘다는 것을 그들은 깨닫지 못하는 것 같습니다.

01:51:17.200 --> 01:51:20.720
제 나라, 인도의 사람들,

01:51:20.800 --> 01:51:23.800
무언가를 만들고 싶어 하는 젊은 창업가들에게...

01:51:23.880 --> 01:51:25.560
-네. -...그들에게 한 말씀 해 주신다면,

01:51:25.640 --> 01:51:26.680
뭐라고 하시겠습니까?

01:51:32.920 --> 01:51:35.720
저는 무언가를 만들고자 하는 분들의 열렬한 팬입니다.

01:51:35.800 --> 01:51:37.760
그래서 무언가를...

01:51:40.360 --> 01:51:43.520
아시다시피, 가져가는 것보다 더 많이 만들어 내는 분들은 존경합니다.

01:51:43.600 --> 01:51:47.800
그러니 그것이 여러분이 가장 목표로 해야 할 핵심입니다,

01:51:47.880 --> 01:51:49.720
가져가는 것보다 더 많이 만들어 내는 것을 목표로 하십시오.

01:51:51.080 --> 01:51:55.600
사회에 순기여를 하는 사람이 되십시오.

01:51:59.280 --> 01:52:02.240
그리고 이건 일종의 행복의 추구와도 같습니다.

01:52:02.320 --> 01:52:06.400
경제적으로 가치 있는 무언가를 만들고 싶다면,

01:52:06.480 --> 01:52:08.560
그것 자체를 추구하지 마십시오.

01:52:08.640 --> 01:52:13.920
대신 유용한 제품과 서비스를 제공하는 것을 추구하는 것이 가장 좋습니다.

01:52:14.000 --> 01:52:18.520
그렇게 하면 돈은 그에 따른 자연스러운 결과로 따라오게 됩니다,

01:52:18.600 --> 01:52:21.040
돈을 직접 추구하는 것과는 다릅니다.

01:52:21.120 --> 01:52:23.160
행복을 직접적으로 추구할 수 없는 것과 마찬가지입니다,

01:52:23.240 --> 01:52:25.800
행복으로 이어지는 것들을 추구하게 됩니다.

01:52:25.880 --> 01:52:29.400
하지만 행복을 직접적으로 추구하는 방식은 없습니다.

01:52:29.480 --> 01:52:30.920
예를 들어...

01:52:32.920 --> 01:52:37.080
의미 있는 일, 공부, 친구, 사랑하는 사람들 같은 것들을 하면,

01:52:38.560 --> 01:52:41.720
그 결과로 행복해지게 됩니다.

01:52:42.720 --> 01:52:45.120
그러니, 매우 당연하게 들릴 수 있습니다만...

01:52:48.600 --> 01:52:51.000
일반적으로 누군가 회사를 제대로 굴리려 한다면,

01:52:51.080 --> 01:52:52.960
매우 강도 높은 노력을 해야 한다는 점을 각오해야 합니다,

01:52:53.800 --> 01:52:57.080
의미 있는 수준의 실패 가능성이 있다는 점도 받아들여야 합니다,

01:52:59.360 --> 01:53:06.360
그러되 산출물이 투입보다 더 가치 있게 되도록 만드는 데만 집중하십시오.

01:53:07.920 --> 01:53:09.720
즉, 당신은 가치를 창출하는 사람입니까?

01:53:11.080 --> 01:53:12.880
그게 정말로 중요합니다.

01:53:16.360 --> 01:53:18.600
가져가는 것보다 더 많이 만들어내는 것입니다.

01:53:18.680 --> 01:53:20.560
이렇게 마무리하는 것이 좋은 방법이라고 생각합니다.

01:53:20.640 --> 01:53:23.120
-로런이 마무리해 달라고 요청하고 있습니다. -알겠습니다.

01:53:24.560 --> 01:53:31.320
이 기회에 IGF의 제 친구인 마노지 라드와께도 감사드리고 싶습니다.

01:53:31.400 --> 01:53:37.120
그분은 제 생각에 여기 계신 분들 같은 인도 분들을,

01:53:37.200 --> 01:53:40.280
당신 같은 분들과 연결해 주시는 일을 정말 훌륭하게 해내십니다...

01:53:41.760 --> 01:53:44.560
그렇게 해서 무엇보다 서로를 알아가고 친구가 될 수 있다고 생각합니다.

01:53:44.640 --> 01:53:47.520
친구가 되면 어쩌면 함께 일을 시작할 수 있기 때문입니다.

01:53:48.760 --> 01:53:51.880
그래서 이 모든 것을 준비해 주신 마노지 라드와께 감사드리고, IGF에도 감사드립니다.

01:53:51.960 --> 01:53:53.480
[청중 박수]

01:53:53.560 --> 01:53:55.440
그리고 시간 내주신 일론 머스크께도 정말 감사드립니다.

01:53:55.520 --> 01:53:56.800
천만의 말씀입니다.

01:54:00.240 --> 01:54:03.360
-재미있으셨습니까, 아니면 지루하셨습니까? -네, 흥미로운 대화였습니다.

01:54:03.440 --> 01:54:06.400
가끔 이런 답변들이 맥락에서 떼어져 인용되기도 합니다.

01:54:06.480 --> 01:54:09.720
하지만... 좋은 대화였다고 생각합니다.
