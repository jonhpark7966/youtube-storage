1
00:00:00,033 --> 00:00:02,068
By the way, I don't have a psychosis.

2
00:00:02,068 --> 00:00:03,737
I have a Claude complex.

3
00:00:03,737 --> 00:00:06,039
Why is everyone making that joke? Wait.

4
00:00:06,039 --> 00:00:08,775
Which joke? The psychosis joke.

5
00:00:08,775 --> 00:00:11,778
I thought you were going to be proud of me
for saying Claude Complex.

6
00:00:11,911 --> 00:00:13,279
Oh, that is very good.

7
00:00:13,279 --> 00:00:17,384
I think I do one pun finally for Tracy,
and I was over making that joke.

8
00:00:17,417 --> 00:00:19,953
Well, I was thinking that was a joke.
I had to go.

9
00:00:19,953 --> 00:00:22,155
I finally make a pun,
and you just jump right over it.

10
00:00:22,155 --> 00:00:26,026
Well, everyone keeps saying
that Claude code is I psychosis for smart

11
00:00:26,026 --> 00:00:28,661
people, right? Like,
how did that become addictive?

12
00:00:28,661 --> 00:00:29,763
Yeah. All right.

13
00:00:29,763 --> 00:00:31,898
But there's a good. Fun
also very bro coded.

14
00:00:31,898 --> 00:00:34,901
I find.

15
00:00:38,705 --> 00:00:39,239
Hello and

16
00:00:39,239 --> 00:00:42,242
welcome to another episode of the Odd Lots
podcast.

17
00:00:42,275 --> 00:00:43,443
I'm Joe Weisenthal

18
00:00:43,443 --> 00:00:46,146
And I'm Tracy
Alloway. So, Tracy you're cool.

19
00:00:46,146 --> 00:00:47,213
Like, if I like,

20
00:00:48,181 --> 00:00:48,815
you know, just

21
00:00:48,815 --> 00:00:51,951
start doing this part time as I like,
build out my software business.

22
00:00:51,951 --> 00:00:53,219
Right. Like you're cool about that.

23
00:00:53,219 --> 00:00:56,990
I was going to say I've been thinking
about AI and productivity.

24
00:00:56,990 --> 00:01:00,660
And so far
your productivity has gone down, Joe.

25
00:01:00,760 --> 00:01:04,497
So instead of doing all thoughts things,
you're coding your own software.

26
00:01:04,798 --> 00:01:07,500
Except that I'm creating content
for the Odd Lots

27
00:01:07,500 --> 00:01:10,470
newsletter about coding
and that is productivity.

28
00:01:11,071 --> 00:01:11,838
A creative.

29
00:01:11,838 --> 00:01:13,473
Debatable. Debatable.

30
00:01:13,473 --> 00:01:15,542
But but you're cool with that.

31
00:01:15,542 --> 00:01:16,476
You're cool with like me.

32
00:01:16,476 --> 00:01:16,876
Like, oh,

33
00:01:16,876 --> 00:01:19,879
I'm just going to, like, check in part
time on Odd Lots when we have a record.

34
00:01:19,913 --> 00:01:21,147
Well, oh. Of course not.

35
00:01:21,147 --> 00:01:24,050
Okay, good, good, good.
That's the right answer. I want you to.

36
00:01:24,050 --> 00:01:25,085
I want you to be really sad.

37
00:01:25,085 --> 00:01:28,088
But like a few other people, you know,
I have, like,

38
00:01:28,254 --> 00:01:32,459
caught the sort of, like, bug of, like,
AI coding, and I'm totally blown away.

39
00:01:32,625 --> 00:01:34,561
I like, played with it from the beginning.

40
00:01:34,561 --> 00:01:37,664
I started playing around with it
last year, but then over the holidays

41
00:01:37,664 --> 00:01:39,532
and I've been writing about this
in the newsletter suddenly, like,

42
00:01:39,532 --> 00:01:42,535
my Twitter feed is like club code, plug
code, plug code

43
00:01:42,769 --> 00:01:46,539
and you just cursor before
which I was very impressed by at the time.

44
00:01:46,906 --> 00:01:50,643
And so when I got home from vacation,
one of the first things I did

45
00:01:50,643 --> 00:01:54,147
is like, figure out
how to install plug code on my computer.

46
00:01:54,481 --> 00:01:56,416
And I was like, oh, I am like hooked.

47
00:01:56,416 --> 00:01:58,651
And this is actually like,

48
00:01:58,651 --> 00:02:02,255
I see why I have my Twitter feed
is just like people posting about this.

49
00:02:02,522 --> 00:02:02,889
All right.

50
00:02:02,889 --> 00:02:06,226
So I have to say,
I have not tried it because I only have

51
00:02:06,226 --> 00:02:09,229
a work computer
and I can't install new software.

52
00:02:09,362 --> 00:02:12,132
And I probably definitely cannot install

53
00:02:12,132 --> 00:02:15,101
new software that then makes changes
to existing software.

54
00:02:15,502 --> 00:02:17,537
I don't think Bloomberg would like that.

55
00:02:17,537 --> 00:02:19,372
But I have seen the hype.

56
00:02:19,372 --> 00:02:21,474
Lots of people talking about it.

57
00:02:21,474 --> 00:02:24,611
Have you seen, Claude Co-work?

58
00:02:24,944 --> 00:02:26,446
Have you heard of. Oh, yeah. Yeah,
yeah, yeah.

59
00:02:26,446 --> 00:02:30,750
So one of the criticisms of Claude Code
was that, you know, like, okay, you code,

60
00:02:30,750 --> 00:02:33,753
but you still need some background
knowledge and coding because,

61
00:02:33,753 --> 00:02:36,756
like, you know,
the interface is kind of like.

62
00:02:36,756 --> 00:02:42,529
Is. And, and all of that or 1990s, co-work
apparently, like, goes

63
00:02:42,529 --> 00:02:48,001
a step further for, for normal people,
including it makes it super, super easy.

64
00:02:48,001 --> 00:02:53,306
And the funniest thing is that apparently
Claude code actually coded.

65
00:02:53,373 --> 00:02:54,374
Yeah.

66
00:02:54,374 --> 00:02:58,044
So the so this is like really relates
to my experience last year

67
00:02:58,044 --> 00:02:59,145
and then this year,

68
00:02:59,145 --> 00:03:03,149
which is that even last year,
like trying to use the AI coding tools,

69
00:03:03,783 --> 00:03:07,353
it was an annoying process
because there were various things

70
00:03:07,353 --> 00:03:10,356
that you had to do in the actual command
line of the computer

71
00:03:10,657 --> 00:03:13,726
that were like, I didn't,
I don't know, command line vernacular.

72
00:03:13,726 --> 00:03:15,728
And you have to like
install these libraries and stuff.

73
00:03:15,728 --> 00:03:15,962
Yeah.

74
00:03:15,962 --> 00:03:20,700
So there was this sort of like barrier
that existed and

75
00:03:21,501 --> 00:03:24,571
but what's the
what's really changed in the last year

76
00:03:24,771 --> 00:03:27,607
or with the, with Claude code,
which has actually been around for a while

77
00:03:27,607 --> 00:03:28,741
and I should have like played with it

78
00:03:28,741 --> 00:03:32,512
before is the like
because it sits on your computer.

79
00:03:32,812 --> 00:03:36,216
It's sort of takes away in deeper access
and so when you talk about.

80
00:03:36,216 --> 00:03:37,884
It, it actually does the stuff.

81
00:03:37,884 --> 00:03:38,251
It does.

82
00:03:38,251 --> 00:03:39,152
Is it just like,

83
00:03:39,152 --> 00:03:40,053
oh, it's like, oh, we're

84
00:03:40,053 --> 00:03:43,756
going to need to install this open source
natural language processing library.

85
00:03:43,890 --> 00:03:45,091
It just does it automatically.

86
00:03:45,091 --> 00:03:46,426
Instead of me trying to like figure out

87
00:03:46,426 --> 00:03:48,628
like what are the right keystrokes
to pull that in or

88
00:03:48,628 --> 00:03:52,198
why is this not going into the right file
folder or whatever.

89
00:03:52,398 --> 00:03:56,035
And so like, like Co-work,
it's like all, like all of these sort

90
00:03:56,035 --> 00:03:59,205
of like little friction,
like these technical things like command

91
00:03:59,205 --> 00:04:02,742
line use are very rapidly
are like dissipating.

92
00:04:02,742 --> 00:04:03,109
Yeah.

93
00:04:03,109 --> 00:04:05,211
And so that like then
you have something like Co-work

94
00:04:05,211 --> 00:04:07,480
where it's just like they know
they're taking care of that.

95
00:04:07,480 --> 00:04:10,483
And so you get this like user interface
that's just like

96
00:04:10,650 --> 00:04:12,352
it's just getting easier and friendlier.

97
00:04:12,352 --> 00:04:15,555
There's almost no technical frictions
at all anymore.

98
00:04:15,588 --> 00:04:19,092
Also, it feels very iterative,
like the code is improving upon itself.

99
00:04:19,125 --> 00:04:19,425
Yeah.

100
00:04:19,425 --> 00:04:22,128
At this point I think that was
one of Claude's main selling points.

101
00:04:22,128 --> 00:04:26,766
Well, this is like you've seen like people
talk about like, oh, is AGI here?

102
00:04:27,033 --> 00:04:31,371
And this is like part of the debate
because one of the ideas, I guess, behind

103
00:04:31,371 --> 00:04:32,305
AGI is like, well,

104
00:04:32,305 --> 00:04:35,775
what happens when you have software
that can train itself and so forth?

105
00:04:35,908 --> 00:04:39,712
And I don't really know if I buy that,
but you do just see, like how fast

106
00:04:39,712 --> 00:04:41,214
the iteration cycles are.

107
00:04:41,214 --> 00:04:44,217
And I think
we want to get into this in part,

108
00:04:44,317 --> 00:04:46,853
they're fast because a bunch of people
are suddenly getting excited,

109
00:04:46,853 --> 00:04:49,322
and then the human provides
this sort of like

110
00:04:49,322 --> 00:04:52,725
we're sowing the seeds of our own demise
because we're so enthusiastically

111
00:04:52,725 --> 00:04:54,794
participating in the evolution.

112
00:04:54,794 --> 00:04:58,731
But I just like it's suddenly clear, like,
oh, this is going to change.

113
00:04:58,731 --> 00:05:00,366
I think computing.

114
00:05:00,366 --> 00:05:04,203
And the other thing is the code works
like it creates code that like

115
00:05:04,470 --> 00:05:06,739
this is like
there's no bugs. You know, it works.

116
00:05:07,840 --> 00:05:10,109
Did you
see speaking of automating yourself?

117
00:05:10,109 --> 00:05:10,376
Yeah.

118
00:05:10,376 --> 00:05:13,646
See there was a post on Reddit
from a lawyer who said he's basically used

119
00:05:13,646 --> 00:05:17,283
cloud code to automate, like,
his entire job, and he hasn't told anyone.

120
00:05:17,717 --> 00:05:21,421
I'm not exactly surprised, because
the other thing that I experimented with

121
00:05:22,121 --> 00:05:25,825
is, and I haven't 100% verified this,
but on jobs day last week,

122
00:05:26,392 --> 00:05:30,163
I downloaded the full PDF
and I just typed into the cloud code

123
00:05:30,163 --> 00:05:34,200
like find the most interesting details
and make some charts based on.

124
00:05:34,200 --> 00:05:36,903
And it did it in like a couple of minutes.
I have no like, ability.

125
00:05:36,903 --> 00:05:41,040
Like I've never like built charts myself
and or whatever, or like designer

126
00:05:41,074 --> 00:05:41,908
or whatever.

127
00:05:41,908 --> 00:05:44,677
And I didn't totally confirm yet
that the data was all correct,

128
00:05:44,677 --> 00:05:47,447
but I'm pretty sure it was
because everything I spot, so I didn't.

129
00:05:47,447 --> 00:05:49,482
Just that crucial. Detail,
I know I didn't.

130
00:05:49,482 --> 00:05:52,285
That's why I didn't want to like,
oh, like, here's what, here's the here's

131
00:05:52,285 --> 00:05:53,453
jobs report and charts.

132
00:05:53,453 --> 00:05:54,554
But it might.

133
00:05:54,554 --> 00:05:57,657
But what application did
it actually build it in the charts?

134
00:05:57,857 --> 00:05:58,358
I don't know.

135
00:05:58,358 --> 00:05:59,859
I just had a like that's the thing.

136
00:05:59,859 --> 00:06:02,762
I had a file on my computer at that
point. What kind of file?

137
00:06:03,863 --> 00:06:04,831
Like a PNG file.

138
00:06:04,831 --> 00:06:05,598
Like an image file?

139
00:06:05,598 --> 00:06:08,101
Yeah, that's the crazy thing,
I don't know.

140
00:06:08,101 --> 00:06:10,770
And so there was just this image
that had a bunch of charts, and my spark

141
00:06:10,770 --> 00:06:13,773
chunks did suggest, like,
I didn't see anything off.

142
00:06:13,773 --> 00:06:17,210
And people get paid money
to, like, build that kind of stuff

143
00:06:17,210 --> 00:06:19,645
for, like,
analysts and stuff like that. Right.

144
00:06:19,645 --> 00:06:21,414
So this is the other big question.

145
00:06:21,414 --> 00:06:25,551
If everyone can build their own software,
what actually happens to software?

146
00:06:25,551 --> 00:06:26,919
And I was reading something.

147
00:06:26,919 --> 00:06:30,423
I forget who it was by,
but someone used cloud code to create.

148
00:06:30,623 --> 00:06:34,160
They wanted a website that would basically
make them money for doing nothing.

149
00:06:34,160 --> 00:06:37,130
And that was the prompt.
And did they do? Yeah.

150
00:06:37,130 --> 00:06:40,733
So the idea that,
the model came up with was

151
00:06:41,000 --> 00:06:43,803
you can sell
prompts, packages of good prompts

152
00:06:43,803 --> 00:06:46,973
and sell them for like 40 bucks
and you'll make tons of money.

153
00:06:47,473 --> 00:06:51,110
And I was thinking about that, like, okay,
it's possible to make money that way.

154
00:06:51,110 --> 00:06:54,881
But also,
why wouldn't I just use cloud code. To.

155
00:06:54,881 --> 00:06:56,783
Do the same thing?

156
00:06:56,783 --> 00:06:59,152
There are many big questions
that we as an economy

157
00:06:59,152 --> 00:07:00,153
are going to have to think about.

158
00:07:00,153 --> 00:07:02,388
And I think my main takeaway
is we're going to have to

159
00:07:02,388 --> 00:07:03,956
think about this sooner rather than later.

160
00:07:03,956 --> 00:07:06,592
But what is cloud code?
Why is everyone so hyped about it?

161
00:07:06,592 --> 00:07:09,996
And what is it about this
particular piece of software that versus

162
00:07:09,996 --> 00:07:13,032
what exists from OpenAI and Gemini
and all this stuff?

163
00:07:13,032 --> 00:07:15,468
Like, why is this captured
everyone's imagination?

164
00:07:15,468 --> 00:07:18,538
We really do have the perfect guys
because it's someone who, unlike me,

165
00:07:19,472 --> 00:07:21,641
has been getting their hands dirty
and this stuff for longer.

166
00:07:21,641 --> 00:07:26,946
One of the few people that I know
who is into LMS before ChatGPT existed

167
00:07:27,079 --> 00:07:31,050
and was actually using them via
the API, and was actually talking about

168
00:07:31,150 --> 00:07:36,556
their technical capacity to do things
like coding even before November of 2022.

169
00:07:36,756 --> 00:07:39,192
So truly the perfect guys we're going
to be speaking with Noah Brier.

170
00:07:39,192 --> 00:07:43,029
He's the co-founder of L'Ã©chec,
a consultancy that helps big companies

171
00:07:43,196 --> 00:07:44,297
deal with AI stuff.

172
00:07:44,297 --> 00:07:47,133
So, Noah, thank you so much for coming
on, and let's thank.

173
00:07:47,133 --> 00:07:48,401
You for having. Me. What's the deal?

174
00:07:48,401 --> 00:07:51,804
How are you like using lemons
before chat, GPT existed?

175
00:07:51,804 --> 00:07:54,740
I don't know, I know
very few people who were doing that.

176
00:07:54,740 --> 00:07:58,578
I had the good fortune
of shutting down a startup in 2022,

177
00:07:58,578 --> 00:08:00,279
and so I had a lot of free time
on my hands.

178
00:08:00,279 --> 00:08:01,614
And then how are you using it, though?

179
00:08:01,614 --> 00:08:04,250
Like how do you look at your like,
how did you aware

180
00:08:04,250 --> 00:08:07,153
that there was this thing
that could be of potential use to.

181
00:08:07,153 --> 00:08:10,356
So my very first thing I was doing
was using GitHub copilot,

182
00:08:10,356 --> 00:08:15,061
which at the time was built into VS code
and it was autocomplete inside VS code.

183
00:08:15,061 --> 00:08:18,498
So it was a nice and pretty immediately
realized that there were certain

184
00:08:18,498 --> 00:08:21,968
coding tasks
that it could just handle completely.

185
00:08:22,835 --> 00:08:24,604
Anything that was very pattern based.

186
00:08:24,604 --> 00:08:27,306
So if you write code,
you write a lot of tests.

187
00:08:27,306 --> 00:08:30,176
If you write tests, every test
kind of follows the same pattern

188
00:08:30,176 --> 00:08:32,011
and you want it to follow
the same pattern, you're

189
00:08:32,011 --> 00:08:34,413
looking for that structure
in and over time,

190
00:08:34,413 --> 00:08:37,416
because it was looking at your code base,
it was able to basically autocomplete it.

191
00:08:37,850 --> 00:08:41,721
I also started playing with the GPT
three API,

192
00:08:41,954 --> 00:08:44,957
which had come out,
I think that came out in November of 2021,

193
00:08:45,324 --> 00:08:48,361
and that was the first time
it was publicly available to everybody.

194
00:08:48,361 --> 00:08:52,899
And they had a large language model
as we know it today, available to them.

195
00:08:52,899 --> 00:08:57,370
So I was just testing and building things,
and I pretty immediately

196
00:08:57,904 --> 00:08:59,572
realized the very first thing I did

197
00:08:59,572 --> 00:09:02,642
where it just blew my mind,
was I built a web scraper.

198
00:09:02,642 --> 00:09:05,645
So I was I was just trying
to pull pricing data from a website.

199
00:09:05,978 --> 00:09:08,147
And I've done a lot of this in my career.

200
00:09:08,147 --> 00:09:11,284
It's maybe the most annoying task
you have to do in all of coding,

201
00:09:11,284 --> 00:09:14,287
because HTML is the most miserable
language to have to parse.

202
00:09:14,587 --> 00:09:17,890
And I just had this thing
where I took the page, I took the content,

203
00:09:17,890 --> 00:09:21,060
I took the text, and I gave it to the AI,
and I asked it to give me back

204
00:09:21,060 --> 00:09:23,663
the pricing table, and it gave me back
the pricing table.

205
00:09:23,663 --> 00:09:26,732
And I just thought,
I'll never do it the other way again.

206
00:09:26,732 --> 00:09:29,268
That's is that HTML mentioned?

207
00:09:29,268 --> 00:09:33,873
Just brought up like memories of me
in like the mid-nineties on HTML.

208
00:09:33,873 --> 00:09:35,608
Good. Easy to remember that site.

209
00:09:35,608 --> 00:09:36,275
Yeah.

210
00:09:36,275 --> 00:09:38,411
I wonder if it's still is it still up?

211
00:09:38,411 --> 00:09:39,245
That would be wild.

212
00:09:40,846 --> 00:09:42,114
Does clawed code?

213
00:09:42,114 --> 00:09:43,783
Does that count as AGI?

214
00:09:43,783 --> 00:09:46,552
This seems to be the debate right?
Is it AGI?

215
00:09:46,552 --> 00:09:49,322
I try not to wade into what's AGI
and what's not.

216
00:09:49,322 --> 00:09:52,291
I think my guess on on AGI,
for what it's worth, is that

217
00:09:52,992 --> 00:09:55,461
it's probably going to be a conversation
like the Turing test,

218
00:09:55,461 --> 00:09:57,496
where everybody thought it was really,
really important.

219
00:09:57,496 --> 00:09:59,298
For a really long time,
we thought the Turing test

220
00:09:59,298 --> 00:10:02,301
was the biggest thing for 70 years
or whatever.

221
00:10:02,301 --> 00:10:04,837
And then.

222
00:10:04,837 --> 00:10:06,906
ChatGPT
very clearly passed the Turing test,

223
00:10:06,906 --> 00:10:10,076
and now everybody pretends like it's
just that they forgot.

224
00:10:10,109 --> 00:10:11,711
They pretend that it never mattered.

225
00:10:11,711 --> 00:10:16,148
Oh, and so I am kind of
guessing that that's going to be

226
00:10:16,148 --> 00:10:17,149
what the conversation is like.

227
00:10:17,149 --> 00:10:19,952
It's just going to be a sort of forever
moving goalpost.

228
00:10:19,952 --> 00:10:22,321
Because it turns out that the idea we had
for what

229
00:10:22,321 --> 00:10:25,791
general intelligence looks like
is not quite that.

230
00:10:26,225 --> 00:10:30,463
But I also think, you know, the computer
scientists and the sort of serious

231
00:10:30,463 --> 00:10:34,333
AI researchers would say that
much of what's going on inside cloud

232
00:10:34,333 --> 00:10:38,070
code is not the model itself,
it's the model paired with a human.

233
00:10:38,504 --> 00:10:41,240
And I think that is
a pretty important distinction.

234
00:10:41,240 --> 00:10:42,842
But I don't know about AGI.

235
00:10:42,842 --> 00:10:49,148
Well, okay, so you were using, GPT to code
prior to the release of ChatGPT.

236
00:10:49,315 --> 00:10:53,019
So therefore coding models
have been around a long time.

237
00:10:53,352 --> 00:10:56,656
So what is for those who haven't played
or played around with it.

238
00:10:56,722 --> 00:10:58,157
What is Claude code?

239
00:10:58,157 --> 00:11:01,160
Because again, coding models
have been around for a long time.

240
00:11:01,227 --> 00:11:04,330
If people maybe have heard of cursor
Copilot

241
00:11:04,330 --> 00:11:07,600
or some of these other harnesses, etc.,
what is cloud code?

242
00:11:07,733 --> 00:11:11,837
So if we back up first
and we go to copilot because so copilot

243
00:11:11,837 --> 00:11:15,541
was the first sort of commercial
application of a large language model.

244
00:11:16,742 --> 00:11:17,843
By most accounts.

245
00:11:17,843 --> 00:11:21,447
And what copilot did in its initial
instantiation was just.

246
00:11:21,447 --> 00:11:23,516
Auto some Microsoft. Product.
It's a Microsoft product.

247
00:11:23,516 --> 00:11:26,519
So Microsoft owns GitHub, GitHub
developer Copilot.

248
00:11:27,319 --> 00:11:30,289
It was Microsoft
had the partnership with OpenAI.

249
00:11:30,289 --> 00:11:33,559
And so they built it in and what it was
doing was doing autocomplete.

250
00:11:33,559 --> 00:11:35,127
So if you're writing code,

251
00:11:35,127 --> 00:11:39,265
a lot of writing code is boilerplate or
trying to remember the name of a function.

252
00:11:39,498 --> 00:11:42,068
And, you know, the reason
StackOverflow existed

253
00:11:42,068 --> 00:11:45,071
was because you can never remember
the exact name of that function or,

254
00:11:45,104 --> 00:11:50,042
or the exact regex that you need to use
in order to find and replace something.

255
00:11:50,309 --> 00:11:52,445
And so you would go search for it.

256
00:11:52,445 --> 00:11:55,548
And they realized that you could just
build that into the IDE,

257
00:11:56,449 --> 00:11:59,251
your code editor and,
and have it autocomplete for you.

258
00:11:59,251 --> 00:12:01,454
And it was pretty amazing. Yeah.

259
00:12:02,455 --> 00:12:04,123
Then,

260
00:12:04,123 --> 00:12:07,960
ChatGPT came out, and even before that,
I had built a simple chat bot for myself

261
00:12:07,960 --> 00:12:09,128
because I realized that, hey,

262
00:12:09,128 --> 00:12:12,131
I could just ask this and instead of going
and searching StackOverflow,

263
00:12:12,298 --> 00:12:15,601
it was totally capable
of answering code questions,

264
00:12:15,601 --> 00:12:17,970
and it was capable of writing regex
or doing these things.

265
00:12:17,970 --> 00:12:19,338
And did it make mistakes? Yes.

266
00:12:19,338 --> 00:12:23,142
But like there's famous mistakes
on StackOverflow of incorrect regex

267
00:12:23,142 --> 00:12:26,145
that now exists
in every codebase in the world.

268
00:12:26,712 --> 00:12:28,581
And so, you know, there were a lot of us

269
00:12:28,581 --> 00:12:32,218
just kind of playing with these things
and realizing they were a huge boon.

270
00:12:32,585 --> 00:12:35,888
And so I think really
the next step is Curser comes out.

271
00:12:35,888 --> 00:12:39,625
And the thing is to realize that copilot
didn't was that it wasn't good enough

272
00:12:39,658 --> 00:12:40,392
to have autocomplete.

273
00:12:40,392 --> 00:12:41,794
You also needed the Q&A

274
00:12:41,794 --> 00:12:44,663
because you have these things
that you can't just autocomplete.

275
00:12:44,663 --> 00:12:46,265
You want to be able to ask the question
and answer it.

276
00:12:46,265 --> 00:12:49,335
And then ChatGPT came out
and everybody was switching between idea.

277
00:12:50,269 --> 00:12:54,540
And then I think really the next big piece
is that cloud code came out,

278
00:12:54,540 --> 00:12:56,909
and what Cloud Code did
that was so remarkable

279
00:12:56,909 --> 00:12:59,912
was they took
the same set of models, really.

280
00:13:00,513 --> 00:13:03,582
And they took them out of the chat bot
and they really just gave it

281
00:13:03,582 --> 00:13:08,854
some very basic functionality
to operate within your machine.

282
00:13:08,854 --> 00:13:09,155
Right.

283
00:13:09,155 --> 00:13:12,158
And so, you know, if you really look
at kind of what exists within cloud code,

284
00:13:12,424 --> 00:13:15,427
you're calling out to a model
and they gave it capability around

285
00:13:15,427 --> 00:13:16,562
sort of two big things.

286
00:13:16,562 --> 00:13:19,532
One is you can read
and write files on your computer.

287
00:13:19,899 --> 00:13:23,035
And then two is that you can operate Unix.

288
00:13:23,035 --> 00:13:27,540
The, the base commands, the bash commands
that exist in your environment.

289
00:13:28,541 --> 00:13:32,077
And again, because
these models were trained on the internet

290
00:13:32,077 --> 00:13:34,046
and there's no greater
source of information

291
00:13:34,046 --> 00:13:36,048
on the internet
than how to make the internet,

292
00:13:36,048 --> 00:13:39,752
they know how to use Unix commands
incredibly well.

293
00:13:39,752 --> 00:13:42,688
Right? Because Unix has existed
for whatever it is 60 years.

294
00:13:42,688 --> 00:13:45,724
And the way these commands were designed,
they're all designed to be very,

295
00:13:45,724 --> 00:13:46,392
very simple.

296
00:13:46,392 --> 00:13:47,726
There's a find command

297
00:13:47,726 --> 00:13:50,830
and, you know, there's a thing called grep
and it can search to a code base.

298
00:13:50,830 --> 00:13:55,267
And Unix has this sort of beautiful way
of tying one command to another

299
00:13:55,267 --> 00:13:58,270
so you can take the output of one command
and send it to another.

300
00:13:58,437 --> 00:14:02,842
And they kind of just gave the model
access to these 2 or 3 very simple things.

301
00:14:03,375 --> 00:14:06,979
And it kind of turned out that it unlocked
a whole bunch of functionality

302
00:14:06,979 --> 00:14:10,449
that I don't think even the people
who built it fully realized.

303
00:14:10,449 --> 00:14:14,787
Like one example that I think about a lot
is just the challenge

304
00:14:14,787 --> 00:14:18,924
you have with all of these
AI models is that they're stateless.

305
00:14:19,091 --> 00:14:24,463
So every time you talk to ChatGPT, it's
sending your entire conversation history

306
00:14:24,463 --> 00:14:28,901
back to ChatGPT because it has no saved
history of that chat.

307
00:14:28,901 --> 00:14:31,370
Right?
And that's fine. It's the way it works.

308
00:14:31,370 --> 00:14:34,540
It just fact, but it means that,
you know, it forgets things.

309
00:14:34,540 --> 00:14:38,077
It doesn't know conversation,
a conversation and one

310
00:14:38,077 --> 00:14:41,513
very easy way to save
your state is just write it to a file.

311
00:14:42,781 --> 00:14:43,382
And so

312
00:14:43,382 --> 00:14:46,518
you give it right access
and it can create files.

313
00:14:46,518 --> 00:14:50,222
And now all of a sudden
you've overcome this like probably

314
00:14:50,222 --> 00:14:53,592
the single biggest challenge
that exists inside these large

315
00:14:53,592 --> 00:14:56,595
language models, which is that
they're fundamentally stateless.

316
00:14:56,896 --> 00:15:00,266
So Claude writes itself
little like memory notes, right,

317
00:15:00,266 --> 00:15:03,302
to to remember
the entire context of the conversation.

318
00:15:03,702 --> 00:15:05,271
And that's how it solved that problem.

319
00:15:05,271 --> 00:15:09,275
No. So there's sort of two things
going on in cloud code beneath the hood.

320
00:15:09,541 --> 00:15:12,811
There's one thing that works exactly
like ChatGPT or any of these other ones,

321
00:15:12,878 --> 00:15:15,214
which is it's maintaining
a conversation history.

322
00:15:15,214 --> 00:15:18,284
So every message you send it and every,

323
00:15:19,752 --> 00:15:22,321
action, it takes, it's recording to a log.

324
00:15:22,321 --> 00:15:22,922
Right.

325
00:15:22,922 --> 00:15:27,359
Which is just one big file that's really
no different than what ChatGPT can do.

326
00:15:27,526 --> 00:15:29,094
Where it gets really interesting,

327
00:15:29,094 --> 00:15:32,665
though, is it can also write files
that it can then read.

328
00:15:33,132 --> 00:15:37,002
So whereas that conversation
history is all saved off

329
00:15:37,002 --> 00:15:38,904
and eventually
that conversation gets too long

330
00:15:38,904 --> 00:15:40,839
and it needs to do a thing
called compaction.

331
00:15:40,839 --> 00:15:44,810
And when it compacts it,
it tries to sort of just remember the bits

332
00:15:45,010 --> 00:15:47,947
because there the total window is, is, is

333
00:15:49,248 --> 00:15:49,748
large.

334
00:15:49,748 --> 00:15:52,151
But I mean, it's like 100,000 tokens.

335
00:15:52,151 --> 00:15:54,053
So that's what I mean by memory
notes. Right?

336
00:15:54,053 --> 00:15:57,256
It compacts the information
into the important stuff.

337
00:15:57,423 --> 00:15:59,725
So it doesn't retrieve. It does that.

338
00:15:59,725 --> 00:16:01,160
It only does that at the end.

339
00:16:01,160 --> 00:16:03,128
Like once it runs out of space, okay.

340
00:16:03,128 --> 00:16:04,830
Once it runs out of context window.

341
00:16:04,830 --> 00:16:08,267
So it has 200,000 tokens,
I think, and 200,000 tokens in rough

342
00:16:08,267 --> 00:16:11,270
terms is probably 150,000 words.

343
00:16:11,403 --> 00:16:15,207
It says, okay, it's
time for me to compact all of this stuff.

344
00:16:15,374 --> 00:16:18,610
And so it still saves your whole history
on your computer.

345
00:16:18,610 --> 00:16:20,212
You still have the entire message.

346
00:16:20,212 --> 00:16:24,083
But for that session, it just compacts it
down to this, you know,

347
00:16:24,683 --> 00:16:29,321
maybe 25,000 token memory. 25.

348
00:16:29,321 --> 00:16:31,357
What it was. Yeah.

349
00:16:31,357 --> 00:16:33,792
And is this,
like something that was not obvious

350
00:16:33,792 --> 00:16:37,162
before as a solution like this compaction.

351
00:16:37,162 --> 00:16:40,666
How important is it for this being like,

352
00:16:41,033 --> 00:16:44,636
okay, as a human, I can work on this
on a project for a long time.

353
00:16:44,636 --> 00:16:47,139
Like how much of an unlock was there?

354
00:16:47,139 --> 00:16:49,341
I'm not sure compaction was the okay.

355
00:16:49,341 --> 00:16:52,511
I think the compaction
functionality is helpful.

356
00:16:52,511 --> 00:16:53,078
Okay.

357
00:16:53,078 --> 00:16:55,014
The way ChatGPT does it for
what it's worth is

358
00:16:55,014 --> 00:16:58,117
they don't do compaction,
they just forget your messages eventually.

359
00:16:58,117 --> 00:17:02,021
So if you're in one chat,
eventually your oldest message is going

360
00:17:02,021 --> 00:17:03,088
to fall off the back.

361
00:17:04,123 --> 00:17:05,124
For coding,

362
00:17:05,124 --> 00:17:08,627
that's probably less helpful,
but there are trade offs.

363
00:17:08,627 --> 00:17:10,262
I have both techniques work.

364
00:17:10,262 --> 00:17:11,730
I think fundamentally

365
00:17:11,730 --> 00:17:14,833
the thing that is special about cloud
code is not the compaction,

366
00:17:15,134 --> 00:17:19,271
it's the it's the ability
to write and read files on your computer.

367
00:17:19,304 --> 00:17:21,840
Yeah. Which means
you can always write off memories.

368
00:17:21,840 --> 00:17:23,609
And then what does that mean?
Right off memory.

369
00:17:23,609 --> 00:17:25,177
So you could say, hey,

370
00:17:25,177 --> 00:17:28,080
I it's really important that
I remember this thing for future sessions.

371
00:17:28,080 --> 00:17:29,448
I want to always work this way.

372
00:17:29,448 --> 00:17:32,451
So in a code base of mine,

373
00:17:32,584 --> 00:17:35,254
I have a set of documentation

374
00:17:35,254 --> 00:17:39,191
that explains how I like to do things,
and cloud code makes a mistake.

375
00:17:39,191 --> 00:17:39,958
And so the next time

376
00:17:39,958 --> 00:17:44,263
I can write a memory, essentially
it's written as a thing they call a skill.

377
00:17:44,963 --> 00:17:48,033
And you can write it off and you say, hey,
whenever you run into this,

378
00:17:48,033 --> 00:17:50,102
I want you to operate in this kind of way.

379
00:17:50,102 --> 00:17:53,372
And that existing across every session

380
00:17:53,705 --> 00:17:57,576
is really a thing you can only do
when you can store it as a file.

381
00:17:57,609 --> 00:18:00,746
Yeah, it's a thing you can't do in
quite the same way when you're

382
00:18:00,746 --> 00:18:03,816
operating in this environment where it's
just going back and forth to the API.

383
00:18:03,816 --> 00:18:07,352
So this access to the file system
is one really big piece.

384
00:18:07,352 --> 00:18:10,355
And then the second is,
is just the Unix commands, I mean

385
00:18:10,622 --> 00:18:13,192
computers, every computer program

386
00:18:13,192 --> 00:18:17,196
lives
on top of the sort of baseline functions.

387
00:18:17,463 --> 00:18:20,432
And the way that the designers of Unix

388
00:18:20,432 --> 00:18:24,269
built them is really elegant
and they're very small.

389
00:18:24,269 --> 00:18:27,506
They all do one thing
and they're all composable.

390
00:18:27,506 --> 00:18:27,840
And in

391
00:18:28,841 --> 00:18:31,877
coding terms, composable means they can be
they can be chained together.

392
00:18:31,877 --> 00:18:32,111
Right.

393
00:18:32,111 --> 00:18:37,049
And so you can say, hey,
look for files that mention this word

394
00:18:37,049 --> 00:18:40,552
and then from those files,
I want you to take this second action.

395
00:18:40,552 --> 00:18:43,422
And then from the output of that action,
I want you to take a third action.

396
00:18:43,422 --> 00:18:45,124
And that's just built into Unix.

397
00:18:45,124 --> 00:18:45,591
You literally

398
00:18:45,591 --> 00:18:49,428
just put a little pipe in between
and you just pipe them from one to another

399
00:18:49,428 --> 00:18:50,395
and, and that's it.

400
00:18:50,395 --> 00:18:51,296
And so

401
00:18:51,296 --> 00:18:52,264
you give it access

402
00:18:52,264 --> 00:18:53,699
to write these commands,
and all of a sudden

403
00:18:53,699 --> 00:18:56,101
it gets these sort of second and third
order effects

404
00:18:56,101 --> 00:18:59,872
that are just incredibly powerful
and built over a really long time.

405
00:18:59,872 --> 00:19:03,809
So how much of Claude code,
the way it's different to other models,

406
00:19:03,809 --> 00:19:07,112
how much of that was overcoming
technological challenges versus

407
00:19:07,112 --> 00:19:11,116
like just having a good idea
because hearing you describe it,

408
00:19:11,350 --> 00:19:15,654
I mean, giving access to a computer
seems like kind of obvious.

409
00:19:15,654 --> 00:19:17,556
Like, let's, let's just do that.

410
00:19:19,224 --> 00:19:20,559
I don't have a good answer to that.

411
00:19:20,559 --> 00:19:23,295
I think that it was kind of
just a good idea.

412
00:19:23,295 --> 00:19:25,797
Yeah. I think they did some patterns
really well.

413
00:19:25,797 --> 00:19:28,200
They're clearly incredibly talented,

414
00:19:28,200 --> 00:19:32,571
not just engineers, but kind of thinkers
about how to structure it.

415
00:19:32,571 --> 00:19:36,175
Like, the, the primitives inside
called code are just smart.

416
00:19:36,341 --> 00:19:40,646
And then the thing that they've done
and Boris Cherny, who's the,

417
00:19:41,547 --> 00:19:46,185
lead developer on cloud coded anthropic,
he talks about, latent demand a lot.

418
00:19:46,251 --> 00:19:46,485
Right.

419
00:19:46,485 --> 00:19:49,555
And latent demand is basically just,
hey, look at the ways people are using

420
00:19:49,555 --> 00:19:53,192
these systems and then figure out ways
to make that a part of the product itself.

421
00:19:53,492 --> 00:19:57,062
I think what they've done brilliantly,
and this is kind of easy when you have

422
00:19:57,062 --> 00:20:00,065
a community of developers who are nerds,
who want to go talk about all the ways

423
00:20:00,065 --> 00:20:02,668
that they're using these things,
is they have.

424
00:20:02,668 --> 00:20:06,271
I am amazed at the speed in which,
you know, I have a small community

425
00:20:06,271 --> 00:20:09,675
of 15 CTOs
who all use this stuff religiously.

426
00:20:09,675 --> 00:20:12,244
And, you know,
when we first started that community,

427
00:20:12,244 --> 00:20:15,013
it took them a month to
I would see it in the chat,

428
00:20:15,013 --> 00:20:17,549
and then a month later,
it would get built into cloud code.

429
00:20:17,549 --> 00:20:19,651
And then increasingly like
it's like a day later,

430
00:20:19,651 --> 00:20:21,520
it feels like they're just
they're just listening to it.

431
00:20:21,520 --> 00:20:25,357
But I think they're just not only tapped
in, but they're really fundamentally,

432
00:20:25,824 --> 00:20:27,359
you know, they're they're dog fooding.

433
00:20:27,359 --> 00:20:30,429
They use their own products
when you, you know,

434
00:20:30,429 --> 00:20:33,765
they talk about the productivity
engineering, productivity at anthropic.

435
00:20:34,399 --> 00:20:38,270
You know, despite growing at a crazy clip,
it continues to go up.

436
00:20:38,337 --> 00:20:42,841
And, you know, anybody who's built
had to manage large scale

437
00:20:43,675 --> 00:20:47,846
pieces of software, large scale
codebases knows that's not the norm.

438
00:20:48,313 --> 00:20:52,651
So vs code and cursor, these are ideas.

439
00:20:53,685 --> 00:20:56,722
Cloud code is not an ID, it's a CLI.

440
00:20:56,888 --> 00:20:58,557
A clear command line interface.

441
00:20:58,557 --> 00:20:58,924
Got it.

442
00:20:58,924 --> 00:21:02,027
And the other labs
now they also have close.

443
00:21:02,160 --> 00:21:06,265
So why are we all talk about cloud code
and AI charging.

444
00:21:06,265 --> 00:21:07,833
Because users are called Codex.

445
00:21:07,833 --> 00:21:10,402
I don't know what Gemini's is called.
I think it's just called the gem.

446
00:21:10,402 --> 00:21:10,936
Okay, so.

447
00:21:10,936 --> 00:21:15,307
Why are we all talk about cloud code
rather than the other classes

448
00:21:15,307 --> 00:21:18,243
that kind of have the same thing?
Like what is the difference?

449
00:21:18,243 --> 00:21:19,945
I think first and foremost
they were first.

450
00:21:19,945 --> 00:21:22,681
Okay. So and I think they've
they've had a lot more.

451
00:21:22,681 --> 00:21:26,585
And you know, from
my very personal opinion, I think they've

452
00:21:26,918 --> 00:21:31,256
done some things smarter and better
as far as the Permissioning models.

453
00:21:31,256 --> 00:21:32,724
So, you know, one of the really dangerous

454
00:21:32,724 --> 00:21:34,459
things is you've got this thing
running on your computer.

455
00:21:34,459 --> 00:21:36,161
You don't want it to go
and delete everything.

456
00:21:36,161 --> 00:21:36,495
Right?

457
00:21:36,495 --> 00:21:40,399
And, they have a very fine grained
permissioning model

458
00:21:40,399 --> 00:21:42,801
where you can say, hey,
I want to allow this just this one time.

459
00:21:42,801 --> 00:21:44,002
I want to always allow it.

460
00:21:44,002 --> 00:21:46,738
You know. I always click, always allow.
I living on the edge.

461
00:21:46,738 --> 00:21:49,241
You can, you can, next time you run it,

462
00:21:49,241 --> 00:21:52,411
you can just do a flag
that says dangerously skip permissions.

463
00:21:53,178 --> 00:21:55,580
And and it'll
just, they call it yolo mode.

464
00:21:56,948 --> 00:21:57,849
I think

465
00:21:57,849 --> 00:22:02,821
I think more fundamentally, though,
if I look at at Codex versus Cloud Code,

466
00:22:02,821 --> 00:22:06,992
I think it's, a difference
in philosophy around what you want.

467
00:22:06,992 --> 00:22:08,527
AI to do.

468
00:22:08,527 --> 00:22:14,032
To me, Codex,
which is excellent, is very focused on

469
00:22:14,232 --> 00:22:18,236
building an agent that you can just
give something to and it'll just go do it.

470
00:22:18,503 --> 00:22:19,971
So I want to give it that task.

471
00:22:19,971 --> 00:22:21,273
I don't want to intercede.

472
00:22:21,273 --> 00:22:23,275
I don't want to give it any more feedback.

473
00:22:23,275 --> 00:22:25,877
And cloud code

474
00:22:25,877 --> 00:22:30,082
is much more designed
to be, kind of a pair programmer.

475
00:22:30,215 --> 00:22:33,418
And so, you know, in engineering,
pair programing has existed for a while.

476
00:22:33,585 --> 00:22:36,188
It's a really weird
sort of productivity thing

477
00:22:36,188 --> 00:22:39,191
where you put two engineers
on the same problem and it turns out

478
00:22:39,324 --> 00:22:42,160
that you can get better code and worse,
multiply.

479
00:22:42,160 --> 00:22:42,427
Yeah.

480
00:22:42,427 --> 00:22:45,430
And it sort of makes up for the fact
that obviously, you know, you're

481
00:22:45,430 --> 00:22:48,433
doubling the staff on it,
but because of how many fewer bugs

482
00:22:48,433 --> 00:22:51,737
because you have both sets of eyes, it
it has seemed to work out for many folks.

483
00:22:52,270 --> 00:22:53,872
Most companies don't practice it.

484
00:22:53,872 --> 00:22:58,610
But I think cloud code fundamentally
is much more designed in that way.

485
00:22:58,610 --> 00:22:59,478
It's a pair programmer.

486
00:22:59,478 --> 00:23:03,882
It's, they, you know, whenever
I start a project, I start in plan mode.

487
00:23:03,882 --> 00:23:05,784
So you start in plan mode,
you put together a plan.

488
00:23:05,784 --> 00:23:07,753
I really I mean,
I spend a lot of time in plan mode.

489
00:23:07,753 --> 00:23:10,122
You go through you,
it gives you a plan back.

490
00:23:10,122 --> 00:23:11,223
It asks you how you feel.

491
00:23:11,223 --> 00:23:13,358
You can give it
a whole bunch of direction,

492
00:23:13,358 --> 00:23:16,661
and then it's only then that it goes off
and it goes into it.

493
00:23:16,695 --> 00:23:19,831
So, you know, we're working together
and I actually have a whole system now

494
00:23:19,831 --> 00:23:20,832
that I've designed where,

495
00:23:22,000 --> 00:23:24,436
I use
a task management system called linear.

496
00:23:24,436 --> 00:23:27,205
So I have quad code
write tasks off to linear.

497
00:23:27,205 --> 00:23:32,177
And then I've worked, with cloud code
to write a document that helps

498
00:23:32,177 --> 00:23:34,246
sort of decide
a set of heuristics to decide

499
00:23:34,246 --> 00:23:37,716
when you should assign it to Codex versus
when you should give it to cloud code.

500
00:23:37,916 --> 00:23:39,384
And so if it's tightly defined enough

501
00:23:39,384 --> 00:23:41,219
and simple enough,
I just send it off to Codex.

502
00:23:41,219 --> 00:23:43,288
And it does it totally independently.

503
00:23:43,288 --> 00:23:46,591
And then if it's complicated enough
that I think it requires

504
00:23:46,591 --> 00:23:52,597
my time and attention, then it
it saves it for me, us to do together.

505
00:23:53,331 --> 00:23:55,200
And we'll work on it together.

506
00:23:55,200 --> 00:23:57,602
And so if it's, it's sort of touching,

507
00:23:57,602 --> 00:24:00,939
kind of important enough if it's changing
some part of the data model,

508
00:24:01,173 --> 00:24:02,407
there's these other kind of,

509
00:24:02,407 --> 00:24:05,043
you know, fairly
basic set of criteria that I use. And,

510
00:24:06,278 --> 00:24:08,580
but that
to me is the fundamental distinction.

511
00:24:08,580 --> 00:24:14,419
And, you know, I find cloud code
in that way to be just in it

512
00:24:14,453 --> 00:24:18,123
sort of fits what I want to do
and how I want to work.

513
00:24:18,824 --> 00:24:19,858
Much better.

514
00:24:19,858 --> 00:24:24,496
Talk a little bit more
about how it actually impacts the workflow

515
00:24:24,496 --> 00:24:30,168
of an engineer, because, you know,
my impression was people can code, right?

516
00:24:30,168 --> 00:24:33,572
Like the coding problem
is kind of solved at this point.

517
00:24:33,572 --> 00:24:36,741
And even if you can't code, even
if you're not a professional engineer,

518
00:24:36,975 --> 00:24:40,712
you can hire someone from like India
or Indonesia

519
00:24:40,712 --> 00:24:42,414
or wherever to just write you a code.

520
00:24:42,414 --> 00:24:46,318
Maybe it'll take them a week
instead of like two days with cloud code.

521
00:24:46,518 --> 00:24:49,788
But how much does this actually change

522
00:24:50,555 --> 00:24:53,091
the workflow for an engineer?

523
00:24:53,091 --> 00:24:55,293
As completely as it could be changed.

524
00:24:55,293 --> 00:24:58,296
I mean, I would say that over
the last three months

525
00:24:59,097 --> 00:25:02,033
I've written personally,

526
00:25:02,033 --> 00:25:05,937
I don't know, a few hundred lines of code,
like, I, I am mostly

527
00:25:05,937 --> 00:25:10,575
a manager of a set of agents
who are writing code on my behalf.

528
00:25:10,575 --> 00:25:13,211
And, you know, increasingly,
what I think is interesting,

529
00:25:13,211 --> 00:25:15,947
I've been thinking about
this bunch lately is like,

530
00:25:15,947 --> 00:25:18,550
in some ways, it's just bringing me back
to the core challenge

531
00:25:18,550 --> 00:25:22,754
that has always existed in software
development, which is how do you manage,

532
00:25:23,488 --> 00:25:26,124
large scale software development projects?

533
00:25:26,124 --> 00:25:27,459
Coordination. Right.

534
00:25:27,459 --> 00:25:29,160
It has become a coordination problem.

535
00:25:29,160 --> 00:25:33,532
And, and I spent a lot of time sort of now
designing

536
00:25:34,399 --> 00:25:37,669
my cloud code system
to ensure that code goes through

537
00:25:37,669 --> 00:25:41,373
all the proper checks
and that it it has all these things.

538
00:25:41,506 --> 00:25:45,944
The other thing that, you know, makes code
a particularly good place to do this

539
00:25:45,977 --> 00:25:50,448
is that code is verifiable in a way
that, you know, most other work is not.

540
00:25:50,615 --> 00:25:55,186
So, you know, with code, you can verify
that the build works, right?

541
00:25:55,186 --> 00:25:58,323
So you can say, hey, I want to build this,
I want to build this package.

542
00:25:58,323 --> 00:25:59,858
I want to make sure
that it's actually going to build

543
00:25:59,858 --> 00:26:01,293
and that there's not going to be
no failures.

544
00:26:01,293 --> 00:26:04,229
That's a very easy check. It's
either true or it's not true.

545
00:26:04,229 --> 00:26:07,933
There's also coders use linting.

546
00:26:07,933 --> 00:26:12,537
And so linting is a way to kind of
look it's static code analysis.

547
00:26:12,537 --> 00:26:14,873
So it basically tries to sort of find,

548
00:26:17,442 --> 00:26:20,478
things in your code base
that are not going to work ahead of time,

549
00:26:20,645 --> 00:26:25,250
where you can predict that obviously,
you can't predict, Alan Turing, proved

550
00:26:25,250 --> 00:26:28,253
that you can't predict, with certainty
whether code is going to run.

551
00:26:28,253 --> 00:26:30,455
But there are certain patterns
and things that it can find.

552
00:26:30,455 --> 00:26:32,891
It's essentially does static pattern
analysis.

553
00:26:32,891 --> 00:26:35,894
And, so, you know,
you haven't run all these things, but,

554
00:26:36,428 --> 00:26:39,664
the more kind of opinionated
you can be about that

555
00:26:39,664 --> 00:26:41,099
and the more steps
you can have a go through.

556
00:26:41,099 --> 00:26:42,133
So I find, you know,

557
00:26:42,133 --> 00:26:45,170
now I'm kind of the designer,
which honestly, as an entrepreneur

558
00:26:45,170 --> 00:26:48,840
and as a CEO of companies
like that's kind of always been my job.

559
00:26:48,840 --> 00:26:52,677
Like I've been up not I have less and less
been a person who writes code.

560
00:26:52,677 --> 00:26:54,980
And more and more
I've been a person who designs

561
00:26:54,980 --> 00:26:58,416
a system, in that case, a company
with a bunch of people who write code.

562
00:26:59,684 --> 00:27:01,219
One of the funny things it

563
00:27:01,219 --> 00:27:04,856
seems to me
is that setting aside clawed code

564
00:27:05,023 --> 00:27:08,360
code itself has a reputation for.

565
00:27:08,727 --> 00:27:11,763
It's a nicer chat bot to talk to people,
find it,

566
00:27:12,998 --> 00:27:16,534
you know, ChatGPT
seems to really be sycophantic.

567
00:27:16,534 --> 00:27:17,535
I still think it's.

568
00:27:17,535 --> 00:27:19,838
I know it's improved, but I actually don't
think it's improved enough.

569
00:27:19,838 --> 00:27:20,505
It's still.

570
00:27:20,505 --> 00:27:24,643
People like the prose style of,
claw clawed.

571
00:27:24,843 --> 00:27:28,546
And I'm curious
that in the pair trading, pair trading,

572
00:27:28,546 --> 00:27:31,549
I'm thinking about finance, the peer
engineering model,

573
00:27:31,683 --> 00:27:36,321
whether there is also an edge there,
which is like here is a chat bot

574
00:27:36,421 --> 00:27:39,391
that is not annoying to talk
to while you're iterating,

575
00:27:39,391 --> 00:27:42,761
and whether that is like a meaningful
distinction between,

576
00:27:43,395 --> 00:27:46,097
you know, coding with Codex or whatever.

577
00:27:46,097 --> 00:27:50,969
Yeah, I, I don't know, I it still can be
very annoying, I can tell you.

578
00:27:50,969 --> 00:27:55,106
And it'll still sometimes, be overly,

579
00:27:56,708 --> 00:27:59,310
overly
effusive with me about a design choice

580
00:27:59,310 --> 00:28:02,947
I made or sort of noticed something,
which I could live without.

581
00:28:02,981 --> 00:28:06,751
I so I'm working on this project
that's, doing this linguistic things,

582
00:28:06,951 --> 00:28:09,954
and I eventually had to say, like,
give it to me straight.

583
00:28:09,954 --> 00:28:11,056
How bad is this?

584
00:28:11,056 --> 00:28:14,359
And then so I said, I said, actually,
what I said was and assume

585
00:28:14,359 --> 00:28:17,362
for a moment that you are
a quantitative linguistics for the PhD.

586
00:28:17,762 --> 00:28:20,732
Give me your honest assessment
of where we are with this.

587
00:28:21,066 --> 00:28:23,702
And it said, like you've developed

588
00:28:23,702 --> 00:28:27,105
a nice toy and there's no evidence
that it actually does.

589
00:28:27,105 --> 00:28:28,873
And I was like, okay, that's nice to hear.

590
00:28:28,873 --> 00:28:30,875
I actually like I,
you know, I appreciate that.

591
00:28:30,875 --> 00:28:34,612
And it was like a very blunt,
no, you know, it's still like polite,

592
00:28:34,713 --> 00:28:37,682
but it was like, this does it
you do have a really showing anything

593
00:28:37,682 --> 00:28:40,652
you haven't really established at all
that your software does what it claims to.

594
00:28:40,752 --> 00:28:42,487
Yeah, I think so.

595
00:28:42,487 --> 00:28:45,790
I think stylistically
I kind of personally agree.

596
00:28:45,790 --> 00:28:49,160
I my theory,
by the way on on Claude versus

597
00:28:50,228 --> 00:28:52,230
OpenAI ChatGPT models is

598
00:28:52,230 --> 00:28:56,334
I think Claude is actually better
at sort of reflecting what you give it.

599
00:28:56,935 --> 00:28:58,403
And so I think part of why we think

600
00:28:58,403 --> 00:29:01,506
it's better is it
it's better at pretending it's us.

601
00:29:01,506 --> 00:29:01,840
Yeah.

602
00:29:01,840 --> 00:29:05,510
And so we tend to like that is
this is purely, speculation.

603
00:29:05,510 --> 00:29:07,045
But that's always been my theory on.

604
00:29:07,045 --> 00:29:09,013
On to flatters you in a different. Way.

605
00:29:09,013 --> 00:29:10,982
I think it's flattering you in a much.

606
00:29:10,982 --> 00:29:13,284
More subtle way. Yeah. Interesting.

607
00:29:13,284 --> 00:29:16,287
But, for a long time, just,

608
00:29:16,821 --> 00:29:19,691
anthropic has been producing
the best coding models, you know?

609
00:29:19,691 --> 00:29:22,694
I mean, there's
there can be some debate there now, but,

610
00:29:23,294 --> 00:29:24,496
you know, there's a great story

611
00:29:24,496 --> 00:29:28,566
from cursor, actually,
where cursor basically wasn't that good.

612
00:29:28,566 --> 00:29:31,569
And then sonnet 3.5 came out
and all of a sudden

613
00:29:31,669 --> 00:29:35,940
cursor was amazing and cursor became
a tool that everybody started using.

614
00:29:35,940 --> 00:29:36,508
But it wasn't

615
00:29:36,508 --> 00:29:39,410
until this other model came out
and they made that the default model.

616
00:29:39,410 --> 00:29:41,646
And, you know, I for what it's worth,

617
00:29:41,646 --> 00:29:44,649
I think the other takeaway from that,
which is a kind of big theme

618
00:29:45,283 --> 00:29:49,154
we see in the market, is the thing that,
the Cloud Code team has talked about is,

619
00:29:49,721 --> 00:29:52,991
you just constantly
have to be building ahead with AI in a way

620
00:29:52,991 --> 00:29:56,394
that is very unique
in the world of software,

621
00:29:56,394 --> 00:30:01,266
where you kind of always want to build
things that are working at like 70 or 80%,

622
00:30:01,266 --> 00:30:04,636
because if you really spend the time
to get it up to 90 or 100,

623
00:30:04,836 --> 00:30:07,839
you're going to lose all the gains you get
when the next model comes out.

624
00:30:07,972 --> 00:30:11,276
And the, you know, with the amount
of CapEx being spent at these models,

625
00:30:11,276 --> 00:30:13,545
like there's a next model
that's going to come out,

626
00:30:13,545 --> 00:30:15,246
that's going to be awesome,
and you just kind of

627
00:30:15,246 --> 00:30:18,416
want to be downstream from that,
and you don't want to waste six months

628
00:30:18,416 --> 00:30:22,287
getting an extra 3% when that new model
is going to give you an extra seven.

629
00:30:23,154 --> 00:30:23,388
Yeah.

630
00:30:23,388 --> 00:30:26,457
This is the only certainty with
AI is like, there's always going to be

631
00:30:26,457 --> 00:30:27,091
a new model.

632
00:30:27,091 --> 00:30:30,195
It's the worst model ever used
is the one that we're using.

633
00:30:30,428 --> 00:30:32,130
That's right, that's right.

634
00:30:32,130 --> 00:30:35,133
Are we all going
to become coding illiterate?

635
00:30:35,166 --> 00:30:38,503
Are we just going to forget how to code
if everyone's using, you know,

636
00:30:38,703 --> 00:30:41,206
general language. To forget
I never learned.

637
00:30:41,206 --> 00:30:43,708
Yeah, okay. You know what
I've been thinking about? You know that,

638
00:30:45,276 --> 00:30:47,478
Scott Karp, the, CEO of Palantir.

639
00:30:47,478 --> 00:30:49,714
He has that line. He's like,
when I was young,

640
00:30:49,714 --> 00:30:52,150
I was too poor to have a car or so
I didn't get a.

641
00:30:52,150 --> 00:30:53,418
So I never learned to drive.

642
00:30:53,418 --> 00:30:55,820
And now I'm too rich.
So I never learned to drive.

643
00:30:55,820 --> 00:30:58,890
I feel like when I was young,
I was too dumb to learn to code.

644
00:30:58,890 --> 00:31:00,992
And now. You leaped. Ahead.

645
00:31:00,992 --> 00:31:01,226
Yeah.

646
00:31:01,226 --> 00:31:04,229
No, I'm too smart to learn Python
or HTML or whatever.

647
00:31:04,963 --> 00:31:07,465
I have a couple of takes on this one
personally.

648
00:31:07,465 --> 00:31:10,468
So, the first one is I just think like

649
00:31:10,935 --> 00:31:13,137
this is the worry of all technology ever.

650
00:31:13,137 --> 00:31:17,041
There was a paper that came out
that showed that people were,

651
00:31:18,610 --> 00:31:20,345
you know, they were forgetting
more things or something

652
00:31:20,345 --> 00:31:22,247
because they were
using ChatGPT. But, you know,

653
00:31:23,248 --> 00:31:25,383
in Phaedrus, Plato was worried

654
00:31:25,383 --> 00:31:29,020
that people were going to forget things
because they started writing things down.

655
00:31:29,487 --> 00:31:31,689
And, you know, I think the trade off
there was pretty good.

656
00:31:31,689 --> 00:31:34,692
We got this scientific revolution,
a couple other things. So,

657
00:31:35,927 --> 00:31:38,930
you know, I think that's
the sort of natural kneejerk.

658
00:31:40,198 --> 00:31:42,433
With that said, it is

659
00:31:42,433 --> 00:31:45,970
I it's very strange when you have people,

660
00:31:46,471 --> 00:31:49,474
you know, the Cloud code team is talking
about how little code they write.

661
00:31:50,041 --> 00:31:54,078
Now, I draw a distinction
in between the sort of vibe coding

662
00:31:54,078 --> 00:31:57,916
and the kind of amateur people
who have never written code.

663
00:31:57,916 --> 00:32:00,151
And I think that is amazing, by the way.

664
00:32:00,151 --> 00:32:03,988
And I think, there's a lot of software
developers who are really mad about that,

665
00:32:04,355 --> 00:32:07,959
because they're, they, they claim
it's for safety reasons or whatever.

666
00:32:07,959 --> 00:32:10,261
But I think fundamentally it's just
they've got people on their turf.

667
00:32:11,562 --> 00:32:12,997
But I think that's incredible.

668
00:32:12,997 --> 00:32:17,735
I mean, my, I, my, my nine year
old, vibe coded a website.

669
00:32:18,303 --> 00:32:20,838
Oh, wow. And, for secrets. Santa.

670
00:32:20,838 --> 00:32:21,773
She's now ten.

671
00:32:21,773 --> 00:32:23,041
She would get mad at me
if I called her nine,

672
00:32:23,041 --> 00:32:26,010
but I think she got it when she was nine.

673
00:32:26,010 --> 00:32:29,080
But, that that's awesome, right?

674
00:32:29,080 --> 00:32:31,282
I don't know, that's amazing.
That's a way for people

675
00:32:31,282 --> 00:32:34,018
to express themselves
in a way that they couldn't before.

676
00:32:34,018 --> 00:32:35,954
You did your your linguistics project.

677
00:32:35,954 --> 00:32:38,957
That's that's fun and interesting.

678
00:32:39,357 --> 00:32:43,361
But yeah, I, I also think the other the,
the thing that's happening

679
00:32:43,361 --> 00:32:45,730
with professional software developers,
when you hear from anthropic

680
00:32:45,730 --> 00:32:48,766
or you know what I'm talking about, it's,
you know,

681
00:32:48,766 --> 00:32:51,769
the code is going through this process
and, you know,

682
00:32:52,603 --> 00:32:54,605
all the code
still gets reviewed by people.

683
00:32:54,605 --> 00:32:57,976
We're not letting it get out the door
if it's not at the same level as human.

684
00:32:58,009 --> 00:32:58,743
And it's just

685
00:32:58,743 --> 00:33:02,580
but what's amazing is I'm, I'm running
five of these sessions at a time.

686
00:33:02,580 --> 00:33:02,780
Right.

687
00:33:02,780 --> 00:33:03,481
And so I've got like,

688
00:33:03,481 --> 00:33:07,051
software being developed in parallel
in a way that is unimaginable.

689
00:33:07,318 --> 00:33:09,120
And, you know, the other thing is just,

690
00:33:10,088 --> 00:33:12,890
now the best software engineers
wrote the least code.

691
00:33:12,890 --> 00:33:14,158
Anyway,

692
00:33:14,158 --> 00:33:16,561
you know, the sort of classic story of,
like,

693
00:33:16,561 --> 00:33:19,998
the difference between a junior developer
and or senior developer is that a junior

694
00:33:19,998 --> 00:33:22,500
developer gets a problem and they sit down

695
00:33:22,500 --> 00:33:25,136
and they put their fingers on the keyboard
and they start writing code.

696
00:33:25,136 --> 00:33:29,073
And, senior developer gets a problem
and sits there for three hours

697
00:33:29,073 --> 00:33:30,942
and tries to figure out
what the best way to solve it is,

698
00:33:30,942 --> 00:33:33,411
and then spends five minutes
writing code to get it done.

699
00:33:33,411 --> 00:33:35,246
True elegance is restraint.

700
00:33:35,246 --> 00:33:36,347
That's what I say.

701
00:33:36,347 --> 00:33:39,250
What are you seeing in the companies
you're working for?

702
00:33:39,250 --> 00:33:42,253
Like, I find it hard to believe,

703
00:33:42,253 --> 00:33:45,023
and I was maybe skeptical of this,
but it feels like right now

704
00:33:45,023 --> 00:33:46,190
we're here with technology.

705
00:33:46,190 --> 00:33:48,092
We're like,
if I were like, companies like,

706
00:33:48,092 --> 00:33:48,960
like I said,

707
00:33:48,960 --> 00:33:51,996
you can build a charts of data
in a way that used to be like

708
00:33:51,996 --> 00:33:54,332
someone would have had to get their hands
dirty or etc.

709
00:33:54,332 --> 00:33:58,102
in the companies that you talk to
is right now this having an effect

710
00:33:58,102 --> 00:34:00,371
on how they think about
what positions they're hiring for

711
00:34:00,371 --> 00:34:02,473
and the skills they're looking for
and so forth.

712
00:34:02,473 --> 00:34:04,075
I think that

713
00:34:05,410 --> 00:34:07,645
it's hard to answer right there.

714
00:34:07,645 --> 00:34:10,415
I think that certainly,

715
00:34:10,415 --> 00:34:14,052
I do think, I personally think
if I look at the sort of layoffs

716
00:34:14,052 --> 00:34:15,219
in the technology industry

717
00:34:15,219 --> 00:34:18,423
over the last couple of years,
I think some part of that is just looking

718
00:34:18,423 --> 00:34:21,392
at the output of these models
and saying, hey,

719
00:34:22,193 --> 00:34:25,196
these models are able to produce it,
you know, the median.

720
00:34:25,296 --> 00:34:26,697
And I have a whole bunch

721
00:34:26,697 --> 00:34:30,301
of sort of middle managers
who are producing at the 65th percentile.

722
00:34:30,301 --> 00:34:34,839
And it's like, I can produce median
for $1.50 per million tokens, or

723
00:34:34,839 --> 00:34:39,811
I can produce 65th percentile for however
many hundreds of thousand dollars a year.

724
00:34:39,811 --> 00:34:42,013
It's a sort of fairly simple trade off.

725
00:34:42,013 --> 00:34:42,647
I think.

726
00:34:42,647 --> 00:34:44,882
So I do think there's
a lot of downstream effects.

727
00:34:44,882 --> 00:34:47,385
I think the other thing that's happening
is, is kind of like middle

728
00:34:47,385 --> 00:34:50,421
management is under threat
because it's the realization that, hey,

729
00:34:50,421 --> 00:34:53,458
like part of what these models
are amazing at is, is,

730
00:34:53,758 --> 00:34:55,393
I think of them as like a fuzzy interface.

731
00:34:55,393 --> 00:34:58,362
They can sort of turn
any data into any other data, right?

732
00:34:58,362 --> 00:35:01,666
You can sort of transform data
from one format to another.

733
00:35:01,799 --> 00:35:04,268
You can take a PDF
and you can turn it into charts. Right.

734
00:35:04,268 --> 00:35:05,503
And there's whole people who exist.

735
00:35:05,503 --> 00:35:07,438
Or, you know,
if you think about what product managers

736
00:35:07,438 --> 00:35:09,607
do, a lot of what product managers do
is they take

737
00:35:09,607 --> 00:35:13,044
how people are using a product
and they try to transform it into a,

738
00:35:13,177 --> 00:35:16,981
format that engineers can
then use to figure out what to do.

739
00:35:16,981 --> 00:35:18,249
And I think a lot of those kind of,

740
00:35:20,251 --> 00:35:21,853
a lot of those pieces that

741
00:35:21,853 --> 00:35:25,556
used to just be kind
of transferring knowledge.

742
00:35:26,457 --> 00:35:28,826
I've always said, Tracy,

743
00:35:28,826 --> 00:35:31,762
I think one of the most important roles
in any organization

744
00:35:31,762 --> 00:35:33,264
is essentially translation work.

745
00:35:33,264 --> 00:35:37,001
And you see it in the newsroom
where it's like, here is a team

746
00:35:37,001 --> 00:35:41,906
specialized in emerging market currencies,
and then they have to like

747
00:35:42,340 --> 00:35:45,276
they have to then tell the senior editors
what they're working on.

748
00:35:45,276 --> 00:35:48,713
But the senior editors who are maybe
more generalist don't really know, like,

749
00:35:48,713 --> 00:35:51,716
why like some sort of like, you know, one.

750
00:35:51,782 --> 00:35:51,916
Yeah.

751
00:35:51,916 --> 00:35:53,451
And Carrie is important

752
00:35:53,451 --> 00:35:56,754
and that a really important role within
any organization is essentially the,

753
00:35:57,054 --> 00:36:00,024
the team that can translate between
the generalist team and the specialist.

754
00:36:00,024 --> 00:36:00,725
Absolutely.

755
00:36:00,725 --> 00:36:03,661
And so I that's an interesting observation
in the sort of engineering

756
00:36:03,661 --> 00:36:07,231
world is like, okay, these are tools
that are in some sense translation tool.

757
00:36:07,765 --> 00:36:08,766
So we talked to

758
00:36:08,766 --> 00:36:12,036
I agree completely by the way,
but we talked about vibe coding.

759
00:36:12,036 --> 00:36:16,641
And Joe has this application, that
I don't think you're looking to monetize.

760
00:36:16,707 --> 00:36:19,110
No, I'm just trying to make it
for the good of the world.

761
00:36:19,110 --> 00:36:21,112
Right. Okay.
When did that become a common,

762
00:36:22,647 --> 00:36:23,781
What did.

763
00:36:23,781 --> 00:36:28,052
But like this opens up massive questions
for software as a service, right.

764
00:36:28,052 --> 00:36:28,653
For SAS.

765
00:36:28,653 --> 00:36:31,956
Because if everyone
can write their own software,

766
00:36:32,790 --> 00:36:36,561
you can replicate anything that's out
there that is currently charging money.

767
00:36:36,561 --> 00:36:39,564
What's going to happen to software?

768
00:36:39,897 --> 00:36:42,033
I think software is pretty screwed.

769
00:36:42,033 --> 00:36:43,301
A lot of it at least.

770
00:36:43,301 --> 00:36:44,035
Not all of it.

771
00:36:44,035 --> 00:36:44,402
You know,

772
00:36:44,402 --> 00:36:47,939
you still, depends on whether you call
that cloud provider software or not.

773
00:36:48,306 --> 00:36:50,007
You know, you still need to run this stuff
somewhere.

774
00:36:50,007 --> 00:36:53,411
And I think there's, there's certain
kinds of software that,

775
00:36:53,411 --> 00:36:56,414
you know, you just don't really want to be
in the business of writing.

776
00:36:56,681 --> 00:37:00,017
You know, I, as someone who's tried
to build a project management

777
00:37:00,017 --> 00:37:01,285
system, I'd really rather.

778
00:37:01,285 --> 00:37:03,487
I don't think anybody
should be in that business.

779
00:37:05,056 --> 00:37:06,090
But I do think

780
00:37:06,090 --> 00:37:09,227
fundamentally, I mean, we see this
every day inside enterprises.

781
00:37:09,227 --> 00:37:14,298
The the sort of build versus buy
pendulum has just swung.

782
00:37:14,298 --> 00:37:18,669
And, you know, I mean, I used to run
a SAS company and we sold to enterprises

783
00:37:18,669 --> 00:37:23,241
and, you know, for a long time that, that
I think that made a lot of sense, right?

784
00:37:23,241 --> 00:37:24,542
Because like, hey,

785
00:37:24,542 --> 00:37:27,545
it just didn't make sense
to try to build this thing on your own.

786
00:37:27,678 --> 00:37:31,048
And so but the price of that was,
you know, won the price, right?

787
00:37:31,082 --> 00:37:33,217
Like,
and it got to be more and more expensive.

788
00:37:33,217 --> 00:37:36,053
The other price was that you were paying
for a lot of stuff you didn't need.

789
00:37:36,053 --> 00:37:36,187
Right?

790
00:37:36,187 --> 00:37:41,259
Because the whole job of building SAS is
you need to generalize problems

791
00:37:41,259 --> 00:37:44,462
and say you build things
that are going to work for everybody,

792
00:37:44,695 --> 00:37:47,431
and that means either
you have to sort of adapt

793
00:37:47,431 --> 00:37:50,468
or you have to build this sort
of very configurable, software.

794
00:37:51,569 --> 00:37:53,004
And I think and

795
00:37:53,004 --> 00:37:56,007
what I see just, you know,
firsthand is that,

796
00:37:56,707 --> 00:37:59,977
inside these organizations,
you can now solve

797
00:38:00,478 --> 00:38:03,848
very specific problems
that are highly valuable.

798
00:38:05,683 --> 00:38:09,954
And not only can you solve them
better than generic software,

799
00:38:09,954 --> 00:38:12,990
but you can actually, in a lot of ways,
do it for less money

800
00:38:12,990 --> 00:38:14,859
because you're trying to tackle
less stuff.

801
00:38:14,859 --> 00:38:16,627
You didn't need the 16

802
00:38:16,627 --> 00:38:19,630
other features you bought it for, the one
that you really, really cared about.

803
00:38:20,564 --> 00:38:24,302
And so, I think that part of it, you know,
I don't like there's,

804
00:38:24,368 --> 00:38:26,871
I definitely think there are pieces
of the software industry

805
00:38:26,871 --> 00:38:29,040
that are going to,
you know, come out the other side.

806
00:38:29,040 --> 00:38:31,375
You're going to
nobody wants to deal with payroll, right?

807
00:38:31,375 --> 00:38:32,777
Like, you know,
somebody, you're still going to buy

808
00:38:32,777 --> 00:38:35,446
some payroll software
and you're still going to have that.

809
00:38:35,446 --> 00:38:37,948
But, you know,
I do think there are a lot of pieces

810
00:38:37,948 --> 00:38:42,653
where the software existed essentially
as a kind of wrapper around a database.

811
00:38:42,820 --> 00:38:46,624
And now you're just going to, you know,
with just the database, you can do that.

812
00:38:46,791 --> 00:38:50,227
And then, you know, the other piece
I'd say here is it's this is not this is

813
00:38:50,227 --> 00:38:54,532
a kind of confluence of circumstances
where it's not just the coding, it's

814
00:38:54,532 --> 00:38:58,703
also the fact that you have AI
to do a whole bunch of work.

815
00:38:58,703 --> 00:39:02,340
So, you know, if we pick on CRM
for a second, right, like, you know.

816
00:39:02,340 --> 00:39:03,174
Salesforce.com.

817
00:39:03,174 --> 00:39:07,445
Salesforce.com, we can, you know,
you look at what the interface of that is.

818
00:39:07,445 --> 00:39:11,782
And essentially it has existed
to get salespeople to take unstructured

819
00:39:11,782 --> 00:39:14,852
data, which is sales meetings,
and turn it into structured data that so

820
00:39:14,852 --> 00:39:18,589
it can be stored in a database
and now you have AI.

821
00:39:18,589 --> 00:39:22,593
And AI is very capable
of taking unstructured data

822
00:39:22,993 --> 00:39:24,328
directly from the source.

823
00:39:24,328 --> 00:39:26,163
So you have people recording meetings

824
00:39:26,163 --> 00:39:29,400
and then it can structured
into any data that you want.

825
00:39:29,433 --> 00:39:33,304
This is one of the very first sort of mind
blowing moments I had was

826
00:39:33,304 --> 00:39:34,405
that I could give it,

827
00:39:35,873 --> 00:39:37,074
Json interface.

828
00:39:37,074 --> 00:39:40,711
I could describe exactly what I wanted
the data structure to be,

829
00:39:40,878 --> 00:39:44,181
and it would give me back that information
in that data structure.

830
00:39:44,348 --> 00:39:46,450
And we've just basically been having
a bunch of humans

831
00:39:46,450 --> 00:39:48,753
do that work for a very long time,
whether it's in CRM

832
00:39:48,753 --> 00:39:50,521
or project management
or any of these other places,

833
00:39:50,521 --> 00:39:52,857
and the ability to just kind of
get rid of that whole thing.

834
00:39:52,857 --> 00:39:55,493
I think it really does bring into question

835
00:39:55,493 --> 00:39:57,395
the value of a lot of these software
companies.

836
00:39:57,395 --> 00:39:57,561
Well,

837
00:39:57,561 --> 00:40:01,298
so we have seen like a lot of software
stocks, they look like melting ice cubes

838
00:40:01,599 --> 00:40:02,400
right now.

839
00:40:02,400 --> 00:40:06,303
Maybe the so what I want to talk
I mean this is like

840
00:40:06,337 --> 00:40:08,072
you know, our listeners who are investors,

841
00:40:08,072 --> 00:40:11,742
there's a pretty high stakes question
of like what residual value there is.

842
00:40:11,742 --> 00:40:13,978
But talk a little bit
more about Salesforce.

843
00:40:13,978 --> 00:40:14,779
Maybe this should be a time

844
00:40:14,779 --> 00:40:18,783
to learn about what it actually does
as it's massively being disrupted.

845
00:40:18,783 --> 00:40:21,185
Now we get around to learning
what Salesforce is.

846
00:40:21,185 --> 00:40:23,187
But I know it's like many things,
there are apps

847
00:40:23,187 --> 00:40:26,490
that people built on to Salesforce,
but this sounds like we're hitting on one.

848
00:40:26,490 --> 00:40:27,992
I think
probably one of the crucial questions

849
00:40:27,992 --> 00:40:29,994
for like the future
of the software industry.

850
00:40:29,994 --> 00:40:30,928
So talk a little bit

851
00:40:30,928 --> 00:40:33,964
more about like the current approach
and what people are buying

852
00:40:33,964 --> 00:40:38,302
when they buy a package or subscribe
to a service from Salesforce.

853
00:40:38,436 --> 00:40:42,139
And then what
the unlock opportunity is from having,

854
00:40:42,473 --> 00:40:45,476
I like, live in the same world
as all your files.

855
00:40:45,876 --> 00:40:46,210
Yeah.

856
00:40:46,210 --> 00:40:49,213
So I think if you if we take CRM

857
00:40:49,513 --> 00:40:52,583
as a general category, say,
you know, the biggest players there are.

858
00:40:52,616 --> 00:40:53,684
That's customer relationship.

859
00:40:53,684 --> 00:40:55,653
Customer relationship management,
that's like where

860
00:40:55,653 --> 00:40:59,457
you know Salesforce does it, SAP does
it, HubSpot does it for the mid-market.

861
00:41:01,025 --> 00:41:04,094
You know, when I think about that product
and I think about the way we've used it

862
00:41:04,094 --> 00:41:04,829
inside enterprise

863
00:41:04,829 --> 00:41:08,599
sales organizations, essentially,
you know, it's a database of companies.

864
00:41:08,599 --> 00:41:09,800
It's a database of contacts.

865
00:41:09,800 --> 00:41:12,069
It's a database of deals
you have in the pipeline,

866
00:41:12,069 --> 00:41:15,806
and it's a way to track all those deals
you guys hit on something before

867
00:41:15,806 --> 00:41:20,377
that I think is is really it,
which is like inside companies.

868
00:41:21,278 --> 00:41:24,415
There is a huge group of people
and who exists to answer

869
00:41:24,415 --> 00:41:27,418
the question from management
of what is the status of something.

870
00:41:27,751 --> 00:41:28,085
Right.

871
00:41:28,085 --> 00:41:30,588
And you know, that can be sales
management, it can be product management.

872
00:41:30,588 --> 00:41:32,823
It doesn't matter. Right?
It could be within a newsroom.

873
00:41:32,823 --> 00:41:36,293
Somebody wants to know what the status is
and somebody else exists

874
00:41:36,293 --> 00:41:38,729
to go figure out what the answer
to that question is.

875
00:41:38,729 --> 00:41:42,099
And so fundamentally,
I think those CRM tools

876
00:41:42,099 --> 00:41:45,936
are bought first and foremost to answer
what is the status, right?

877
00:41:45,936 --> 00:41:47,671
What's my pipeline look like?

878
00:41:47,671 --> 00:41:49,006
And to answer
what your pipeline looks like,

879
00:41:49,006 --> 00:41:52,009
you need a bunch of salespeople
putting deals in.

880
00:41:52,276 --> 00:41:54,245
And those deals are associated
with contacts and companies,

881
00:41:54,245 --> 00:41:55,946
and they say,
when is that deal going to close?

882
00:41:55,946 --> 00:41:58,949
And and essentially you were asking

883
00:41:58,949 --> 00:42:02,753
the salespeople to make the updates
in the system to do that. And

884
00:42:03,854 --> 00:42:06,457
just very tactically, I mean, you know,

885
00:42:06,457 --> 00:42:10,427
I run a company now, we talk to a lot of
we have a lot of sales calls.

886
00:42:10,427 --> 00:42:14,398
We record those calls
and they get transcribed.

887
00:42:14,398 --> 00:42:17,401
And the AI then looks through them
and makes decisions

888
00:42:17,401 --> 00:42:20,804
about where
this deal should be in the process.

889
00:42:21,171 --> 00:42:25,075
And it's much better than having somebody
try to go update it,

890
00:42:25,075 --> 00:42:26,410
because those people never updated.

891
00:42:26,410 --> 00:42:29,146
Anyway, the secret of all of this
enterprise software

892
00:42:29,146 --> 00:42:32,149
is that nobody was using it
the way that anybody wanted to anyway.

893
00:42:32,583 --> 00:42:33,884
And so, you know,

894
00:42:33,884 --> 00:42:38,522
I think that that is sort of,
you know, a lot of what's happening there.

895
00:42:38,522 --> 00:42:39,990
Again, it's sort of
some of it's the coding,

896
00:42:39,990 --> 00:42:41,559
some of it's just the core capabilities.

897
00:42:41,559 --> 00:42:43,627
And then, you know,
you still need databases, right?

898
00:42:43,627 --> 00:42:45,863
So it's like, you know,
you look at what Databricks and Snowflake

899
00:42:45,863 --> 00:42:48,866
and, you know, I think those folks
are still sort of genuinely sitting

900
00:42:48,866 --> 00:42:52,937
in a pretty good place where, you know,
all software has to sit on, sort of

901
00:42:53,203 --> 00:42:57,141
on top of some database
that you can sort of read and write to.

902
00:42:58,042 --> 00:43:01,045
But, you know,
I think some of those categories that were

903
00:43:01,512 --> 00:43:05,549
specifically focused
on kind of like human input.

904
00:43:06,283 --> 00:43:08,552
Now, of course,
you know, Salesforce has a whole AI thing

905
00:43:08,552 --> 00:43:10,254
and they're saying, hey,
you shouldn't have humans

906
00:43:10,254 --> 00:43:14,191
inputting in Salesforce, you know, to at
sales is just one small piece.

907
00:43:14,191 --> 00:43:17,795
I have a whole customer support thing,
which obviously also has

908
00:43:17,795 --> 00:43:21,365
an interesting implication where you know,
you're doing support with AI agents.

909
00:43:21,365 --> 00:43:23,100
And so some of it comes back to seeds.

910
00:43:23,100 --> 00:43:26,637
I mean, you know, it gets to be fairly
complicated, but I do think

911
00:43:26,870 --> 00:43:31,408
I think the fundamental underlying thing
is anybody who buys software

912
00:43:31,909 --> 00:43:36,647
that is, you know, SAS,
you're always buying for a subset

913
00:43:36,647 --> 00:43:41,085
of the functionality that there's nobody
is using 100% of the functionality of SAS.

914
00:43:41,352 --> 00:43:43,954
And so there's always a trade off
that's happening there where, you know,

915
00:43:43,954 --> 00:43:45,956
you're spending more money
than you need to

916
00:43:45,956 --> 00:43:48,192
because
you're not using all of these pieces.

917
00:43:48,192 --> 00:43:50,961
And so, you know,
if you can more narrowly focus that,

918
00:43:50,961 --> 00:43:54,431
that is where you could say, hey, we could
solve this kind of more narrow problem.

919
00:43:54,431 --> 00:43:56,000
And not only can
we solve it more narrowly,

920
00:43:56,000 --> 00:43:57,901
we can solve it way more effectively.

921
00:43:57,901 --> 00:44:02,239
Because, you know, the trick with AI
is that the more specific

922
00:44:02,239 --> 00:44:04,508
you are with it, the better
the output is, right?

923
00:44:04,508 --> 00:44:05,476
So it's like if you know,

924
00:44:05,476 --> 00:44:08,979
if outside of coding,
if you just asked ChatGPT to write you

925
00:44:08,979 --> 00:44:12,383
a story, it's going to write you a very,
very median story.

926
00:44:12,383 --> 00:44:14,818
Right? Sort of exactly the median.

927
00:44:14,818 --> 00:44:19,356
But if you work with it and you, you know,
then you're going to get it.

928
00:44:19,423 --> 00:44:22,359
The more of your own expertise
you imbuing it,

929
00:44:22,359 --> 00:44:25,329
the further up above the median it's
going to be.

930
00:44:25,329 --> 00:44:28,332
And it's going to be, you know,
of course, that also means it's less

931
00:44:28,832 --> 00:44:31,135
where the line is between
what's AI and what's not.

932
00:44:31,135 --> 00:44:34,138
AI is going to continue to get blurrier.

933
00:44:34,138 --> 00:44:37,141
Joe, how much does cloud code
actually cost?

934
00:44:37,241 --> 00:44:38,108
Do you know?

935
00:44:38,108 --> 00:44:40,644
Well, I paid for the,

936
00:44:40,644 --> 00:44:44,848
200 or $200 a month version, but,
like high roller.

937
00:44:44,848 --> 00:44:47,651
Yeah. No, but, you know, I think it's.

938
00:44:47,651 --> 00:44:49,420
You could get it
with the pro version of like,

939
00:44:49,420 --> 00:44:51,655
or whatever
the, the version of that below $20.

940
00:44:51,655 --> 00:44:54,658
But I hit a limit fairly quickly and
I was like, I didn't have my website up.

941
00:44:54,658 --> 00:44:56,493
So like and then I bought the fact.

942
00:44:56,493 --> 00:45:01,198
Then I paid $5 for the extra compute
and I was like, this is dumb.

943
00:45:01,198 --> 00:45:02,433
I think I'll just.

944
00:45:02,433 --> 00:45:03,667
Yeah. Oh, okay.

945
00:45:03,667 --> 00:45:06,670
So we going out to two nice dinners,
right?

946
00:45:06,670 --> 00:45:08,238
That's not
you know, when I think about that way,

947
00:45:08,238 --> 00:45:10,607
it doesn't seem that big of a deal. It's
worth it to you. Yeah. Okay.

948
00:45:10,607 --> 00:45:12,076
So I think we can all agree

949
00:45:12,076 --> 00:45:16,013
this is like a valuable service
that cloud code is providing.

950
00:45:16,413 --> 00:45:18,849
But we touched on this in the intro.

951
00:45:18,849 --> 00:45:23,153
It seems like the models
just keep replicating themselves really,

952
00:45:23,153 --> 00:45:23,721
really quickly.

953
00:45:23,721 --> 00:45:27,491
So anything that cloud code can do,
I would expect another model

954
00:45:27,491 --> 00:45:31,328
will come in in like a month,
maybe less, and do the exact same thing.

955
00:45:31,829 --> 00:45:36,500
What does that mean for the actual
like valuations of these companies

956
00:45:36,500 --> 00:45:40,571
and the models like how are they going
to monetize it when it seems so difficult

957
00:45:40,938 --> 00:45:43,741
to actually differentiate yourself,
especially

958
00:45:43,741 --> 00:45:46,744
for like a substantial portion of time?

959
00:45:46,744 --> 00:45:47,244
Yeah.

960
00:45:47,244 --> 00:45:48,579
Well, so again here,

961
00:45:48,579 --> 00:45:53,083
I think we have to distinguish
between cloud code and the cloud model.

962
00:45:53,083 --> 00:45:56,754
So in Cloud Code's case,
if you're using, you know the latest

963
00:45:56,754 --> 00:45:59,790
version, you're using opus 4.5
which is the model.

964
00:45:59,790 --> 00:46:02,025
Opus 4.5 has a price of,

965
00:46:02,025 --> 00:46:05,996
you know, something in the dollar, 50
to $2 for a million input tokens

966
00:46:05,996 --> 00:46:07,498
and whatever it is on the output,

967
00:46:07,498 --> 00:46:10,167
which is like roughly
the going rate for cutting edge models.

968
00:46:10,167 --> 00:46:12,603
Gemini three Pro is the same price.

969
00:46:14,304 --> 00:46:17,174
OpenAI, ChatGPT 5.2 is there.

970
00:46:17,174 --> 00:46:18,108
They're all the same price.

971
00:46:18,108 --> 00:46:21,111
So the first thing is, is
you have to differentiate between those.

972
00:46:21,712 --> 00:46:24,782
And so I think a big part of
what anthropic is trying to do

973
00:46:24,782 --> 00:46:26,650
is they're trying to lock people
into cloud code.

974
00:46:26,650 --> 00:46:30,120
In fact,
there's just some, controversy amongst

975
00:46:30,320 --> 00:46:35,292
some nerds, where, open code,
which is a competitor to cloud Code,

976
00:46:36,260 --> 00:46:39,563
used to let you use your cloud Max $200.

977
00:46:39,563 --> 00:46:43,367
So the trick with the cloud
Max plan is if you're just buying those,

978
00:46:43,367 --> 00:46:46,970
that number of tokens, it would cost
you significantly more than $200.

979
00:46:46,970 --> 00:46:49,439
It is a super, super discounted plan.

980
00:46:49,439 --> 00:46:53,443
You are probably you have the access
I have the access to use,

981
00:46:53,877 --> 00:46:57,381
I would guess in the
thousand or $2,000 of tokens,

982
00:46:58,615 --> 00:47:00,017
for my $200 a month.

983
00:47:00,017 --> 00:47:03,520
So it's it's a very, very heavily
subsidized plan and open code,

984
00:47:03,520 --> 00:47:06,957
which is an open source version
of cloud code, a sort of competitor.

985
00:47:07,858 --> 00:47:11,361
They had found a way that they would let
you use your cloud

986
00:47:11,361 --> 00:47:15,232
Max plan
with open code and anthropic last week.

987
00:47:15,899 --> 00:47:17,434
Shut that down. Yeah.

988
00:47:17,434 --> 00:47:20,337
And some open code, people got very upset,
because they

989
00:47:20,337 --> 00:47:23,407
said, like, this is not
what you're supposed to do, or.

990
00:47:23,407 --> 00:47:25,475
I mean, I'm
not sure exactly what they said.

991
00:47:25,475 --> 00:47:28,478
I never felt like I got
a particularly good argument out of it.

992
00:47:29,213 --> 00:47:31,682
But, you know,
I do think part of what they're

993
00:47:31,682 --> 00:47:34,651
trying to get at, because is

994
00:47:34,818 --> 00:47:37,087
that, you know, at the very top models

995
00:47:37,087 --> 00:47:40,290
like these are
all amazing, like the Google,

996
00:47:41,258 --> 00:47:43,227
OpenAI and anthropic,

997
00:47:43,227 --> 00:47:46,463
their best models are all on par
with each other.

998
00:47:46,463 --> 00:47:48,866
I mean,
I would move them around a little bit.

999
00:47:48,866 --> 00:47:51,869
I still think opus
4.5 is the best model out there.

1000
00:47:51,869 --> 00:47:54,605
But you know,
I mean that might change tomorrow.

1001
00:47:54,605 --> 00:47:57,841
Like, and that's where something like
Cloud Code is really interesting

1002
00:47:57,841 --> 00:48:01,044
because it's a, a product
that is very it's just theirs.

1003
00:48:01,044 --> 00:48:02,279
It's not it's a piece of software.

1004
00:48:02,279 --> 00:48:04,381
It's not an AI model.

1005
00:48:04,381 --> 00:48:07,751
And so it's sort of it's
less able to be disrupted.

1006
00:48:07,784 --> 00:48:11,288
Now, again, I think
if somebody else wanted to copy that.

1007
00:48:11,288 --> 00:48:13,223
Exactly, they could.

1008
00:48:13,223 --> 00:48:15,826
Codex has one, Gemini has one.

1009
00:48:15,826 --> 00:48:19,029
I just think they take a very different
tact with it where it's much less.

1010
00:48:19,029 --> 00:48:19,630
And so,

1011
00:48:19,630 --> 00:48:20,731
you know,
I think what they're trying to do

1012
00:48:20,731 --> 00:48:21,798
is get developers like me

1013
00:48:21,798 --> 00:48:25,736
to feel very comfortable inside that,
so that when we go open, I still open

1014
00:48:25,736 --> 00:48:29,172
Codex or try Gemini or I was playing with
open Code the other day and,

1015
00:48:30,507 --> 00:48:32,976
it just doesn't feel familiar
in the same way that, you know, if you're

1016
00:48:32,976 --> 00:48:36,179
trying to move somebody from a PC
to a mac, it doesn't feel familiar, right?

1017
00:48:36,179 --> 00:48:37,948
They want to own like the ecosystem, the.

1018
00:48:37,948 --> 00:48:39,316
Environment. The environment.

1019
00:48:39,316 --> 00:48:41,251
Work on One world.

1020
00:48:41,251 --> 00:48:43,687
Noah,
thank you so much for coming on Atlas.

1021
00:48:43,687 --> 00:48:46,323
I was like dying to do an episode
about this topic.

1022
00:48:46,323 --> 00:48:49,760
By the way, I don't have I psychosis,
I have a cloud complex.

1023
00:48:50,093 --> 00:48:52,396
Why is everyone making that joke? Wait.

1024
00:48:52,396 --> 00:48:55,132
Which joke? The psychosis joke.

1025
00:48:55,132 --> 00:48:58,468
I thought you're going to be proud of me
for saying cloud complex. Oh.

1026
00:48:58,535 --> 00:48:59,636
Oh, that is very good.

1027
00:48:59,636 --> 00:49:02,239
I it's like I do one pun
finally for Tracy.

1028
00:49:02,239 --> 00:49:03,774
No, it's like,
well, I was over making that joke.

1029
00:49:03,774 --> 00:49:06,276
Well, I was thinking that was a joke.
I was handed a shirt.

1030
00:49:06,276 --> 00:49:08,512
I finally make a pun
and you just jump right over it.

1031
00:49:08,512 --> 00:49:09,446
Well, everyone keeps saying

1032
00:49:09,446 --> 00:49:13,016
that cloud code is AI psychosis
for smart people, right?

1033
00:49:13,016 --> 00:49:15,018
Like, how did that become a thing?

1034
00:49:15,018 --> 00:49:16,119
Yeah. All right.

1035
00:49:16,119 --> 00:49:18,922
But there's a good. Fun
also very bro coded I find.

1036
00:49:18,922 --> 00:49:21,658
You think so all of. AI is bro coded.

1037
00:49:21,658 --> 00:49:22,859
This is true.

1038
00:49:22,859 --> 00:49:23,860
We should talk more about this.

1039
00:49:23,860 --> 00:49:25,162
You know, we should have David Shaw on.

1040
00:49:25,162 --> 00:49:26,363
He's been doing a lot of polling

1041
00:49:26,363 --> 00:49:29,266
about various demographics
and how they feel about AI.

1042
00:49:29,266 --> 00:49:31,034
We should, And, yeah, some interesting I.

1043
00:49:31,034 --> 00:49:31,535
See into that.

1044
00:49:31,535 --> 00:49:32,803
Yeah, we should, do that.

1045
00:49:32,803 --> 00:49:35,038
Anyway, Noah,
thank you so much for coming on out, love.

1046
00:49:35,038 --> 00:49:35,973
Thanks for having me.

1047
00:49:35,973 --> 00:49:38,308
Well, that was fun. Tracy.
I really like I.

1048
00:49:38,308 --> 00:49:39,242
It's obvious

1049
00:49:39,242 --> 00:49:43,013
to anyone who's been within five minutes,
five feet of me for the last two weeks.

1050
00:49:43,013 --> 00:49:45,615
I'm like, totally addicted and gone down.

1051
00:49:45,615 --> 00:49:47,985
I never gone down the rabbit
hole and stuff.

1052
00:49:47,985 --> 00:49:52,322
But like, I for the first time
unironically, I'm like, okay,

1053
00:49:52,622 --> 00:49:56,126
this is transformative technology
beyond being very impressive.

1054
00:49:56,126 --> 00:49:57,060
Technology, right?

1055
00:49:57,060 --> 00:50:01,231
So I've been coming to a conclusion,
which is that, you know,

1056
00:50:01,832 --> 00:50:07,571
I can be both under hyped,
and overvalued simultaneously.

1057
00:50:07,571 --> 00:50:10,974
Like, I feel like that's kind of
where we are at the moment, where.

1058
00:50:10,974 --> 00:50:12,142
You're making your stock call.

1059
00:50:12,142 --> 00:50:15,145
Yeah. No, but seriously like it.

1060
00:50:15,746 --> 00:50:16,780
It's a big deal.

1061
00:50:16,780 --> 00:50:18,582
It's going to change the way we work.

1062
00:50:18,582 --> 00:50:20,884
But is it monetizable?

1063
00:50:20,884 --> 00:50:22,919
Can you differentiate the actual models?

1064
00:50:22,919 --> 00:50:26,189
The better
the technology gets, like, the easier

1065
00:50:26,189 --> 00:50:28,358
it is
to just do what everyone else is doing.

1066
00:50:28,358 --> 00:50:31,194
And also like
the compute gets cheaper and cheaper.

1067
00:50:31,194 --> 00:50:33,697
So I just don't know how you monetize
this. Well.

1068
00:50:33,697 --> 00:50:35,132
So that's very interesting.

1069
00:50:35,132 --> 00:50:39,236
His point, which is that it's
the tokens are heavily subsidized still.

1070
00:50:39,236 --> 00:50:39,603
Yeah.

1071
00:50:39,603 --> 00:50:43,407
And so that if you're paying
and actually using that $200 max program

1072
00:50:43,407 --> 00:50:48,612
and you actually use it to the limit,
Claude is going to lose money on this.

1073
00:50:48,678 --> 00:50:50,680
Right? And then the prices keep dropping.

1074
00:50:50,680 --> 00:50:53,617
And I know, like Claude code is okay.

1075
00:50:53,617 --> 00:50:57,020
They're attempting to create something
that resembles a traditional software

1076
00:50:57,020 --> 00:51:00,023
ecosystem that you feel as a user
that you're locked into.

1077
00:51:00,090 --> 00:51:05,562
But so far in my various
like since November 2022,

1078
00:51:05,562 --> 00:51:07,130
when I started playing with AI,

1079
00:51:07,130 --> 00:51:10,500
it hasn't felt like anyone has established
lock in with anything.

1080
00:51:10,500 --> 00:51:11,701
And it's very,

1081
00:51:13,203 --> 00:51:14,638
it's very movable.

1082
00:51:14,638 --> 00:51:17,641
And I suspect even though I have this file
now on my desktop

1083
00:51:17,641 --> 00:51:21,812
that has a file called Claude mode
that gives instructions, etc.,

1084
00:51:22,179 --> 00:51:25,482
I'm certain that if I open this file
with Codex or Googles,

1085
00:51:25,782 --> 00:51:27,784
I could probably just pick it up the same.
Yeah.

1086
00:51:27,784 --> 00:51:31,288
I also think there's a fundamental issue
with the lock in strategy,

1087
00:51:31,288 --> 00:51:34,357
because when you're talking
about technology in the internet, like

1088
00:51:34,791 --> 00:51:39,896
it just feels very against the grain
to try to lock people into anything.

1089
00:51:39,896 --> 00:51:42,933
And we've seen various projects
over the years

1090
00:51:42,933 --> 00:51:45,902
and it's it's a lot harder than it looks.

1091
00:51:46,203 --> 00:51:46,570
Yeah.

1092
00:51:46,570 --> 00:51:49,206
I mean, I guess I would say
it's a lot harder than it looks.

1093
00:51:49,206 --> 00:51:52,442
But then we also know the flip side,
which is that tons of people are locked

1094
00:51:52,442 --> 00:51:54,644
into software that they hate. Right?
Yeah. People are.

1095
00:51:54,644 --> 00:51:55,512
Oh, I hate people.

1096
00:51:55,512 --> 00:51:58,315
How many times have you or
I hate outlook, right?

1097
00:51:58,315 --> 00:52:02,752
Or I hate Microsoft Teams and I hate this
and I spend money on it every month

1098
00:52:02,752 --> 00:52:05,856
and my organization can't move off of it
or we can't migrate off of it.

1099
00:52:06,022 --> 00:52:07,824
So I do think that cuts both ways.

1100
00:52:07,824 --> 00:52:12,929
I do think he offered the best explanation
I've heard of why

1101
00:52:13,163 --> 00:52:18,301
the AI coding models are a threat to a lot
of pretty big software businesses,

1102
00:52:18,401 --> 00:52:22,105
especially, especially the point
about how the user never uses

1103
00:52:22,105 --> 00:52:25,842
all of the features that they actually
that the software got built for.

1104
00:52:26,009 --> 00:52:30,847
And therefore maybe the build versus
buy calculation really starts to shift

1105
00:52:31,014 --> 00:52:34,017
when they can just design that one feature
very quickly.

1106
00:52:34,050 --> 00:52:34,885
I totally agree.

1107
00:52:34,885 --> 00:52:37,921
On the software side,
it seems like an existential threat, but

1108
00:52:37,921 --> 00:52:42,526
just like the locked in ecosystem
of a particular model.

1109
00:52:43,026 --> 00:52:47,130
I know he said it's not actually a model,
but that seems like a bigger issue to me.

1110
00:52:47,397 --> 00:52:48,732
I don't know, I guess we'll see.

1111
00:52:48,732 --> 00:52:51,601
We're going to see and I don't know,
I kind of think we're gonna see quickly.

1112
00:52:51,601 --> 00:52:52,269
Yeah.

1113
00:52:52,269 --> 00:52:55,672
That's again, that's the only certainty is
like, stuff is happening.

1114
00:52:55,672 --> 00:52:56,973
Stuff is. Happening now. Yeah.

1115
00:52:56,973 --> 00:52:59,075
All right. Shall we leave it
there? Let's leave it there.

1116
00:52:59,075 --> 00:52:59,342
Okay.

1117
00:52:59,342 --> 00:53:02,012
This has been another episode
of the Odd Lots podcast.

1118
00:53:02,012 --> 00:53:03,013
I'm Tracy Alloway.

1119
00:53:03,013 --> 00:53:04,981
You can follow me @tracyalloway

1120
00:53:04,981 --> 00:53:06,249
And I'm Joe Weisenthal.

1121
00:53:06,249 --> 00:53:08,051
You can follow me @thestalwart

1122
00:53:08,051 --> 00:53:09,653
Follow our guest Noah Brier.

1123
00:53:09,653 --> 00:53:11,321
He's @Heyitsnoah

1124
00:53:11,321 --> 00:53:14,057
Follow our producers Carmen Rodriguez
@carmenarmen,

1125
00:53:14,057 --> 00:53:17,127
Dashiel Bennett @dashbot
and Cale Brooks @calebrooks

1126
00:53:17,127 --> 00:53:21,097
And for more Odd Lots content,
and to see what Joe has actually

1127
00:53:21,097 --> 00:53:24,367
been working on in Cloud Code,
check out our daily newsletter.

1128
00:53:24,367 --> 00:53:26,069
You can find that at bloomberg.com.

1129
00:53:26,069 --> 00:53:27,871
Forward slash Odd Lots.

1130
00:53:27,871 --> 00:53:30,574
And you can join
fellow listeners in conversation

1131
00:53:30,574 --> 00:53:34,277
24 seven in our discord,
discord.GG slash Odd Lots.

1132
00:53:34,377 --> 00:53:38,181
And if you enjoyed this conversation,
if you like it when we talk about AI,

1133
00:53:38,181 --> 00:53:40,984
then please leave a comment
or like the video.

1134
00:53:40,984 --> 00:53:43,320
Or better yet, subscribe.
Thanks for watching.

