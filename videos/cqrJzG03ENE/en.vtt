WEBVTT

00:00:00.000 --> 00:00:01.840
I think perhaps the thing that most surprised

00:00:01.840 --> 00:00:03.980
me is the extent to which I feel

00:00:03.980 --> 00:00:05.060
like the AI economy

00:00:05.060 --> 00:00:07.220
stabilized. We have like the model layer companies

00:00:07.220 --> 00:00:09.280
and the application layer companies and the

00:00:09.280 --> 00:00:10.960
infrastructure layer companies. It seems like everyone is

00:00:10.960 --> 00:00:12.740
going to make a lot of money and

00:00:12.740 --> 00:00:14.720
there's kind of like a relative playbook for

00:00:14.720 --> 00:00:16.320
how to build an AI native company on

00:00:16.320 --> 00:00:16.940
top of the models.

00:00:17.120 --> 00:00:18.800
Many episodes ago we talked about how it

00:00:18.800 --> 00:00:20.820
was felt easier than ever to peer and

00:00:20.820 --> 00:00:21.820
find a startup idea

00:00:21.820 --> 00:00:23.840
because if you could just survive, if you

00:00:23.840 --> 00:00:25.460
just wait a few months, there was likely

00:00:25.460 --> 00:00:25.780
going to be

00:00:25.780 --> 00:00:28.640
some like big announcement that would completely make

00:00:28.640 --> 00:00:30.420
a new set of ideas possible. And so

00:00:30.420 --> 00:00:30.620
like

00:00:30.620 --> 00:00:32.720
finding ideas is sort of returning to sort

00:00:32.720 --> 00:00:34.560
of normal levels of difficulty.

00:00:42.020 --> 00:00:44.300
Welcome back to another episode of The Light

00:00:44.300 --> 00:00:46.540
Cone. Today we're talking about the most surprising

00:00:46.540 --> 00:00:49.220
things that we saw this year in 2025.

00:00:50.060 --> 00:00:53.400
Diana, you found a pretty crazy one. It's

00:00:53.400 --> 00:00:53.960
sort of a changing

00:00:53.960 --> 00:00:56.460
of the guard almost in who is the

00:00:56.460 --> 00:00:59.860
preferred LLM at YC during the YC batch.

00:01:00.120 --> 00:01:02.440
Yes. In fact, we just wrapped up the

00:01:02.440 --> 00:01:06.660
winter 26 selection cycle for companies. And one

00:01:06.660 --> 00:01:06.880
of the

00:01:06.880 --> 00:01:09.240
questions we asked to all the founders that

00:01:09.240 --> 00:01:11.720
apply to YC is what is your tech

00:01:11.720 --> 00:01:13.640
stack and model of choice?

00:01:14.000 --> 00:01:16.040
And one of the shocking things is that

00:01:16.040 --> 00:01:18.920
for the longest time, OpenAI was the clear

00:01:18.920 --> 00:01:19.540
winner

00:01:19.540 --> 00:01:22.920
for all of last year, last couple of

00:01:22.920 --> 00:01:25.460
batches, though that number has been coming down.

00:01:26.380 --> 00:01:30.520
And shockingly, in this batch, the number one

00:01:30.520 --> 00:01:34.920
API is actually Anthropic. It came out a

00:01:34.920 --> 00:01:35.540
bit more than

00:01:35.540 --> 00:01:37.800
OpenAI, which who would have thought? I think

00:01:37.800 --> 00:01:40.620
when we started this podcast series back then,

00:01:40.620 --> 00:01:44.180
OpenAI was like 90 plus percent. And now,

00:01:44.940 --> 00:01:46.620
Anthropic, who would have thought?

00:01:46.860 --> 00:01:48.620
Yeah. And you know, they'd been hovering around

00:01:48.620 --> 00:01:52.060
like 20, 25% for most of like

00:01:52.060 --> 00:01:55.980
2024 and early 2025. And then

00:01:55.980 --> 00:01:58.280
only even in the last three to six

00:01:58.280 --> 00:02:00.740
months, did this sort of changing of the

00:02:00.740 --> 00:02:01.640
guard actually happen?

00:02:01.640 --> 00:02:03.860
They had this hockey stick with the with

00:02:03.860 --> 00:02:06.060
the growth are over 52%.

00:02:06.060 --> 00:02:07.420
Why do you think that is?

00:02:07.660 --> 00:02:09.380
I think there's a couple of things in

00:02:09.380 --> 00:02:11.440
terms of the tech stack selection. I think

00:02:11.440 --> 00:02:12.760
as we've seen this year,

00:02:13.280 --> 00:02:16.000
there's been a lot of wins in terms

00:02:16.000 --> 00:02:18.220
of vibe coding tools that are getting built

00:02:18.220 --> 00:02:19.680
out out there. And

00:02:19.680 --> 00:02:22.700
coding agents are so many categories that this

00:02:22.700 --> 00:02:25.740
ended up being a bigger problem space that

00:02:25.740 --> 00:02:26.240
actually is

00:02:26.240 --> 00:02:28.140
creating a lot of value. And it turns

00:02:28.140 --> 00:02:30.760
out the model that performs the best at

00:02:30.760 --> 00:02:31.580
it is actually

00:02:32.580 --> 00:02:35.800
models from Anthropic. And I think that's not

00:02:35.800 --> 00:02:38.080
by accident. I think from hearing the conversation

00:02:38.080 --> 00:02:39.780
we had with Tom Brown, not too long

00:02:39.780 --> 00:02:41.500
ago, he came and spoke is that was

00:02:41.500 --> 00:02:43.180
one of their internal evals.

00:02:43.360 --> 00:02:45.940
They, on purpose, made them their North Star.

00:02:46.120 --> 00:02:47.840
And you can see it in the model

00:02:47.840 --> 00:02:49.220
taste as a result of

00:02:49.740 --> 00:02:53.060
what's the best choice of model for a

00:02:53.060 --> 00:02:55.580
lot of founders building products is Anthropic.

00:02:55.840 --> 00:02:58.140
The vast majority of the use cases people

00:02:58.140 --> 00:03:00.060
are using it for, though, is not coding.

00:03:00.240 --> 00:03:01.000
So I wonder if there's

00:03:01.000 --> 00:03:02.320
like a bleed through effect, where people are

00:03:02.320 --> 00:03:05.420
using Claude for their personal coding. And then

00:03:05.420 --> 00:03:07.680
as a result, they're more likely to choose

00:03:07.680 --> 00:03:09.260
it for their application, even if their application

00:03:09.260 --> 00:03:09.460
is

00:03:09.460 --> 00:03:10.300
not doing coding at all.

00:03:10.300 --> 00:03:12.940
Because you'd be very familiar with like the

00:03:12.940 --> 00:03:15.940
personality of Claude Opus or whatever they're

00:03:15.940 --> 00:03:17.720
choosing. Sonnet, I suppose.

00:03:18.140 --> 00:03:20.440
How about Gemini? How's Gemini doing in those

00:03:20.440 --> 00:03:20.720
rankings?

00:03:21.060 --> 00:03:23.440
Gemini has also pretty much has been climbing

00:03:23.440 --> 00:03:25.780
up pretty, pretty high. I think last year

00:03:25.780 --> 00:03:26.000
was

00:03:26.000 --> 00:03:28.640
probably single digit percent or even like two,

00:03:28.800 --> 00:03:32.480
three percent. And now for winter 26, it's

00:03:32.480 --> 00:03:32.660
about

00:03:32.660 --> 00:03:36.320
23 percent. And we've personally been using also

00:03:36.320 --> 00:03:38.320
a lot of Gemini 3.0 and we've

00:03:38.320 --> 00:03:39.140
been impressed with

00:03:39.140 --> 00:03:42.200
the quality of it. I think it's really,

00:03:42.420 --> 00:03:43.300
really working.

00:03:43.540 --> 00:03:45.800
I mean, they have all different personalities, don't

00:03:45.800 --> 00:03:45.980
they?

00:03:46.160 --> 00:03:46.280
That too.

00:03:46.560 --> 00:03:46.760
Yeah.

00:03:47.300 --> 00:03:49.940
It's kind of the classic where OpenAI sort

00:03:49.940 --> 00:03:52.740
of has the black cat energy. And almost

00:03:52.740 --> 00:03:53.020
like

00:03:54.340 --> 00:03:55.780
Anthropic is kind of more the happy-go

00:03:55.780 --> 00:03:58.660
-lucky, a bit more very helpful golden retriever.

00:03:58.840 --> 00:03:59.240
At least

00:03:59.240 --> 00:04:00.360
that's what I feel when I talk to

00:04:00.360 --> 00:04:00.520
them.

00:04:00.940 --> 00:04:01.920
And how about Gemini?

00:04:02.140 --> 00:04:03.220
It's kind of like in between.

00:04:03.780 --> 00:04:05.480
Harj, you prefer Gemini, actually.

00:04:05.860 --> 00:04:08.900
Yeah, I've switched to Gemini this year as

00:04:08.900 --> 00:04:11.340
my just go-to model. I think even

00:04:11.340 --> 00:04:13.360
before 2.5 Pro came

00:04:13.360 --> 00:04:16.920
out and just seemed better at reasoning for

00:04:16.920 --> 00:04:19.400
me, it was just like the increasingly I

00:04:19.400 --> 00:04:20.120
replaced my

00:04:20.120 --> 00:04:22.420
Google searches with Gemini. And I just sort

00:04:22.420 --> 00:04:24.960
of trusted that Google's, I think like the

00:04:24.960 --> 00:04:25.320
groundings

00:04:25.320 --> 00:04:27.340
API and its ability to actually like use

00:04:27.340 --> 00:04:29.740
the Google index to give you like real

00:04:29.740 --> 00:04:30.820
-time information

00:04:30.820 --> 00:04:32.900
correctly. I just found it was better than,

00:04:33.100 --> 00:04:34.660
personally I found it was better than all

00:04:34.660 --> 00:04:34.760
the

00:04:34.760 --> 00:04:35.840
other tools for that. And it was better

00:04:35.840 --> 00:04:37.780
than Perplexity on it too. Like Perplexity would

00:04:37.780 --> 00:04:37.940
be

00:04:37.940 --> 00:04:40.300
fast, but not always accurate. And Gemini was

00:04:40.300 --> 00:04:42.040
not quite as fast as Perplexity, but it

00:04:42.040 --> 00:04:42.400
was always

00:04:42.400 --> 00:04:44.760
pretty accurate if I asked it about something

00:04:44.760 --> 00:04:45.940
that happened today, for example.

00:04:45.940 --> 00:04:47.960
Even if you use Gemini as the reasoning

00:04:47.960 --> 00:04:49.420
engine in Perplexity?

00:04:50.140 --> 00:04:51.200
I have not done that.

00:04:51.440 --> 00:04:53.640
Interesting. Yeah. So it's hard to know like

00:04:53.640 --> 00:04:55.020
how much of it is the tooling and

00:04:55.020 --> 00:04:55.800
how much of it is

00:04:55.800 --> 00:04:57.100
like the base LLM.

00:04:57.220 --> 00:04:57.640
That's fair.

00:04:57.880 --> 00:04:59.900
Yeah. I mean, what are your guys' tools

00:04:59.900 --> 00:05:01.860
of choice? I haven't switched off of ChatGPT.

00:05:02.000 --> 00:05:02.140
I mean,

00:05:02.260 --> 00:05:04.440
I find the memory very sticky. It knows

00:05:04.440 --> 00:05:06.400
me, it knows my personality, it knows the

00:05:06.400 --> 00:05:06.800
things that

00:05:06.800 --> 00:05:09.620
I think about. And so I'll use Perplexity

00:05:09.620 --> 00:05:13.580
for fast web searches or things that I

00:05:13.580 --> 00:05:14.200
know is like

00:05:14.200 --> 00:05:16.680
a research task because I think ChatGPT is

00:05:16.680 --> 00:05:17.960
still like a little bit of a step

00:05:17.960 --> 00:05:19.320
behind for searching

00:05:19.320 --> 00:05:20.940
the web. I don't know. I think memory

00:05:20.940 --> 00:05:25.540
is turning into an actual moat for like

00:05:25.540 --> 00:05:26.740
that consumer experience.

00:05:26.740 --> 00:05:29.340
And I don't expect Gemini to ever have

00:05:29.340 --> 00:05:32.400
the personality that I would expect from ChatGPT.

00:05:32.560 --> 00:05:34.600
It just feels like a different like entity,

00:05:34.920 --> 00:05:35.140
you know?

00:05:35.480 --> 00:05:37.340
The thing I'm still surprised about is why

00:05:37.340 --> 00:05:42.380
there just aren't more consumer apps around like

00:05:42.380 --> 00:05:42.780
all the

00:05:42.780 --> 00:05:44.960
various things we do. Like if I think

00:05:44.960 --> 00:05:46.400
back, one of the big changes for me

00:05:46.400 --> 00:05:47.960
this year is just the amount of

00:05:48.840 --> 00:05:51.220
prompting and context engineering I do for like

00:05:51.220 --> 00:05:53.620
my life. Like we bought a house recently

00:05:53.620 --> 00:05:54.020
and like

00:05:54.020 --> 00:05:55.700
the whole thing, like I just had like

00:05:55.700 --> 00:05:59.220
a really long running ChatGPT conversation stuffing it

00:05:59.220 --> 00:05:59.440
full of

00:05:59.440 --> 00:06:01.980
context of like every inspection report or like

00:06:01.980 --> 00:06:04.400
wanting it to be like level the playing

00:06:04.400 --> 00:06:04.880
field between

00:06:04.880 --> 00:06:06.720
me and like the realtor to understand kind

00:06:06.720 --> 00:06:08.420
of all the dynamics and things that are

00:06:08.420 --> 00:06:08.920
going on.

00:06:09.120 --> 00:06:11.240
And it just feels like there should be

00:06:11.240 --> 00:06:12.180
an app for that.

00:06:12.180 --> 00:06:15.800
But simultaneously, I'm sure you took the PDFs

00:06:15.800 --> 00:06:18.080
and just like dropped them into Gemini and

00:06:18.080 --> 00:06:18.640
said

00:06:18.640 --> 00:06:20.900
like, well, summarize and tell me what's important

00:06:20.900 --> 00:06:21.280
for me.

00:06:21.360 --> 00:06:23.180
I guess I worry about, I worried about,

00:06:23.220 --> 00:06:25.260
I still don't trust the models enough to

00:06:25.260 --> 00:06:25.460
be

00:06:25.460 --> 00:06:28.160
accurate without lots of prompting. And it's a

00:06:28.160 --> 00:06:29.820
high value transaction. So you don't want to

00:06:29.820 --> 00:06:30.100
like

00:06:30.100 --> 00:06:32.360
get incorrect data out of it. So I

00:06:32.360 --> 00:06:33.580
still feel like you need to put in

00:06:33.580 --> 00:06:34.760
the work and it feels like

00:06:34.760 --> 00:06:37.360
there should still be apps that just do

00:06:37.360 --> 00:06:38.260
all the work for you.

00:06:38.380 --> 00:06:40.080
Did you see Karpathy release like sort of

00:06:40.080 --> 00:06:42.920
a LLM arena of a sort, which I

00:06:42.920 --> 00:06:44.320
mean, I do by like hand

00:06:44.320 --> 00:06:46.480
right now using tabs. It's like you have

00:06:46.480 --> 00:06:49.260
Claude open, you have Gemini open, you have

00:06:49.260 --> 00:06:50.020
ChatGPT open,

00:06:50.020 --> 00:06:52.400
and you give it the same task. And

00:06:52.400 --> 00:06:54.240
then you take the output from each. And

00:06:54.240 --> 00:06:55.440
then I usually go to Claude

00:06:55.440 --> 00:06:56.900
at that point. And I'm like, all right,

00:06:57.040 --> 00:06:58.380
Claude, this is what the other one said.

00:06:58.480 --> 00:06:59.020
What do you think?

00:06:59.020 --> 00:07:01.060
And check each other's work. I actually think

00:07:01.060 --> 00:07:02.860
that that particular behavior at the consumer,

00:07:03.000 --> 00:07:06.360
that level that we're doing, startups are doing

00:07:06.360 --> 00:07:08.360
as well. They are actually arbitraging

00:07:08.360 --> 00:07:09.660
a lot of the models. I had some

00:07:09.660 --> 00:07:12.320
conversations with a number of founders where before

00:07:12.320 --> 00:07:12.620
they

00:07:12.620 --> 00:07:15.180
might've been loyalists to, let's say, open AI

00:07:15.180 --> 00:07:18.580
models or Anthropic. And I just had some

00:07:18.580 --> 00:07:20.760
conversations recently with them. And these are founders

00:07:20.760 --> 00:07:23.380
that are running larger companies like

00:07:23.380 --> 00:07:26.420
series B level type of companies. With AI,

00:07:26.680 --> 00:07:29.600
they're actually abstracting all that away

00:07:29.600 --> 00:07:33.580
and building this orchestration layer where perhaps as

00:07:33.580 --> 00:07:35.620
each new model release comes out,

00:07:35.760 --> 00:07:37.980
they can swap them in and out, or

00:07:37.980 --> 00:07:40.360
they can use specific models that are better

00:07:40.360 --> 00:07:41.440
at certain things

00:07:41.440 --> 00:07:43.700
for just that. For example, I heard from

00:07:43.700 --> 00:07:47.000
the startup, they use Gemini 3 to do

00:07:47.000 --> 00:07:47.600
the context

00:07:47.600 --> 00:07:50.740
engineering, which they actually then fed into OpenAI

00:07:50.740 --> 00:07:52.540
to execute it. And they keep swapping it

00:07:52.540 --> 00:07:52.960
as

00:07:52.960 --> 00:07:55.000
new models come up and the winner for

00:07:55.000 --> 00:07:58.600
each category or type of agent work is

00:07:58.600 --> 00:07:58.960
different.

00:07:59.600 --> 00:08:02.680
And ultimately they can do this because it

00:08:02.680 --> 00:08:04.840
is all grounded based on the evals. And

00:08:04.840 --> 00:08:05.580
the evals are all

00:08:05.580 --> 00:08:07.820
proprietary to them because they're a vertical AI

00:08:07.820 --> 00:08:09.540
agent and they just work in a very

00:08:09.540 --> 00:08:10.420
regulated industry

00:08:10.420 --> 00:08:12.300
and they have this data set that just

00:08:12.300 --> 00:08:14.020
works the best for them. I think this

00:08:14.020 --> 00:08:15.300
is the new normal right

00:08:15.300 --> 00:08:17.600
now where people are expecting, yeah, that it's

00:08:17.600 --> 00:08:20.260
cool that the model companies, they're spending all

00:08:20.260 --> 00:08:20.400
this

00:08:20.400 --> 00:08:23.960
money and making intelligence faster and better and

00:08:23.960 --> 00:08:25.240
we can all benefit. Let's just do the

00:08:25.240 --> 00:08:25.580
best.

00:08:26.020 --> 00:08:28.700
It's almost like the era of Intel and

00:08:28.700 --> 00:08:31.240
AMD with new architecture would come up. People

00:08:31.240 --> 00:08:31.800
could just swap

00:08:31.800 --> 00:08:33.380
them, right? Yeah, if it was at the

00:08:33.380 --> 00:08:35.960
highest level, that angst around where's the value

00:08:35.960 --> 00:08:36.660
going to accrue?

00:08:36.800 --> 00:08:37.560
Is it going to go to the model

00:08:37.560 --> 00:08:39.660
companies or like the application layer, i.e.

00:08:39.660 --> 00:08:40.900
the startups, feels like

00:08:40.900 --> 00:08:43.760
that ebbs and flows in either direction a

00:08:43.760 --> 00:08:45.200
little bit throughout the year to me. Like

00:08:45.200 --> 00:08:46.020
I feel there are moments

00:08:46.020 --> 00:08:49.080
where Claude Code, amazing launch and it was

00:08:49.080 --> 00:08:50.540
like, oh, okay, like the model companies are

00:08:50.540 --> 00:08:50.700
actually

00:08:50.700 --> 00:08:52.380
going to play out the application layer. But

00:08:52.380 --> 00:08:53.760
then to me at least it's all vibes

00:08:53.760 --> 00:08:54.420
based. Like the

00:08:54.420 --> 00:08:56.400
Gemini surge, especially over the last few months,

00:08:56.480 --> 00:08:57.900
just feels like it returns us to a

00:08:57.900 --> 00:08:58.460
world of where

00:08:58.460 --> 00:09:00.800
exactly that. Like the models are all essentially

00:09:00.800 --> 00:09:02.800
commoditizing each other and it's just like the

00:09:03.520 --> 00:09:05.240
application layer and the startups are going to

00:09:05.240 --> 00:09:07.540
set up to have another fantastic year if

00:09:07.540 --> 00:09:08.040
that continues.

00:09:08.040 --> 00:09:10.840
I'm curious what you think, Jared, with some,

00:09:10.840 --> 00:09:15.700
a lot of perhaps the negative comments on

00:09:15.700 --> 00:09:15.940
Twitter

00:09:15.940 --> 00:09:17.560
around, is this a bit of a bubble,

00:09:17.860 --> 00:09:22.020
an AI bubble? Yeah. When I talk to

00:09:22.020 --> 00:09:23.140
undergrads, this is like a

00:09:23.140 --> 00:09:25.080
common question that I get is like, oh,

00:09:25.220 --> 00:09:27.800
like I heard it's a big AI bubble

00:09:27.800 --> 00:09:29.180
because like there's all

00:09:29.180 --> 00:09:31.320
this like crazy round tripping going between NVIDIA

00:09:31.320 --> 00:09:35.400
and OpenAI and like, is it all fake?

00:09:35.600 --> 00:09:35.760
Yeah.

00:09:35.760 --> 00:09:38.420
No, this is fantastic, right? Like people look

00:09:38.420 --> 00:09:39.700
at the telecom bubble and it's like there's

00:09:39.700 --> 00:09:39.880
just,

00:09:39.920 --> 00:09:41.840
you know, billions of dollars, like tens of

00:09:41.840 --> 00:09:43.400
billions, hundreds of billions, just like

00:09:43.400 --> 00:09:45.960
sort of sitting in a bunch of telecom

00:09:45.960 --> 00:09:48.620
back in like the, you know, 90s. Actually,

00:09:48.680 --> 00:09:49.640
that's why YouTube was

00:09:49.640 --> 00:09:52.020
able to exist, right? Like if you just

00:09:52.020 --> 00:09:53.940
have a whole bunch of extra bandwidth that

00:09:53.940 --> 00:09:54.780
isn't being used and

00:09:54.780 --> 00:09:56.680
is relatively cheap, the cost is low enough

00:09:56.680 --> 00:09:58.660
for like something like YouTube to exist. Like

00:09:58.660 --> 00:09:58.920
if there

00:09:58.920 --> 00:10:02.060
wasn't a glut of telecom, then like maybe

00:10:02.060 --> 00:10:03.300
YouTube would have happened and just would have

00:10:03.300 --> 00:10:03.560
happened

00:10:03.560 --> 00:10:05.560
later. And then that, isn't that like sort

00:10:05.560 --> 00:10:07.560
of what we're talking about here? Like how

00:10:07.560 --> 00:10:07.860
do we,

00:10:07.980 --> 00:10:10.280
we have to accelerate, right? We have the

00:10:10.280 --> 00:10:12.120
age of intelligence, the rocks can talk, they

00:10:12.120 --> 00:10:12.580
can think,

00:10:12.700 --> 00:10:13.880
and they can do work and you just

00:10:13.880 --> 00:10:16.100
have to zap them more and you get

00:10:16.100 --> 00:10:17.820
like smarter and smarter stuff at

00:10:17.820 --> 00:10:20.060
this point. I think the argument to college

00:10:20.060 --> 00:10:22.500
students is actually like, because there will be

00:10:22.500 --> 00:10:22.880
a glut,

00:10:23.480 --> 00:10:25.460
there is an opportunity for you. And if

00:10:25.460 --> 00:10:27.780
there was not a glut, then there wouldn't

00:10:27.780 --> 00:10:28.160
be as much

00:10:28.160 --> 00:10:31.900
competition. The prices would be higher. The margins

00:10:31.900 --> 00:10:34.640
lower in the stack would be higher, right?

00:10:35.020 --> 00:10:36.300
And then, you know, what's one of the

00:10:36.300 --> 00:10:39.140
big stories this year? Like Nvidia suddenly is

00:10:39.140 --> 00:10:40.240
on the outs. Like

00:10:40.240 --> 00:10:41.940
I think their stock is today is like

00:10:41.940 --> 00:10:44.380
around 170s or something. You know, I think

00:10:44.380 --> 00:10:45.540
I'm still a long-term

00:10:45.540 --> 00:10:47.780
buy and hold, honestly. But for the moment,

00:10:48.000 --> 00:10:49.500
people are like, oh, well, Gemini is so

00:10:49.500 --> 00:10:49.960
good.

00:10:49.960 --> 00:10:52.140
And all the, you know, nobody seems to

00:10:52.140 --> 00:10:55.260
be Nvidia only now and everyone's buying AMD

00:10:55.260 --> 00:10:56.040
and everyone's,

00:10:56.180 --> 00:10:59.160
you know, and TPUs are working. So, you

00:10:59.160 --> 00:11:01.200
know, at the moment it looks like there's,

00:11:01.360 --> 00:11:01.580
you know,

00:11:01.700 --> 00:11:04.680
what does that mean? Like there's competition and

00:11:04.680 --> 00:11:07.920
it means that there will be more compute,

00:11:08.080 --> 00:11:11.200
not less. And then that means that probably

00:11:11.200 --> 00:11:13.880
a little bit better things for all of

00:11:13.880 --> 00:11:14.900
the big LLM

00:11:14.900 --> 00:11:16.800
companies like sort of the, you know, the

00:11:16.800 --> 00:11:19.180
AI labs, they get a little bit of

00:11:19.180 --> 00:11:19.900
power, but,

00:11:20.020 --> 00:11:22.440
you know, they too are in competition with

00:11:22.440 --> 00:11:24.200
one another. So then what does that mean?

00:11:24.320 --> 00:11:24.380
Well,

00:11:24.460 --> 00:11:26.260
then it's, you know, go up another level

00:11:26.260 --> 00:11:28.200
in this stack, right? Like as long as

00:11:28.200 --> 00:11:29.240
there are a great many

00:11:29.700 --> 00:11:32.160
AI labs that are in a deep competition

00:11:32.160 --> 00:11:35.680
with one another, then that's even better for

00:11:35.680 --> 00:11:36.640
that college

00:11:36.640 --> 00:11:38.820
student who's about to start a company at

00:11:38.820 --> 00:11:41.160
the application level. Yeah, I think that's exactly

00:11:41.160 --> 00:11:41.400
right.

00:11:41.400 --> 00:11:43.560
It's like people are asking this question, like,

00:11:43.700 --> 00:11:45.840
is it a bubble? That's maybe a question

00:11:45.840 --> 00:11:46.060
that's

00:11:46.060 --> 00:11:47.580
really relevant. If you're like the equivalent of

00:11:47.580 --> 00:11:49.860
like Comcast, like if you're Nvidia, that's a

00:11:49.860 --> 00:11:50.020
very

00:11:50.020 --> 00:11:52.320
relevant question. Like, oh, are people overbuilding GPU

00:11:52.320 --> 00:11:54.660
capacity, but like the college students, they're

00:11:54.660 --> 00:11:57.100
not Comcast. They're actually like YouTube. If you're

00:11:57.100 --> 00:11:58.480
doing a startup in your dorm room, it's

00:11:58.480 --> 00:11:58.580
like

00:11:58.580 --> 00:12:00.220
the AI equivalent of like YouTube and like

00:12:00.220 --> 00:12:02.380
kind of doesn't really matter that much. Maybe

00:12:02.380 --> 00:12:02.800
Nvidia's

00:12:02.800 --> 00:12:04.700
talk will go down next year. I don't

00:12:04.700 --> 00:12:07.060
know. But like, even if it does, that

00:12:07.060 --> 00:12:07.800
doesn't actually mean

00:12:07.800 --> 00:12:08.900
that it's like a bad time to be

00:12:08.900 --> 00:12:10.540
working on an AI startup. Yeah, it's what

00:12:10.540 --> 00:12:11.220
Zuck said in a

00:12:11.220 --> 00:12:12.720
podcast early this year, I think, right? It's

00:12:12.720 --> 00:12:15.420
like Meta may end up over investing like

00:12:15.420 --> 00:12:16.000
a significant

00:12:16.000 --> 00:12:19.620
amount in like the capex and infrastructure, but

00:12:19.620 --> 00:12:21.360
like they essentially have to, the big companies

00:12:21.360 --> 00:12:22.720
have to do it because they can't just

00:12:22.720 --> 00:12:24.860
like sit on the sidelines. And in the

00:12:24.860 --> 00:12:27.200
case, like demand falls

00:12:27.200 --> 00:12:29.300
off a cliff for some reason, it's their

00:12:29.300 --> 00:12:31.380
capex, not the startup's capex. And there's still

00:12:31.380 --> 00:12:31.780
going to be

00:12:31.780 --> 00:12:34.120
tons of infrastructure and ideas to still continue

00:12:34.120 --> 00:12:36.820
building. There was this book written by this

00:12:36.820 --> 00:12:40.380
economist called Carlota Perez, who studied a lot

00:12:40.380 --> 00:12:43.140
of tech trends, and it studies a lot

00:12:43.140 --> 00:12:43.340
of

00:12:44.220 --> 00:12:47.200
technology revolutions. And it summarizes that there's really

00:12:47.200 --> 00:12:49.840
two phases. There's the phase of

00:12:49.840 --> 00:12:52.100
installation, which is where a lot of the

00:12:52.100 --> 00:12:56.180
very heavy capex investment come in. And then

00:12:56.180 --> 00:12:56.580
there's the

00:12:56.580 --> 00:13:00.520
deployment phase where really ripples, where it rips,

00:13:00.600 --> 00:13:03.000
and then everything explodes in terms of abundance.

00:13:03.000 --> 00:13:06.840
And during the initial phase of installation is

00:13:06.840 --> 00:13:08.340
where it feels like a bubble. There's a

00:13:08.340 --> 00:13:08.580
bit of a

00:13:08.580 --> 00:13:10.540
frenzy because it starts first with a, there's

00:13:10.540 --> 00:13:13.040
this new technology that's amazing, which happened

00:13:13.040 --> 00:13:16.080
with the ChatGPT moment in 2023. Everyone got

00:13:16.080 --> 00:13:18.420
super excited about the tech, and then everyone's

00:13:18.420 --> 00:13:18.640
got

00:13:18.640 --> 00:13:21.800
super hyped and got into investing into a

00:13:21.800 --> 00:13:23.440
lot of the infrastructure with buying a lot

00:13:23.440 --> 00:13:24.240
of GPUs and

00:13:24.240 --> 00:13:27.040
all the giant gigawatt data center build out.

00:13:27.160 --> 00:13:28.680
And then people say, but what is the

00:13:28.680 --> 00:13:29.340
demand? What are

00:13:29.340 --> 00:13:30.760
going to be all the applications to be

00:13:30.760 --> 00:13:32.300
built out? I think right now we're in

00:13:32.300 --> 00:13:32.860
that transition,

00:13:32.880 --> 00:13:36.140
which is actually really good news for startup

00:13:36.140 --> 00:13:38.980
founders because they are not involved into the

00:13:38.980 --> 00:13:41.280
building the data centers, but they're going to

00:13:41.280 --> 00:13:44.600
build the next generation of applications in the

00:13:44.600 --> 00:13:48.180
deployment phase when it really proliferates. And what

00:13:48.180 --> 00:13:50.320
happened, just going back to the analogy with

00:13:50.320 --> 00:13:53.800
with the era of the internet, before the

00:13:53.800 --> 00:13:55.660
2000, there was a lot of heavy capex

00:13:55.660 --> 00:13:56.740
investment into

00:13:56.740 --> 00:14:00.480
the telcos, right? Those were giant projects that

00:14:00.480 --> 00:14:02.800
college students wouldn't be involved,

00:14:03.000 --> 00:14:05.660
but they were very heavily invested. And in

00:14:05.660 --> 00:14:07.740
some cases were over invested. I mean,

00:14:07.820 --> 00:14:09.660
there's a whole thing with dark fiber and

00:14:09.660 --> 00:14:11.760
some pipes that are not used and that's

00:14:11.760 --> 00:14:12.020
fine.

00:14:12.260 --> 00:14:15.280
The internet ended up being still a giant

00:14:15.280 --> 00:14:18.720
economic driver. And what that means is startups

00:14:18.720 --> 00:14:19.340
like the

00:14:19.340 --> 00:14:21.400
future Facebook or the future Google are yet

00:14:21.400 --> 00:14:23.160
to be started because those come in in

00:14:23.160 --> 00:14:23.780
the deployment

00:14:23.780 --> 00:14:26.440
phase. Because right now I think things are

00:14:26.440 --> 00:14:28.440
still getting built up. I do think the

00:14:28.440 --> 00:14:29.100
foundation lab

00:14:29.100 --> 00:14:31.820
companies and GPUs very much are falling into

00:14:31.820 --> 00:14:33.060
the bucket of infrastructure.

00:14:33.500 --> 00:14:35.460
Yeah. I mean, it's interesting to watch how

00:14:35.460 --> 00:14:37.160
this stuff is evolving a little bit. So

00:14:37.160 --> 00:14:37.540
do you remember

00:14:37.540 --> 00:14:40.340
summer 24, there was a company called StarCloud

00:14:40.340 --> 00:14:42.440
that came out and was one of the

00:14:42.440 --> 00:14:43.300
first to come out and

00:14:43.300 --> 00:14:45.840
say, we're going to make data centers in

00:14:45.840 --> 00:14:48.560
space. And what was the reaction when, you

00:14:48.560 --> 00:14:48.660
know,

00:14:48.660 --> 00:14:50.980
people laugh at them on the internet. Yeah.

00:14:51.380 --> 00:14:52.800
They said, that's the stupidest idea ever.

00:14:53.160 --> 00:14:55.760
You know, I guess 18 months later, suddenly

00:14:55.760 --> 00:14:57.900
Google's doing it. Elon's doing it.

00:14:57.900 --> 00:14:59.460
So now it mentions it in every interview

00:14:59.460 --> 00:15:00.040
now, apparently.

00:15:00.220 --> 00:15:00.460
Is that right?

00:15:00.520 --> 00:15:02.160
It seems to be like his top talking

00:15:02.160 --> 00:15:02.400
point.

00:15:02.620 --> 00:15:04.500
Yeah. And so, I mean, why is that?

00:15:04.700 --> 00:15:06.180
Like, I feel like one of the aspects

00:15:06.180 --> 00:15:06.860
is that like,

00:15:07.360 --> 00:15:10.200
part of the infrastructure build out right now

00:15:10.200 --> 00:15:12.880
that's so intense is like, we literally don't

00:15:12.880 --> 00:15:13.300
have

00:15:13.860 --> 00:15:17.620
power generation. Boom Supersonic, instead of making supersonic

00:15:17.620 --> 00:15:18.400
jets right now,

00:15:18.600 --> 00:15:21.220
is on this good quest to create enough

00:15:21.220 --> 00:15:24.260
power for a bunch of these AI data

00:15:24.260 --> 00:15:25.060
centers that are being

00:15:25.060 --> 00:15:28.140
built right now. They use jet engines. And

00:15:28.140 --> 00:15:30.240
even those like are so bad, you know,

00:15:30.280 --> 00:15:30.880
the supply chain

00:15:30.880 --> 00:15:32.880
for jet engines to generate power for data

00:15:32.880 --> 00:15:35.100
centers is so backed up that, you know,

00:15:35.220 --> 00:15:35.840
you would have had

00:15:35.840 --> 00:15:38.040
to have ordered these things, you know, two

00:15:38.040 --> 00:15:40.420
or three years ago just to even have

00:15:40.420 --> 00:15:41.660
it in two or three

00:15:41.660 --> 00:15:45.180
years from now. You know, these constraints, uh,

00:15:45.420 --> 00:15:48.640
end up like influencing like fairly directly

00:15:48.640 --> 00:15:51.800
what the giant tech companies need to do

00:15:51.800 --> 00:15:53.520
to win the game three or five years

00:15:53.520 --> 00:15:53.920
out.

00:15:54.700 --> 00:15:57.940
Like suddenly there's not enough land, you know,

00:15:58.020 --> 00:16:00.380
in America, we can't build. The regulations are

00:16:00.380 --> 00:16:00.520
too

00:16:00.520 --> 00:16:02.860
high. In California, we have CEQA, which is

00:16:02.860 --> 00:16:06.140
totally abused by the environmental lobby to stop

00:16:06.140 --> 00:16:06.460
all

00:16:06.460 --> 00:16:09.880
innovation and building housing. By the way, we

00:16:09.880 --> 00:16:13.640
just don't have enough terrestrially like to just

00:16:13.640 --> 00:16:15.820
do the things that society sort of needs

00:16:15.820 --> 00:16:18.160
right now. So, you know, the escape valve

00:16:18.160 --> 00:16:18.520
is like,

00:16:18.660 --> 00:16:20.840
actually, let's just do it in space. Yeah.

00:16:20.900 --> 00:16:22.000
Come to think about, we, we kind of

00:16:22.000 --> 00:16:22.120
have

00:16:22.120 --> 00:16:24.220
the trifecta of YC companies that are solving

00:16:24.220 --> 00:16:26.320
the data center buildup problem. Well, you need

00:16:26.320 --> 00:16:26.580
fusion

00:16:26.580 --> 00:16:29.640
energy. Yeah. Yeah. Well, we have the company

00:16:29.640 --> 00:16:32.620
that's solving the no land problem by building

00:16:32.620 --> 00:16:34.920
the data centers in space. We have boom

00:16:34.920 --> 00:16:36.940
and helium, which are solving that we don't

00:16:36.940 --> 00:16:37.560
have an energy

00:16:37.560 --> 00:16:40.160
problem. I just found today, uh, a space

00:16:40.160 --> 00:16:43.240
fusion company that just graduated called Zephyr fusion.

00:16:43.460 --> 00:16:44.900
That's a cool one. And they actually had

00:16:44.900 --> 00:16:46.600
a great seed round out of demo day.

00:16:46.780 --> 00:16:47.640
They're in their forties,

00:16:47.680 --> 00:16:51.140
they're national lab engineers who their entire careers,

00:16:51.140 --> 00:16:53.620
they were building, you know, tokamaks and

00:16:53.620 --> 00:16:56.580
fusion energy. And they came into the lab

00:16:56.580 --> 00:16:58.960
one day, they looked at the physics, they,

00:16:59.100 --> 00:17:00.120
you know, looked at the

00:17:00.120 --> 00:17:03.020
math and the models and they said, you

00:17:03.020 --> 00:17:05.040
know what, if we did this in space,

00:17:05.340 --> 00:17:06.700
it would actually pencil.

00:17:07.040 --> 00:17:08.660
And so that's, they're on like this sort

00:17:08.660 --> 00:17:11.500
of grand next five, 10 year quest to

00:17:11.500 --> 00:17:13.220
actually manifest it,

00:17:13.300 --> 00:17:15.980
to actually create it in space, uh, because

00:17:15.980 --> 00:17:18.980
the equations say that it is possible. And,

00:17:18.980 --> 00:17:19.100
uh,

00:17:19.180 --> 00:17:20.560
if they do it, it's actually the only

00:17:20.560 --> 00:17:23.280
path to gigawatts of energy, uh, up there

00:17:23.280 --> 00:17:24.560
in space. So,

00:17:24.700 --> 00:17:26.300
you know, it might be, you know, an

00:17:26.300 --> 00:17:28.500
even more perfect trifecta, uh, shortly.

00:17:28.500 --> 00:17:30.280
Yeah. Something else I feel like happened over

00:17:30.280 --> 00:17:32.300
the course of this year is the, um,

00:17:32.660 --> 00:17:35.740
interest in starting model companies. Like, I guess

00:17:35.740 --> 00:17:37.200
that maybe at both ends, there's like

00:17:37.200 --> 00:17:39.180
the people who can raise the capital to

00:17:39.180 --> 00:17:41.040
go and actually try and build a head

00:17:41.040 --> 00:17:41.800
on competitor to

00:17:41.800 --> 00:17:43.240
open AI, which there are very, very few,

00:17:43.320 --> 00:17:46.040
like maybe have ILIO with SSI, but then

00:17:46.040 --> 00:17:47.360
more so within YC,

00:17:47.680 --> 00:17:49.800
people trying to build like smaller models. Um,

00:17:50.060 --> 00:17:51.360
I've certainly had more of those in the

00:17:51.360 --> 00:17:51.740
last few

00:17:51.740 --> 00:17:53.720
batches than before, like whether it's sort of

00:17:53.720 --> 00:17:55.800
like a models run on edge devices or

00:17:55.800 --> 00:17:56.460
maybe like a voice

00:17:56.460 --> 00:17:59.520
model specific to a particular language. And I'm

00:17:59.520 --> 00:18:01.640
curious to see if that trend continues going

00:18:01.640 --> 00:18:01.860
back

00:18:01.860 --> 00:18:04.140
to this early era of YC. Actually, we

00:18:04.140 --> 00:18:06.040
sort of saw the explosion of just startups

00:18:06.040 --> 00:18:06.700
being created

00:18:06.700 --> 00:18:10.280
and maybe especially SaaS startups. Partly what, what,

00:18:10.400 --> 00:18:13.080
um, fed that was just knowledge about startups

00:18:13.080 --> 00:18:15.500
became more dispersed. There wasn't like a canon

00:18:15.500 --> 00:18:17.520
of library information on the internet about like

00:18:17.520 --> 00:18:18.900
how to start a startup, how to build

00:18:18.900 --> 00:18:21.320
software. And then over like a decade that

00:18:21.320 --> 00:18:21.920
just became more

00:18:21.920 --> 00:18:25.640
commonplace and that just exploded like society's knowledge

00:18:25.640 --> 00:18:27.100
of startups and how to build things.

00:18:27.440 --> 00:18:29.540
And it's maybe feels like maybe we're going

00:18:29.540 --> 00:18:31.300
through that moment in sort of the AI

00:18:31.300 --> 00:18:32.580
research

00:18:32.580 --> 00:18:35.680
meets like actually building things with, with training

00:18:35.680 --> 00:18:37.160
models. I think we are absolutely going

00:18:37.160 --> 00:18:39.080
through that right now. Yes. Like where it's

00:18:39.080 --> 00:18:41.340
going from being a very rare skill set

00:18:41.340 --> 00:18:42.220
to a more common

00:18:42.220 --> 00:18:44.320
one. Cause like open AI a decade ago,

00:18:44.500 --> 00:18:45.760
it was like a rare, like you needed,

00:18:45.900 --> 00:18:46.700
you need like a,

00:18:46.700 --> 00:18:49.400
a unique combination of skills, right? You need

00:18:49.400 --> 00:18:50.800
like your researcher brain,

00:18:50.800 --> 00:18:53.340
your sort of like engineering brain, maybe like

00:18:53.340 --> 00:18:55.560
your sort of finance business brain.

00:18:55.880 --> 00:18:57.960
Wait, wait, wait. So did you just describe

00:18:57.960 --> 00:19:00.580
Ilya, Greg, and Sam?

00:19:00.640 --> 00:19:01.060
You got it.

00:19:03.100 --> 00:19:04.960
That was like a rare team, right? There

00:19:04.960 --> 00:19:07.080
was, wasn't that configuration of team around very

00:19:07.080 --> 00:19:07.940
much. And now

00:19:07.940 --> 00:19:11.820
a decade later, there's like a plethora of

00:19:11.820 --> 00:19:14.260
people who have like the research background,

00:19:14.480 --> 00:19:17.940
the engineering background, um, the startup capital raising,

00:19:17.940 --> 00:19:19.660
um, background, or at least can be taught

00:19:19.660 --> 00:19:20.600
how to do all of that kind of

00:19:20.600 --> 00:19:22.700
stuff. And I'm curious if that would just

00:19:22.700 --> 00:19:23.820
mean we'll just see more

00:19:24.960 --> 00:19:28.180
applied AI company starting, and maybe there'll be

00:19:28.180 --> 00:19:30.440
like even more models to choose from for

00:19:30.440 --> 00:19:30.540
all

00:19:30.540 --> 00:19:32.560
the various specific tasks. I think so. I

00:19:32.560 --> 00:19:34.880
think the other thing that's even contributing and

00:19:34.880 --> 00:19:35.480
making

00:19:35.480 --> 00:19:39.260
this an even bigger snowball is because of

00:19:39.260 --> 00:19:41.620
RL. I think there's all these new open

00:19:41.620 --> 00:19:43.120
source models that

00:19:43.120 --> 00:19:46.060
people are doing the fine tune on top

00:19:46.060 --> 00:19:48.980
of it with a particular RL environment and

00:19:48.980 --> 00:19:51.060
task. So it is very

00:19:51.060 --> 00:19:55.280
possible that you can create the best domain

00:19:55.280 --> 00:19:59.220
specific, let's say, healthcare model trained on a

00:19:59.220 --> 00:20:02.020
generic open source model by just doing fine

00:20:02.020 --> 00:20:04.960
tuning on it and doing RL. It beats

00:20:04.960 --> 00:20:06.260
the regular big model.

00:20:06.260 --> 00:20:08.380
Actually, I've heard and seen a number of

00:20:08.380 --> 00:20:11.900
startups where their domain specific model beats, uh,

00:20:12.300 --> 00:20:12.500
open

00:20:12.500 --> 00:20:14.540
AI, let's say on healthcare. There's this particular

00:20:14.540 --> 00:20:16.740
YC startup that told me that they collected

00:20:16.740 --> 00:20:17.180
the best

00:20:17.180 --> 00:20:20.520
data set for, for healthcare and they ended

00:20:20.520 --> 00:20:22.620
up performing better than open AI and a

00:20:22.620 --> 00:20:22.840
lot of the

00:20:22.840 --> 00:20:25.580
benchmarks for, for healthcare with only 8 billion

00:20:25.580 --> 00:20:27.620
parameters. I guess what's funny is, uh, you

00:20:27.620 --> 00:20:27.920
do need

00:20:27.920 --> 00:20:30.360
to have a post-training infrastructure. You know,

00:20:30.400 --> 00:20:32.940
we've also had YC companies where, uh, they

00:20:32.940 --> 00:20:33.560
had something that

00:20:33.560 --> 00:20:36.060
beat open AI, uh, you know, GPT 3

00:20:36.060 --> 00:20:38.500
.5 and they were doing fine tuning with

00:20:38.500 --> 00:20:42.360
RL, but then, uh, yeah, GPT 4.5

00:20:42.360 --> 00:20:42.600
and

00:20:42.600 --> 00:20:45.920
then 5.1 came out and, uh, you

00:20:45.920 --> 00:20:48.000
know, basically blew their fine tuning out of

00:20:48.000 --> 00:20:49.240
the water. You have to keep

00:20:49.240 --> 00:20:51.160
going. Yeah. Yeah. You gotta keep going. Yeah.

00:20:51.240 --> 00:20:53.260
I mean, you actually have to continue to,

00:20:53.260 --> 00:20:54.560
uh, get to the

00:20:54.560 --> 00:20:57.260
edge. Anything else, uh, that really sort of

00:20:57.260 --> 00:21:00.060
stood out from this past year that jumps

00:21:00.060 --> 00:21:00.500
out to you?

00:21:00.500 --> 00:21:02.640
Uh, it's funny. We started the year with

00:21:02.640 --> 00:21:04.640
one of our episodes that got a lot

00:21:04.640 --> 00:21:05.460
of views around

00:21:05.460 --> 00:21:07.760
vibe coding. I think we were talking about

00:21:07.760 --> 00:21:10.060
it more as observing a behavior that was

00:21:10.060 --> 00:21:10.400
happening

00:21:10.400 --> 00:21:13.560
from our founders. And I was surprised to

00:21:13.560 --> 00:21:16.220
see that this became like a giant category.

00:21:16.400 --> 00:21:16.560
There's

00:21:16.560 --> 00:21:19.460
lots of companies that are winning. I mean,

00:21:19.540 --> 00:21:22.600
we have Replit, there's Emergence, there's a bunch

00:21:22.600 --> 00:21:22.900
of them.

00:21:22.900 --> 00:21:25.540
Varun Mohan had gone over to Google. He

00:21:25.540 --> 00:21:28.340
released anti-gravity. And, uh, did you guys

00:21:28.340 --> 00:21:28.960
see the video?

00:21:29.200 --> 00:21:30.640
I actually, I'm sort of curious whether they

00:21:30.640 --> 00:21:33.300
actually used nano banana or any of these

00:21:33.300 --> 00:21:33.860
video

00:21:33.860 --> 00:21:36.160
gen things. Cause it's like a little too

00:21:36.160 --> 00:21:38.180
perfect, but Google has the budget to do

00:21:38.180 --> 00:21:38.640
the high

00:21:38.640 --> 00:21:41.380
production value video, but it's, you know, Varun

00:21:41.380 --> 00:21:43.460
at the keyboard and then, you know,

00:21:43.940 --> 00:21:46.120
Sergey is like right behind him. So I

00:21:46.120 --> 00:21:48.120
was like, it was very cinematic. Anyway, I

00:21:48.120 --> 00:21:49.280
think Sundar was, uh,

00:21:49.280 --> 00:21:51.800
you know, also not only talking about, um,

00:21:52.600 --> 00:21:55.680
space data centers, uh, he was also talking

00:21:55.680 --> 00:21:56.180
about vibe

00:21:56.180 --> 00:21:58.280
coding and I knew that I was a

00:21:58.280 --> 00:22:00.980
little bit trolling back, but knowing what we

00:22:00.980 --> 00:22:02.600
know, I mean, yes, vibe

00:22:02.600 --> 00:22:06.620
coding is not, you know, completely usable and

00:22:06.620 --> 00:22:09.700
trustable for, uh, you know, a hundred percent

00:22:09.700 --> 00:22:10.380
of your

00:22:10.380 --> 00:22:13.520
coding period. Like this, you know, it is

00:22:13.520 --> 00:22:16.560
not true that you can like ship a

00:22:16.560 --> 00:22:17.780
hundred, a hundred percent

00:22:17.780 --> 00:22:21.600
solid production code today as of 2020 and

00:22:21.600 --> 00:22:22.540
the end of 2025.

00:22:23.120 --> 00:22:24.580
Yeah. I was thinking about things that surprised

00:22:24.580 --> 00:22:26.960
me in 2025. And I think perhaps the

00:22:26.960 --> 00:22:27.440
thing that most

00:22:27.440 --> 00:22:29.680
surprised me is the extent to which I

00:22:29.680 --> 00:22:32.480
feel like the AI economy stabilized. Like I

00:22:32.480 --> 00:22:33.120
feel like when we did

00:22:33.120 --> 00:22:35.300
this episode at the end of 2024, it

00:22:35.300 --> 00:22:36.600
felt like we were still in the middle

00:22:36.600 --> 00:22:37.520
of a period of incredibly

00:22:37.520 --> 00:22:39.060
rapid change where the ground was shifting under

00:22:39.060 --> 00:22:41.300
our feet and like nobody knew when the

00:22:41.300 --> 00:22:41.660
other shoe

00:22:41.660 --> 00:22:43.640
might drop and like what exactly was going

00:22:43.640 --> 00:22:45.140
to happen with startups and AI and the

00:22:45.140 --> 00:22:46.140
economy. Now I feel like

00:22:46.140 --> 00:22:48.240
we've kind of settled into like a fairly

00:22:48.240 --> 00:22:50.380
stable AI economy where we have like the

00:22:50.380 --> 00:22:50.760
model layer

00:22:50.760 --> 00:22:52.980
companies and the application layer companies and seem,

00:22:53.140 --> 00:22:54.420
and the infrastructure layer companies,

00:22:54.580 --> 00:22:55.600
it seems like everyone is going to make

00:22:55.600 --> 00:22:57.540
a lot of money and there's kind of

00:22:57.540 --> 00:22:58.860
like a relative playbook

00:22:58.860 --> 00:23:00.540
for how to build an AI native company

00:23:00.540 --> 00:23:02.100
on top of the models. I feel like

00:23:02.100 --> 00:23:03.440
things really kind of matured

00:23:03.440 --> 00:23:05.080
in that way. Which feels it's all downstream

00:23:05.080 --> 00:23:07.560
of like the models themselves have incrementally

00:23:07.560 --> 00:23:09.740
improved this year, but there haven't been like

00:23:09.740 --> 00:23:12.040
major steps forward that have shaken everything up,

00:23:12.040 --> 00:23:13.820
which is, has a knock on effect. Many

00:23:13.820 --> 00:23:15.420
episodes ago, we talked about how it was

00:23:15.420 --> 00:23:16.600
felt easier than

00:23:16.600 --> 00:23:18.280
ever to pivot and find a startup idea.

00:23:18.480 --> 00:23:20.300
Because if you could just survive, if you

00:23:20.300 --> 00:23:20.980
just wait a few

00:23:20.980 --> 00:23:22.520
months, there was likely going to be some

00:23:22.520 --> 00:23:25.180
like big announcement that would completely make a

00:23:25.180 --> 00:23:25.440
new set

00:23:25.440 --> 00:23:28.020
of ideas possible and create more opportunities to

00:23:28.020 --> 00:23:30.540
build things. It certainly feels like that has

00:23:30.540 --> 00:23:32.900
slowed down. And so like finding ideas is

00:23:32.900 --> 00:23:35.380
sort of returning to sort of normal levels

00:23:35.380 --> 00:23:35.920
of difficulty,

00:23:35.920 --> 00:23:37.680
in my experience, not for hours. I agree.

00:23:37.880 --> 00:23:40.180
I'll tell you what's not a surprise. Do

00:23:40.180 --> 00:23:40.520
you remember

00:23:40.520 --> 00:23:43.580
that report, AI 2027, where it was just

00:23:43.580 --> 00:23:45.460
sort of like this doomer piece that said

00:23:45.460 --> 00:23:46.220
like, oh, well,

00:23:46.380 --> 00:23:47.960
society is going to start falling apart in

00:23:47.960 --> 00:23:50.300
2027. But, you know, at some point, they

00:23:50.300 --> 00:23:51.500
quietly revised it

00:23:51.500 --> 00:23:53.820
to say that it wasn't 2027, but they

00:23:53.820 --> 00:23:55.760
kept the title. Maybe it's not a surprise.

00:23:56.020 --> 00:23:57.000
Like I was always a

00:23:57.000 --> 00:23:59.740
little bit of a skeptic of like this

00:23:59.740 --> 00:24:03.360
fast takeoff argument, because even with the scaling

00:24:03.360 --> 00:24:04.340
law, it is

00:24:04.340 --> 00:24:09.000
log linear. So it is slower, it requires

00:24:09.000 --> 00:24:12.140
like 10x more compute, and it's still sort

00:24:12.140 --> 00:24:13.040
of, you know,

00:24:13.180 --> 00:24:16.040
topping out, right. And that's one form of

00:24:16.040 --> 00:24:18.520
good news. Another form of it's weird to

00:24:18.520 --> 00:24:19.100
call this good

00:24:19.100 --> 00:24:23.280
news, but human beings don't like change. In

00:24:23.280 --> 00:24:25.220
our previous episode, where we sort of blew

00:24:25.220 --> 00:24:25.740
up that

00:24:26.340 --> 00:24:28.620
MIT report that said that, you know, 98

00:24:28.620 --> 00:24:32.520
% or 90% of enterprise AI projects

00:24:32.520 --> 00:24:33.880
fail. Well, it turns out that

00:24:33.880 --> 00:24:37.400
90% of enterprises don't know how to

00:24:37.400 --> 00:24:40.540
do, you know, IT, let alone AI. It's

00:24:40.540 --> 00:24:41.280
weird to say that

00:24:41.280 --> 00:24:42.780
that's a good thing. But in the context

00:24:42.780 --> 00:24:44.780
of fast takeoff, like, that is a real

00:24:44.780 --> 00:24:46.940
break on the ability

00:24:46.940 --> 00:24:50.480
of this new, really insane technology from actually

00:24:50.480 --> 00:24:53.300
permeating society. I love to accelerate, but like,

00:24:53.400 --> 00:24:55.580
it's weird to say, like, oh, well, actually,

00:24:55.660 --> 00:24:57.080
in this case, maybe that's a good thing,

00:24:57.220 --> 00:24:57.640
right? Like,

00:24:57.640 --> 00:25:01.680
it is a shockingly powerful technology. But, you

00:25:01.680 --> 00:25:03.760
know, between being log linear scaling,

00:25:04.020 --> 00:25:07.620
and human beings really don't like change, like

00:25:07.620 --> 00:25:10.980
organizationally speaking, society will absorb

00:25:10.980 --> 00:25:14.160
this technology, everyone will have enough time to

00:25:14.160 --> 00:25:16.880
sort of process it, like culture will catch

00:25:16.880 --> 00:25:17.240
up,

00:25:17.420 --> 00:25:19.620
governments will be able to respond to it,

00:25:19.860 --> 00:25:23.120
not in like a frantic SB 1047 sort

00:25:23.120 --> 00:25:24.320
of like, you know,

00:25:24.320 --> 00:25:26.220
let's stop all the compute past 10 to

00:25:26.220 --> 00:25:28.700
the 26, right? Like just these knee jerk

00:25:28.700 --> 00:25:29.400
responses

00:25:29.980 --> 00:25:33.860
to technology. We're excited about the Arc AGI

00:25:33.860 --> 00:25:36.340
prize is, you know, going to come in

00:25:36.340 --> 00:25:36.760
and do the

00:25:36.760 --> 00:25:39.580
winter 26 batch as a nonprofit. The funny

00:25:39.580 --> 00:25:41.620
thing about that is like, yeah, maybe there's

00:25:42.160 --> 00:25:45.060
a team right now that is climbing the

00:25:45.060 --> 00:25:47.680
leaderboard of Arc AGI, and they're going to

00:25:47.680 --> 00:25:48.400
accelerate this

00:25:48.400 --> 00:25:48.880
thing again.

00:25:48.880 --> 00:25:50.840
Something that surprised me to relate to that

00:25:50.840 --> 00:25:52.300
with the startups is I remember around this

00:25:52.300 --> 00:25:52.580
time last

00:25:52.580 --> 00:25:54.580
year, we were talking about how companies are

00:25:54.580 --> 00:25:56.240
getting to a million dollars ARR and raising

00:25:56.240 --> 00:25:56.560
series

00:25:56.560 --> 00:25:58.720
A's without hiring, like some cases, not hiring

00:25:58.720 --> 00:26:00.980
anyone, just the founders, maybe hiring one person,

00:26:00.980 --> 00:26:04.040
which just felt very unusual. I feel like

00:26:04.040 --> 00:26:08.560
a year on, that hasn't translated into, okay,

00:26:08.640 --> 00:26:10.100
and then they went and hit like 10

00:26:10.100 --> 00:26:13.320
million ARR, or they scaled without adding any

00:26:13.320 --> 00:26:14.120
more people to.

00:26:14.120 --> 00:26:16.980
No, they turned around and started hiring like

00:26:16.980 --> 00:26:17.500
actual teams.

00:26:17.720 --> 00:26:20.540
Yeah. Like post series A, it actually largely

00:26:20.540 --> 00:26:23.680
feels like the playbook is the same and

00:26:23.680 --> 00:26:24.640
the companies

00:26:24.640 --> 00:26:26.760
might be smaller for the same amount of

00:26:26.760 --> 00:26:29.560
revenue, but it feels it's entirely because they

00:26:29.560 --> 00:26:29.880
hit the

00:26:29.880 --> 00:26:32.060
revenue so fast and there's still just bottlenecked

00:26:32.060 --> 00:26:33.480
on how long it takes to hire people

00:26:33.480 --> 00:26:34.400
versus they

00:26:34.400 --> 00:26:35.600
have demand for less people.

00:26:35.800 --> 00:26:37.500
I still think there is like, you know,

00:26:37.580 --> 00:26:39.920
some effect, but it is not like open

00:26:39.920 --> 00:26:41.540
and shut. It is not like you

00:26:41.540 --> 00:26:43.840
don't have to hire executives anymore. I think

00:26:43.840 --> 00:26:45.720
they're like, there might be a case of

00:26:45.720 --> 00:26:46.780
two foie

00:26:46.780 --> 00:26:49.720
gras startups, like one being Harvey and the

00:26:49.720 --> 00:26:52.020
other one being open evidence, right? Harvey,

00:26:52.300 --> 00:26:55.200
the founders are incredible. They were very early.

00:26:55.200 --> 00:26:57.480
And then there's this sort of idea of

00:26:57.480 --> 00:26:57.740
like,

00:26:58.000 --> 00:26:59.920
for VCs, you could just go down Sand

00:26:59.920 --> 00:27:02.100
Hill Road and like the fixes in, like

00:27:02.100 --> 00:27:03.260
you just sort of block out

00:27:03.260 --> 00:27:04.800
all of them. And then all the people,

00:27:05.000 --> 00:27:07.420
you know, maybe 30 people who could write

00:27:07.420 --> 00:27:08.860
checks of like 10 to

00:27:08.860 --> 00:27:10.480
a hundred million dollars. And if you just

00:27:10.480 --> 00:27:12.260
sort of get all of their money, like

00:27:12.260 --> 00:27:12.980
there's sort of no

00:27:12.980 --> 00:27:15.260
one who can actually come in and do

00:27:15.260 --> 00:27:17.440
the next series A, and then basically you're

00:27:17.440 --> 00:27:17.980
safe. Like

00:27:17.980 --> 00:27:20.060
you have capital as a bludgeon is capital

00:27:20.060 --> 00:27:21.980
as a moat in that case, right? So

00:27:21.980 --> 00:27:22.960
yeah, Harvey is interesting

00:27:22.960 --> 00:27:25.380
because, you know, uh, Lagora is coming fast

00:27:25.380 --> 00:27:27.900
for them. And obviously we have some skin

00:27:27.900 --> 00:27:28.280
in the game

00:27:28.280 --> 00:27:30.000
on Lagora, but we think that they have,

00:27:30.100 --> 00:27:32.120
uh, as good a shot at any, I

00:27:32.120 --> 00:27:33.160
guess that's one trend that we saw

00:27:33.160 --> 00:27:34.720
in 2025 is that there was like a

00:27:34.720 --> 00:27:37.000
first wave of like AI hate of companies

00:27:37.000 --> 00:27:37.840
like Harvey.

00:27:38.160 --> 00:27:39.480
Who might've wasted a lot of money on

00:27:39.480 --> 00:27:40.420
fine tuning actually.

00:27:40.980 --> 00:27:42.960
Totally. That like broke out really big in

00:27:42.960 --> 00:27:45.240
2023 and kind of did a victory lap

00:27:45.240 --> 00:27:45.680
that, you know,

00:27:45.780 --> 00:27:47.640
oh, we've won the space. And now we're

00:27:47.640 --> 00:27:49.660
seeing a second wave of companies like Lagora

00:27:49.660 --> 00:27:50.300
and Giga.

00:27:50.400 --> 00:27:51.780
And it turns out that like, oh, actually

00:27:51.780 --> 00:27:53.940
like it isn't so simple.

00:27:54.180 --> 00:27:56.860
Yeah. The wood beneficiary of, um, you know,

00:27:57.100 --> 00:28:00.720
burning some non-trivial double-digit percentage of

00:28:00.720 --> 00:28:03.640
your capital stack on fine tuning that buys,

00:28:03.640 --> 00:28:06.220
you know, advantage is like basically the investors

00:28:06.220 --> 00:28:07.840
are the only winners there because they just

00:28:07.840 --> 00:28:09.140
own more of your company, you know?

00:28:09.600 --> 00:28:10.740
Yeah. So at least it relates to like

00:28:10.740 --> 00:28:12.760
the, the hiring and team size. I feel

00:28:12.760 --> 00:28:13.160
like

00:28:13.160 --> 00:28:15.960
of the two camps, one being the AI

00:28:15.960 --> 00:28:17.100
is going to make everything more efficient. You

00:28:17.100 --> 00:28:17.500
will need less

00:28:17.500 --> 00:28:19.840
people and the other AI is going to

00:28:19.840 --> 00:28:21.960
reduce the cost of like producing the time

00:28:21.960 --> 00:28:22.580
to produce things.

00:28:22.740 --> 00:28:25.040
And so then the expectations from your users

00:28:25.040 --> 00:28:26.560
and customers will just go up and you'll

00:28:26.560 --> 00:28:26.760
need to

00:28:26.760 --> 00:28:28.680
keep hiring more people to satisfy like the

00:28:28.680 --> 00:28:29.560
growing expectations.

00:28:29.560 --> 00:28:31.640
I feel like this year has been more

00:28:31.640 --> 00:28:33.740
in that second camp. And I think that

00:28:33.740 --> 00:28:34.880
is what's driving the fact

00:28:34.880 --> 00:28:36.380
that the companies are still just hiring as

00:28:36.380 --> 00:28:38.840
many people as they were pre AI. It's

00:28:38.840 --> 00:28:39.480
just like the bar

00:28:39.480 --> 00:28:41.320
for what the software, what their customers expect.

00:28:41.760 --> 00:28:42.900
And they're all in the, you know, like

00:28:42.900 --> 00:28:43.660
Lagora's

00:28:43.660 --> 00:28:46.620
racing with Harvey, Giga's racing with Sierra. Like

00:28:46.620 --> 00:28:49.140
they're all still competing for the same set

00:28:49.140 --> 00:28:49.240
of

00:28:49.240 --> 00:28:51.720
customers and they still ultimately are bottlenecked on

00:28:51.720 --> 00:28:54.940
like people and like, I don't think anyone's

00:28:54.940 --> 00:28:56.700
bottlenecked on ideas, but they're bottlenecked on like

00:28:56.700 --> 00:28:58.140
people who can execute really well.

00:28:58.140 --> 00:28:59.560
I don't know. I think that's like, so

00:28:59.560 --> 00:29:01.260
it's exciting. It feels like an exciting phase.

00:29:01.420 --> 00:29:04.240
I agree with you that like the era

00:29:04.240 --> 00:29:07.340
of the one person running a trillion dollar

00:29:07.340 --> 00:29:08.340
company is not

00:29:08.340 --> 00:29:09.200
here. Not yet.

00:29:09.460 --> 00:29:10.980
Yeah. But I think it's going to trend

00:29:10.980 --> 00:29:13.320
that way eventually. That'll be a wild time.

00:29:13.640 --> 00:29:14.040
Maybe that's

00:29:14.040 --> 00:29:15.600
a prediction for... For next year?

00:29:15.680 --> 00:29:16.600
...2026. Yeah.

00:29:16.720 --> 00:29:17.300
Do you think it's coming?

00:29:17.300 --> 00:29:18.660
I mean, I don't think it'll happen in

00:29:18.660 --> 00:29:20.900
2026 either, honestly. I mean, I think you

00:29:20.900 --> 00:29:21.400
will have

00:29:21.400 --> 00:29:25.260
many stories of companies run by, you know,

00:29:25.420 --> 00:29:27.360
under a hundred people that are making hundreds

00:29:27.360 --> 00:29:27.560
of

00:29:27.560 --> 00:29:28.600
millions of dollars. Yeah.

00:29:28.600 --> 00:29:31.060
So, I mean, Gamma was interesting to see.

00:29:31.200 --> 00:29:33.200
Like one of the biggest things that they

00:29:33.200 --> 00:29:34.060
said in their launch

00:29:34.060 --> 00:29:35.680
that I think is a very good trend

00:29:35.680 --> 00:29:37.300
is they said they got to a hundred

00:29:37.300 --> 00:29:40.120
million dollars in ARR with

00:29:40.120 --> 00:29:42.660
only 50 employees. So, which is very different.

00:29:42.940 --> 00:29:44.800
It's, you know, such an inversion, right? Like

00:29:44.800 --> 00:29:47.400
normally you have the big banner and the

00:29:47.400 --> 00:29:49.840
like little X thing, you know, image. And

00:29:49.840 --> 00:29:50.660
it's like, oh yeah,

00:29:50.800 --> 00:29:52.700
like we raised all this money and look

00:29:52.700 --> 00:29:54.240
at all the people who work for us.

00:29:54.240 --> 00:29:56.500
It's a good trend to have the reverse

00:29:56.500 --> 00:29:58.220
flex, which is like, look at all this

00:29:58.220 --> 00:29:59.360
revenue and look how few

00:29:59.360 --> 00:30:01.340
people work for us. Well, that's all we

00:30:01.340 --> 00:30:03.520
have time for this time. We just wanted

00:30:03.520 --> 00:30:04.060
to wish you

00:30:04.060 --> 00:30:06.220
a really happy holidays and happy new year

00:30:06.220 --> 00:30:08.180
from all of us to you and yours.

00:30:08.460 --> 00:30:09.260
See you next time.
