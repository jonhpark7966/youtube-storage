WEBVTT

00:00:04.880 --> 00:00:08.160
그럼 더 지체하지 않고 시작하겠습니다. 오늘은,

00:00:08.220 --> 00:00:10.560
제가 로봇에 관한 연구를 말씀드리겠습니다.

00:00:10.560 --> 00:00:13.720
물리 기반 PDE 사전지식을 활용한 모션 러닝에 대해 말씀드리겠습니다.

00:00:15.600 --> 00:00:18.360
그래서 먼저, 그러니까, 무엇이

00:00:18.360 --> 00:00:21.400
모션 플래닝의 문제인지 소개드리겠습니다. 그리고 모션 플래닝은

00:00:21.400 --> 00:00:23.760
에이전트가 조정하는 방법입니다.

00:00:23.760 --> 00:00:26.320
주어진 시작점에서

00:00:26.320 --> 00:00:28.820
주어진 목표까지 모든 원하는 제약을 만족시키면서 행동을 조정하는 것입니다.

00:00:28.820 --> 00:00:32.740
그래서 동적 시스템이나 로봇이

00:00:32.740 --> 00:00:35.440
움직일 필요가 있을 때마다, 이 문제를 풀어야 합니다.

00:00:35.440 --> 00:00:37.700
즉, 이 모션 플래닝 문제를요, 알겠죠?

00:00:38.080 --> 00:00:40.340
그리고 이것에는 응용이 있는데, 또는 이것들이

00:00:40.340 --> 00:00:42.840
제 연구실이 집중하는 응용들인데요, 예를 들면

00:00:42.840 --> 00:00:45.180
전신 모션 플래닝부터 시작합니다.

00:00:45.400 --> 00:00:48.500
여기에는 이동 로봇이 있는데, 이동 로봇, 일반적인

00:00:48.500 --> 00:00:51.000
로봇입니다. 어떤 물체를

00:00:51.000 --> 00:00:52.560
주어진 시작점에서 주어진 목표로 옮기고 있습니다.

00:00:52.560 --> 00:00:55.840
그다음, 우리는 이 문제를 동적인

00:00:55.840 --> 00:00:59.600
환경에서도 푸는데, 로봇 앞에 장애물을 동적으로

00:00:59.600 --> 00:01:00.560
배치합니다.

00:01:01.000 --> 00:01:04.240
또 다른 분야로, 우리가 매우 기대하고 관심을 갖고

00:01:04.240 --> 00:01:06.380
있는 것은 반응형 조작입니다.

00:01:06.620 --> 00:01:09.260
로봇이 제약 하에서 조작 플래닝 문제를 풀 때,

00:01:09.260 --> 00:01:12.000
어떤 교란을 경험할 수 있습니다.

00:01:12.000 --> 00:01:15.920
로봇이 그 교란에 어떻게 동적으로 적응하고

00:01:15.920 --> 00:01:17.760
할당된 과제를 계속 수행할 수 있을까요?

00:01:19.840 --> 00:01:22.540
마지막으로, 우리는 또한 탐구하고 있습니다.

00:01:22.560 --> 00:01:26.340
이 모션 플래닝 도구들을 반응형 다중

00:01:26.340 --> 00:01:28.300
에이전트 플래닝에 적용하는 것으로, 많은 수의

00:01:28.300 --> 00:01:28.700
에이전트가 있고,

00:01:28.720 --> 00:01:31.940
그들이 할당된 과제를 수행하다가, 그리고 나서

00:01:31.940 --> 00:01:34.840
서로 충돌하는 것을 반응적으로 피해야 합니다.

00:01:34.840 --> 00:01:35.280
서로요.

00:01:35.980 --> 00:01:40.620
그래서 이런 모든 문제들 전반에 걸쳐, 핵심

00:01:40.620 --> 00:01:43.460
쟁점은 이 모션 플래닝

00:01:43.460 --> 00:01:43.780
문제들을 어떻게 푸느냐입니다.

00:01:43.880 --> 00:01:45.840
어떻게 도구를 만들어낼 것이냐,

00:01:45.840 --> 00:01:51.040
효율적인 도구를요. 그리고 제 연구실의 초점은

00:01:51.040 --> 00:01:53.820
이런 도구들을 실제로 사용할 수 있게 개발하는 것입니다.

00:01:53.820 --> 00:01:54.120
실시간으로

00:01:54.120 --> 00:01:57.420
로봇 움직임의 실시간 조정을 가능하게 하는

00:01:57.420 --> 00:02:01.200
비정형적이고 제약된 환경에서 최소한의 사전 훈련

00:02:01.200 --> 00:02:02.000
또는 시행착오로 작동하는 것입니다.

00:02:02.460 --> 00:02:05.680
저는 이 목표를 해결하거나 달성하기 위해

00:02:05.680 --> 00:02:07.280
꽤 오랜 시간 동안 노력해 왔습니다.

00:02:07.520 --> 00:02:10.220
학부 시절, 저는 샘플링 기반

00:02:10.220 --> 00:02:13.620
모션 계획 방법으로 시작했고, 제 초점은

00:02:13.620 --> 00:02:16.140
적응형 샘플링 기법을 개발하는 것이었습니다.

00:02:16.140 --> 00:02:18.960
이 샘플링 기반 방법들이

00:02:18.960 --> 00:02:20.700
트리를 가능한 빨리 구성할 수 있도록 하기 위해서입니다.

00:02:20.700 --> 00:02:22.800
그러면 그 트리의 한 가지가 여러분의

00:02:22.800 --> 00:02:24.560
시작점과 목표점 사이의 경로 해가 됩니다.

00:02:25.320 --> 00:02:29.420
그리고 박사 과정 동안 저는

00:02:29.420 --> 00:02:33.220
이 방법들을 데이터 기반 접근법으로 확장하는 방향으로 나아갔습니다.

00:02:33.460 --> 00:02:36.140
그러니까, 고전적인 샘플링 기반 방법의 문제는

00:02:36.140 --> 00:02:39.160
그 기법들이 계산적으로 매우 느렸다는 점이었습니다.

00:02:39.320 --> 00:02:41.680
로봇의 차원이 증가하면, 예를 들어

00:02:41.680 --> 00:02:44.560
사람의, 음, 동작을 계획한다든지

00:02:44.560 --> 00:02:45.000
인간형 로봇의 경우,

00:02:45.160 --> 00:02:46.880
자유도가 엄청나게 큽니다.

00:02:46.880 --> 00:02:49.720
그런 종류의 시스템에서는 계산 시간이

00:02:49.720 --> 00:02:50.940
매우 느려졌습니다.

00:02:51.040 --> 00:02:53.460
그래서 실시간으로 할 수 있는

00:02:53.460 --> 00:02:56.600
응용을 많이 할 수가 없었습니다. 느린 계산 속도 때문에

00:02:56.600 --> 00:02:57.060
그런 방법들 말입니다.

00:02:57.180 --> 00:03:00.560
그다음 저는 데이터 기반 접근으로 옮겨갔습니다.

00:03:02.020 --> 00:03:05.120
2018년이나 2019년쯤에는, 그 이전에는, 많은

00:03:05.120 --> 00:03:07.340
사람들이 모션 계획 문제를 풀려고 했는데

00:03:07.340 --> 00:03:08.940
이런, 음, 신경망으로 말입니다,

00:03:08.980 --> 00:03:12.000
하지만 한 가지 핵심 요소가 빠져 있었습니다.

00:03:12.000 --> 00:03:14.300
그리고 이, 이 논문들에서 저는

00:03:14.300 --> 00:03:18.080
신경망만 갖고서는 충분하지 않다는

00:03:18.080 --> 00:03:18.540
처방을 제시했습니다.

00:03:18.540 --> 00:03:21.240
예를 들어 모방 학습을 해도,

00:03:21.240 --> 00:03:21.940
여전히 학습이 되지 않습니다.

00:03:22.100 --> 00:03:24.720
이런 모델에는 확률성이 필요합니다.

00:03:24.780 --> 00:03:27.600
그리고 확률성은 여러 방식으로 포함할 수 있습니다.

00:03:27.900 --> 00:03:29.920
저희 연구에서는 드롭아웃을 사용했습니다.

00:03:30.360 --> 00:03:33.220
그다음 사람들은 그 아이디어를 받아들여, 옮겨가서

00:03:33.220 --> 00:03:35.000
변분 오토인코더를 사용하는 쪽으로 갔습니다.

00:03:35.060 --> 00:03:36.800
이제는 확산 모델을 사용합니다.

00:03:36.980 --> 00:03:38.960
그것들은, 그것들은 어떤 형태로든 확률성이 있습니다.

00:03:38.960 --> 00:03:42.120
어떤 노이즈에서 시작해서 그다음 디노이즈를

00:03:42.120 --> 00:03:42.760
시간에 따라 수행합니다.

00:03:42.920 --> 00:03:45.820
그래서 어떤 형태의 무작위성이 포함되어

00:03:45.820 --> 00:03:48.940
과정에 포함되어 이 모델들이 계획하게

00:03:48.940 --> 00:03:49.980
동작을 계획하도록 도와줍니다.

00:03:50.340 --> 00:03:53.100
그래서 핵심 처방은, 신경망이 필요하다는 것입니다.

00:03:53.100 --> 00:03:53.440
그리고요.

00:03:53.620 --> 00:03:55.820
또 어떤 형태의, 음,

00:03:56.000 --> 00:03:58.780
과정에 확률성이 필요합니다. 그래서, 음,

00:03:59.260 --> 00:04:01.860
신경망은, 해를 근사하고 있기 때문에,

00:04:01.860 --> 00:04:03.980
국소 최소값에 빠질 수 있습니다.

00:04:03.980 --> 00:04:06.820
노이즈 제거 과정이 있거나 여러 개의

00:04:06.820 --> 00:04:08.700
음, 시드로 시작하게 됩니다.

00:04:09.000 --> 00:04:11.580
기본적으로 이 신경망들이

00:04:11.580 --> 00:04:12.780
국소 최솟값에서 벗어나도록 돕습니다.

00:04:12.980 --> 00:04:13.520
알겠습니까?

00:04:13.920 --> 00:04:16.720
하지만 이 모델들에 대한 제 주요 문제는

00:04:16.900 --> 00:04:20.120
훈련 비용이었습니다.

00:04:20.400 --> 00:04:23.260
오프라인에서, 우리는 이런

00:04:23.260 --> 00:04:25.480
고전적인 방법들을 실행해서 모든 데이터를 수집해야 했습니다.

00:04:25.480 --> 00:04:28.560
그리고 그 데이터로 이 모델들을

00:04:28.560 --> 00:04:29.460
훈련시켰습니다.

00:04:29.700 --> 00:04:32.080
그리고 네, 추론 시에는 빠른

00:04:32.080 --> 00:04:32.440
추론을 제공했습니다.

00:04:33.160 --> 00:04:35.660
하지만 생각해보면, 이것들이 정말로

00:04:35.660 --> 00:04:39.180
이 방법들의, 음, 느린 계산 속도를

00:04:39.560 --> 00:04:42.480
극복하고 있었을까요?

00:04:42.580 --> 00:04:44.520
훈련 시간을 더하면

00:04:44.520 --> 00:04:47.160
또는 데이터를 얻는 데 소요된 시간을

00:04:47.160 --> 00:04:48.980
추론 시간과 합치면

00:04:48.980 --> 00:04:51.120
실제로 이득이 되지 않는다고 생각할 수 있습니다.

00:04:51.120 --> 00:04:53.680
그래서 제가 퍼듀 대학교에서 교수로

00:04:53.680 --> 00:04:56.360
시작했을 때, 저는 전문가 시연 없이

00:04:56.360 --> 00:04:59.920
이 신경망들을 훈련시키는 다른 방법을 찾기 시작했습니다.

00:05:00.820 --> 00:05:03.460
그리고 제 연구실이 집중하는

00:05:03.460 --> 00:05:04.060
세 가지 특징이 있습니다.

00:05:04.240 --> 00:05:05.600
예를 들어, 하나는 추론 효율성입니다.

00:05:05.880 --> 00:05:08.240
저는 즉시 실행이 가능하도록 하는 방법을 개발하고 싶습니다.

00:05:08.240 --> 00:05:10.760
즉, 계획을 가능한 한 빠르게 추론하도록 하는 것입니다.

00:05:11.620 --> 00:05:13.900
그다음 우리가 찾는 두 번째 특성은

00:05:13.900 --> 00:05:14.680
학습 효율성입니다.

00:05:14.680 --> 00:05:17.700
모델 학습 비용을 줄이고 싶습니다.

00:05:17.840 --> 00:05:20.080
전문가, 즉 전문가의 필요성을 없애고 싶습니다.

00:05:20.080 --> 00:05:20.820
주석 작업을 말입니다.

00:05:21.440 --> 00:05:23.560
그리고 이는 셀룰러 전이 가능성입니다.

00:05:23.820 --> 00:05:26.940
예를 들어, 지금은 누군가와 이야기할 때마다,

00:05:26.940 --> 00:05:28.700
모방 학습을 하거나

00:05:28.700 --> 00:05:30.560
아주 큰 모델을 학습시키는 사람에게는 두 번째 질문이

00:05:30.560 --> 00:05:30.980
늘 나오는데요,

00:05:31.280 --> 00:05:33.820
다른 환경이나

00:05:33.820 --> 00:05:34.660
처음 보는 환경으로 전이할 수 있느냐는 것입니다.

00:05:34.720 --> 00:05:36.840
왜냐하면 문제는, 다른 환경으로 옮기면

00:05:36.840 --> 00:05:37.800
환경이 달라질 때

00:05:37.800 --> 00:05:40.120
모든 데이터를 다시

00:05:40.120 --> 00:05:40.380
수집해야 할 수도 있기 때문입니다.

00:05:40.380 --> 00:05:43.240
하지만 학습 비용이 매우 낮은

00:05:43.240 --> 00:05:44.440
모델이 있고,

00:05:44.620 --> 00:05:47.340
전문가 시연의 필요를 없애 준다면,

00:05:47.740 --> 00:05:50.060
그 모델을 매우 쉽게 전이해서

00:05:50.060 --> 00:05:51.720
새로운 도메인으로 가져갈 수 있습니다.

00:05:52.740 --> 00:05:54.540
세 번째로, 매우 중요한 특성이 있습니다.

00:05:54.740 --> 00:05:56.400
예를 들어, 우리는 이런 모델을

00:05:56.400 --> 00:05:59.160
높은 자유도에 적응하도록 설계하고 싶고,

00:05:59.340 --> 00:06:03.020
매우 복잡한 구조, 미지의 환경, 또는, 음, 매우

00:06:03.020 --> 00:06:03.860
복잡한 제약조건에도요.

00:06:03.900 --> 00:06:06.580
예컨대, 음, 조작 문제에 수반되는 제약조건 같은 것들입니다.

00:06:06.580 --> 00:06:08.940
또한 아주 많은 수의 에이전트로도 확장되어야 해서

00:06:08.940 --> 00:06:10.800
여러 대의 로봇을 배치해

00:06:10.800 --> 00:06:11.860
운용할 수 있어야 합니다.

00:06:11.860 --> 00:06:13.660
음, 주어진 환경에서 말입니다.

00:06:13.800 --> 00:06:15.740
그렇게 하면 어떤 작업을

00:06:15.740 --> 00:06:19.000
협조적으로, 또는 분산 방식으로 해결할 수 있습니다.

00:06:20.700 --> 00:06:23.640
그래서 개괄적으로 말씀드리면, 이런 특성들의 관점에서

00:06:23.640 --> 00:06:25.520
현재 우리가 어디에 서 있는지 보면요.

00:06:25.880 --> 00:06:28.320
우리는 최적화 기반 기법을 가지고 있습니다.

00:06:29.300 --> 00:06:33.700
그리고 이 기법들은 높은 추론 효율성을 가지고 있습니다.

00:06:33.920 --> 00:06:36.220
우리는 아주 좋은 최적화 기반 도구들을 가지고 있어서

00:06:36.220 --> 00:06:39.520
궤적을 매우 효율적으로 찾을 수 있습니다.

00:06:39.520 --> 00:06:42.480
매우 높은, 음, 훈련 효율성을 가지고 있습니다.

00:06:42.480 --> 00:06:44.800
최적화기를 다시, 사전 훈련할

00:06:44.800 --> 00:06:45.500
필요가 없습니다.

00:06:45.700 --> 00:06:48.200
하지만 매우 복잡한 시나리오에는

00:06:48.200 --> 00:06:48.480
적응하지 못합니다.

00:06:48.600 --> 00:06:51.180
국소 최솟값에 빠지기 쉽고

00:06:51.180 --> 00:06:52.460
자주 거기에 갇힐 수 있습니다.

00:06:52.460 --> 00:06:56.600
그 다음으로, 로봇 계획 및 제어 문제를 해결하기 위한

00:06:56.600 --> 00:06:59.040
고전적인 도구들이 있습니다.

00:06:59.240 --> 00:07:02.820
이산화 기반 접근법이 있습니다.

00:07:03.000 --> 00:07:04.560
A*를 아실 것입니다. 아셔야 합니다.

00:07:04.720 --> 00:07:07.280
그리고 샘플링 기반 접근법도 있습니다.

00:07:07.580 --> 00:07:10.380
제어 분야에는 다른 고전적 도구들도 있습니다, 예를 들어

00:07:10.380 --> 00:07:13.240
랜덤 슈팅 방법과 그런 기법들이 있습니다.

00:07:13.240 --> 00:07:18.580
이 방법들은 낮은 훈련 효율성을, 음,

00:07:18.780 --> 00:07:20.460
높은 훈련 효율성을 가지고 있습니다.

00:07:20.640 --> 00:07:21.940
훈련할 필요가 없습니다.

00:07:22.440 --> 00:07:24.800
하지만 추론 효율성은 매우 느립니다.

00:07:25.060 --> 00:07:27.960
이 방법들은 전체 공간을 이산화하거나

00:07:27.960 --> 00:07:30.080
그래프를 구성해야 하기 때문입니다.

00:07:30.220 --> 00:07:32.440
그리고 그것을 통해 경로를 찾아야 합니다.

00:07:32.880 --> 00:07:35.740
최근의 발전으로, 제가 인정해야 할 점은 사람들이

00:07:35.740 --> 00:07:37.980
이런 방법들에서 대규모

00:07:37.980 --> 00:07:41.000
병렬화를 어떻게 활용해 속도를 높일 수 있는지

00:07:41.000 --> 00:07:41.460
탐구하고 있다는 것입니다.

00:07:41.460 --> 00:07:43.580
하지만 여전히 우리는

00:07:43.580 --> 00:07:47.780
이런 방법들이 복잡한, 어, 운동학적

00:07:47.780 --> 00:07:48.240
제약을 어떻게 다루는지 지켜봐야 합니다.

00:07:49.220 --> 00:07:51.780
그다음에는 모방학습 같은 데이터 기반 접근이나

00:07:51.780 --> 00:07:53.900
강화학습이 있습니다.

00:07:54.200 --> 00:07:56.600
이들은, 어, 학습 효율이

00:07:56.600 --> 00:07:57.840
매우 낮다는 것을 알고 있습니다.

00:07:58.160 --> 00:08:01.000
하지만 한 번 학습되면 추론 효율은 매우

00:08:01.000 --> 00:08:01.260
높습니다.

00:08:01.380 --> 00:08:04.000
그리고 매우 복잡한 시나리오에도 적응합니다.

00:08:04.440 --> 00:08:07.360
그런데 우리가 하나의 방법을 가질 수 있을까요, 그러니까 저는

00:08:07.360 --> 00:08:09.440
이 세 가지 범주를 모두 언급했습니다.

00:08:09.440 --> 00:08:13.260
그 범주들은 그 특징들 중 하나 이상이

00:08:13.260 --> 00:08:13.860
빠져 있었습니다.

00:08:15.000 --> 00:08:17.800
최적화 기반은 복잡성에 적응하지 못했습니다.

00:08:18.040 --> 00:08:20.840
샘플링이나 고전적 방법은, 어,

00:08:21.120 --> 00:08:22.860
추론 효율이, 어,

00:08:23.060 --> 00:08:24.620
낮았고, 데이터 기반은 매우

00:08:24.620 --> 00:08:25.860
낮은 학습 효율을 보였습니다.

00:08:25.960 --> 00:08:28.140
이 세 가지 특징을 모두 갖는 방법이

00:08:28.140 --> 00:08:28.780
가능할까요?

00:08:29.320 --> 00:08:30.760
그래서 저희 답은 예입니다.

00:08:30.760 --> 00:08:34.540
즉, 물리에서 얻을 수 있는 어떤, 어, 사전지식을

00:08:34.540 --> 00:08:36.880
도입하면 이 세 가지 특징을 모두

00:08:36.880 --> 00:08:38.640
달성할 수 있습니다.

00:08:38.640 --> 00:08:41.000
그리고 이것이 제 발표의 남은

00:08:41.000 --> 00:08:42.820
부분에서의 핵심 주제가 될 것입니다.

00:08:43.160 --> 00:08:45.900
그래서 제가 물리 사전지식을 사용한다고 말할 때

00:08:45.900 --> 00:08:47.940
자주 나오는 질문이 있습니다.

00:08:48.060 --> 00:08:49.720
어떤 물리 사전지식을 쓰느냐는 것입니다.

00:08:50.500 --> 00:08:50.980
알겠습니까?

00:08:51.340 --> 00:08:53.840
사람들은 종종 이 물리 사전지식을

00:08:53.840 --> 00:08:55.620
물리 엔진이나 시뮬레이터와 혼동합니다.

00:08:55.620 --> 00:08:58.800
하지만 제 발표에서는 PDE 사전지식을 쓴다고

00:08:58.800 --> 00:09:00.600
아주 명확히 말씀드렸습니다.

00:09:00.600 --> 00:09:02.840
왜냐하면 이 질문을 계속해서

00:09:02.840 --> 00:09:03.040
반복해서 받았기 때문입니다.

00:09:03.140 --> 00:09:04.520
그럼 여기서 시뮬레이션은 어디에 있느냐는 질문입니다.

00:09:04.660 --> 00:09:06.240
즉, 이것은 물리 시뮬레이션이 아닙니다.

00:09:06.240 --> 00:09:09.060
우리가 사전지식으로 사용하는 것은

00:09:09.060 --> 00:09:09.260
PDE입니다.

00:09:09.600 --> 00:09:12.360
그래서 PDE를 이야기할 때, 여러분이 들어보셨을

00:09:12.360 --> 00:09:15.040
PDE 중 하나가, 어,

00:09:15.040 --> 00:09:15.740
HJB PDE입니다.

00:09:16.020 --> 00:09:18.160
해밀토니언-자코비-벨만 방정식입니다.

00:09:18.540 --> 00:09:21.180
그리고 이는 일부 동적

00:09:21.180 --> 00:09:21.520
시스템의 운동을 지배합니다.

00:09:21.800 --> 00:09:23.700
하지만 그 PDE는 풀기가 매우 어렵습니다.

00:09:23.700 --> 00:09:26.940
특이점과 다봉성(multimodal) 문제가 있습니다.

00:09:27.000 --> 00:09:29.920
그리고 운동학적 제약과

00:09:29.920 --> 00:09:33.100
동역학적 제약을 모두 적용하면, 어,

00:09:33.100 --> 00:09:33.280
풀기가 더욱 어려워집니다.

00:09:33.560 --> 00:09:35.920
그래서 저희는 그 방정식을 분석하고,

00:09:35.940 --> 00:09:38.520
동역학을 단순하게 가정하면,

00:09:38.800 --> 00:09:42.340
그 식이 이 에이코널(Eikonal) PDE로 환원된다고 말했습니다.

00:09:42.340 --> 00:09:46.100
이 에이코널 PDE에는 두 함수가 있습니다.

00:09:46.580 --> 00:09:48.020
하나는 T입니다.

00:09:48.340 --> 00:09:49.940
다른 하나는 S입니다.

00:09:50.760 --> 00:09:52.740
T는 미지의 함수입니다.

00:09:52.940 --> 00:09:54.660
그리고 이는 가치 함수입니다.

00:09:54.660 --> 00:09:56.760
이 PDE를 풀어서

00:09:56.760 --> 00:09:57.980
이 미지의 함수 T를 찾고자 합니다.

00:09:58.700 --> 00:10:00.260
S는 알려진 함수입니다.

00:10:00.480 --> 00:10:03.180
그리고 기본적으로 제약을 정의합니다.

00:10:03.400 --> 00:10:05.740
예를 들어 장애물까지의 거리일 수 있습니다.

00:10:06.060 --> 00:10:08.820
로봇의 구성이 주어졌다고 하면,

00:10:08.820 --> 00:10:09.440
예를 들어 QS라고 하겠습니다.

00:10:09.440 --> 00:10:12.220
이 S는

00:10:12.220 --> 00:10:15.060
로봇이 가장 가까운 장애물로부터 얼마나 떨어져 있는지 알려줍니다.

00:10:15.500 --> 00:10:16.360
이해되셨습니까?

00:10:16.860 --> 00:10:18.960
또는 그 제약을

00:10:18.960 --> 00:10:19.500
다른 것으로 바꿀 수도 있습니다.

00:10:19.660 --> 00:10:22.220
예를 들어 장애물까지의 거리를 두는 대신,

00:10:22.300 --> 00:10:24.380
가장 가까운 매니폴드까지의 거리일 수도 있습니다.

00:10:24.920 --> 00:10:25.460
괜찮습니까?

00:10:25.820 --> 00:10:27.840
조작 매니폴드 같은 것일 수도 있습니다.

00:10:28.080 --> 00:10:29.740
그러면 이 S 함수는 알려져 있습니다.

00:10:30.080 --> 00:10:32.320
저는 이 PDE를 풀어서

00:10:32.320 --> 00:10:34.840
가치 함수인 T를 찾고 싶습니다.

00:10:34.840 --> 00:10:37.500
그리고 이 방정식을 풀면

00:10:37.500 --> 00:10:41.700
이러한 파면(wavefront)이 나오고, 이를 이용해 로봇이

00:10:41.700 --> 00:10:43.540
한 지점에서 다른 지점으로 이동할 수 있습니다.

00:10:43.800 --> 00:10:46.460
따라서 출발점을 주면, 이

00:10:46.460 --> 00:10:49.120
즉 PDE를 풀면, 이동 시간

00:10:49.120 --> 00:10:51.540
함수인 T를 얻게 됩니다.

00:10:51.880 --> 00:10:53.880
이 이동 시간 함수도 가치

00:10:53.880 --> 00:10:54.200
함수입니다.

00:10:54.400 --> 00:10:56.500
따라서 이 T의 그래디언트를 따라가기만 하면,

00:10:56.640 --> 00:10:59.280
환경 내 어떤 지점으로든

00:10:59.280 --> 00:10:59.980
이동할 수 있습니다.

00:10:59.980 --> 00:11:03.640
수치적으로는 FFM이라고 불리는 방법이 있는데,

00:11:03.720 --> 00:11:04.800
패스트 마칭 메서드(fast marching method)입니다.

00:11:04.940 --> 00:11:07.560
이 방법은 이 PDE를 풀지만, 수치적

00:11:07.560 --> 00:11:08.020
접근법입니다.

00:11:08.120 --> 00:11:10.340
3차원을 넘어서는 스케일링이 어렵습니다.

00:11:10.380 --> 00:11:12.660
그래서, 어, 우리가 이 PDE를 시작했을 때, 저희의

00:11:12.720 --> 00:11:15.340
주된 관심사는 이것을

00:11:15.340 --> 00:11:18.740
3차원을 넘어 실제로 복잡한 로봇 시스템까지 확장할 수 있는가였습니다.

00:11:20.040 --> 00:11:22.780
그래서 신경망이, 어,

00:11:22.780 --> 00:11:24.900
가능한 방법을 제시해 주었는데, 수치 해석기를 쓰는 대신

00:11:24.900 --> 00:11:27.400
신경망을 사용해서

00:11:27.400 --> 00:11:29.800
고차원에서 이 PDE를 풀 수 있다는 것이었습니다.

00:11:30.160 --> 00:11:33.120
그래서 우리가 처음으로 한 일은,

00:11:33.120 --> 00:11:36.540
이것을 풀려고 하는 신경망을 두는 것이었습니다.

00:11:36.540 --> 00:11:38.040
이 에이코널(Eikonal) PDE를 말입니다.

00:11:38.040 --> 00:11:40.700
그러면 이 신경망의 입력은, 그러니까

00:11:40.700 --> 00:11:43.200
이 신경망은 블랙박스이지만,

00:11:43.200 --> 00:11:45.480
이 PDE의 성질을

00:11:45.480 --> 00:11:48.820
존중하도록 신경망에 구조를 넣었습니다.

00:11:48.880 --> 00:11:50.740
이에 대해서는 간단히만 설명하겠지만, 관심이 있으시면

00:11:50.740 --> 00:11:53.480
논문을 찾아보셔서

00:11:53.480 --> 00:11:55.300
이 신경망의 구조를 이해해 보시기 바랍니다.

00:11:55.380 --> 00:11:57.420
하지만 단순화를 위해, 이것을

00:11:57.420 --> 00:12:01.340
로봇의

00:12:01.340 --> 00:12:05.600
입력은 로봇 시작 QS, 로봇 목표 QG, 그리고 환경 인지입니다.

00:12:05.600 --> 00:12:06.300
이를 입력으로 사용합니다.

00:12:06.300 --> 00:12:09.080
출력은 이 이동 시간 함수입니다.

00:12:09.600 --> 00:12:11.280
따라서 이는 미지의 함수입니다.

00:12:11.320 --> 00:12:13.280
그래서 저는 이 신경망을 학습시키고자 합니다.

00:12:13.280 --> 00:12:15.840
이 PDE를 풀도록 해서, 한 번 학습되면

00:12:16.000 --> 00:12:19.220
정확하거나 근사적으로 정확한 이동

00:12:19.220 --> 00:12:19.780
시간 함수를 갖게 됩니다.

00:12:20.120 --> 00:12:23.500
이제 이 모델을 학습시키는 방법은 다음과 같습니다.

00:12:23.500 --> 00:12:26.860
이 입력을 주면, 어, 신경망이 이를 처리합니다.

00:12:26.860 --> 00:12:27.680
이 이동 시간을 예측합니다.

00:12:27.680 --> 00:12:30.920
그다음 아이코널(Eikonal) PDE는 다음과 같이 말합니다.

00:12:30.920 --> 00:12:33.700
이 이동 시간을 입력에 대해 미분해 그래디언트를 구합니다.

00:12:33.700 --> 00:12:37.060
이 경우 입력은 QS이며, 그 결과는

00:12:37.060 --> 00:12:38.860
제약 함수의 역수와 같습니다.

00:12:39.440 --> 00:12:41.860
따라서 이 PDE는 우리에게 어떤 구조를 제공합니다.

00:12:42.380 --> 00:12:44.340
그래서 학습이 매우 단순해집니다.

00:12:44.580 --> 00:12:47.320
그래서 여러분은 로봇을 많이 샘플링하고

00:12:47.320 --> 00:12:48.600
시작 및 목표 구성(configuration)을 뽑습니다.

00:12:48.600 --> 00:12:50.600
환경 인지가 있습니다.

00:12:50.880 --> 00:12:51.460
환경 인지가 있습니다.

00:12:51.460 --> 00:12:52.980
이러한 각 쌍은

00:12:52.980 --> 00:12:53.600
신경망을 통과합니다.

00:12:53.780 --> 00:12:55.020
그들의 이동 시간을 예측합니다.

00:12:55.220 --> 00:12:59.700
그다음 역전파로 이 근사된 제약

00:12:59.700 --> 00:13:02.120
함수를 아이코널(Eikonal) PDE에 따라 계산합니다.

00:13:02.320 --> 00:13:03.280
그러면 끝입니다.

00:13:03.420 --> 00:13:03.600
네?

00:13:04.920 --> 00:13:05.540
질문이 있습니다.

00:13:05.960 --> 00:13:07.920
그러면 문제를 어떻게 인코딩하시나요?

00:13:07.920 --> 00:13:08.860
여러분의 공식에서는 어떻게 표현하시나요?

00:13:09.120 --> 00:13:13.440
음, SQ를 쓰는 건가요, 아니면요?

00:13:14.020 --> 00:13:14.900
좋은 질문입니다.

00:13:15.080 --> 00:13:16.020
그 부분은 곧 말씀드리겠습니다.

00:13:16.140 --> 00:13:16.420
알겠습니다.

00:13:16.580 --> 00:13:17.100
잠시 후에요.

00:13:17.380 --> 00:13:20.120
그래서 이 경우 QS는,

00:13:20.120 --> 00:13:22.640
모션 플래닝 문제는 로봇의

00:13:22.640 --> 00:13:24.900
시작, 목표, 그리고 환경 인지로 정의됩니다.

00:13:25.680 --> 00:13:26.120
맞습니까?

00:13:26.280 --> 00:13:28.340
표준 모션 플래닝 문제에서는 이를

00:13:28.340 --> 00:13:30.220
고전적 방법이나 옵티마이저에 넣습니다.

00:13:30.400 --> 00:13:32.240
그것은 시작과 목표, 그리고 여러분의

00:13:32.240 --> 00:13:35.140
환경, 예를 들면 장애물까지의 거리 같은 관측이나

00:13:35.140 --> 00:13:35.920
사용 가능한 어떤 관측이든을 받습니다.

00:13:36.300 --> 00:13:36.800
맞습니까?

00:13:37.020 --> 00:13:38.400
그래서 그것이 문제를 정의합니다.

00:13:39.120 --> 00:13:41.560
그리고 이 경우에는 우리는 오직

00:13:41.560 --> 00:13:42.500
이 문제 세트만을 제공합니다.

00:13:42.500 --> 00:13:45.780
즉 QS와 QG, 그리고 환경 인지가

00:13:45.780 --> 00:13:47.420
신경망을 통과하고 이것을 예측합니다,

00:13:47.420 --> 00:13:47.620
T입니다.

00:13:48.160 --> 00:13:51.140
그다음 이 손실을 학습시키는 방법은, 음,

00:13:51.340 --> 00:13:53.800
이 신경망을 그래디언트 매칭 손실

00:13:53.800 --> 00:13:54.160
함수로 학습시키는 것입니다.

00:13:54.440 --> 00:13:57.620
그래서 우리는 역전파로 이 그래디언트를

00:13:57.620 --> 00:13:58.400
QS에 대해 계산합니다.

00:13:58.680 --> 00:14:01.580
그리고 아이코널(Eikonal) PDE에 따르면 이것의

00:14:01.580 --> 00:14:05.820
그래디언트 노름의 역수가 기본적으로 제약 함수입니다.

00:14:07.140 --> 00:14:07.780
알겠습니까?

00:14:07.780 --> 00:14:11.020
그래서 이 제약 함수를 근사하고 이를 비교합니다,

00:14:11.020 --> 00:14:13.280
정답(ground truth) 제약 함수와요.

00:14:13.420 --> 00:14:15.440
예를 들어 정답(ground truth) 장애물 거리 같은 것입니다.

00:14:16.500 --> 00:14:17.460
이해되셨습니까?

00:14:17.620 --> 00:14:20.740
즉 손실 함수는 그래디언트에 대해 정의됩니다,

00:14:20.740 --> 00:14:21.520
신경망의요.

00:14:21.640 --> 00:14:23.380
순전파 경로에 두었다가

00:14:23.380 --> 00:14:25.760
어떤 출력을 계산한 다음 정의하는 것이 아닙니다.

00:14:25.760 --> 00:14:29.500
손실 함수는

00:14:29.500 --> 00:14:30.820
신경망의 그래디언트에 있습니다.

00:14:31.260 --> 00:14:31.740
네.

00:14:31.980 --> 00:14:32.200
좋습니다.

00:14:32.380 --> 00:14:32.700
질문입니다.

00:14:33.240 --> 00:14:34.920
신경망의 출력에 대해

00:14:34.920 --> 00:14:36.280
그리고 그 출력을 어떻게 사용해서

00:14:36.280 --> 00:14:36.700
그 출력을 통해

00:14:36.700 --> 00:14:39.080
원하는, 어, 로봇의 포즈를

00:14:39.080 --> 00:14:39.440
얻는지 설명해 주실 수 있습니까?

00:14:39.740 --> 00:14:42.060
네, 그 부분도 곧 말씀드리겠지만,

00:14:42.100 --> 00:14:43.460
아주 좋은 질문입니다.

00:14:43.460 --> 00:14:46.560
그래서 이 경우 출력은

00:14:46.560 --> 00:14:48.960
이동 시간 T입니다.

00:14:49.120 --> 00:14:50.260
이는 값 함수(value function)의 값입니다.

00:14:50.560 --> 00:14:52.200
그래서 그래디언트를 얻으려면,

00:14:52.200 --> 00:14:54.780
그 값 함수의 그래디언트를 따라가기만 하면 되고

00:14:54.780 --> 00:14:55.360
그 결과로

00:14:55.360 --> 00:14:56.700
궤적이 나옵니다.

00:14:57.200 --> 00:14:57.560
알겠습니까?

00:14:58.320 --> 00:15:00.820
그래서 우리는 이 단순한 그래디언트 매칭 손실

00:15:00.820 --> 00:15:01.100
함수를 사용합니다.

00:15:01.140 --> 00:15:02.880
그러니 생각해 보면 제가 필요한 유일한 데이터는

00:15:02.880 --> 00:15:04.960
무작위로 샘플링한 간단한 시작과

00:15:04.960 --> 00:15:05.200
목표,

00:15:06.640 --> 00:15:08.380
그리고 장애물까지의 거리입니다.

00:15:09.200 --> 00:15:09.840
그게 전부입니다.

00:15:09.840 --> 00:15:12.360
그래서 이것이 표준적인 모션 플래닝 도구인데,

00:15:12.360 --> 00:15:14.740
예를 들어 샘플링

00:15:14.740 --> 00:15:16.860
기반 방법인 RRT나 RRT*를 사용하면,

00:15:17.100 --> 00:15:19.640
충돌 검사기와

00:15:19.640 --> 00:15:21.120
구성을 무작위로 샘플링하는 방법이 필요합니다.

00:15:21.120 --> 00:15:23.560
그리고 나서

00:15:23.560 --> 00:15:24.740
궤적을 찾기 위한 메커니즘이 있지요, 맞습니까?

00:15:25.220 --> 00:15:26.200
우리의 데이터도 비슷합니다.

00:15:26.380 --> 00:15:30.660
우리는 로봇 구성을 무작위로 샘플링한 것과

00:15:30.660 --> 00:15:33.380
이 경우 제약조건 또는 충돌까지의 거리를

00:15:33.380 --> 00:15:33.600
필요로 합니다.

00:15:33.740 --> 00:15:36.740
그리고 그 제약 함수를

00:15:36.740 --> 00:15:39.280
전문가로 삼아 모델을 학습시킵니다.

00:15:39.280 --> 00:15:44.220
왜냐하면 신경망의 그래디언트가

00:15:44.220 --> 00:15:45.200
제약 함수를 근사하게 만들기 때문입니다.

00:15:45.360 --> 00:15:47.760
그리고 이렇게 근사된 제약 함수를

00:15:47.760 --> 00:15:48.320
실제 값과 비교합니다.

00:15:48.880 --> 00:15:49.480
답이 되었습니까?

00:15:49.780 --> 00:15:54.200
그래서 이론적으로는 모두 단순해 보이지만,

00:15:54.200 --> 00:15:55.260
실제로 적용해 보니,

00:15:55.400 --> 00:15:57.720
이 방법을 4

00:15:57.720 --> 00:15:58.060
차원을 넘어 확장할 수 없었습니다.

00:15:58.800 --> 00:16:02.440
수치 솔버는 3

00:16:02.440 --> 00:16:02.740
차원에서는 이를 풀고 있었습니다.

00:16:02.740 --> 00:16:04.860
우리는 '좋습니다, 4

00:16:04.860 --> 00:16:07.520
…차원이지만 수치적 방법도 4

00:16:07.520 --> 00:16:07.800
차원도 할 수 있었습니다.

00:16:07.960 --> 00:16:09.240
그저 조금 더 빠를 뿐이었습니다.

00:16:09.640 --> 00:16:12.680
그리고 나서 '무슨 문제가 있는지'를

00:16:12.680 --> 00:16:13.040
조사하기 시작했습니다.

00:16:13.540 --> 00:16:15.220
그 결과,

00:16:15.220 --> 00:16:16.860
두 가지 주요 한계가 있음을 알아냈습니다.

00:16:17.160 --> 00:16:20.720
첫째로, 아이코널 PDE는 해가 여러 개일 수 있고,

00:16:20.720 --> 00:16:23.060
우리의 신경망은 그 여러 해를

00:16:23.060 --> 00:16:24.380
포착하지 못했습니다.

00:16:24.380 --> 00:16:27.820
그래서 이 모델은

00:16:27.820 --> 00:16:29.400
그 다중 모드 문제로 어려움을 겪었습니다.

00:16:29.960 --> 00:16:33.320
둘째로, 저는 이 모델을

00:16:33.320 --> 00:16:35.020
무작위로 샘플링한 시작점과 목표점으로 학습시키기 때문에,

00:16:35.940 --> 00:16:40.260
연속된 구성들 사이의 그래디언트가 제어되지 않습니다.

00:16:40.360 --> 00:16:43.400
하지만 궤적을 생각해 보면,

00:16:43.400 --> 00:16:45.280
시작점에서 출발해

00:16:45.280 --> 00:16:46.140
다음 구성으로 이동하고,

00:16:46.360 --> 00:16:48.020
또 다음 구성으로 이동하면서

00:16:48.020 --> 00:16:48.760
하나의 궤적이 만들어집니다.

00:16:48.760 --> 00:16:52.000
따라서 연속된 구성들 사이의 그래디언트가

00:16:52.000 --> 00:16:54.800
제어되지 않으면 오류로 이어질 수 있습니다.

00:16:54.900 --> 00:16:56.800
그리고 잠시 후에

00:16:56.800 --> 00:16:57.680
그 모습이 어떤지 보여드리겠습니다.

00:16:58.520 --> 00:17:00.740
그래서 이것이 우리가 발견한 두 가지 한계였습니다.

00:17:00.740 --> 00:17:04.380
그리고 우리는 이것이 우리 모델을 본질적으로 제한한다고 생각했고,

00:17:04.380 --> 00:17:04.580
즉,

00:17:04.720 --> 00:17:07.100
4차원을 넘어서 확장하지 못하게 했습니다.

00:17:07.840 --> 00:17:10.720
그래서 우리가 처음으로 탐색한 해결책은,

00:17:10.720 --> 00:17:13.840
점성 아이코널 PDE를 사용할 수 있느냐는 것이었습니다.

00:17:14.040 --> 00:17:16.780
제가 강조한 문제 중 하나는 아이코널

00:17:16.780 --> 00:17:18.080
PDE가 해가 여러 개라는 점이었습니다.

00:17:18.080 --> 00:17:21.460
그런데 여기에 라플라시안을 추가하면,

00:17:21.460 --> 00:17:23.100
이 아이코널 PDE는 유일한 해를 갖게 됩니다.

00:17:24.980 --> 00:17:28.080
그리고 그것이

00:17:28.080 --> 00:17:28.580
훨씬 더 나은 성능으로 이어졌습니다.

00:17:28.860 --> 00:17:31.120
이 모델로 우리는

00:17:31.120 --> 00:17:33.120
최대 약 6자유도

00:17:33.120 --> 00:17:33.860
로봇 팔까지 확장할 수 있었습니다.

00:17:34.120 --> 00:17:36.440
또한 아주

00:17:36.440 --> 00:17:37.060
좁은 통로에서의 모션에도 적용할 수 있었습니다.

00:17:37.340 --> 00:17:41.180
하지만 음, 이 점성 아이코널 PDE에는

00:17:41.180 --> 00:17:41.600
비용이 따랐습니다.

00:17:41.780 --> 00:17:45.060
그래서 이제 저는 신경망을

00:17:45.060 --> 00:17:46.300
…에 대해 이차 미분한 항을 갖게 되고,

00:17:46.300 --> 00:17:47.900
즉 라플라시안이 생깁니다.

00:17:48.080 --> 00:17:51.200
그래서 이를 계산하는 데 계산 비용이 매우 컸습니다.

00:17:51.580 --> 00:17:53.580
그리고 학습 비용이 매우 높아졌습니다.

00:17:53.780 --> 00:17:56.540
그래서 그것은 다시 제가 원했던 목표와는 달랐습니다.

00:17:56.540 --> 00:17:59.040
저는 매우 빠르게 학습되는

00:17:59.040 --> 00:17:59.480
모델을 원했기 때문입니다.

00:17:59.700 --> 00:18:03.600
하지만 이 점성 아이코널 PDE는

00:18:03.600 --> 00:18:04.620
더 나은 성능으로 이어지긴 했습니다.

00:18:04.980 --> 00:18:08.640
하지만 그럼에도 우리는 여전히

00:18:08.640 --> 00:18:12.100
연속된 구성들 사이의 그래디언트를 조절하기 위한

00:18:12.100 --> 00:18:14.600
아무 조치도 하지 않았고, 무작위로 샘플링한

00:18:14.600 --> 00:18:15.760
시작점과 목표점으로 이 모델을 계속 학습시켰습니다.

00:18:16.520 --> 00:18:19.240
또 다른 기법도 진행 과정에서

00:18:19.240 --> 00:18:21.940
우리가 제안했는데, 이 라플라시안을

00:18:21.940 --> 00:18:23.920
그리슐리 에너지 최소화로 근사할 수 있습니다.

00:18:23.920 --> 00:18:26.000
자세한 내용은 다루지 않겠지만,

00:18:26.000 --> 00:18:28.800
관심이 있으시면 이 논문을 참고하시기 바랍니다.

00:18:29.060 --> 00:18:31.360
최근 IROS에 게재된 논문입니다.

00:18:31.700 --> 00:18:34.780
그래서 이 논문은, 예를 들어, 어떻게

00:18:34.780 --> 00:18:38.940
그리슐리 에너지 최소화를 사용해서 라플라시안을 근사하면서

00:18:38.940 --> 00:18:39.760
모델을 학습할 수 있는지 논의합니다.

00:18:40.400 --> 00:18:44.780
이는 라플라시안을 더 저렴하게 근사하는 방법입니다.

00:18:44.780 --> 00:18:46.920
그럼에도 여전히 많은 반복이 필요합니다.

00:18:46.920 --> 00:18:49.940
시간이 지나면서 이 라플라시안을

00:18:49.940 --> 00:18:50.420
근사하기 때문입니다.

00:18:50.460 --> 00:18:52.240
그래서 처음에는 모델이

00:18:52.240 --> 00:18:52.700
매우 나쁘게 동작할 것입니다.

00:18:54.200 --> 00:18:58.880
그래서 그 성질들로 다시 돌아가 보면,

00:18:58.880 --> 00:18:59.960
즉 해가 여러 개라는 점이 있고,

00:19:01.340 --> 00:19:04.320
또한 음,

00:19:04.320 --> 00:19:07.720
연속된 구성들 사이의 그래디언트가 제어되지 않는다는 점이 있습니다.

00:19:07.720 --> 00:19:10.780
우리는 이러한 문제들의 해법이

00:19:10.780 --> 00:19:14.480
아이코널 PDE의 성질들 안에 존재한다는 것을 알게 되었습니다.

00:19:14.740 --> 00:19:17.740
아이코널 PDE는 지오데식

00:19:17.740 --> 00:19:18.080
거리입니다.

00:19:18.220 --> 00:19:21.180
아이코널 PDE의 해는 지오데식

00:19:21.180 --> 00:19:21.780
함수입니다.

00:19:22.400 --> 00:19:25.300
따라서 지오데식 거리의 성질을

00:19:25.300 --> 00:19:27.360
예를 들어 삼각 부등식 같은 성질을

00:19:27.360 --> 00:19:29.880
비롯하여 여러 지오데식 거리

00:19:29.880 --> 00:19:32.360
성질들을 만족해야 합니다.

00:19:32.880 --> 00:19:36.140
또 지오데식 거리도 해가 여러

00:19:36.140 --> 00:19:36.620
개일 수 있습니다.

00:19:36.620 --> 00:19:40.500
즉 여러 지오데식 경로를 포착할 수 있는데,

00:19:40.600 --> 00:19:41.980
예를 들어 시작점과 목표점이 있으면,

00:19:42.160 --> 00:19:43.760
저는 이쪽으로 갈 수도 있고,

00:19:43.760 --> 00:19:44.800
저쪽으로도 갈 수 있습니다.

00:19:44.920 --> 00:19:48.940
그래서 가능한 해가 여러 개이고,

00:19:48.940 --> 00:19:51.140
그 해들 모두가 더 짧은 경로이거나

00:19:51.380 --> 00:19:53.440
이동 시간 측면에서의 해일 수도 있습니다.

00:19:53.680 --> 00:19:56.540
즉 구성 공간에 어떤 대칭성이

00:19:56.540 --> 00:19:58.000
있을 수도 있고,

00:19:58.120 --> 00:19:59.260
그래서 해가 여러 개가 될 수 있습니다.

00:19:59.680 --> 00:20:02.440
그 모두가 똑같이 중요할 수 있습니다.

00:20:02.440 --> 00:20:06.380
두 번째 성질은 에이코널

00:20:06.380 --> 00:20:07.920
PDE의 해가 가치 함수라는 점입니다.

00:20:08.340 --> 00:20:11.540
따라서 벨만 최적성 원리를 만족해야 합니다.

00:20:11.540 --> 00:20:13.100
이는 잠시 후에 설명드리겠습니다.

00:20:13.300 --> 00:20:15.560
그럼, 음, 첫 번째 성질부터 시작하겠습니다.

00:20:15.800 --> 00:20:18.140
에이코널 PDE의 해는 지오데식

00:20:18.140 --> 00:20:18.520
거리입니다.

00:20:20.400 --> 00:20:24.100
그래서, 그래서 메트릭 학습을 사용해야 합니다.

00:20:24.100 --> 00:20:28.100
예측이 유효한 메트릭 공간이 되도록 강제해야 하고

00:20:28.100 --> 00:20:28.520
즉,

00:20:28.520 --> 00:20:31.280
지오데식 거리의 모든 성질을

00:20:31.280 --> 00:20:32.180
존중할 수 있어야 합니다.

00:20:32.180 --> 00:20:35.380
따라서 지오데식 거리와의 일관성을 보장해야 합니다.

00:20:36.000 --> 00:20:38.660
예를 들어, 음, 대칭성 성질이 있습니다.

00:20:38.980 --> 00:20:41.060
음, 삼각 부등식도 있습니다.

00:20:41.520 --> 00:20:45.620
예를 들어, 시작과 목표 사이의

00:20:45.620 --> 00:20:46.340
직선 경로와,

00:20:46.540 --> 00:20:50.220
어떤 중간 지점을 거치는 경로에서

00:20:50.220 --> 00:20:51.900
그 경로의 길이는

00:20:51.900 --> 00:20:52.540
직선보다 더 길어야 합니다.

00:20:53.020 --> 00:20:53.540
알겠습니까?

00:20:53.580 --> 00:20:54.980
이것이 삼각 부등식입니다.

00:20:55.260 --> 00:20:58.660
따라서 이런 지오데식 거리에서는 신경망도

00:20:58.660 --> 00:20:59.960
그 성질을 만족해야 합니다.

00:20:59.960 --> 00:21:04.200
그래서 이를 위해, 음, 이런 구조를

00:21:04.200 --> 00:21:04.880
신경망에 제안합니다.

00:21:05.180 --> 00:21:07.780
이 구조가 무엇을 하는지 말씀드리면, 이전에는

00:21:07.780 --> 00:21:08.240
우리는 이렇게 하고 있었습니다.

00:21:08.340 --> 00:21:09.620
그러니 이 문제를 생각해 보겠습니다.

00:21:09.760 --> 00:21:11.440
A에서 B로 가는 두 경로가 있다고 하겠습니다.

00:21:13.020 --> 00:21:15.400
만약 손실 함수에서 L2 노름만 사용하면,

00:21:15.400 --> 00:21:17.500
그것이 이 두 경로를

00:21:17.500 --> 00:21:18.000
이 직선으로 압축해 버립니다.

00:21:19.300 --> 00:21:21.680
하지만 우리가 제안한 이 손실 함수를 쓰면,

00:21:21.680 --> 00:21:22.800
즉 우리가 가진 이 구조를 쓰면,

00:21:22.940 --> 00:21:26.560
QS를 받아서 이를

00:21:26.560 --> 00:21:27.480
어떤 잠재 상태로 보내고,

00:21:27.480 --> 00:21:29.760
그다음 그 위에 맥스 풀링을

00:21:29.760 --> 00:21:30.100
적용합니다.

00:21:30.680 --> 00:21:33.080
그러면 이것이 하는 일은 해를 구간별로

00:21:33.080 --> 00:21:34.480
근사하는 것입니다.

00:21:34.640 --> 00:21:36.660
그래서 보시면, 이런 마름모꼴 형태의

00:21:36.660 --> 00:21:38.700
경로 근사를 얻게 됩니다.

00:21:38.800 --> 00:21:41.640
이 원들 대신, 여러분은 구간별로 근사해서

00:21:41.640 --> 00:21:43.100
그 여러 해들을 모두 근사합니다.

00:21:43.260 --> 00:21:46.020
그래서 여기의 메트릭 학습은

00:21:46.020 --> 00:21:47.280
QS와 QG를 받아서,

00:21:47.500 --> 00:21:49.380
어떤 신경망을 통과시키고,

00:21:49.380 --> 00:21:53.500
그리고 나서 QS와 QG의 잠재

00:21:53.500 --> 00:21:55.840
특징에 대해 어떤 연산을 합니다,

00:21:55.840 --> 00:21:57.940
예를 들어 맥스 연산을 적용하고, 그다음

00:21:57.940 --> 00:22:01.140
음, 무한 노름을

00:22:01.340 --> 00:22:02.600
그 잠재 표현에 적용합니다.

00:22:02.720 --> 00:22:05.200
그러니 생각해 보시면, 우리는

00:22:05.200 --> 00:22:07.400
시작점과 목표점을 어떤 잠재 공간으로 옮긴 다음,

00:22:07.400 --> 00:22:10.100
그 잠재 공간에서 지오데식 거리를

00:22:10.100 --> 00:22:10.860
학습합니다.

00:22:11.880 --> 00:22:12.780
이해되십니까?

00:22:14.840 --> 00:22:15.360
좋습니다.

00:22:15.480 --> 00:22:17.040
그래서 이것이 우리가 한 첫 번째 변경입니다.

00:22:17.700 --> 00:22:20.640
둘째로, 이 에이코널 PDE의 해는

00:22:20.860 --> 00:22:21.900
가치 함수입니다.

00:22:21.900 --> 00:22:24.620
따라서 벨만 최적성 원리를 따라야 합니다.

00:22:25.200 --> 00:22:27.680
그리고 우리는 이것이 실제로

00:22:27.680 --> 00:22:28.180
해결해 주고 있다는 것을 알게 되었는데,

00:22:28.400 --> 00:22:31.080
연속된 점들 사이에서 기울기가

00:22:31.080 --> 00:22:33.860
통제되지 않는 문제를 해결할 수 있었습니다.

00:22:34.060 --> 00:22:36.540
그러니 이 간단한 에이코널 PDE를 생각해 보십시오.

00:22:36.860 --> 00:22:39.200
이는 절댓값 함수입니다.

00:22:40.080 --> 00:22:42.200
그러니 제가 이 절댓값 함수를 가지고 있고,

00:22:42.200 --> 00:22:43.940
제가 신경망을 학습시키는 방식은

00:22:43.940 --> 00:22:46.660
저 초록색 점들을 무작위로 샘플링하는 것입니다.

00:22:47.440 --> 00:22:50.280
그래서 제가 그 점들로 신경망을 학습시키면

00:22:50.280 --> 00:22:50.820
그 점들에서

00:22:50.960 --> 00:22:53.200
손실 함수는 오직 그

00:22:53.200 --> 00:22:53.640
점들에서만 최소화됩니다.

00:22:53.880 --> 00:22:56.600
그 구간들에서는 아무것도 하지 않습니다.

00:22:57.140 --> 00:23:01.300
따라서 그 신경망 입장에서는 두 함수가 모두

00:23:01.300 --> 00:23:01.720
정확합니다,

00:23:03.240 --> 00:23:05.820
왜냐하면 그 초록색 점들에서의 오차가

00:23:05.820 --> 00:23:06.100
0이기 때문입니다.

00:23:06.280 --> 00:23:08.420
하지만 그 사이에 작은 점프가

00:23:08.420 --> 00:23:09.340
있다면,

00:23:09.480 --> 00:23:11.540
제 신경망은 그것을 알지 못합니다,

00:23:11.540 --> 00:23:14.480
왜냐하면 제가 조절하기 위해 아무것도 하지 않았고

00:23:14.480 --> 00:23:17.460
그 연속된 점들 사이의 기울기를 규제하지 않았기 때문입니다.

00:23:17.580 --> 00:23:19.780
하지만 로봇 궤적을 생각해 보면,

00:23:20.100 --> 00:23:22.400
한 점에서 시작해서 그리고 여러분은,

00:23:22.400 --> 00:23:23.360
계속 진행합니다.

00:23:23.640 --> 00:23:25.820
그 사이에 이런 작은 오차들이 있으면,

00:23:26.220 --> 00:23:29.000
궤적이 원하는

00:23:29.000 --> 00:23:29.240
목표에서 벗어날 수 있습니다.

00:23:29.440 --> 00:23:30.440
이해되십니까?

00:23:32.080 --> 00:23:34.600
그래서 우리는 이 기울기를 규제해서

00:23:34.600 --> 00:23:37.360
여러분이 보고 있는 이런 범프들이

00:23:37.380 --> 00:23:39.880
이 절댓값 함수를 포착하도록 해야 했습니다.

00:23:41.360 --> 00:23:43.740
그래서 이 문제의 해결책은,

00:23:43.880 --> 00:23:47.320
음, 에이코널 PDE의 해를 최적

00:23:47.320 --> 00:23:48.480
가치 함수의 값으로 취급하는 것이고,

00:23:48.680 --> 00:23:52.060
또한 벨만 최적성 원리를 만족해야 합니다.

00:23:53.060 --> 00:23:56.200
따라서 벨만

00:23:56.200 --> 00:23:57.360
최적성 원리를 만족해야 한다고 할 때,

00:23:57.560 --> 00:23:59.760
우리는 시간차 학습을 해야 합니다.

00:24:02.500 --> 00:24:05.460
표준적인

00:24:05.460 --> 00:24:07.600
Q-러닝, 딥 Q-러닝을 알고 계신 분은 몇 분이나 계십니까?

00:24:09.300 --> 00:24:11.100
일부이긴 하지만, 대부분은 알고 계시는군요.

00:24:11.280 --> 00:24:13.080
그래서 Q-러닝에서는 보상

00:24:13.080 --> 00:24:13.480
함수가 있고,

00:24:14.540 --> 00:24:17.680
다음 상태의 다음 행동에서의 Q 함수에서,

00:24:17.980 --> 00:24:20.620
현재 상태의 현재

00:24:20.620 --> 00:24:21.300
행동에서의 Q 함수를 빼는 것이지요?

00:24:21.300 --> 00:24:22.940
이것이 Q-러닝입니다.

00:24:24.120 --> 00:24:27.380
그리고 이것은 시간차(Temporal Difference) 값에서 나왔는데,

00:24:27.540 --> 00:24:30.100
가치 함수로 보면, 다음 상태에서의 보상 값이

00:24:30.100 --> 00:24:30.540
있고,

00:24:30.540 --> 00:24:33.260
현재 상태의 가치를 빼는 것과 비슷하지요?

00:24:33.580 --> 00:24:35.300
그래서 이 식은 유사합니다.

00:24:35.600 --> 00:24:38.700
저희는 이 식에 도달하는 완전한 유도 과정을

00:24:38.700 --> 00:24:39.680
보여드립니다.

00:24:39.680 --> 00:24:42.720
하지만 핵심은 이것이

00:24:42.720 --> 00:24:43.400
가치 함수라는 점입니다.

00:24:43.640 --> 00:24:45.260
즉 Q들이 있고,

00:24:45.640 --> 00:24:48.600
그 Q들을 어떤 방향으로 교란합니다.

00:24:48.600 --> 00:24:50.860
그러면 다음 상태에서의 값이 있고,

00:24:52.440 --> 00:24:54.440
여기에 어떤 보상이 더해지고,

00:24:54.660 --> 00:24:58.200
그리고 다음이 아니라, 음, 이전 또는

00:24:58.200 --> 00:24:59.160
현재 상태의 값이 있습니다.

00:24:59.160 --> 00:25:01.060
따라서 T는 가치 함수입니다.

00:25:01.980 --> 00:25:05.180
저희는 어떤 방향으로 Q들을 교란하여

00:25:05.180 --> 00:25:06.220
다음 상태를 얻습니다.

00:25:06.560 --> 00:25:08.280
그래서 이것은 다음 상태에서의 값입니다.

00:25:08.960 --> 00:25:10.780
저것은 현재 상태에서의 값입니다.

00:25:10.900 --> 00:25:13.100
그리고 이것은 비용 함수이고,

00:25:13.220 --> 00:25:15.800
이는, 음, 제약 조건의 역수로,

00:25:15.900 --> 00:25:17.540
여러분이 주는 값이 예를 들어 거리 같은 것입니다.

00:25:17.780 --> 00:25:20.740
그래서 제가 최소화하거나 최대화하고 싶다면

00:25:20.740 --> 00:25:21.900
장애물까지의 거리를,

00:25:22.120 --> 00:25:24.120
그것이 보상 함수이거나 비용

00:25:24.120 --> 00:25:24.420
함수입니다.

00:25:26.740 --> 00:25:30.880
그래서 이 시간차 학습을 결합하면,

00:25:30.980 --> 00:25:33.480
즉 저희 논문에서는, 여러분이

00:25:33.480 --> 00:25:35.400
이 U를 해석적으로 계산할 수 있음을 보여드립니다.

00:25:35.640 --> 00:25:38.180
그렇다면 이 Q들을 어떻게 교란해서

00:25:38.180 --> 00:25:38.720
어떤 방향으로

00:25:38.720 --> 00:25:41.320
다음의 보존적인 상태를 얻을 수 있을까요?

00:25:41.520 --> 00:25:44.440
그래서 기본적으로 이 U는, 음, 짧게 말하면,

00:25:44.820 --> 00:25:47.660
그냥 이동 시간의 기울기입니다.

00:25:47.700 --> 00:25:51.540
그래서 여러분은 작은 한 걸음을

00:25:51.540 --> 00:25:54.280
음, 이동 시간 기울기의 방향으로

00:25:54.280 --> 00:25:55.120
이동합니다.

00:25:55.220 --> 00:25:56.160
그래서 그것이 다음 상태입니다.

00:25:56.920 --> 00:25:57.440
이해되시지요?

00:25:57.760 --> 00:26:00.160
그리고 그 기울기는 해석적으로 계산할 수 있습니다.

00:26:01.540 --> 00:26:04.740
그래서 그다음 저희는 기울기 매칭 손실을

00:26:04.740 --> 00:26:06.000
이 3D 손실과 결합했고,

00:26:06.740 --> 00:26:10.640
그러고 나서 이 모델은

00:26:10.640 --> 00:26:11.300
매우 잘 수행할 수 있었습니다.

00:26:11.380 --> 00:26:13.060
우리는 이를 아주

00:26:13.060 --> 00:26:14.120
고차원 문제로 확장할 수 있었고

00:26:14.120 --> 00:26:15.660
곧 제가 보여드리겠습니다.

00:26:15.980 --> 00:26:19.040
그래서 먼저, 아주 단순한 문제에서,

00:26:19.580 --> 00:26:21.340
이는 미로 같은 환경입니다.

00:26:21.340 --> 00:26:24.460
만약 여러분이, 음,

00:26:24.620 --> 00:26:27.120
기울기 매칭 손실 같은 접근을 3D

00:26:27.120 --> 00:26:27.420
학습과 결합하면,

00:26:27.740 --> 00:26:29.320
이런 종류의 등고선을 얻고,

00:26:29.380 --> 00:26:31.800
이것이 이 전문가 결과와 일치하는 것을 보실 수 있습니다.

00:26:31.800 --> 00:26:35.580
즉 전문가, 음, FFM과의 일치입니다.

00:26:35.680 --> 00:26:36.960
이는 수치적 접근법입니다.

00:26:37.060 --> 00:26:38.940
3차원까지만 가능하고,

00:26:39.120 --> 00:26:40.640
아주 좋은 컴퓨터가 있다면,

00:26:40.760 --> 00:26:41.640
4차원까지도 할 수 있습니다.

00:26:41.940 --> 00:26:44.360
하지만 시간 등고선이 거의

00:26:44.360 --> 00:26:44.800
비슷합니다.

00:26:45.400 --> 00:26:49.120
그래서 이런, 음, 신경망

00:26:49.120 --> 00:26:49.780
접근법을 쓰면,

00:26:49.900 --> 00:26:51.160
비슷한 해를 포착할 수 있습니다.

00:26:51.320 --> 00:26:53.100
하지만 여기에는 두 가지 방법이 있습니다.

00:26:53.460 --> 00:26:54.780
첫 번째는 저희의 첫 번째 방법입니다.

00:26:54.980 --> 00:26:57.280
이는 3D 학습이나 메트릭

00:26:57.280 --> 00:26:57.620
학습 없이 수행한 것입니다.

00:26:57.620 --> 00:27:01.100
처음에는 소스에서의 기울기가

00:27:01.100 --> 00:27:01.840
초기에는

00:27:01.840 --> 00:27:02.520
아주 좋다는 것을 볼 수 있지만,

00:27:02.540 --> 00:27:04.820
소스 지점에서 멀어질수록

00:27:04.820 --> 00:27:05.100
즉 멀리 갈수록,

00:27:05.240 --> 00:27:07.120
기울기가 매우 나빠지기 시작합니다.

00:27:07.500 --> 00:27:10.120
그래서 보존적 상태들 사이의 오차가

00:27:10.120 --> 00:27:12.860
전파되면서 모든 것이 잘못됩니다.

00:27:13.660 --> 00:27:16.260
그리고 이것이 점성 에이코널 PDE입니다.

00:27:16.500 --> 00:27:19.340
이는 이것보다는 더 나은 해를 갖지만,

00:27:19.500 --> 00:27:21.020
그래도 여전히,

00:27:21.140 --> 00:27:22.940
음, 정규화하지는 못했고,

00:27:24.060 --> 00:27:26.020
보존적 상태들 사이의 기울기를요.

00:27:26.200 --> 00:27:29.380
그래서 그 플롯에서 보시는 것처럼

00:27:29.380 --> 00:27:30.360
여전히 몇 가지 인공물이 있습니다.

00:27:30.720 --> 00:27:34.420
그래서 기울기 매칭을 TD 학습과 결합하면

00:27:34.420 --> 00:27:34.600
즉,

00:27:34.660 --> 00:27:36.220
훨씬 더 좋은 결과로 이어집니다.

00:27:37.380 --> 00:27:39.780
그래서 이제 하나씩 논의하겠습니다.

00:27:39.780 --> 00:27:41.580
추론 효율성,

00:27:41.580 --> 00:27:42.540
학습 효율성,

00:27:42.900 --> 00:27:44.500
그리고 이 모델의 적응성입니다.

00:27:46.580 --> 00:27:48.640
그럼 추론 효율성부터 시작하겠습니다.

00:27:50.280 --> 00:27:52.060
이는 간단한, 음,

00:27:52.240 --> 00:27:54.080
7자유도(DOF) 설정입니다.

00:27:54.400 --> 00:27:55.700
보시다시피 여기에서,

00:27:55.760 --> 00:27:59.060
그 계획을 찾는 데 0.07초가 걸리고,

00:27:59.060 --> 00:27:59.660
바로 그 계획입니다.

00:28:00.320 --> 00:28:03.280
그리고, 음, MpyNet은 음,

00:28:03.280 --> 00:28:03.840
NVIDIA에서 나온 것입니다.

00:28:03.840 --> 00:28:06.660
방대한 양의 데이터로 학습되었습니다.

00:28:06.820 --> 00:28:07.480
제가 보여드리겠습니다.

00:28:07.660 --> 00:28:09.700
그 데이터를 수집하는 데는 몇 주가 걸렸고요,

00:28:09.700 --> 00:28:09.980
데이터를요,

00:28:10.100 --> 00:28:11.720
그 모델을 학습시키는 데는 1주일이 걸렸습니다.

00:28:11.720 --> 00:28:12.260
그 모델입니다.

00:28:12.900 --> 00:28:14.920
반면 저희 모델은,

00:28:15.580 --> 00:28:17.440
제가 보여드리겠지만,

00:28:17.680 --> 00:28:17.800
음,

00:28:19.500 --> 00:28:20.860
데이터 수집에 1분도 채 걸리지 않았고,

00:28:21.520 --> 00:28:23.920
학습에도 1시간도 채 걸리지 않았습니다, 그러니까 음,

00:28:24.140 --> 00:28:26.260
300개 환경에서 이 모델을 학습시킨 것입니다.

00:28:26.260 --> 00:28:29.300
즉 하나의 모델이 300개의

00:28:29.300 --> 00:28:31.040
서로 다른 환경으로 일반화됩니다.

00:28:31.400 --> 00:28:33.500
그럼에도 MpyNet과, 음,

00:28:33.660 --> 00:28:35.480
전체적으로 보시면 성공률이 매우

00:28:35.480 --> 00:28:35.900
비슷합니다.

00:28:36.600 --> 00:28:40.000
그리고 계획 시간은, 음, 저희 경우가

00:28:40.000 --> 00:28:40.560
훨씬 더 빠릅니다.

00:28:40.840 --> 00:28:45.180
또 lazy PRM의 경우, 이 값은

00:28:45.180 --> 00:28:46.500
그래프 질의 시간만을 보여줍니다.

00:28:46.820 --> 00:28:50.020
그래프 구축 시간은 포함하지 않았습니다.

00:28:50.680 --> 00:28:52.780
그래서 그래프를 미리 구축해 두고

00:28:52.780 --> 00:28:54.960
그 그래프를 사용해, 음, 시간을 질의했고

00:28:54.960 --> 00:28:55.380
그 시간을 측정했습니다.

00:28:58.960 --> 00:29:01.120
그다음에는, 그러니까,

00:29:01.240 --> 00:29:03.680
매우 복잡한, 음, 실내 환경으로도 확장되었습니다.

00:29:03.700 --> 00:29:05.460
즉 다층 구조의 환경입니다.

00:29:05.740 --> 00:29:08.440
그리고 성공률도 다시 보시다시피

00:29:08.440 --> 00:29:09.020
매우 높습니다.

00:29:09.460 --> 00:29:11.280
그리고 계획 시간도 매우 낮고

00:29:11.280 --> 00:29:13.440
다른 접근법과 비교하면, 그러니까 음,

00:29:13.780 --> 00:29:15.260
그래서 차이가 있는데요,

00:29:15.400 --> 00:29:16.680
이것이 가치함수이기 때문입니다.

00:29:16.980 --> 00:29:20.260
이 가치함수를 MPC에 통합할 수 있고

00:29:20.260 --> 00:29:21.180
또는 MPPI에도 통합할 수 있습니다.

00:29:21.180 --> 00:29:25.520
따라서 음, 이용 가능한 어떤 도구든

00:29:25.520 --> 00:29:26.600
가치함수를 사용할 수 있다면요.

00:29:26.780 --> 00:29:29.160
궤적 최적화에도 통합할 수 있습니다.

00:29:29.500 --> 00:29:31.540
그래서 저희는 이것을

00:29:31.540 --> 00:29:32.180
MPPI와 결합하면,

00:29:32.460 --> 00:29:35.120
훨씬 더 빠르게 동작함을 보였는데,

00:29:35.120 --> 00:29:37.520
그때는

00:29:37.520 --> 00:29:37.800
그래디언트를 계산할 필요가 없기 때문입니다.

00:29:37.960 --> 00:29:40.660
그냥 음, 예측을 그대로 사용하시면 되고,

00:29:40.940 --> 00:29:43.260
cost-to-go 또는 가치함수

00:29:43.260 --> 00:29:44.120
출력값을요.

00:29:44.480 --> 00:29:47.160
하지만 이 그래디언트는, 또한

00:29:47.160 --> 00:29:47.480
이 그래디언트를

00:29:47.480 --> 00:29:49.280
이 이동 시간의 그래디언트로 궤적을

00:29:49.280 --> 00:29:49.700
여전히 찾아내는 데도 사용할 수 있습니다.

00:29:50.220 --> 00:29:54.040
음, 음, 계산 시간도

00:29:54.040 --> 00:29:54.480
크게 증가하지 않고,

00:29:55.000 --> 00:29:56.480
성공률도 높습니다.

00:29:57.940 --> 00:29:59.980
그리고 나서 저희는 이를

00:29:59.980 --> 00:30:01.060
트라이얼 DOF까지 확장할 수 있었습니다.

00:30:01.200 --> 00:30:03.440
이는 이러한 모델들에게 매우 복잡한 환경입니다,

00:30:03.440 --> 00:30:03.720
이 모델들에겐요,

00:30:03.720 --> 00:30:05.640
아주 얇은 장애물이 있기 때문이고,

00:30:05.860 --> 00:30:07.620
이러한 PDE 해법은 어려움을 겪습니다

00:30:07.620 --> 00:30:09.220
이런 얇은 장애물이 있을 때입니다.

00:30:09.240 --> 00:30:11.060
그래서 저희는 이 환경을 특별히 선택했습니다

00:30:11.060 --> 00:30:14.580
이런 얇은 장애물을

00:30:14.580 --> 00:30:14.920
잘 포착할 수 있음을 보여드리기 위해서입니다.

00:30:14.920 --> 00:30:16.560
그리고도, 음, 계획을 수행할 수 있습니다.

00:30:17.560 --> 00:30:19.140
이는 15 DOF입니다,

00:30:20.980 --> 00:30:24.760
그리고 이 환경은 특히 이

00:30:24.760 --> 00:30:24.960
로봇에게 도전적입니다.

00:30:25.060 --> 00:30:26.260
이 로봇은 매우 크고,

00:30:26.280 --> 00:30:27.660
이 방은 매우 작았으며,

00:30:27.680 --> 00:30:29.380
그래서 매우 협소한 환경이고

00:30:29.380 --> 00:30:31.280
이 로봇이 움직일 수 있어야

00:30:31.280 --> 00:30:33.000
한 지점에서 다른 지점으로 이동할 수 있습니다.

00:30:34.020 --> 00:30:36.460
지금까지가, 그러니까, 추론 효율성에 관한 내용이었습니다.

00:30:36.720 --> 00:30:38.640
제가, 제가 이런 모델들을 보여드렸는데,

00:30:38.760 --> 00:30:40.100
차원이 높아질수록,

00:30:40.280 --> 00:30:42.220
계산상의 이점을 유지한다는 점입니다.

00:30:42.860 --> 00:30:44.160
이제 제가 가장 좋아하는 슬라이드인데요,

00:30:44.240 --> 00:30:46.080
제가, 제가 학습 효율성에 대해 말씀드리겠습니다.

00:30:50.300 --> 00:30:52.340
여기에는 서로 다른 환경들이 있고,

00:30:52.480 --> 00:30:54.260
예를 들어 이 7 DOF(자유도)

00:30:54.260 --> 00:30:54.920
환경만 선택한다고 하면,

00:30:56.460 --> 00:30:57.940
그 환경에서는,

00:30:58.200 --> 00:31:00.100
데이터 수집에, 그러니까, 음,

00:31:00.100 --> 00:31:02.460
어, 저희는 50

00:31:02.460 --> 00:31:02.880
분이 걸렸습니다,

00:31:02.880 --> 00:31:04.120
데이터를 수집하는 데요.

00:31:04.360 --> 00:31:05.600
즉 환경 하나당,

00:31:05.600 --> 00:31:06.980
몇 초씩 걸렸고,

00:31:07.180 --> 00:31:08.640
그래서 50을 곱하면,

00:31:08.780 --> 00:31:10.040
대략 50분이 걸렸습니다.

00:31:10.460 --> 00:31:13.260
학습에는, 어, 46분이 걸렸고,

00:31:13.320 --> 00:31:15.220
EmpireNet과 비교했는데,

00:31:15.380 --> 00:31:17.720
이 수치들은 그들의 논문에서 가져온 것입니다.

00:31:17.900 --> 00:31:19.520
그들은 많은 양의 데이터를

00:31:19.520 --> 00:31:19.880
수집하는 데

00:31:20.040 --> 00:31:21.460
몇 주가 걸렸고,

00:31:21.480 --> 00:31:22.900
그리고 학습에는 1주일이 걸렸습니다.

00:31:23.180 --> 00:31:25.640
저희 모델은 GPU 한 대로 학습시켰고,

00:31:26.340 --> 00:31:27.340
표준적인 3090이었습니다,

00:31:28.000 --> 00:31:30.080
반면 EmpireNet은 학습되었는데,

00:31:30.100 --> 00:31:32.800
음, NVIDIA Tesla GPU 8대로 학습되었습니다.

00:31:32.960 --> 00:31:34.860
그래서 상당한, 음,

00:31:34.940 --> 00:31:36.300
막대한 컴퓨팅 자원이

00:31:36.300 --> 00:31:37.280
그 모델을 학습시키는 데 필요했습니다.

00:31:38.540 --> 00:31:39.460
그리고, 음,

00:31:39.780 --> 00:31:41.020
이 Gibson 환경에서는,

00:31:41.260 --> 00:31:42.080
보시다시피,

00:31:42.400 --> 00:31:44.380
음, 데이터 수집에 24초가

00:31:44.380 --> 00:31:45.160
걸렸고,

00:31:45.260 --> 00:31:46.120
학습에는 9분이 걸렸습니다.

00:31:46.260 --> 00:31:46.960
그래서 제가,

00:31:46.980 --> 00:31:48.200
여기서 강조하고 싶은 것은,

00:31:48.340 --> 00:31:50.540
이런 PDE 프라이어를 사용하면,

00:31:52.380 --> 00:31:53.400
그러니까,

00:31:53.480 --> 00:31:55.100
학습 효율이 훨씬 높아진다는 점입니다.

00:31:55.840 --> 00:31:57.700
제 관점에서는,

00:31:58.660 --> 00:32:00.780
물리학자들이 이런 물리 모델을 제공해 주었고,

00:32:01.320 --> 00:32:03.380
그것이 어떤 동역학 시스템을 지배합니다.

00:32:03.680 --> 00:32:06.160
이제 궤적들을 다시 모으고 있습니다,

00:32:06.340 --> 00:32:07.400
이 모델들은 무시한 채로,

00:32:07.620 --> 00:32:09.640
그저 이 모델들을 재현하기 위해서입니다.

00:32:10.460 --> 00:32:10.980
알겠습니까?

00:32:11.160 --> 00:32:12.640
그렇다면 왜 그냥 이를 사용하지 않습니까?

00:32:12.740 --> 00:32:13.260
이미 존재합니다.

00:32:13.300 --> 00:32:14.360
그리고 이를 사용하면,

00:32:14.520 --> 00:32:16.880
학습 효율이 매우 높아지고,

00:32:16.940 --> 00:32:19.040
추론 효율도 매우 높아지며,

00:32:19.040 --> 00:32:20.860
또한 이 모델들은 여전히

00:32:20.860 --> 00:32:22.440
매우 복잡한 환경에도 적응할 수 있습니다.

00:32:22.640 --> 00:32:24.360
그리고 이 모델들은 전이 가능합니다.

00:32:24.820 --> 00:32:27.100
그래서 제가 이 연구를 시작했을 때,

00:32:28.320 --> 00:32:29.880
저희 모델은 학습에

00:32:29.900 --> 00:32:31.560
대략 이틀이 걸렸습니다.

00:32:32.220 --> 00:32:33.960
그러니까 어, 학습이 이틀씩 걸렸는데,

00:32:34.000 --> 00:32:36.460
저희가 제대로 만족시키지 못했기 때문입니다.

00:32:36.460 --> 00:32:37.880
이러한 PDE들의 성질을 말입니다.

00:32:37.940 --> 00:32:39.780
그런데 이런 성질들을 만족시키고 나니,

00:32:40.040 --> 00:32:42.160
결국, 한

00:32:42.160 --> 00:32:42.300
시간도

00:32:42.300 --> 00:32:44.320
채 안 걸릴 정도가 되었고, 제 연구실은 지금도 더 앞으로 나아가려고

00:32:45.020 --> 00:32:46.260
그 이상을 계속 밀어붙이고 있습니다.

00:32:46.800 --> 00:32:49.580
그러니까 어, 저희가, 저희는,

00:32:49.580 --> 00:32:51.600
논문을 아직 준비 중입니다.

00:32:51.800 --> 00:32:53.420
제 생각에 저희 최신 모델은,

00:32:53.620 --> 00:32:55.360
음, 12 자유도에서,

00:32:55.540 --> 00:32:57.720
학습에 5분도

00:32:57.720 --> 00:32:57.960
채 걸리지 않습니다.

00:32:58.860 --> 00:33:00.120
그래서 훨씬 빠릅니다.

00:33:00.280 --> 00:33:00.500
예?

00:33:01.460 --> 00:33:03.680
그러면, 예를 들어,

00:33:03.800 --> 00:33:06.260
S, 음, S 함수 안의 제약은

00:33:06.440 --> 00:33:07.940
그게 단지 이동 시간만을 의미하나요?

00:33:08.120 --> 00:33:09.220
아니면 다른 제약도 있나요?

00:33:09.220 --> 00:33:11.640
아니요, S가 제약 함수입니다.

00:33:11.820 --> 00:33:12.960
충돌까지의 거리입니다.

00:33:13.200 --> 00:33:13.680
예.

00:33:14.160 --> 00:33:15.240
그래서 이동 시간이 아닙니다.

00:33:15.360 --> 00:33:17.360
이동 시간은 미지 함수이고,

00:33:17.600 --> 00:33:19.200
이 제약 함수가 주어졌을 때 정의되는 것입니다.

00:33:19.340 --> 00:33:21.680
그래서 그 PDE를 풀어서

00:33:21.680 --> 00:33:22.200
이 이동 시간을 구했습니다.

00:33:23.680 --> 00:33:25.440
또, 모델 아키텍처는

00:33:25.740 --> 00:33:28.080
그러니까, 예를 들어,

00:33:28.200 --> 00:33:31.480
MPI와 여러분 논문 사이에서,

00:33:31.600 --> 00:33:33.060
모델 아키텍처가 얼마나 다른가요?

00:33:33.180 --> 00:33:34.780
저희 모델 아키텍처는 매우 다릅니다.

00:33:35.040 --> 00:33:37.420
저희 모델 아키텍처는

00:33:37.420 --> 00:33:39.760
아이코널 PDE의 몇 가지 성질을 따르도록 설계되었습니다.

00:33:39.780 --> 00:33:41.420
예를 들어, 한 가지 성질을 말씀드리면,

00:33:42.160 --> 00:33:44.160
대칭성이라는 성질이 있습니다.

00:33:44.360 --> 00:33:46.660
그래서 시작점에서 목표점까지의 이동 시간과

00:33:46.660 --> 00:33:48.400
목표점에서 시작점까지의 이동 시간은

00:33:48.400 --> 00:33:49.160
같아야 합니다.

00:33:49.540 --> 00:33:50.920
따라서 대칭성을 갖습니다.

00:33:51.200 --> 00:33:53.100
그리고 저희 아키텍처는

00:33:53.100 --> 00:33:54.480
그 대칭성을 존중하도록 설계되었습니다.

00:33:54.740 --> 00:33:57.620
이 가치 함수가 그 대칭성을 만족하도록 강제합니다.

00:33:57.840 --> 00:33:59.580
그리고 제가 말씀드린 다른 점은,

00:33:59.700 --> 00:34:01.660
저희 가치 함수가 측지 거리라는 것입니다.

00:34:02.020 --> 00:34:03.660
그래서 아키텍처도

00:34:03.660 --> 00:34:05.520
그런 삼각, 어,

00:34:05.680 --> 00:34:06.960
삼각 부등식 같은 것들을 만족하도록 설계되었습니다.

00:34:06.960 --> 00:34:09.680
반면 MPI Net은 표준적인,

00:34:10.020 --> 00:34:14.140
우리가 보통 사용하는 표준 아키텍처로,

00:34:14.140 --> 00:34:15.300
대규모 모델에 사용합니다.

00:34:17.140 --> 00:34:17.720
예.

00:34:18.360 --> 00:34:20.420
음, 그래서 매우 좋은

00:34:20.420 --> 00:34:20.660
아이디어라고 생각합니다.

00:34:20.660 --> 00:34:23.940
매니퓰레이터 과제에 아이코널 PDE를 적용하는 것은요,

00:34:24.120 --> 00:34:26.440
왜냐하면 아이코널 PDE에서는

00:34:26.440 --> 00:34:29.680
동역학 제약이, 어,

00:34:29.680 --> 00:34:29.860
들어 있지 않기 때문입니다.

00:34:29.860 --> 00:34:33.100
따라서 모든 상태에서 아마도

00:34:33.100 --> 00:34:33.820
매니퓰레이터가

00:34:33.820 --> 00:34:35.540
어느 방향으로든 잘 움직일 수 있다고 가정하실 텐데요.

00:34:35.940 --> 00:34:38.760
하지만 실제로는 여전히

00:34:38.760 --> 00:34:41.560
동역학 제약이 있고, 또 특이점이

00:34:41.560 --> 00:34:42.500
매니퓰레이터에 존재합니다.

00:34:42.800 --> 00:34:45.160
그래서 그런 문제를 겪어보신 적이 있습니까?

00:34:45.160 --> 00:34:45.260
아이코널 PDE에서 말입니다.

00:34:45.380 --> 00:34:46.780
아주 좋은 질문입니다.

00:34:46.940 --> 00:34:49.400
현재로서는, 어, 이 연구에서는

00:34:49.400 --> 00:34:50.540
운동학만 고려합니다.

00:34:50.700 --> 00:34:53.240
올해 뉴립스에 채택된 논문이

00:34:53.240 --> 00:34:53.500
있는데요,

00:34:53.500 --> 00:34:56.100
그 논문에서 운동역학 문제를

00:34:56.100 --> 00:34:57.320
이 아이코널 PDE로 다뤘습니다.

00:34:57.320 --> 00:35:01.080
그리고, 어, 저희는 기본적으로 이 아이코널

00:35:01.080 --> 00:35:01.700
PDE가

00:35:01.700 --> 00:35:04.700
여전히 해를 정규화할 수 있다는 것을

00:35:04.700 --> 00:35:05.840
HJB PDE의 해에 대해 보여드렸습니다.

00:35:06.420 --> 00:35:08.660
그래서 이를 사전조건으로

00:35:08.660 --> 00:35:10.920
어떤 HJB PDE 솔버를 웜 스타트하기 위한 것으로

00:35:10.920 --> 00:35:13.720
생각하실 수 있고, 또 몇 가지 운동역학적 예도

00:35:13.720 --> 00:35:16.520
그러니까 어, 휴머노이드 과제에서,

00:35:16.600 --> 00:35:19.840
접촉이 많은, 어, 어,

00:35:20.060 --> 00:35:20.620
보행을 어떻게 하는지 보여드렸습니다.

00:35:20.780 --> 00:35:22.900
그리고 기억이 맞다면 조작도

00:35:22.900 --> 00:35:23.300
함께 보여드렸습니다.

00:35:23.300 --> 00:35:27.300
하지만 두 번째 포인트에서 여러분이 지적하신

00:35:27.300 --> 00:35:27.960
다른 부분도

00:35:27.960 --> 00:35:29.540
있었는데요, 그러니까 어, 조작에서는,

00:35:29.620 --> 00:35:31.100
조작 이야기는 곧 하겠습니다.

00:35:31.840 --> 00:35:32.280
예.

00:35:32.660 --> 00:35:32.900
예.

00:35:33.540 --> 00:35:34.500
그냥 궁금한데요,

00:35:34.660 --> 00:35:36.380
데이터 생성도 해야 하고

00:35:36.380 --> 00:35:36.920
학습도 해야 하지 않나요?

00:35:37.180 --> 00:35:39.800
어, 그러니까, 어, 채널에서,

00:35:40.700 --> 00:35:41.520
한 위치에서,

00:35:41.720 --> 00:35:42.360
우리가 완고한 것입니까?

00:35:43.940 --> 00:35:45.360
그래서 이 경우에는 그렇습니다.

00:35:45.560 --> 00:35:48.240
그래서 저희는, 어, 어, 제가

00:35:48.240 --> 00:35:49.040
작업 하나를 더 논의하겠습니다.

00:35:49.200 --> 00:35:52.040
예를 들어, 신경망을 선택적으로 재학습할 수 있습니다.

00:35:52.040 --> 00:35:53.280
예를 들어, 제가 어떻게 하면

00:35:53.280 --> 00:35:54.100
재학습해야 하는 파라미터를

00:35:54.100 --> 00:35:55.460
선택할 수 있는지

00:35:55.460 --> 00:35:57.060
환경의 일부가 바뀌었을 때입니다.

00:35:57.160 --> 00:35:59.160
전부를 재학습할 필요는 없습니다.

00:35:59.400 --> 00:35:59.860
좋습니다, 좋습니다.

00:36:00.020 --> 00:36:02.300
그리고 강력한 학습은, 저는...

00:36:02.300 --> 00:36:04.640
네트워크에

00:36:04.640 --> 00:36:06.760
임의의 시작점과 기본 위치를 설정할 수 있습니다.

00:36:06.920 --> 00:36:07.060
네, 맞습니다.

00:36:07.180 --> 00:36:07.580
좋습니다.

00:36:07.700 --> 00:36:07.880
네.

00:36:09.500 --> 00:36:12.100
자, 지금까지는 학습 효율성을 논의했고,

00:36:12.240 --> 00:36:13.520
복잡성에 대한 적응성도 논의했습니다.

00:36:13.700 --> 00:36:15.480
제가 이것이 매우 높은 차원까지 확장된다는 것을 보여드렸지만,

00:36:15.480 --> 00:36:17.100
이제 조작 문제로 어떻게 유도할 수 있는지,

00:36:17.100 --> 00:36:17.820
그러니까,

00:36:17.880 --> 00:36:19.800
조작으로도

00:36:19.800 --> 00:36:21.880
아주 큰 환경으로도 어떻게 유도할 수 있는지 논의하고자 합니다.

00:36:22.020 --> 00:36:23.340
신경망에는 이런 문제가 있습니다.

00:36:23.480 --> 00:36:25.120
아주 큰 환경이 있으면,

00:36:25.420 --> 00:36:26.420
잘 처리하지 못합니다.

00:36:26.580 --> 00:36:28.860
즉, 신경망은 스펙트럼 편향 문제를

00:36:28.860 --> 00:36:30.800
어, 겪습니다.

00:36:31.140 --> 00:36:34.300
그래서 먼저 이를 매니폴드

00:36:34.300 --> 00:36:35.580
또는 조작 문제로 확장하려면,

00:36:36.020 --> 00:36:38.380
바꿔야 할 것은 전문가

00:36:38.380 --> 00:36:39.360
속도 함수뿐입니다.

00:36:39.640 --> 00:36:41.120
장애물까지의 거리 대신,

00:36:41.520 --> 00:36:43.340
제약 매니폴드까지의 거리로 바꾸십시오.

00:36:43.340 --> 00:36:45.160
예를 들어 문

00:36:45.160 --> 00:36:45.840
여는 작업을 한다면,

00:36:46.000 --> 00:36:46.880
그것이 하나의 매니폴드입니다.

00:36:47.320 --> 00:36:49.600
그리고 만약

00:36:49.600 --> 00:36:50.400
로봇 구성에서

00:36:50.400 --> 00:36:51.340
그 매니폴드까지의 거리를 계산할 수 있다면,

00:36:51.540 --> 00:36:54.080
그것을, 어, 학습

00:36:54.080 --> 00:36:54.500
함수로 사용할 수 있습니다.

00:36:55.120 --> 00:36:58.020
그리고 우리는 이것을 해결할 수 있었는데요,

00:36:58.180 --> 00:36:58.640
그러니까, 어,

00:36:58.900 --> 00:37:01.300
이 모델은, 그러니까, 문을 열고,

00:37:01.320 --> 00:37:03.000
그다음 이 컵을

00:37:03.000 --> 00:37:05.520
기울이지 않고 한 지점에서 다른 지점으로 옮기는데,

00:37:05.520 --> 00:37:07.200
이 제한된 공간에서 말입니다.

00:37:08.280 --> 00:37:10.060
그래서 다시, 어,

00:37:10.200 --> 00:37:11.960
계산 시간은 매우 짧습니다.

00:37:12.120 --> 00:37:13.400
성공률은 매우 높습니다.

00:37:13.660 --> 00:37:16.020
그리고 우리는 이를 C-by-RRT와 비교했는데,

00:37:16.140 --> 00:37:17.420
이는 샘플링 기반 접근법입니다.

00:37:17.900 --> 00:37:19.940
CompNet X는 데이터 기반, 그러니까,

00:37:20.100 --> 00:37:21.760
모방 학습 기반 접근법입니다.

00:37:22.100 --> 00:37:24.640
제가 박사 과정 동안 제안한 CompNet X는

00:37:24.640 --> 00:37:25.100
박사 과정에서,

00:37:25.400 --> 00:37:27.700
이런, 어, 조작 문제를 풀기 위한 것이었습니다.

00:37:27.820 --> 00:37:30.520
하지만 어떤 C-by-RRT 같은

00:37:30.520 --> 00:37:31.460
또는 고전적 플래너로 데이터를 수집해

00:37:31.460 --> 00:37:33.320
그 모델을 학습시켜야 합니다.

00:37:35.060 --> 00:37:36.940
그리고 나서 이런 질문이 나옵니다,

00:37:37.080 --> 00:37:38.980
어떻게 다중 모달 문제로 확장할 수 있습니까?

00:37:39.140 --> 00:37:40.920
예를 들어 이 컵이 있고,

00:37:40.960 --> 00:37:42.820
이것을 움직이면서 똑바로 세운 채로 유지하다가,

00:37:43.000 --> 00:37:43.680
그다음에는 기울입니다.

00:37:43.800 --> 00:37:44.920
이는 서로 다른 두 가지 제약입니다.

00:37:45.120 --> 00:37:46.980
그리고 이 로봇은 또한 열어야 합니다,

00:37:46.980 --> 00:37:47.440
캐비닛을,

00:37:47.600 --> 00:37:48.240
무언가를 꺼내야 합니다.

00:37:48.700 --> 00:37:50.300
그리고 조향을 한다면,

00:37:50.760 --> 00:37:53.180
그러면 스푼 동작은 하나의 매니폴드이고,

00:37:53.400 --> 00:37:54.820
그다음 조향은 또 다른 매니폴드입니다.

00:37:55.040 --> 00:37:56.500
망치질을 하거나

00:37:56.500 --> 00:37:58.080
또는 모든 도구 조작을 한다면,

00:37:58.300 --> 00:38:02.480
그것들은 다중 모달, 어, 어, 제약 문제입니다.

00:38:02.480 --> 00:38:05.440
그렇다면 이런 방법들을 어떻게 확장하여

00:38:05.440 --> 00:38:07.440
그런 다중 모달 제약을 풀 수 있습니까?

00:38:07.780 --> 00:38:11.560
그래서 그, 그 해법은, 어, 다음에 달려 있습니다,

00:38:11.780 --> 00:38:14.440
고전 PDE 문헌에,

00:38:14.660 --> 00:38:16.840
즉, 고전 PDE 문헌을 공부해 보면,

00:38:17.080 --> 00:38:19.960
그들은 PDE 해를

00:38:19.960 --> 00:38:22.260
유한한 기저 함수들의 합으로

00:38:23.360 --> 00:38:23.690
표현하곤 했습니다, 아시겠습니까?

00:38:24.260 --> 00:38:26.540
그래서 이런 각 기저 함수가

00:38:26.540 --> 00:38:28.340
하나의 매니폴드를 나타낸다면,

00:38:28.660 --> 00:38:30.820
그러면 그것들을 결합해서

00:38:30.820 --> 00:38:31.760
전역 궤적을 얻을 수 있습니다.

00:38:31.760 --> 00:38:33.000
그래서 우리가 하는 것이 이것입니다.

00:38:33.200 --> 00:38:36.240
즉, 문제를 다음과 같이 분해합니다,

00:38:36.520 --> 00:38:38.280
이는 단지 설명을 위한 것입니다.

00:38:38.720 --> 00:38:40.080
이 2차원 환경을 생각해 보십시오.

00:38:40.320 --> 00:38:43.000
이를 여러 조각으로 나눌 수 있습니다.

00:38:43.660 --> 00:38:45.360
그리고 각 조각마다,

00:38:45.440 --> 00:38:47.160
몇몇 기저 함수를 학습할 수 있습니다.

00:38:48.120 --> 00:38:50.520
그다음 기저 함수들을 결합해서

00:38:50.520 --> 00:38:52.860
전역 가치 함수를 얻습니다.

00:38:53.040 --> 00:38:55.560
하지만 거기에는, 거기에는 어려움이 있었습니다.

00:38:55.560 --> 00:38:58.420
저는 가치 함수가

00:38:58.420 --> 00:38:58.880
연속적이기를 원합니다,

00:38:58.900 --> 00:39:00.460
즉, 공간적으로 완전히 연결되도록 말입니다,

00:39:00.520 --> 00:39:01.820
왜냐하면 궤적에서는,

00:39:02.000 --> 00:39:03.560
이렇게 분해를 하면,

00:39:04.160 --> 00:39:07.260
이 모든 분할 경계에서

00:39:07.260 --> 00:39:07.840
특이점이 생길 수 있기 때문입니다.

00:39:08.500 --> 00:39:10.940
그래서 이 전역 가치 함수를 어떻게 얻어서

00:39:10.940 --> 00:39:11.260
가치 함수가

00:39:11.260 --> 00:39:13.060
어느 지점에서든 어느 지점으로

00:39:13.060 --> 00:39:13.780
갈 수 있게 하고,

00:39:13.900 --> 00:39:15.720
이 구간에서 저 구간으로,

00:39:15.860 --> 00:39:19.820
불연속이나 국소 최소에 빠지지 않고 갈 수 있겠습니까?

00:39:20.280 --> 00:39:21.540
그래서 그것이 도전 과제였습니다.

00:39:21.740 --> 00:39:23.620
그리고 우리는 몇 가지 아키텍처를 제안했습니다.

00:39:24.100 --> 00:39:24.960
관심이 있으시면,

00:39:24.980 --> 00:39:26.960
자세한 내용은 거기서 보실 수 있습니다.

00:39:27.400 --> 00:39:29.520
하지만, 어, 이 아키텍처는 기본적으로,

00:39:30.220 --> 00:39:32.220
문제를 부분 영역들로 분해한 다음

00:39:32.220 --> 00:39:34.620
이 전역 함수를 학습합니다.

00:39:34.780 --> 00:39:36.540
그래서 그것이 질문에 대한 답이 됩니다,

00:39:36.640 --> 00:39:38.420
예를 들어 환경의 어떤 부분이 바뀌면,

00:39:39.080 --> 00:39:40.780
모든 것을 다시 학습할 필요가 없습니다.

00:39:40.920 --> 00:39:42.800
그 기저 함수만 다시 학습하면 됩니다.

00:39:42.800 --> 00:39:44.180
그리고 그것은 매우 빠릅니다.

00:39:46.500 --> 00:39:48.180
그래서 우리는 이를

00:39:48.180 --> 00:39:49.280
매우 큰 환경까지 확장할 수 있었습니다.

00:39:50.160 --> 00:39:53.960
어, 그리고, 어, 여전히 아주

00:39:53.960 --> 00:39:54.720
높은 성공률을 유지합니다.

00:39:54.840 --> 00:39:56.520
이 분해의 또 다른 장점은,

00:39:56.880 --> 00:40:01.500
엔드투엔드 함수에 비해

00:40:01.500 --> 00:40:02.120
더 적은 파라미터가 필요하다는 것입니다.

00:40:02.280 --> 00:40:03.440
그래서 그렇게 확인했습니다.

00:40:03.860 --> 00:40:06.200
그리고 이것은 레일 위에 있고,

00:40:06.200 --> 00:40:07.620
캠퍼스 위를 지나갑니다.

00:40:07.660 --> 00:40:10.520
즉, 이 로봇은 여러 개의 좁은

00:40:10.520 --> 00:40:11.000
통로들을 이동하며

00:40:11.000 --> 00:40:12.200
한 지점에서 다른 지점으로 이동하고,

00:40:12.200 --> 00:40:15.660
이 전체 환경은, 어,

00:40:16.000 --> 00:40:17.140
여러 개의 기저 함수로 분해되었습니다.

00:40:19.320 --> 00:40:22.000
그리고 같은 아이디어가 여러분의

00:40:22.000 --> 00:40:23.080
다중 모달 조작에도 적용됩니다.

00:40:23.280 --> 00:40:25.980
다중 모달로 여러 개의 매니폴드를 갖습니다.

00:40:26.200 --> 00:40:28.840
이를 기저 함수로 표현할 수 있습니다.

00:40:29.060 --> 00:40:31.200
그것들을 결합해 궤적을 얻을 수 있습니다.

00:40:31.280 --> 00:40:34.300
그래서 이것은 하나의 신경 모델이, 어,

00:40:34.600 --> 00:40:35.160
문을 여는 작업을 수행하고,

00:40:35.180 --> 00:40:37.400
그다음 이 컵을 집어 올리는데,

00:40:37.400 --> 00:40:37.920
기울이지 않습니다.

00:40:37.960 --> 00:40:40.580
그리고 나서 붓기 작업을 수행합니다.

00:40:48.220 --> 00:40:50.640
최근에는 휴머노이드 로봇으로 옮겼습니다.

00:40:50.820 --> 00:40:52.760
그래서 이 모든 작업은

00:40:52.760 --> 00:40:53.220
휴머노이드가 해결하고 있습니다.

00:40:53.380 --> 00:40:57.460
따라서 이런 분해는 공간에서도 이뤄집니다.

00:40:57.680 --> 00:40:59.500
그래서 로봇은

00:40:59.500 --> 00:40:59.860
환경 어디로든 이동할 수 있습니다.

00:40:59.860 --> 00:41:02.640
그래서, 어, 이것이 평면에서의 분해입니다.

00:41:02.820 --> 00:41:04.840
그다음에는 매니폴드에서의 분해가 있습니다.

00:41:05.220 --> 00:41:08.160
그래서 이런 모든, 그러니까, 다중 모달 문제는

00:41:08.160 --> 00:41:08.860
해결되고 있습니다.

00:41:09.020 --> 00:41:11.400
그리고 이 논문은, 잘되면, 곧

00:41:11.400 --> 00:41:13.660
학회에 제출할 계획입니다.

00:41:13.660 --> 00:41:16.920
어, 하지만 여러분이 보시는 다중 모달 조작

00:41:16.920 --> 00:41:18.080
문제는 해결할 수 있습니다.

00:41:18.540 --> 00:41:21.520
요즘 모방 학습이나 데이터 기반

00:41:21.520 --> 00:41:22.340
접근법에서 매우 인기가 있습니다.

00:41:22.340 --> 00:41:25.020
그 모든 문제들을, 어, 저희는

00:41:25.020 --> 00:41:25.600
이 모델들로 해결할 수 있습니다.

00:41:26.760 --> 00:41:29.660
또 저희가 확장한 다른 영역은, 그러니까, 미지의

00:41:29.660 --> 00:41:30.140
환경입니다.

00:41:30.320 --> 00:41:32.620
지금은 우리가 환경을 안다고 가정하고,

00:41:32.640 --> 00:41:34.040
그리고 그 환경으로부터,

00:41:34.040 --> 00:41:36.440
어, 장애물까지의 거리를 계산했습니다.

00:41:36.620 --> 00:41:38.100
조금 속도를 내겠습니다.

00:41:38.600 --> 00:41:42.700
그래서 저희가 생각하기에

00:41:42.700 --> 00:41:44.900
모션 플래닝 문제가 계산적으로 비싼 이유는

00:41:44.900 --> 00:41:48.440
매핑 특징이

00:41:48.440 --> 00:41:49.200
모션 플래닝에 적합하지 않기 때문입니다.

00:41:49.360 --> 00:41:52.220
매핑 특징과

00:41:52.220 --> 00:41:53.760
모션 플래너 사이에는 큰 간극이 있습니다.

00:41:53.920 --> 00:41:55.740
예를 들어 부호 거리장이나

00:41:55.740 --> 00:41:59.780
점유 지도 같은 것이 있어서

00:41:59.780 --> 00:42:03.360
모션 플래닝을 위해 계산 비용이 큰 도구들을 만들게 됩니다.

00:42:03.640 --> 00:42:06.400
예를 들어 그런 지도를

00:42:06.400 --> 00:42:06.820
C-공간으로 변환하려면,

00:42:07.000 --> 00:42:08.780
샘플링 기반 기법을 쓰거나

00:42:08.780 --> 00:42:09.520
최적화를 해야 합니다.

00:42:09.760 --> 00:42:12.440
그다음 C

00:42:12.440 --> 00:42:12.680
-공간에서 궤적을 찾습니다.

00:42:12.680 --> 00:42:15.320
그러면 더 나은 매핑을

00:42:15.320 --> 00:42:18.600
이런, 어, 매우 복잡한

00:42:19.020 --> 00:42:19.280
도구 없이 만들 수 있을까요?

00:42:19.440 --> 00:42:20.640
답은 그렇습니다.

00:42:20.840 --> 00:42:25.200
만약 지도를, 어, 이동 시간 함수로

00:42:25.200 --> 00:42:27.660
학습할 수 있다면, 어떤

00:42:27.660 --> 00:42:27.920
플래너도 필요 없습니다.

00:42:27.980 --> 00:42:30.120
그 이동 시간의 기울기를 따라가기만 하면,

00:42:30.120 --> 00:42:32.320
그것이 궤적을 제공합니다.

00:42:32.600 --> 00:42:36.120
그래서 저희는 그것을 조사했습니다.

00:42:36.120 --> 00:42:38.340
로봇이 환경을 탐색하면서

00:42:38.340 --> 00:42:39.620
깊이 인식을 얻고,

00:42:39.620 --> 00:42:43.060
제약 함수를 로컬하게 근사할 수 있습니다.

00:42:43.640 --> 00:42:46.640
그래서 데이터가 들어오는 대로

00:42:46.640 --> 00:42:47.520
이 모델을 학습시킬 수 있습니다.

00:42:47.680 --> 00:42:49.340
그래서, 어, 여기 영상은

00:42:49.340 --> 00:42:51.160
로봇이 환경을 탐색하는 모습을 보여줍니다.

00:42:52.240 --> 00:42:54.280
인식 정보가 스트림으로 들어오고,

00:42:54.280 --> 00:42:56.580
이 도달 시간 필드 지도를 구축하고 있습니다.

00:42:59.380 --> 00:43:01.200
그리고 이 지도가 있으면,

00:43:01.200 --> 00:43:02.500
어떤 모션 플래닝 도구도 필요 없습니다.

00:43:02.600 --> 00:43:04.720
그냥 이 지도의 기울기를 따라가면 됩니다.

00:43:04.880 --> 00:43:09.100
이 지도에는 로봇의 환경 탐색에 도움이 되는 기하학적 표현이

00:43:09.100 --> 00:43:10.580
통합되어 있습니다.

00:43:12.320 --> 00:43:16.800
그리고 이 논문에서는 매핑 시간이

00:43:16.800 --> 00:43:20.700
표준 매핑, 예를 들어 점유

00:43:20.700 --> 00:43:21.040
지도보다 두 배였습니다.

00:43:21.240 --> 00:43:23.200
하지만 최신 모델에서는

00:43:23.200 --> 00:43:25.620
이 시간을 약 40% 줄일 수 있었습니다.

00:43:25.620 --> 00:43:29.020
그래서, 어, 매번, 즉 각 프레임마다,

00:43:29.200 --> 00:43:31.680
이 경우 신경망은 학습에 2초가

00:43:31.680 --> 00:43:32.300
걸립니다.

00:43:32.300 --> 00:43:34.360
하지만 최신 모델은, 제 생각에,

00:43:34.360 --> 00:43:36.220
로봇이 탐색하는 동안 학습하는 데

00:43:36.220 --> 00:43:37.240
1초도 채 걸리지 않습니다.

00:43:37.740 --> 00:43:41.920
그리고 이것은, 그러니까, 어, 어,

00:43:43.080 --> 00:43:45.780
그래서 이것은 RARE 로봇이 이

00:43:45.780 --> 00:43:46.260
환경을 매핑하는 모습입니다.

00:43:51.460 --> 00:43:53.380
탐색하는 동안을 보시면,

00:43:53.420 --> 00:43:55.460
즉석에서 모델을 학습하면서,

00:43:55.480 --> 00:43:58.340
어, 그 이동 시간을 얻고 있습니다.

00:43:58.340 --> 00:44:00.180
그래서 이런 지도를

00:44:00.180 --> 00:44:02.980
점유 지도와 거의 같은 시간 안에

00:44:02.980 --> 00:44:03.260
얻을 수 있다면,

00:44:03.460 --> 00:44:05.200
그러면 모션 플래너가 전혀 필요 없습니다.

00:44:05.420 --> 00:44:08.320
그냥 로봇을

00:44:08.320 --> 00:44:09.140
미지의 환경 어디에든 배치할 수 있고,

00:44:09.200 --> 00:44:10.900
로봇이 어떻게 움직여야 하는지

00:44:10.900 --> 00:44:13.640
이러한 플러그앤플레이

00:44:13.640 --> 00:44:14.160
모델로 그 환경에서 스스로 알아냅니다.

00:44:16.000 --> 00:44:18.320
그리고 또 다른 장점으로는, 그러니까, 여러분이

00:44:18.320 --> 00:44:19.700
이것으로 조작까지 할 수 있습니다.

00:44:19.800 --> 00:44:21.940
로봇에 손안(인핸드)

00:44:21.940 --> 00:44:22.320
카메라를

00:44:22.340 --> 00:44:24.800
장착할 수 있고, 로봇이 탐색하면서 이러한 도달

00:44:24.800 --> 00:44:26.400
시간 필드 맵을 C-공간에서 구축합니다.

00:44:27.200 --> 00:44:29.720
그리고 여전히, 어, 또 여전히, 그러니까,

00:44:29.800 --> 00:44:30.180
내비게이션도 합니다.

00:44:30.440 --> 00:44:32.880
그래서 저희는 이를, 어, TRO

00:44:32.880 --> 00:44:33.240
논문에서 보여드립니다.

00:44:33.580 --> 00:44:35.580
관심이 있으시면 이것을 확인해 보십시오.

00:44:38.000 --> 00:44:38.480
네.

00:44:39.780 --> 00:44:42.140
그래서 이것이, 그러니까, 로봇 팔 셋업

00:44:42.140 --> 00:44:42.560
구성이었습니다.

00:44:42.660 --> 00:44:44.400
이것은 이 인핸드 카메라를 사용해서

00:44:44.400 --> 00:44:46.840
6차원 C-공간에서 이 도달 시간 필드 맵을

00:44:46.840 --> 00:44:47.800
구축하는 것이었습니다.

00:44:49.900 --> 00:44:51.960
또 우리가 관심 있는 다른 분야는, 그러니까, 어떻게

00:44:51.960 --> 00:44:54.220
이러한 PDE들을, 어,

00:44:55.560 --> 00:44:56.620
어, 다중 에이전트 설정에서 풀 수 있는가입니다.

00:44:56.900 --> 00:44:59.820
그래서 기본적으로, 예를 들어 HGBPD 대신 기본적으로

00:44:59.820 --> 00:45:01.200
HGR을 풉니다.

00:45:01.200 --> 00:45:04.200
여기서 Sumel Benson의 연구를 아실 수도 있습니다.

00:45:04.200 --> 00:45:07.780
그리고, 어, 그의 연구와 다른 점은

00:45:07.780 --> 00:45:09.280
우리가, 그러니까, 이 방법들의

00:45:09.280 --> 00:45:10.480
확장성을 더 밀어붙이려는 것입니다.

00:45:10.480 --> 00:45:13.920
매우 복잡한 로봇 매니퓰레이터와 매우 복잡한

00:45:13.920 --> 00:45:15.420
장애물의 기하 구조까지요.

00:45:16.620 --> 00:45:18.880
그리고 이것이 저희 작업 중 하나인데요,

00:45:18.960 --> 00:45:22.300
어, 어, 여기에서 로봇들이 도달하려고 합니다

00:45:22.300 --> 00:45:22.840
자신들의 목표에

00:45:22.840 --> 00:45:24.440
저희가 적극적으로 충돌을 회피하면서요.

00:45:24.720 --> 00:45:28.200
또한 이를, 어, 조립

00:45:28.200 --> 00:45:30.740
라인 작업으로 확장했는데, 여러 로봇이 자신의,

00:45:30.900 --> 00:45:31.180
어,

00:45:32.320 --> 00:45:34.020
어, 작업을 수행하면서 충돌을 회피하도록 했습니다.

00:45:34.160 --> 00:45:36.260
그래서, 어, 관심이 있으시면, 그러니까, 확인해

00:45:36.260 --> 00:45:37.060
보시면 됩니다.

00:45:37.060 --> 00:45:40.280
그래서 결론적으로, 물리 기반 사전지식을 사용해야 합니다,

00:45:40.280 --> 00:45:42.840
그 이유는 이 세 가지 특징을 제공하기 때문입니다.

00:45:42.840 --> 00:45:43.300
즉,

00:45:43.480 --> 00:45:46.400
추론 효율성, 학습 효율성, 적응성입니다.

00:45:46.700 --> 00:45:50.080
향후 연구 방향으로는, 우선, 우리는

00:45:50.080 --> 00:45:52.060
학습 효율성을 개선하고자 합니다.

00:45:52.320 --> 00:45:54.140
현재 모델은, 그러니까, 5분 정도가 걸립니다.

00:45:54.160 --> 00:45:56.300
저는, 그러니까, 실시간 학습을 달성하고 싶습니다.

00:45:56.540 --> 00:45:59.000
그래서, 그래서 이 신경망이

00:45:59.000 --> 00:46:00.200
플러그앤플레이 모델이 되도록 하려는 것입니다.

00:46:00.760 --> 00:46:01.620
그것이 제 비전입니다.

00:46:01.820 --> 00:46:03.280
즉, 이런 플러그앤플레이

00:46:03.280 --> 00:46:06.500
모델이 있으면, 새로운 환경으로의 전이성과 일반화는

00:46:06.500 --> 00:46:08.920
문제가 되지 않습니다, 로봇이

00:46:08.920 --> 00:46:10.600
그냥 그곳에 가서, 가서

00:46:10.600 --> 00:46:10.860
즉석에서

00:46:10.860 --> 00:46:13.700
모든 조작 모션 플래닝 문제를 수행할 수 있기 때문입니다.

00:46:14.480 --> 00:46:16.860
그리고 우리가 관심 있는 다른 분야는

00:46:16.860 --> 00:46:19.760
반응형인데, 이런 방법들이 매우 빠르기 때문입니다.

00:46:20.220 --> 00:46:23.180
따라서 매우 다른

00:46:23.180 --> 00:46:26.220
설정으로 일반화할 수 있다면, 환경을 교란하더라도,

00:46:26.440 --> 00:46:28.300
아주 빠르게 회복할 수 있습니다.

00:46:30.480 --> 00:46:33.400
그리고 이것은, 그러니까, 멀티모달 문제인데요,

00:46:33.440 --> 00:46:36.240
로봇이 파지와 조작을 위한 계획을 함께 세우는 경우입니다.

00:46:36.240 --> 00:46:38.420
그래서 이것도 우리가

00:46:38.420 --> 00:46:38.860
확장하고 있는 또 다른 분야입니다.

00:46:39.640 --> 00:46:42.800
이것은 제가 최근에 관심을 갖게 된

00:46:42.800 --> 00:46:43.580
새로운 문제입니다.

00:46:43.800 --> 00:46:48.520
이는 보조 조작(assistive manipulation)이라고 하며, 로봇이

00:46:48.520 --> 00:46:51.440
여러 작업을 하기 위해 사람의 몸을 조작하는 것입니다.

00:46:51.560 --> 00:46:54.900
예를 들어 보조 착의는 조작

00:46:54.900 --> 00:46:55.320
문제입니다.

00:46:55.320 --> 00:46:58.500
사람의 몸을 움직이기 위해서는 생체역학적 제약을

00:46:58.500 --> 00:46:59.360
존중해야 합니다.

00:46:59.360 --> 00:47:01.400
저는 이것이 연구하기에 매우 좋은 모션 플래닝

00:47:01.400 --> 00:47:04.080
문제라고 생각하며, 우리는 이러한

00:47:04.080 --> 00:47:04.440
방법들을

00:47:04.440 --> 00:47:05.880
그러한 도메인으로도 확장하고 있습니다.

00:47:06.100 --> 00:47:09.140
그래서 이것은 시뮬레이션에서의 침대 닦기 작업이고,

00:47:09.140 --> 00:47:09.760
시뮬레이션에서 수행됩니다.

00:47:10.000 --> 00:47:12.060
그러니까 로봇이 사람의 팔다리를

00:47:12.060 --> 00:47:14.140
한 지점에서 다른 지점으로 옮기고, 다른 로봇이

00:47:14.140 --> 00:47:15.780
몸을 닦고 있습니다.

00:47:16.340 --> 00:47:18.140
이로써 발표를 마치겠습니다.

00:47:18.140 --> 00:47:19.320
시간도 거의 맞췄습니다.

00:47:19.580 --> 00:47:21.260
그리고 이것이 제 연구실입니다.

00:47:21.440 --> 00:47:23.360
이분들이 없었다면 어떤 것도 가능하지 않았을 것입니다.

00:47:23.360 --> 00:47:25.060
관심이 있으시면 저희

00:47:25.060 --> 00:47:25.720
연구실 웹사이트를 확인해 보십시오.

00:47:27.860 --> 00:47:29.500
이상으로 마치겠습니다.

00:47:29.580 --> 00:47:29.940
감사합니다.

00:47:30.220 --> 00:47:30.820
질문 있으신가요?

00:47:35.760 --> 00:47:36.280
네.

00:47:37.720 --> 00:47:38.880
훌륭한 발표 감사합니다.

00:47:39.200 --> 00:47:41.700
한 가지 여쭙고 싶은데요, 어떻게

00:47:41.700 --> 00:47:43.520
선생님 방법을, 예를 들면, 어떤 다른

00:47:43.520 --> 00:47:43.920
방법들과

00:47:44.740 --> 00:47:47.480
최근의 모션 플래닝 방법들, 예를 들어 기하학적

00:47:47.480 --> 00:47:48.920
패턴, 또는 Drop from All

00:47:48.920 --> 00:47:51.700
Except 같은 것들과 비교하실 수 있을까요, 가능하시다면, 그리고

00:47:51.700 --> 00:47:53.040
그리고 결과적으로, 예를 들어, 그러니까….

00:47:57.020 --> 00:48:00.240
그래서, 그래서, 개념적으로 보면, 저는

00:48:00.240 --> 00:48:03.280
이런 방법들이 몇 가지 가정을 두고 수행된다고 생각합니다.

00:48:03.280 --> 00:48:07.300
예를 들어 볼록한 장애물이 있다는 가정 같은 것입니다.

00:48:07.580 --> 00:48:09.560
그래서 그것이 하나의 가정입니다.

00:48:09.820 --> 00:48:13.060
예를 들어, 보시면, 그게

00:48:13.060 --> 00:48:13.740
이름이 무엇이었습니까?

00:48:14.180 --> 00:48:15.580
쿠로보(Kurobo)라는 것이 있습니다.

00:48:16.020 --> 00:48:18.840
Kurobo가 어떻게 동작하는지 보면, 그들은

00:48:18.840 --> 00:48:23.020
로봇 환경을 여러 개의 구로 표현한다고 가정합니다.

00:48:23.380 --> 00:48:26.220
그다음 모션 플래닝 문제를 매우 빠르게 풉니다.

00:48:26.560 --> 00:48:26.920
알겠습니까?

00:48:27.300 --> 00:48:30.280
그리고 병렬화에 관한 그들의 테스트 작업도

00:48:30.280 --> 00:48:33.260
이 병렬화에 크게 의존합니다.

00:48:33.260 --> 00:48:36.060
즉, 로봇과

00:48:36.060 --> 00:48:36.540
환경의 구형 표현에 의존합니다.

00:48:36.840 --> 00:48:39.620
그리고 이 모션 플래닝 문제를

00:48:39.620 --> 00:48:40.540
기본적으로 작업공간에서 풉니다.

00:48:41.260 --> 00:48:43.120
하지만 거기에는 본질적인 문제가 있습니다.

00:48:43.300 --> 00:48:45.320
예를 들어, 이 문제를

00:48:45.320 --> 00:48:49.140
작업공간에서 풀면, 많은 최신 연구가

00:48:49.220 --> 00:48:50.040
예를 들어 모방학습에서도

00:48:50.160 --> 00:48:51.780
이 문제를 작업공간에서 풀고 있습니다.

00:48:52.420 --> 00:48:54.880
하지만 이 궤적을

00:48:54.880 --> 00:48:56.760
C-공간 궤적으로 매핑할 수 있다는 보장은 없습니다.

00:48:56.980 --> 00:48:58.820
로봇이 국소 최솟값에 빠질 수도 있습니다.

00:48:59.360 --> 00:49:01.960
종종 매우 복잡한

00:49:01.960 --> 00:49:05.200
작업을 수행할 때, 작업공간 궤적에서

00:49:05.200 --> 00:49:07.660
C-공간으로의 직접적인 매핑이

00:49:07.660 --> 00:49:07.880
없다는 것을 보게 됩니다.

00:49:08.100 --> 00:49:11.280
그리고 모션 플래닝을 정말로 깊게 공부하고

00:49:11.280 --> 00:49:16.060
1990년대 초반의 문헌을 살펴보면, 그때는

00:49:16.060 --> 00:49:17.540
작업공간에서 모션 플래닝을 하고 있었습니다.

00:49:17.540 --> 00:49:19.320
그다음 이것이 문제라는 것을 알아냈고,

00:49:19.360 --> 00:49:21.240
그 후 C-공간 플래닝으로 옮겨갔습니다.

00:49:21.820 --> 00:49:24.640
안타깝게도 우리는 다시 작업공간 플래닝으로 돌아가고 있습니다.

00:49:25.040 --> 00:49:27.900
그래서 최신 방법들은 매우 빠르지만,

00:49:28.100 --> 00:49:31.880
이런 가정들에 의존하며, 그것은 결국

00:49:31.880 --> 00:49:33.860
C-공간 궤적으로의 매핑 문제로

00:49:33.860 --> 00:49:34.660
이어질 것입니다.

00:49:34.660 --> 00:49:37.080
네, 저도 그렇게 보지는 않으며, 저는

00:49:37.080 --> 00:49:37.760
그 부분을 잘 접해보지 못했습니다.

00:49:38.800 --> 00:49:41.060
그래서 geometric fabric은 저는 잘 알지 못합니다.

00:49:41.200 --> 00:49:42.640
하지만 말씀하신 다른 논문은

00:49:42.800 --> 00:49:44.720
꽤 합리적인 구형 표현을 가정하는 것 아닙니까?

00:49:45.460 --> 00:49:45.660
그렇지 않습니까?

00:49:46.180 --> 00:49:48.500
아마 제가 다른 논문을 생각하고 있는 것일 수도 있습니다.

00:49:49.040 --> 00:49:49.280
네.

00:49:49.560 --> 00:49:51.080
그렇다면 저는 그것에 대해 잘 알지 못합니다.

00:49:51.320 --> 00:49:55.460
제 생각에는, 기하학적 시스템에는

00:49:55.460 --> 00:49:56.640
매우 흥미로울 수도 있습니다.

00:49:56.880 --> 00:49:57.160
죄송합니다, 뭐라고 하셨습니까?

00:49:57.160 --> 00:50:01.180
즉, 기본적으로 시스템을

00:50:01.180 --> 00:50:03.560
동역학 시스템으로 모델링한 다음, 본질적으로

00:50:03.560 --> 00:50:04.140
추출하여

00:50:04.140 --> 00:50:05.540
흐름 벡터장을 얻으려는 것입니다.

00:50:05.660 --> 00:50:05.980
네.

00:50:06.080 --> 00:50:06.740
왔다 갔다 합니다.

00:50:06.960 --> 00:50:08.800
그러니까 그런 의미에서는, 그것이

00:50:08.800 --> 00:50:10.120
하나의 응용이 될 수도 있습니다.

00:50:10.200 --> 00:50:10.680
네, 네.

00:50:10.920 --> 00:50:11.300
그러면…

00:50:11.300 --> 00:50:13.740
예를 들어 다른 함수를 취하려고 할 때, 그것의

00:50:13.740 --> 00:50:14.880
수렴 특성은 어떻게 됩니까?

00:50:15.180 --> 00:50:17.560
음, 매우 강한 관련성이 있다고 생각합니다.

00:50:17.800 --> 00:50:21.240
예를 들어, 저희가 최근에

00:50:21.240 --> 00:50:24.980
NeurIPS에 제출한 연구는 기본적으로 키노다이내믹 쪽으로, 즉 어떻게

00:50:24.980 --> 00:50:27.400
이런 이동 시간

00:50:27.400 --> 00:50:29.580
장을 동적 공간에서 만들 수 있는가에 관한 것입니다.

00:50:30.360 --> 00:50:32.440
말씀하시는 연구는 제가 잘 알지 못해서

00:50:32.500 --> 00:50:35.140
그 관련성에 대해서는 말씀드리기 어렵습니다.

00:50:35.560 --> 00:50:38.460
하지만 일반적으로 저희는

00:50:38.460 --> 00:50:38.980
벡터장으로 나아가고자 합니다.

00:50:39.220 --> 00:50:41.500
다만 저희는 그것을

00:50:41.500 --> 00:50:43.700
전문가 시연 없이, 전문가로부터

00:50:43.700 --> 00:50:46.100
데이터를 학습하지 않고, 그 PDE들을 푸는 것만으로 이루고자 합니다.

00:50:46.580 --> 00:50:47.080
알겠습니까?

00:50:47.320 --> 00:50:49.220
어떤 연구를 말씀하시는지 잘 모르겠습니다.

00:50:49.340 --> 00:50:50.880
공유해 주시면, 제가

00:50:50.880 --> 00:50:52.820
확인한 뒤 다시 답변드리겠습니다.

00:50:53.300 --> 00:50:53.520
네.

00:50:53.520 --> 00:50:55.140
다른 질문 있으십니까?

00:50:59.560 --> 00:51:00.760
질문이 있습니다.

00:51:02.080 --> 00:51:07.060
제가 가진 한 가지 문제는

00:51:07.060 --> 00:51:09.900
공이 제약에 가까우면

00:51:09.900 --> 00:51:10.520
해가

00:51:11.060 --> 00:51:12.060
상당히 불안정해질 수 있다는 점입니다.

00:51:15.040 --> 00:51:18.060
푸는 과정에서, 그러니까

00:51:18.360 --> 00:51:20.040
제약 주변의 힘이 문제입니다.

00:51:20.780 --> 00:51:23.180
선생님 문제도 비슷한 문제가 있습니까?

00:51:23.720 --> 00:51:24.300
네.

00:51:24.500 --> 00:51:27.080
그래서 데이터를 샘플링하는 방식이 매우

00:51:27.080 --> 00:51:27.560
중요합니다.

00:51:28.540 --> 00:51:31.460
제 생각에는, 제 경험으로는, 저희 경험으로는

00:51:31.460 --> 00:51:34.120
커리큘럼을 만드는 것이 도움이 되는데, 예를 들어

00:51:34.120 --> 00:51:37.020
더 단순한 문제에서 시작해서 천천히

00:51:37.020 --> 00:51:38.520
시작점과 목표점을 아주

00:51:38.520 --> 00:51:40.000
멀게 설정해 가는 것이 도움이 됩니다.

00:51:40.340 --> 00:51:43.080
또 다른 도움이 되는 점은

00:51:43.080 --> 00:51:46.600
장애물 근처의 샘플을 더 많이 갖는 것인데, 왜냐하면

00:51:46.600 --> 00:51:48.540
그런 구간에서 특징이 급격하게

00:51:48.540 --> 00:51:50.480
변하고, 신경망이

00:51:50.480 --> 00:51:51.240
그것을 더 잘 학습하기를 원하기 때문입니다.

00:51:51.240 --> 00:51:54.700
그래서 네, 저희도

00:51:54.700 --> 00:51:57.900
그런 문제를 겪고 있으며, 적응적 샘플링이 도움이 됩니다.

00:51:57.900 --> 00:51:58.000
네.

00:51:58.120 --> 00:51:58.720
알겠습니다.

00:51:58.820 --> 00:52:02.040
하지만 학습을 성공적으로 마친 뒤에는, 그러면

00:52:02.040 --> 00:52:04.160
즉, 그때도 똑같이

00:52:04.760 --> 00:52:07.220
더 저렴하게, 음, 오프스토어에서

00:52:07.220 --> 00:52:07.740
샘플을 뽑아 올릴 수 있다는 뜻인가요?

00:52:09.560 --> 00:52:12.300
그래디언트를 따라가면, 그리고 이는

00:52:12.300 --> 00:52:14.580
근사이기 때문에 로컬 최소값으로 갈 수 있습니다.

00:52:14.700 --> 00:52:16.460
하지만 이 신경망을

00:52:16.460 --> 00:52:19.060
가치 함수로 사용하고 어떤 MPPI에 통합하면,

00:52:19.300 --> 00:52:20.220
그러면

00:52:20.220 --> 00:52:23.020
그런 로컬 최소값 문제를 극복하는 데 도움이 되고

00:52:23.020 --> 00:52:24.400
더 잘 작동합니다.

00:52:24.560 --> 00:52:24.940
알겠습니다.

00:52:25.240 --> 00:52:25.340
알겠습니다.

00:52:25.580 --> 00:52:26.140
물론입니다.

00:52:26.640 --> 00:52:26.760
네.

00:52:26.880 --> 00:52:27.120
감사합니다.

00:52:27.300 --> 00:52:29.700
그리고 또 하나는...

00:52:29.700 --> 00:52:30.260
네.

00:52:33.040 --> 00:52:35.320
음, 상용 시스템들이 어떤 방법을 쓰는지, 음,

00:52:35.720 --> 00:52:36.440
상용...

00:52:39.580 --> 00:52:41.600
아마, 음, 보통은,

00:52:41.860 --> 00:52:44.280
무엇을 쓰는지는 모르겠지만,

00:52:44.280 --> 00:52:44.520
보통은

00:52:44.520 --> 00:52:47.460
어떤 고전적인 기법이거나, 또는,

00:52:47.700 --> 00:52:50.140
고전적인 모션 플래너 같은 것이거나

00:52:50.140 --> 00:52:50.500
그런 것일 것입니다.

00:52:51.120 --> 00:52:52.960
저, 저는 그게

00:52:52.960 --> 00:52:53.600
그럴 거라고 가정하지만, 저는...

00:52:53.600 --> 00:52:54.020
저는...

00:52:54.320 --> 00:52:55.020
저는...

00:52:55.080 --> 00:52:55.780
저는...

00:52:55.780 --> 00:52:56.300
저는...

00:52:59.300 --> 00:53:00.700
저는...

00:53:00.700 --> 00:53:00.780
저는...

00:53:00.780 --> 00:53:00.960
저는...
