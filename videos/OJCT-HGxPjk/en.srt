1
00:00:00,000 --> 00:00:01,540
just like the fact that this whole thing

2
00:00:01,540 --> 00:00:04,920
works it's kind of mind-blowing yeah right

3
00:00:04,920 --> 00:00:05,340
like you

4
00:00:05,340 --> 00:00:07,220
you build this like loosely brain inspired

5
00:00:07,220 --> 00:00:09,100
thing

6
00:00:09,100 --> 00:00:10,590
that has very general purpose learning

7
00:00:10,590 --> 00:00:12,080
algorithm

8
00:00:12,080 --> 00:00:14,600
you feed it data and it somehow gets

9
00:00:14,600 --> 00:00:16,480
it and gets it way better than anything

10
00:00:16,480 --> 00:00:17,460
we've ever had before

11
00:00:17,460 --> 00:00:19,720
and this applies to robots and it applies

12
00:00:19,720 --> 00:00:22,320
to vision and language and sound and all

13
00:00:22,320 --> 00:00:22,640
kinds of

14
00:00:22,640 --> 00:00:25,220
other things and like i think if you

15
00:00:25,220 --> 00:00:27,560
stop for a second and just think about

16
00:00:27,560 --> 00:00:29,000
it how it works and

17
00:00:29,700 --> 00:00:30,650
and that it works it's just like

18
00:00:30,650 --> 00:00:31,600
absolutely

19
00:00:31,600 --> 00:00:32,240
mind-blowing

20
00:00:49,220 --> 00:00:51,240
in this episode we sit down with carol

21
00:00:51,240 --> 00:00:52,460
and toby of physical intelligence a

22
00:00:52,460 --> 00:00:53,680
company building

23
00:00:53,680 --> 00:00:55,320
foundation models for robotics carol and

24
00:00:55,320 --> 00:00:56,960
toby explain

25
00:00:56,960 --> 00:00:58,480
why the classical approach of breaking

26
00:00:58,480 --> 00:00:59,770
robotics down into perception planning and

27
00:00:59,770 --> 00:01:01,060
control was

28
00:01:01,060 --> 00:01:03,100
fundamentally wrong and how end-to-end

29
00:01:03,100 --> 00:01:04,587
learning with reinforcement learning is

30
00:01:04,587 --> 00:01:05,540
finally making deployment

31
00:01:05,540 --> 00:01:07,540
possible you'll hear how they

32
00:01:07,540 --> 00:01:09,516
achieved robust real-world performance

33
00:01:09,516 --> 00:01:10,400
getting robots to

34
00:01:10,400 --> 00:01:12,700
make coffee for 13 hours straight and how

35
00:01:12,700 --> 00:01:12,880
these

36
00:01:12,880 --> 00:01:14,564
models generalize across radically

37
00:01:14,564 --> 00:01:16,000
different tasks from surgical

38
00:01:16,000 --> 00:01:17,880
robots to drone flying in ways that we

39
00:01:17,880 --> 00:01:19,260
don't fully understand we also talk about

40
00:01:19,260 --> 00:01:20,640
the

41
00:01:20,640 --> 00:01:22,310
technical insights behind pi star 0.6

42
00:01:22,310 --> 00:01:23,980
which

43
00:01:23,980 --> 00:01:24,120
is

44
00:01:24,120 --> 00:01:25,864
physical intelligence's newest model that

45
00:01:25,864 --> 00:01:26,800
learns from experience

46
00:01:26,800 --> 00:01:28,940
using reinforcement learning enjoy the

47
00:01:28,940 --> 00:01:32,700
show carl toby thank you so much for

48
00:01:32,700 --> 00:01:34,300
joining us here today thank you for having

49
00:01:34,300 --> 00:01:35,220
us excited to talk

50
00:01:35,220 --> 00:01:37,694
everything physical intelligence general

51
00:01:37,694 --> 00:01:39,240
robotics etc maybe before

52
00:01:39,240 --> 00:01:40,460
we get into it just for our audience

53
00:01:40,460 --> 00:01:41,660
can you share a little bit about what

54
00:01:41,660 --> 00:01:42,550
physical intelligence is and the mission

55
00:01:42,550 --> 00:01:43,440
that you're

56
00:01:43,440 --> 00:01:43,640
after

57
00:01:43,640 --> 00:01:45,290
yeah so at physical intelligence we are

58
00:01:45,290 --> 00:01:46,940
building

59
00:01:46,940 --> 00:01:48,630
robotic foundation models these are models

60
00:01:48,630 --> 00:01:50,320
that in

61
00:01:50,320 --> 00:01:51,780
principle should have should be able to

62
00:01:51,780 --> 00:01:53,240
have

63
00:01:53,240 --> 00:01:57,280
any robot do any task um and over

64
00:01:57,280 --> 00:01:58,200
the past one and a half

65
00:01:58,200 --> 00:02:02,320
years or so we started building the we

66
00:02:02,320 --> 00:02:03,690
we created the right building blocks that

67
00:02:03,690 --> 00:02:05,060
show

68
00:02:05,060 --> 00:02:06,080
how these models could

69
00:02:06,080 --> 00:02:09,160
scale so we've shown that they're able to

70
00:02:09,160 --> 00:02:10,781
control many different robotic form

71
00:02:10,781 --> 00:02:11,800
factors many different

72
00:02:11,800 --> 00:02:12,220
types of

73
00:02:12,220 --> 00:02:13,310
robots we've also shown that they're able

74
00:02:13,310 --> 00:02:14,400
to

75
00:02:14,400 --> 00:02:15,290
generalize so you can bring it to

76
00:02:15,290 --> 00:02:16,180
completely

77
00:02:16,180 --> 00:02:17,060
new environments and

78
00:02:17,060 --> 00:02:19,740
what it takes for them to generalize and

79
00:02:19,740 --> 00:02:22,000
this this last release that we just had

80
00:02:22,000 --> 00:02:23,600
called pi star 06 that

81
00:02:23,600 --> 00:02:24,940
we also wanted to tell you more about

82
00:02:24,940 --> 00:02:27,780
um shows how we can get them to

83
00:02:27,780 --> 00:02:30,800
a good performance so that they're

84
00:02:30,800 --> 00:02:32,460
starting to become deployable and this is

85
00:02:32,460 --> 00:02:34,120
really

86
00:02:34,120 --> 00:02:35,520
important to us because we want to see

87
00:02:35,520 --> 00:02:36,020
this technology

88
00:02:36,020 --> 00:02:37,140
actually deployed in the real world but

89
00:02:37,140 --> 00:02:38,260
also

90
00:02:38,260 --> 00:02:40,030
because we don't have the benefit of

91
00:02:40,030 --> 00:02:41,800
having

92
00:02:41,800 --> 00:02:44,200
the the free data on the

93
00:02:44,200 --> 00:02:47,640
internet there is no data of robot actions

94
00:02:47,640 --> 00:02:49,260
so we need to create the data sets

95
00:02:49,260 --> 00:02:51,280
ourselves so we are

96
00:02:51,280 --> 00:02:52,490
after the problem of physical intelligence

97
00:02:52,490 --> 00:02:53,700
after the

98
00:02:53,700 --> 00:02:54,890
problem of creating foundation models for

99
00:02:54,890 --> 00:02:56,080
robots

100
00:02:56,720 --> 00:02:58,480
and we've made quite a lot of progress

101
00:02:58,480 --> 00:03:01,120
wonderful and can i ask why the decision

102
00:03:01,120 --> 00:03:02,060
to build foundation

103
00:03:02,060 --> 00:03:03,180
models as opposed to you know their

104
00:03:03,180 --> 00:03:04,300
companies

105
00:03:04,300 --> 00:03:05,420
that are building fully vertically

106
00:03:05,420 --> 00:03:06,540
integrated robotic

107
00:03:06,540 --> 00:03:09,200
products right now uh you you know the

108
00:03:09,200 --> 00:03:11,140
sunday launch last month is in the back

109
00:03:11,140 --> 00:03:11,840
of my head you can buy

110
00:03:11,840 --> 00:03:12,910
a cute little robot helper for your

111
00:03:12,910 --> 00:03:13,980
household

112
00:03:13,980 --> 00:03:15,200
there's companies working on cooking

113
00:03:15,200 --> 00:03:16,420
robots there's

114
00:03:16,420 --> 00:03:17,550
obviously the humanoid companies um why

115
00:03:17,550 --> 00:03:18,680
build a

116
00:03:18,680 --> 00:03:20,843
foundation model versus build a robot

117
00:03:20,843 --> 00:03:21,720
yourselves yeah

118
00:03:22,320 --> 00:03:23,780
so i think if you look at the

119
00:03:23,780 --> 00:03:25,320
history of robotics it's very very clear

120
00:03:25,320 --> 00:03:26,860
to

121
00:03:26,860 --> 00:03:27,840
me and i think to many

122
00:03:27,840 --> 00:03:29,770
roboticists that we've been always

123
00:03:29,770 --> 00:03:31,360
bottlenecked on intelligence

124
00:03:31,360 --> 00:03:34,100
we've had robots that are capable of

125
00:03:34,100 --> 00:03:35,180
doing incredible things whether it's in

126
00:03:35,180 --> 00:03:36,260
the home

127
00:03:36,260 --> 00:03:39,263
or in industrial settings we've seen

128
00:03:39,263 --> 00:03:40,180
robots more

129
00:03:40,180 --> 00:03:40,480
than a

130
00:03:40,480 --> 00:03:43,640
decade ago that if tella operated they can

131
00:03:43,640 --> 00:03:47,400
clean the entire house and that the the

132
00:03:47,400 --> 00:03:47,920
really important

133
00:03:47,920 --> 00:03:50,920
caveat is if tella operated so if there's

134
00:03:50,920 --> 00:03:53,180
a human mind behind it it's clear that

135
00:03:53,180 --> 00:03:53,780
the hardware is

136
00:03:53,780 --> 00:03:55,200
capable of doing lots of different things

137
00:03:55,200 --> 00:03:56,620
and

138
00:03:56,620 --> 00:03:58,120
for a very long time robotics companies

139
00:03:58,120 --> 00:03:59,620
have

140
00:03:59,620 --> 00:03:59,780
been

141
00:03:59,780 --> 00:04:00,970
structured the way you described where you

142
00:04:00,970 --> 00:04:02,160
kind

143
00:04:02,160 --> 00:04:03,180
of think of creating a specific robot

144
00:04:03,180 --> 00:04:04,200
that's

145
00:04:04,200 --> 00:04:04,820
designed to

146
00:04:04,820 --> 00:04:06,420
do just a single task or a single

147
00:04:06,420 --> 00:04:08,330
application and instead what we thought

148
00:04:08,330 --> 00:04:10,240
would be

149
00:04:10,240 --> 00:04:11,260
would really help

150
00:04:11,260 --> 00:04:13,940
the field is to focus on the bottleneck

151
00:04:13,940 --> 00:04:14,970
on the intelligence so we created a

152
00:04:14,970 --> 00:04:16,000
company

153
00:04:16,000 --> 00:04:16,700
to focus on

154
00:04:16,700 --> 00:04:17,890
that bottleneck because we think that this

155
00:04:17,890 --> 00:04:19,080
is

156
00:04:19,080 --> 00:04:21,400
if we if we address that bottleneck we

157
00:04:21,400 --> 00:04:22,100
can actually make

158
00:04:22,100 --> 00:04:25,220
robots happen and if you do it any

159
00:04:25,220 --> 00:04:26,530
other way you're basically not making as

160
00:04:26,530 --> 00:04:27,840
much

161
00:04:27,840 --> 00:04:28,900
progress on the bottleneck as

162
00:04:28,900 --> 00:04:30,840
you could be so we thought we would

163
00:04:30,840 --> 00:04:34,260
just target this problem head on focus on

164
00:04:34,260 --> 00:04:35,000
the intelligence and

165
00:04:35,000 --> 00:04:36,340
if we can do that that would lead

166
00:04:36,340 --> 00:04:37,630
to many different vertical products it

167
00:04:37,630 --> 00:04:38,920
will lead

168
00:04:38,920 --> 00:04:40,160
to you know robots

169
00:04:40,160 --> 00:04:41,750
being deployed in the home in in

170
00:04:41,750 --> 00:04:43,340
industrial

171
00:04:43,340 --> 00:04:44,550
settings basically anywhere can i just

172
00:04:44,550 --> 00:04:45,760
pressure that

173
00:04:45,760 --> 00:04:46,180
test that

174
00:04:46,180 --> 00:04:48,180
a little bit um so on the hardware

175
00:04:48,180 --> 00:04:50,260
side like i've seen the latest videos for

176
00:04:50,260 --> 00:04:51,760
example of the the optimist

177
00:04:51,760 --> 00:04:53,780
hand it it's like it's exquisite it's a

178
00:04:53,780 --> 00:04:56,920
it's a piece of art um and i

179
00:04:56,920 --> 00:04:58,620
hadn't seen the videos of people you

180
00:04:58,620 --> 00:04:59,750
tele-operated robots cleaning houses 10

181
00:04:59,750 --> 00:05:00,880
years ago

182
00:05:00,880 --> 00:05:02,340
but i'm wondering if there's a set of

183
00:05:02,340 --> 00:05:03,100
tasks that's

184
00:05:03,100 --> 00:05:04,760
you know maybe now just on the cusp

185
00:05:04,760 --> 00:05:06,310
of becoming possible for example cooking

186
00:05:06,310 --> 00:05:07,860
or like

187
00:05:07,860 --> 00:05:08,260
being able to

188
00:05:08,260 --> 00:05:10,800
you know peel and dice an onion that

189
00:05:10,800 --> 00:05:12,000
like you couldn't have done with with

190
00:05:12,000 --> 00:05:13,200
hardware

191
00:05:13,200 --> 00:05:13,840
prior to

192
00:05:13,840 --> 00:05:15,360
where we currently are so how much of

193
00:05:15,360 --> 00:05:16,680
a why now do you think hardware is

194
00:05:16,680 --> 00:05:19,160
or isn't so there's a lot of

195
00:05:19,160 --> 00:05:21,257
progress in hardware um especially in

196
00:05:21,257 --> 00:05:22,220
humanoid hardware

197
00:05:22,220 --> 00:05:24,620
like dextrous hands for instance as you

198
00:05:24,620 --> 00:05:26,180
mentioned they're that i think they're

199
00:05:26,180 --> 00:05:27,740
much better

200
00:05:27,740 --> 00:05:29,220
now than they were even a few years

201
00:05:29,220 --> 00:05:31,400
ago yeah um but

202
00:05:31,400 --> 00:05:32,490
it still doesn't address the bottleneck we

203
00:05:32,490 --> 00:05:33,580
could

204
00:05:33,580 --> 00:05:35,825
have had robots operating you know

205
00:05:35,825 --> 00:05:37,080
chopping vegetables

206
00:05:37,080 --> 00:05:38,870
or doing cooking even with simple grippers

207
00:05:38,870 --> 00:05:40,660
before

208
00:05:40,660 --> 00:05:43,100
the problem is that we don't have the

209
00:05:43,100 --> 00:05:43,460
intelligence

210
00:05:43,460 --> 00:05:44,810
to operate these robots and the more

211
00:05:44,810 --> 00:05:46,160
complex

212
00:05:46,160 --> 00:05:48,290
the hardware is um it doesn't really

213
00:05:48,290 --> 00:05:50,420
resolve

214
00:05:50,420 --> 00:05:50,600
that

215
00:05:50,600 --> 00:05:53,160
bottleneck right like it allows you to do

216
00:05:53,160 --> 00:05:55,000
more potentially but you're still

217
00:05:55,000 --> 00:05:56,060
bottlenecked by the

218
00:05:56,060 --> 00:05:57,380
fundamental challenge of robots not being

219
00:05:57,380 --> 00:05:58,700
intelligent i

220
00:05:58,700 --> 00:06:00,860
see so hardware may raise the ceiling on

221
00:06:00,860 --> 00:06:01,140
what you're

222
00:06:01,140 --> 00:06:03,540
able to do but like the the capability

223
00:06:03,540 --> 00:06:04,400
floor we're not even there yet that's

224
00:06:04,400 --> 00:06:05,260
right

225
00:06:05,260 --> 00:06:06,180
so even with simple

226
00:06:06,180 --> 00:06:07,700
robots we are not yet at the level

227
00:06:07,700 --> 00:06:10,740
of a human operator so the limit being

228
00:06:10,740 --> 00:06:12,280
the intelligence layer what's the

229
00:06:12,280 --> 00:06:13,620
limit to developing the intelligence is

230
00:06:13,620 --> 00:06:14,960
that collecting

231
00:06:14,960 --> 00:06:18,600
data is it's doing it cheaply because

232
00:06:19,220 --> 00:06:20,240
you know you've broken down the problem

233
00:06:20,240 --> 00:06:21,260
we're

234
00:06:21,260 --> 00:06:22,900
going to keep asking you why why why

235
00:06:22,900 --> 00:06:23,860
and just drill down

236
00:06:23,860 --> 00:06:25,540
further so what's the next layer of the

237
00:06:25,540 --> 00:06:27,598
okay what's the bottleneck for solving

238
00:06:27,598 --> 00:06:29,060
intelligence generalization

239
00:06:29,640 --> 00:06:31,940
it's a it's a good question um so

240
00:06:31,940 --> 00:06:33,900
we thought about it in terms of three

241
00:06:33,900 --> 00:06:35,920
factors we refer to them

242
00:06:35,920 --> 00:06:38,897
as capability generalization and

243
00:06:38,897 --> 00:06:41,780
performance with capability our

244
00:06:41,780 --> 00:06:44,620
our idea was that we want to get

245
00:06:44,620 --> 00:06:44,740
to

246
00:06:44,740 --> 00:06:46,560
the point where as long as you can

247
00:06:46,560 --> 00:06:48,540
collect data for something for a task or

248
00:06:48,540 --> 00:06:49,740
for a robot you should

249
00:06:49,740 --> 00:06:51,020
have a model that should be able to

250
00:06:51,020 --> 00:06:52,540
to replicate that to automate that task

251
00:06:52,540 --> 00:06:54,060
this

252
00:06:54,060 --> 00:06:54,580
is something that

253
00:06:54,580 --> 00:06:57,520
we've gotten to fairly quickly um this was

254
00:06:57,520 --> 00:06:59,520
our pi zero release around a year ago

255
00:06:59,520 --> 00:07:01,360
or so showing that

256
00:07:01,360 --> 00:07:02,390
it's basically possible that if you can

257
00:07:02,390 --> 00:07:03,420
collect

258
00:07:03,420 --> 00:07:05,360
data for any task for any robot you

259
00:07:05,360 --> 00:07:05,860
should be able to

260
00:07:05,860 --> 00:07:07,060
automate it and the model should be able

261
00:07:07,060 --> 00:07:10,400
to learn it um the next challenge is

262
00:07:10,400 --> 00:07:11,700
around generalization and this is

263
00:07:11,700 --> 00:07:14,180
still an open challenge so we wanted to

264
00:07:14,180 --> 00:07:16,160
get to the point where the robots can

265
00:07:16,160 --> 00:07:17,420
just work zero shot and

266
00:07:17,420 --> 00:07:18,440
you can just bring them to a new

267
00:07:18,440 --> 00:07:20,540
home for instance and they should know how

268
00:07:20,540 --> 00:07:21,440
to operate in that home

269
00:07:22,040 --> 00:07:23,010
and this is a really really difficult

270
00:07:23,010 --> 00:07:23,980
problem

271
00:07:23,980 --> 00:07:25,920
right like if you if you put a

272
00:07:25,920 --> 00:07:26,920
robot in a new home it

273
00:07:26,920 --> 00:07:28,000
needs to understand you know where

274
00:07:28,000 --> 00:07:29,080
different items

275
00:07:29,080 --> 00:07:30,390
are the counters look different the

276
00:07:30,390 --> 00:07:31,700
lighting is

277
00:07:31,700 --> 00:07:32,500
different than what you've seen in the

278
00:07:32,500 --> 00:07:33,240
past

279
00:07:33,240 --> 00:07:35,280
and so on and i wouldn't say that

280
00:07:35,280 --> 00:07:36,260
this problem is solved

281
00:07:36,260 --> 00:07:38,780
but i think we start to get a

282
00:07:38,780 --> 00:07:40,780
handle on how to how to solve it

283
00:07:40,780 --> 00:07:43,260
and how it scales and the only answer

284
00:07:43,260 --> 00:07:44,170
to generalization that we know in machine

285
00:07:44,170 --> 00:07:45,080
learning

286
00:07:45,080 --> 00:07:47,560
is through diversity of data so if you

287
00:07:47,560 --> 00:07:48,360
see a lot of

288
00:07:48,360 --> 00:07:49,460
different diverse data sets you should be

289
00:07:49,460 --> 00:07:50,560
able

290
00:07:50,560 --> 00:07:51,640
to generalize to to a setting that's

291
00:07:51,640 --> 00:07:52,720
similar

292
00:07:52,720 --> 00:07:53,080
to the one

293
00:07:53,080 --> 00:07:54,120
you've seen and this is something that

294
00:07:54,120 --> 00:07:55,160
we've

295
00:07:55,160 --> 00:07:57,400
seen with our pi05 release in april of

296
00:07:57,400 --> 00:07:57,820
this year

297
00:07:58,340 --> 00:08:00,000
that we we got to the point where

298
00:08:00,000 --> 00:08:01,280
we can bring a robot to a new

299
00:08:01,280 --> 00:08:02,640
home that has never been to before

300
00:08:02,640 --> 00:08:04,880
and it's able to to to operate in

301
00:08:04,880 --> 00:08:07,120
that home it's not perfect yet but at

302
00:08:07,120 --> 00:08:08,140
least it has some kind of

303
00:08:08,140 --> 00:08:09,780
common sense on you know how to go

304
00:08:09,780 --> 00:08:10,890
about simple tasks like cleaning up the

305
00:08:10,890 --> 00:08:12,000
kitchen

306
00:08:12,000 --> 00:08:12,560
and things like

307
00:08:12,560 --> 00:08:15,100
that and then the last challenge that is

308
00:08:15,100 --> 00:08:16,480
also not fully solved yet is performance

309
00:08:16,480 --> 00:08:17,860
so

310
00:08:17,860 --> 00:08:18,480
how can we get

311
00:08:18,480 --> 00:08:19,500
these models to the point where the

312
00:08:19,500 --> 00:08:20,520
performance

313
00:08:20,520 --> 00:08:22,060
is good enough so you can actually deploy

314
00:08:22,060 --> 00:08:22,300
them

315
00:08:22,300 --> 00:08:24,562
right and deployments here are really

316
00:08:24,562 --> 00:08:25,540
really important

317
00:08:25,540 --> 00:08:27,920
because as i mentioned before we also need

318
00:08:27,920 --> 00:08:28,000
to

319
00:08:28,000 --> 00:08:29,960
gather data and i think that is going

320
00:08:29,960 --> 00:08:31,700
to going to be the most scalable way

321
00:08:31,700 --> 00:08:32,500
of collecting data

322
00:08:32,500 --> 00:08:33,340
because you'll have robots out there in

323
00:08:33,340 --> 00:08:34,180
the

324
00:08:34,180 --> 00:08:36,948
world doing economically valuable tasks

325
00:08:36,948 --> 00:08:37,800
and that way

326
00:08:37,800 --> 00:08:39,320
that the cost of that data collection is

327
00:08:39,320 --> 00:08:41,020
basically negative and the more the more

328
00:08:41,020 --> 00:08:42,720
broadly

329
00:08:42,720 --> 00:08:43,000
you can

330
00:08:43,000 --> 00:08:43,890
deploy this technology the more data

331
00:08:43,890 --> 00:08:44,780
you'll be

332
00:08:44,780 --> 00:08:46,760
getting and i think in the limit that

333
00:08:46,760 --> 00:08:47,620
will be that

334
00:08:47,620 --> 00:08:48,940
will be the biggest source of the data

335
00:08:48,940 --> 00:08:50,130
you can imagine much bigger than internet

336
00:08:50,130 --> 00:08:51,320
data

337
00:08:51,320 --> 00:08:51,880
for instance

338
00:08:51,880 --> 00:08:53,600
and how far away do you think we

339
00:08:53,600 --> 00:08:55,488
are from generalization or from a

340
00:08:55,488 --> 00:08:56,460
performance level

341
00:08:56,460 --> 00:08:56,740
that

342
00:08:57,340 --> 00:08:58,680
maybe it's a control environment maybe

343
00:08:58,680 --> 00:09:00,020
it's a

344
00:09:00,020 --> 00:09:01,490
general environment in homes or offices

345
00:09:01,490 --> 00:09:02,960
but not

346
00:09:02,960 --> 00:09:05,320
the whole whole world if you could limit

347
00:09:05,320 --> 00:09:07,097
that what where do you think

348
00:09:07,097 --> 00:09:08,240
generalization and

349
00:09:08,240 --> 00:09:09,120
performance will

350
00:09:09,820 --> 00:09:12,860
will need to be before we can deploy

351
00:09:12,860 --> 00:09:15,580
these kind of robots i think we are

352
00:09:15,580 --> 00:09:16,580
actually fairly close to

353
00:09:16,580 --> 00:09:18,027
deploying these robots we started

354
00:09:18,027 --> 00:09:19,080
deploying them ourselves

355
00:09:19,080 --> 00:09:21,940
already we thought this was something that

356
00:09:21,940 --> 00:09:22,740
was going to take something like five

357
00:09:22,740 --> 00:09:23,540
years

358
00:09:23,540 --> 00:09:25,320
to get to the point where the technology

359
00:09:25,320 --> 00:09:25,740
is actually

360
00:09:25,740 --> 00:09:27,720
ready to deploy a robot in a in

361
00:09:27,720 --> 00:09:28,670
a commercial setting and have it do

362
00:09:28,670 --> 00:09:29,620
something

363
00:09:29,620 --> 00:09:31,400
valuable but we've done it

364
00:09:31,400 --> 00:09:33,200
i think two months ago or something like

365
00:09:33,200 --> 00:09:37,420
that um so i think we're now getting

366
00:09:37,420 --> 00:09:38,780
to that threshold that

367
00:09:38,780 --> 00:09:40,110
that the models are useful enough they're

368
00:09:40,110 --> 00:09:41,440
perform

369
00:09:41,440 --> 00:09:42,620
performant enough and they can do enough

370
00:09:42,620 --> 00:09:43,800
of

371
00:09:43,800 --> 00:09:45,180
variety of tasks

372
00:09:45,180 --> 00:09:48,260
to be actually useful so that's a really

373
00:09:48,260 --> 00:09:50,900
really exciting moment um we i think we

374
00:09:50,900 --> 00:09:51,540
just crossed that

375
00:09:51,540 --> 00:09:53,820
threshold uh i think it's still to be

376
00:09:53,820 --> 00:09:55,220
determined how wide is the aperture of

377
00:09:55,220 --> 00:09:56,620
where

378
00:09:56,620 --> 00:09:57,360
we can deploy

379
00:09:57,360 --> 00:09:59,480
there are some tasks where the failure can

380
00:09:59,480 --> 00:10:00,400
be really catastrophic maybe these are not

381
00:10:00,400 --> 00:10:01,320
the

382
00:10:01,320 --> 00:10:01,500
best

383
00:10:01,500 --> 00:10:03,460
tests to deploy just yet there are some

384
00:10:03,460 --> 00:10:04,420
tasks that require a ton of generalization

385
00:10:04,420 --> 00:10:05,380
like

386
00:10:05,380 --> 00:10:05,820
deploying in

387
00:10:05,820 --> 00:10:07,740
the homes or that are you know have

388
00:10:07,740 --> 00:10:08,990
privacy concerns or safety concerns and so

389
00:10:08,990 --> 00:10:10,240
on

390
00:10:10,240 --> 00:10:11,100
maybe these

391
00:10:11,100 --> 00:10:12,580
are not the best places to deploy just

392
00:10:12,580 --> 00:10:14,940
yet but i think there is that the

393
00:10:14,940 --> 00:10:16,600
aperture is growing as we

394
00:10:16,600 --> 00:10:17,430
collect more data as these models get

395
00:10:17,430 --> 00:10:18,260
better

396
00:10:18,260 --> 00:10:19,820
we can deploy them in more and more

397
00:10:19,820 --> 00:10:21,880
settings so i

398
00:10:21,880 --> 00:10:22,890
think we're we're starting to get there

399
00:10:22,890 --> 00:10:23,900
where's

400
00:10:23,900 --> 00:10:25,120
the current aperture that you're deploying

401
00:10:25,120 --> 00:10:26,340
right now

402
00:10:27,160 --> 00:10:29,900
um so we're actually this is this is

403
00:10:29,900 --> 00:10:31,190
a really difficult question to answer

404
00:10:31,190 --> 00:10:32,480
because with

405
00:10:32,480 --> 00:10:32,640
these

406
00:10:32,640 --> 00:10:35,378
foundation models sometimes you don't

407
00:10:35,378 --> 00:10:36,340
fully know um

408
00:10:36,340 --> 00:10:39,620
so kind of similarly to to how with

409
00:10:39,620 --> 00:10:40,500
uh large

410
00:10:40,500 --> 00:10:43,520
language models um you know you you train

411
00:10:43,520 --> 00:10:45,460
this model you kind of cook it in

412
00:10:45,460 --> 00:10:46,480
-house you try to make

413
00:10:46,480 --> 00:10:48,460
the best job possible and then at the

414
00:10:48,460 --> 00:10:50,640
very end you get this artifact and you

415
00:10:50,640 --> 00:10:51,540
can't really predict how

416
00:10:51,540 --> 00:10:52,840
good the artifact is going to be you

417
00:10:52,840 --> 00:10:55,800
kind of have to test it and that's

418
00:10:55,800 --> 00:10:56,840
where we are with these models

419
00:10:56,840 --> 00:10:59,740
as well so for instance we open source

420
00:10:59,740 --> 00:11:02,120
them so that we are not the only

421
00:11:02,120 --> 00:11:03,360
ones testing it and we're not

422
00:11:03,360 --> 00:11:05,379
the bottlenecking knowing what their

423
00:11:05,379 --> 00:11:06,500
capabilities are and

424
00:11:06,500 --> 00:11:08,000
by open sourcing them we see them being

425
00:11:08,000 --> 00:11:08,500
applied to

426
00:11:08,500 --> 00:11:09,530
actually many more applications that we

427
00:11:09,530 --> 00:11:10,560
could have

428
00:11:10,560 --> 00:11:14,756
imagined things like driving or surgical

429
00:11:14,756 --> 00:11:15,700
robots or

430
00:11:17,500 --> 00:11:21,380
agriculture and and places like that so i

431
00:11:21,380 --> 00:11:23,220
don't have a very good estimate of what

432
00:11:23,220 --> 00:11:24,040
the aperture is

433
00:11:24,040 --> 00:11:25,840
i think it's wider than what i had

434
00:11:25,840 --> 00:11:28,220
expected and i think it's also will be

435
00:11:28,220 --> 00:11:29,440
it will be growing over

436
00:11:29,440 --> 00:11:31,420
time the more data these models get the

437
00:11:31,420 --> 00:11:33,360
more mature they get and the aperture will

438
00:11:33,360 --> 00:11:34,040
continue to grow

439
00:11:34,520 --> 00:11:36,860
i would add maybe like on the performance

440
00:11:36,860 --> 00:11:39,820
level like as you said the aperture is

441
00:11:39,820 --> 00:11:40,640
probably wider

442
00:11:41,240 --> 00:11:42,090
the starting point is wider than we

443
00:11:42,090 --> 00:11:42,940
thought

444
00:11:42,940 --> 00:11:44,580
but at the same time of course if

445
00:11:44,580 --> 00:11:45,360
you actually want

446
00:11:45,360 --> 00:11:46,510
each of those starting points that you

447
00:11:46,510 --> 00:11:47,660
start

448
00:11:47,660 --> 00:11:49,380
out for each of those applications to be

449
00:11:49,380 --> 00:11:49,880
at a level

450
00:11:49,880 --> 00:11:52,620
where people would want to use this as

451
00:11:52,620 --> 00:11:55,180
a day-to-day driving you know their

452
00:11:55,180 --> 00:11:56,640
businesses where that's

453
00:11:56,640 --> 00:11:57,700
probably still quite a bit of hill

454
00:11:57,700 --> 00:11:58,760
climbing

455
00:11:58,760 --> 00:12:00,400
to do in terms of performance right so

456
00:12:00,400 --> 00:12:01,340
we've with this

457
00:12:01,340 --> 00:12:02,500
release that we're going to talk about a

458
00:12:02,500 --> 00:12:03,980
little bit in a bit i guess the

459
00:12:03,980 --> 00:12:05,220
pi star six we've made

460
00:12:05,220 --> 00:12:06,650
progress on like learning from experience

461
00:12:06,650 --> 00:12:08,080
data getting

462
00:12:08,080 --> 00:12:09,720
that back and making the models better

463
00:12:09,720 --> 00:12:12,960
when they are deployed um it's still for

464
00:12:12,960 --> 00:12:14,960
a lot of things you that i can

465
00:12:14,960 --> 00:12:16,460
naively imagine that there'd be

466
00:12:16,460 --> 00:12:17,830
lots of scenarios where there's a really

467
00:12:17,830 --> 00:12:19,200
really

468
00:12:19,200 --> 00:12:21,120
long tale of things that can go wrong

469
00:12:21,120 --> 00:12:22,240
or that you can

470
00:12:22,240 --> 00:12:24,900
encounter that we we don't yet have a

471
00:12:24,900 --> 00:12:25,850
great grasp on like how to completely

472
00:12:25,850 --> 00:12:26,800
solve

473
00:12:26,800 --> 00:12:27,620
i would say as well

474
00:12:27,620 --> 00:12:29,460
and you guys have been really great about

475
00:12:29,460 --> 00:12:30,830
publishing your results with a lot of

476
00:12:30,830 --> 00:12:32,200
transparency

477
00:12:32,200 --> 00:12:33,940
releasing an open source um so whatever

478
00:12:33,940 --> 00:12:35,680
you're

479
00:12:35,680 --> 00:12:36,600
comfortable sharing can you can you talk

480
00:12:36,600 --> 00:12:37,520
about

481
00:12:37,520 --> 00:12:38,910
what your overall technical architecture

482
00:12:38,910 --> 00:12:40,300
so to speak

483
00:12:40,300 --> 00:12:43,480
is and do you think that the architecture

484
00:12:43,480 --> 00:12:43,740
to

485
00:12:43,740 --> 00:12:45,240
kind of get to this promised land is

486
00:12:45,240 --> 00:12:47,120
you know pretty much baked and it'll be

487
00:12:47,120 --> 00:12:48,900
variations on the theme of

488
00:12:48,900 --> 00:12:50,260
where we are and we just need to

489
00:12:50,260 --> 00:12:52,140
collect a ton of data or do you

490
00:12:52,140 --> 00:12:53,420
think that you know the architecture

491
00:12:53,420 --> 00:12:55,960
is still still being figured out i would

492
00:12:55,960 --> 00:12:57,920
say so i we can maybe start with

493
00:12:57,920 --> 00:12:58,440
like a little bit

494
00:12:58,440 --> 00:13:00,180
discussing like where we are at now and

495
00:13:00,180 --> 00:13:01,580
then we can like go into the details

496
00:13:01,580 --> 00:13:02,640
of like how that might

497
00:13:02,640 --> 00:13:04,940
change so at the moment you know the

498
00:13:04,940 --> 00:13:06,580
the architecture is very analogous to how

499
00:13:06,580 --> 00:13:08,220
um

500
00:13:08,220 --> 00:13:09,820
you know vlms and

501
00:13:09,820 --> 00:13:11,250
are built today's that probably you know

502
00:13:11,250 --> 00:13:12,680
most

503
00:13:12,680 --> 00:13:14,220
of you interact with on a day-to

504
00:13:14,220 --> 00:13:15,080
-day basis right type

505
00:13:15,080 --> 00:13:16,840
something in and put an image in and

506
00:13:16,840 --> 00:13:18,220
ask it to read what's on the image

507
00:13:18,220 --> 00:13:20,020
and and so on and and we've kind

508
00:13:20,020 --> 00:13:20,140
of

509
00:13:20,140 --> 00:13:21,970
like started from um the same standpoint

510
00:13:21,970 --> 00:13:23,800
of

511
00:13:23,800 --> 00:13:25,520
you know there's a model that's trained on

512
00:13:25,520 --> 00:13:25,760
internet

513
00:13:25,760 --> 00:13:28,860
scale data and it's ingested um image data

514
00:13:28,860 --> 00:13:30,780
and text and and we're adding all this

515
00:13:30,780 --> 00:13:31,460
robotics data

516
00:13:31,460 --> 00:13:33,020
and our training actually predominantly

517
00:13:33,020 --> 00:13:34,580
now is on

518
00:13:34,580 --> 00:13:35,510
robotics data on data that we have

519
00:13:35,510 --> 00:13:36,440
collected

520
00:13:36,440 --> 00:13:39,180
ourselves we have a little bit of that

521
00:13:39,180 --> 00:13:41,260
internet data in the mix but the majority

522
00:13:41,260 --> 00:13:41,980
of it is robotics

523
00:13:41,980 --> 00:13:43,370
data the architecture is kind of this

524
00:13:43,370 --> 00:13:44,760
vision

525
00:13:44,760 --> 00:13:47,460
language model and we add something on the

526
00:13:47,460 --> 00:13:48,120
side which is

527
00:13:48,120 --> 00:13:51,540
what we call the action model the action

528
00:13:51,540 --> 00:13:53,740
expert the the part of the model that

529
00:13:53,740 --> 00:13:54,540
actually then has to

530
00:13:54,540 --> 00:13:56,140
drive the robot right so that basically

531
00:13:56,140 --> 00:13:57,740
looks

532
00:13:57,740 --> 00:13:58,760
at the image and the instruction is

533
00:13:58,760 --> 00:13:59,780
getting

534
00:13:59,780 --> 00:14:00,600
and has to

535
00:14:00,600 --> 00:14:03,260
perform the task has to send commands to

536
00:14:03,260 --> 00:14:05,680
the robot and so broadly it's like a

537
00:14:05,680 --> 00:14:07,580
transformer model that is a

538
00:14:07,580 --> 00:14:09,720
a fairly large model up to like some

539
00:14:09,720 --> 00:14:10,970
billion parameters at this point that we

540
00:14:10,970 --> 00:14:12,220
use

541
00:14:12,220 --> 00:14:13,180
that we pre-train

542
00:14:13,180 --> 00:14:15,180
on our robotics data and on on internet

543
00:14:15,180 --> 00:14:18,360
data um and uh it is trained largely

544
00:14:18,360 --> 00:14:20,260
in initially from human

545
00:14:20,260 --> 00:14:21,520
demonstration data carol mentioned this

546
00:14:21,520 --> 00:14:22,780
earlier a little

547
00:14:22,780 --> 00:14:24,700
bit and we have this demonstration data

548
00:14:24,700 --> 00:14:26,070
teleoperated data of humans trying to get

549
00:14:26,070 --> 00:14:27,440
the

550
00:14:27,440 --> 00:14:29,840
robot to do stuff so that's the the

551
00:14:29,840 --> 00:14:30,500
architecture that

552
00:14:30,500 --> 00:14:31,470
looks like now and like roughly the

553
00:14:31,470 --> 00:14:32,440
scaling

554
00:14:32,440 --> 00:14:35,820
um that we're getting is from scaling our

555
00:14:35,820 --> 00:14:37,040
data and we use models

556
00:14:37,040 --> 00:14:39,500
models similar to what comes from the vlm

557
00:14:39,500 --> 00:14:42,100
world um how that might change i think

558
00:14:42,100 --> 00:14:43,080
as an as an open

559
00:14:43,080 --> 00:14:45,843
question i i think there's lots of

560
00:14:45,843 --> 00:14:46,900
opportunities

561
00:14:46,900 --> 00:14:48,500
in in adding more capabilities to these

562
00:14:48,500 --> 00:14:50,100
models

563
00:14:50,100 --> 00:14:50,600
that we're

564
00:14:50,600 --> 00:14:51,920
also exploring right you can imagine that

565
00:14:51,920 --> 00:14:53,240
um

566
00:14:53,240 --> 00:14:55,960
you know you you might want more context

567
00:14:55,960 --> 00:14:56,700
in these models

568
00:14:56,700 --> 00:15:00,600
you might want more um more more cameras

569
00:15:00,600 --> 00:15:02,980
added to to the robots that the model

570
00:15:02,980 --> 00:15:04,080
needs to be able to

571
00:15:04,540 --> 00:15:07,760
to use you might want to have a

572
00:15:07,760 --> 00:15:08,950
better understanding of the physical world

573
00:15:08,950 --> 00:15:10,140
in the

574
00:15:10,140 --> 00:15:11,620
sense of you know

575
00:15:11,620 --> 00:15:12,720
understanding exactly what's in the room

576
00:15:12,720 --> 00:15:13,820
what can

577
00:15:13,820 --> 00:15:15,860
break what is easily movable and so on

578
00:15:15,860 --> 00:15:16,620
so there's lots

579
00:15:16,620 --> 00:15:18,860
to be done i think in both capabilities

580
00:15:18,860 --> 00:15:20,290
and also changing the architecture around

581
00:15:20,290 --> 00:15:21,720
and i

582
00:15:21,720 --> 00:15:22,180
i wouldn't

583
00:15:22,180 --> 00:15:24,020
be surprised if in like five six years

584
00:15:24,020 --> 00:15:27,080
we look back and we say oh you

585
00:15:27,080 --> 00:15:29,820
know maybe the the backbone of

586
00:15:29,820 --> 00:15:31,720
the model that we used at the time

587
00:15:31,720 --> 00:15:33,160
which currently comes from this vlm land

588
00:15:33,160 --> 00:15:34,600
has

589
00:15:34,600 --> 00:15:35,600
changed maybe we've

590
00:15:35,600 --> 00:15:37,840
moved on and we we use something uh

591
00:15:37,840 --> 00:15:38,760
slightly different i think that will

592
00:15:38,760 --> 00:15:39,680
evolve over

593
00:15:39,680 --> 00:15:41,560
time but i think

594
00:15:41,560 --> 00:15:45,700
the the foundation of like the data and

595
00:15:45,700 --> 00:15:47,380
how we bring it into the model will

596
00:15:47,380 --> 00:15:48,440
probably stay stay

597
00:15:48,440 --> 00:15:50,080
like it and should i think about it

598
00:15:50,080 --> 00:15:52,880
as it's pixels or signals in and then

599
00:15:52,880 --> 00:15:55,260
actions out is that yeah and

600
00:15:55,260 --> 00:15:57,220
like like a single single big neural net

601
00:15:57,220 --> 00:15:59,760
it's one big model yeah it's really just

602
00:15:59,760 --> 00:16:01,060
basically images in

603
00:16:01,060 --> 00:16:03,800
text in uh text out and and actions

604
00:16:03,800 --> 00:16:05,400
out at this point yeah and are you

605
00:16:05,400 --> 00:16:07,460
i guess do you have a separate

606
00:16:07,460 --> 00:16:10,027
kind of locomotion versus manipulation

607
00:16:10,027 --> 00:16:11,040
stack and maybe

608
00:16:11,040 --> 00:16:12,740
this this might be a good time to

609
00:16:12,740 --> 00:16:13,200
talk about

610
00:16:13,200 --> 00:16:14,420
kind of just the historical evolution in

611
00:16:14,420 --> 00:16:15,640
and

612
00:16:15,640 --> 00:16:16,940
robotics and the various different waves

613
00:16:16,940 --> 00:16:18,240
of learning

614
00:16:18,240 --> 00:16:18,780
uh

615
00:16:18,780 --> 00:16:21,440
and how it pertains to your stack yeah

616
00:16:21,440 --> 00:16:23,880
so for a long time even before learning

617
00:16:23,880 --> 00:16:25,440
arrived here people

618
00:16:25,440 --> 00:16:26,770
thought that robotics is one of these

619
00:16:26,770 --> 00:16:28,100
problems

620
00:16:28,100 --> 00:16:29,820
where you can if you put enough people

621
00:16:29,820 --> 00:16:30,740
on enough engineers

622
00:16:31,300 --> 00:16:33,880
they can think really hard about it and

623
00:16:33,880 --> 00:16:34,850
eventually write the code that will you

624
00:16:34,850 --> 00:16:35,820
know

625
00:16:35,820 --> 00:16:36,460
have the robot do

626
00:16:36,460 --> 00:16:40,320
anything in the world um and you know

627
00:16:40,320 --> 00:16:42,000
people have tried really really hard to do

628
00:16:42,000 --> 00:16:42,480
it this way

629
00:16:43,020 --> 00:16:44,260
and then it turned out that the world

630
00:16:44,260 --> 00:16:46,340
is just way too complex yep right like

631
00:16:46,340 --> 00:16:46,960
you can't just write

632
00:16:46,960 --> 00:16:48,060
every single every single case you'll

633
00:16:48,060 --> 00:16:49,160
encounter in

634
00:16:49,160 --> 00:16:52,120
the real world so that doesn't work and

635
00:16:52,120 --> 00:16:52,580
and also

636
00:16:52,580 --> 00:16:54,180
as we were you know trying to work

637
00:16:54,180 --> 00:16:56,760
on on that version of the problem what

638
00:16:56,760 --> 00:16:57,700
ended up happening is

639
00:16:57,700 --> 00:17:00,240
people did what they usually do they try

640
00:17:00,240 --> 00:17:01,040
to break down this problem into smaller

641
00:17:01,040 --> 00:17:01,840
sub

642
00:17:01,840 --> 00:17:02,460
problems so

643
00:17:02,460 --> 00:17:03,260
like rather than working on the full

644
00:17:03,260 --> 00:17:03,980
robotics

645
00:17:03,980 --> 00:17:05,020
problem you would say there was a

646
00:17:05,020 --> 00:17:06,060
perception

647
00:17:06,060 --> 00:17:07,270
aspect of the problem there's a control

648
00:17:07,270 --> 00:17:08,480
aspect

649
00:17:08,480 --> 00:17:09,370
of the problem there's the planning part

650
00:17:09,370 --> 00:17:10,260
of

651
00:17:10,260 --> 00:17:10,360
the

652
00:17:10,360 --> 00:17:11,400
problem and this is almost growing to

653
00:17:11,400 --> 00:17:12,440
different

654
00:17:12,440 --> 00:17:13,510
communities there's a planning community

655
00:17:13,510 --> 00:17:14,580
there's

656
00:17:14,580 --> 00:17:15,670
controls community there's they have their

657
00:17:15,670 --> 00:17:16,760
own conferences

658
00:17:16,760 --> 00:17:18,420
their own problems and all of that

659
00:17:19,520 --> 00:17:21,380
so then as we realized that you know

660
00:17:21,380 --> 00:17:22,360
it's not really possible to to handwrite

661
00:17:22,360 --> 00:17:23,340
all

662
00:17:23,340 --> 00:17:24,020
of these rules

663
00:17:24,560 --> 00:17:25,690
people thought that we should learn them

664
00:17:25,690 --> 00:17:26,820
we

665
00:17:26,820 --> 00:17:28,100
should learn them from data which is

666
00:17:28,100 --> 00:17:29,920
seems like a really good idea right this

667
00:17:29,920 --> 00:17:32,900
is how we learn too um but what

668
00:17:32,900 --> 00:17:34,080
ended up happening is that

669
00:17:34,080 --> 00:17:35,170
they started learning each one of those

670
00:17:35,170 --> 00:17:36,260
components

671
00:17:36,260 --> 00:17:38,320
these these broke down components

672
00:17:38,320 --> 00:17:39,790
separate for learning separately yeah so

673
00:17:39,790 --> 00:17:41,260
you would

674
00:17:41,260 --> 00:17:42,390
have a perception layer that is fully

675
00:17:42,390 --> 00:17:43,520
learned

676
00:17:43,520 --> 00:17:43,900
maybe

677
00:17:43,900 --> 00:17:44,700
you'll have a control layer that is

678
00:17:44,700 --> 00:17:45,260
learned

679
00:17:45,260 --> 00:17:46,060
maybe you'll have a planner that is

680
00:17:46,060 --> 00:17:46,620
learned

681
00:17:46,620 --> 00:17:49,000
and that showed

682
00:17:49,000 --> 00:17:51,160
some progress it was better than what we

683
00:17:51,160 --> 00:17:53,280
had before yeah but then turn out that

684
00:17:53,280 --> 00:17:54,000
breaking down these

685
00:17:54,000 --> 00:17:55,210
pro this problem into these sub components

686
00:17:55,210 --> 00:17:56,420
it

687
00:17:56,420 --> 00:17:57,510
actually is the piece that doesn't work

688
00:17:57,510 --> 00:17:58,600
because

689
00:17:58,600 --> 00:17:59,320
you know when

690
00:17:59,320 --> 00:18:00,920
i try to you know pick up this

691
00:18:00,920 --> 00:18:02,620
glass i don't think about it in terms

692
00:18:02,620 --> 00:18:04,340
of perception and then planning

693
00:18:04,340 --> 00:18:06,520
and then control i just i just go

694
00:18:06,520 --> 00:18:08,020
for it i just pick up the glass

695
00:18:08,020 --> 00:18:09,380
and it's just all very natural

696
00:18:10,140 --> 00:18:12,480
so it turned out that the that this

697
00:18:12,480 --> 00:18:14,477
pipeline approach where you have these

698
00:18:14,477 --> 00:18:15,580
predefined interfaces

699
00:18:15,580 --> 00:18:16,750
that like perception gives you the

700
00:18:16,750 --> 00:18:17,920
position of

701
00:18:17,920 --> 00:18:19,800
the object and then the planner gives you

702
00:18:19,800 --> 00:18:20,360
the trajectory

703
00:18:20,360 --> 00:18:22,298
and the control executes it those

704
00:18:22,298 --> 00:18:23,120
interfaces are

705
00:18:23,120 --> 00:18:24,220
the pieces that broke down so everything

706
00:18:24,220 --> 00:18:25,320
that

707
00:18:25,320 --> 00:18:28,200
we thought we knew how we work was

708
00:18:28,200 --> 00:18:31,520
always wrong so then we then arrived to

709
00:18:31,520 --> 00:18:32,420
the next stage of this

710
00:18:32,420 --> 00:18:33,340
where we said well maybe just breaking

711
00:18:33,340 --> 00:18:34,260
down

712
00:18:34,260 --> 00:18:36,100
this problem was a bad idea to begin

713
00:18:36,100 --> 00:18:37,480
with yeah so let's

714
00:18:37,480 --> 00:18:39,280
just train the whole thing end to end

715
00:18:39,280 --> 00:18:42,900
right so we'll take whatever uh uh the

716
00:18:42,900 --> 00:18:44,140
the kind of the sensory

717
00:18:44,140 --> 00:18:46,040
inputs as input to the network and we'll

718
00:18:46,040 --> 00:18:47,680
have actions as the output that's what we

719
00:18:47,680 --> 00:18:48,500
refer to as the end

720
00:18:48,500 --> 00:18:50,440
to end approach where you try to go

721
00:18:50,440 --> 00:18:51,820
straight from pixels to actions and we'll

722
00:18:51,820 --> 00:18:53,200
we'll

723
00:18:53,200 --> 00:18:53,800
have the network

724
00:18:53,800 --> 00:18:54,960
figure out or the learning algorithm

725
00:18:54,960 --> 00:18:56,120
figure out

726
00:18:56,120 --> 00:18:57,080
how to split it into these different

727
00:18:57,080 --> 00:18:58,040
components

728
00:18:58,040 --> 00:18:58,340
if

729
00:18:58,340 --> 00:19:02,420
it's even possible um and then while we

730
00:19:02,420 --> 00:19:03,330
were doing that we figured that it

731
00:19:03,330 --> 00:19:04,240
actually

732
00:19:04,240 --> 00:19:04,980
requires a ton of

733
00:19:04,980 --> 00:19:08,520
data to do this and often it breaks

734
00:19:08,520 --> 00:19:10,860
when it requires some kind of common sense

735
00:19:10,860 --> 00:19:12,060
and to gather that common

736
00:19:12,060 --> 00:19:14,060
sense through first first person action

737
00:19:14,060 --> 00:19:16,060
data sets

738
00:19:16,060 --> 00:19:16,860
is really really hard because you would

739
00:19:16,860 --> 00:19:17,640
need

740
00:19:17,640 --> 00:19:17,740
to

741
00:19:17,740 --> 00:19:18,580
experience every single thing in the world

742
00:19:18,580 --> 00:19:19,420
to

743
00:19:19,420 --> 00:19:22,540
do this and that's where we stumbled upon

744
00:19:22,540 --> 00:19:23,160
vision

745
00:19:23,160 --> 00:19:24,410
language action models where we can use

746
00:19:24,410 --> 00:19:25,660
models

747
00:19:25,660 --> 00:19:26,910
that were pre-trained on internet data

748
00:19:26,910 --> 00:19:28,160
that

749
00:19:28,160 --> 00:19:28,420
already

750
00:19:28,420 --> 00:19:29,370
have pretty good understanding of how the

751
00:19:29,370 --> 00:19:30,320
world

752
00:19:30,320 --> 00:19:34,040
works um and we can utilize that knowledge

753
00:19:34,040 --> 00:19:34,760
so that

754
00:19:34,760 --> 00:19:36,050
we don't need to experience everything

755
00:19:36,050 --> 00:19:37,340
firsthand you

756
00:19:37,340 --> 00:19:39,320
can just add some action components on top

757
00:19:39,320 --> 00:19:39,460
of

758
00:19:39,460 --> 00:19:40,540
it and have a common world understanding

759
00:19:40,540 --> 00:19:41,620
and

760
00:19:41,620 --> 00:19:42,510
connect it to how to actually perform

761
00:19:42,510 --> 00:19:43,400
things

762
00:19:43,400 --> 00:19:45,580
in the world and that's more or less

763
00:19:45,580 --> 00:19:48,280
where we're at today i see um now

764
00:19:48,280 --> 00:19:50,020
at physical intelligence we

765
00:19:50,020 --> 00:19:52,160
figured a few other things so how do

766
00:19:52,160 --> 00:19:53,460
you scale how do you start to scale

767
00:19:53,460 --> 00:19:54,400
these models how do you get

768
00:19:54,400 --> 00:19:56,100
them to generalize how do you get them

769
00:19:56,100 --> 00:19:57,860
to perform much better how do you have

770
00:19:57,860 --> 00:19:58,780
them move much faster

771
00:19:58,780 --> 00:20:00,100
how do you get them to the point

772
00:20:00,100 --> 00:20:02,160
where you can start deploying them but i

773
00:20:02,160 --> 00:20:03,380
think largely we're still in

774
00:20:03,380 --> 00:20:05,420
this in this era of how do you

775
00:20:05,420 --> 00:20:06,380
bring some of the common sense knowledge

776
00:20:06,380 --> 00:20:07,340
from

777
00:20:07,340 --> 00:20:08,400
the internet pre-training

778
00:20:08,840 --> 00:20:10,620
how do you make these models very general

779
00:20:10,620 --> 00:20:12,140
so that they can work on any robot

780
00:20:12,140 --> 00:20:13,120
and perform motions

781
00:20:13,760 --> 00:20:15,320
and can i ask for something like reasoning

782
00:20:15,320 --> 00:20:16,410
right there's there's so much stuff

783
00:20:16,410 --> 00:20:17,500
happening in

784
00:20:17,500 --> 00:20:18,060
the you know

785
00:20:18,060 --> 00:20:18,940
reasoning side of the large language model

786
00:20:18,940 --> 00:20:19,820
space

787
00:20:19,820 --> 00:20:22,320
do you get the benefits of that uh

788
00:20:22,320 --> 00:20:23,660
in as part of

789
00:20:23,660 --> 00:20:24,670
your vla backbone do you have reasoning

790
00:20:24,670 --> 00:20:25,680
kind

791
00:20:25,680 --> 00:20:27,840
of emerge as a consequence of what you're

792
00:20:27,840 --> 00:20:28,180
doing as

793
00:20:28,180 --> 00:20:29,540
you train these end to end or perhaps

794
00:20:29,540 --> 00:20:31,200
i think about you know some of the

795
00:20:31,200 --> 00:20:31,860
benefits of what's

796
00:20:31,860 --> 00:20:33,540
happening in the llm world do they do

797
00:20:33,540 --> 00:20:35,740
they benefit you or not i mean i

798
00:20:35,740 --> 00:20:37,040
think definitely the

799
00:20:37,040 --> 00:20:40,380
models that we have today they are already

800
00:20:40,380 --> 00:20:42,620
planning actions not just at a what is

801
00:20:42,620 --> 00:20:43,160
the immediate

802
00:20:43,160 --> 00:20:45,580
action but kind of what is the what

803
00:20:45,580 --> 00:20:47,440
are the next 50 things i i need

804
00:20:47,440 --> 00:20:49,180
to do right so like the next 50

805
00:20:49,180 --> 00:20:51,020
time steps in in some sense it's a

806
00:20:51,020 --> 00:20:53,220
very short horizon 50 steps means like a

807
00:20:53,220 --> 00:20:54,660
like a second or or two

808
00:20:54,660 --> 00:20:56,550
right and it also additionally kind of

809
00:20:56,550 --> 00:20:58,440
decomposes

810
00:20:58,440 --> 00:20:59,970
tasks into subtasks in language space

811
00:20:59,970 --> 00:21:01,500
already so

812
00:21:01,500 --> 00:21:03,740
when you when we ask it oh clean

813
00:21:03,740 --> 00:21:05,310
the kitchen the first subtask it might

814
00:21:05,310 --> 00:21:06,880
pick

815
00:21:06,880 --> 00:21:08,060
out to do is like oh i have

816
00:21:08,060 --> 00:21:09,620
to drive to the counter and then i

817
00:21:09,620 --> 00:21:12,280
have to like uh pick up the the

818
00:21:12,280 --> 00:21:13,820
glass move the glass into the sink

819
00:21:13,820 --> 00:21:18,100
um so it already has those aspects in

820
00:21:18,100 --> 00:21:20,300
in some sense right so like it decomposes

821
00:21:20,300 --> 00:21:21,440
tasks into subtasks

822
00:21:21,440 --> 00:21:23,820
because it gives itself its own top task

823
00:21:23,820 --> 00:21:25,660
and it predicts like a little bit of

824
00:21:25,660 --> 00:21:26,860
a horizon of how actions

825
00:21:26,860 --> 00:21:28,580
go so so some of this is already

826
00:21:28,580 --> 00:21:31,460
there i think um i think in the

827
00:21:31,460 --> 00:21:33,420
future there will probably be more of

828
00:21:33,420 --> 00:21:36,400
it i do totally expect that um you

829
00:21:36,400 --> 00:21:38,280
know all the advances on like our training

830
00:21:38,280 --> 00:21:39,040
for reasoning all

831
00:21:39,040 --> 00:21:40,780
these things will will also make their way

832
00:21:40,780 --> 00:21:43,580
into robotics yeah um and i think it's

833
00:21:43,580 --> 00:21:44,220
kind of interesting

834
00:21:44,220 --> 00:21:46,960
to think about because it's it's maybe a

835
00:21:46,960 --> 00:21:50,760
little different than than the rl for math

836
00:21:50,760 --> 00:21:51,440
problems that

837
00:21:51,440 --> 00:21:52,670
people do for example right because i

838
00:21:52,670 --> 00:21:53,900
think

839
00:21:53,900 --> 00:21:56,580
those are very easy for easy for us

840
00:21:56,580 --> 00:21:57,680
humans to think of as like

841
00:21:58,720 --> 00:21:59,780
textual problems right you think through

842
00:21:59,780 --> 00:22:00,840
them in

843
00:22:00,840 --> 00:22:03,660
your head in like text okay if i

844
00:22:03,660 --> 00:22:05,580
change this formula

845
00:22:05,580 --> 00:22:07,200
this way i will get this outcome and

846
00:22:07,200 --> 00:22:08,840
so on and i think for the physical

847
00:22:08,840 --> 00:22:09,980
intelligence part of it it

848
00:22:09,980 --> 00:22:11,880
will probably be a bit more than that

849
00:22:11,880 --> 00:22:13,560
right it's going to be a little bit

850
00:22:13,560 --> 00:22:14,880
different when you try to

851
00:22:14,880 --> 00:22:17,080
learn a new sport for example when i

852
00:22:17,080 --> 00:22:19,680
i recently started to try to learn how

853
00:22:19,680 --> 00:22:21,300
to play tennis and you

854
00:22:21,300 --> 00:22:22,840
know i don't think through in my head

855
00:22:22,840 --> 00:22:24,720
of like i need to now grab the

856
00:22:24,720 --> 00:22:26,420
racket i need to move it here and

857
00:22:26,420 --> 00:22:26,560
i

858
00:22:26,560 --> 00:22:28,200
need to do this thing but it's more

859
00:22:28,200 --> 00:22:29,370
like you think through the motion itself

860
00:22:29,370 --> 00:22:30,540
right

861
00:22:30,540 --> 00:22:31,920
i you you think

862
00:22:31,920 --> 00:22:33,720
about like how does your body move how

863
00:22:33,720 --> 00:22:36,960
maybe um maybe your plan in some sense

864
00:22:36,960 --> 00:22:38,340
trajectories of objects

865
00:22:38,340 --> 00:22:40,200
around you in your head and so those

866
00:22:40,200 --> 00:22:42,040
things i think we'll see coming to the

867
00:22:42,040 --> 00:22:43,120
models more over time

868
00:22:43,120 --> 00:22:47,460
yeah i i suspect that over time right

869
00:22:47,460 --> 00:22:49,100
now we're in a place where we benefit

870
00:22:49,100 --> 00:22:50,340
quite a bit from vision

871
00:22:50,340 --> 00:22:52,330
language models i think it's it's very

872
00:22:52,330 --> 00:22:54,320
very

873
00:22:54,320 --> 00:22:56,160
likely that that that's gonna reverse that

874
00:22:56,160 --> 00:22:58,000
a

875
00:22:58,000 --> 00:22:58,580
lot of the

876
00:22:58,580 --> 00:23:00,800
the shortcomings that we see in llms today

877
00:23:00,800 --> 00:23:04,360
are kind of baked in or because we

878
00:23:04,360 --> 00:23:05,880
are focused on on the

879
00:23:05,880 --> 00:23:06,960
text problem on problems like math and

880
00:23:06,960 --> 00:23:08,040
coding

881
00:23:08,040 --> 00:23:10,360
yeah and i think robotics would uh will

882
00:23:10,360 --> 00:23:11,320
offer this this

883
00:23:11,320 --> 00:23:13,220
new avenue where you need to kind of

884
00:23:13,220 --> 00:23:14,990
rethink how how to think about reasoning

885
00:23:14,990 --> 00:23:16,760
reasoning

886
00:23:16,760 --> 00:23:17,260
should probably

887
00:23:17,260 --> 00:23:18,670
happen in some kind of abstract space

888
00:23:18,670 --> 00:23:20,080
where

889
00:23:20,080 --> 00:23:21,640
you know you can reason a little bit

890
00:23:21,640 --> 00:23:22,340
in text you can

891
00:23:22,340 --> 00:23:23,880
reason a little bit in images maybe you

892
00:23:23,880 --> 00:23:26,360
can reason in trajectories or in you know

893
00:23:26,360 --> 00:23:27,100
all kinds of different

894
00:23:27,100 --> 00:23:28,640
spaces to arrive at the answer and

895
00:23:28,640 --> 00:23:30,180
robotics

896
00:23:30,180 --> 00:23:32,680
provides this really nice test bed where

897
00:23:32,680 --> 00:23:35,180
um

898
00:23:35,180 --> 00:23:36,280
you're grounded in

899
00:23:36,280 --> 00:23:39,080
the physical world um there is not that

900
00:23:39,080 --> 00:23:41,500
much data yet so you kind of need

901
00:23:41,500 --> 00:23:42,720
to deal with some of the the

902
00:23:42,720 --> 00:23:43,960
difficulties that come with that but i

903
00:23:43,960 --> 00:23:45,200
think

904
00:23:45,200 --> 00:23:48,600
it will provide for for new findings that

905
00:23:48,600 --> 00:23:49,240
will then be

906
00:23:49,240 --> 00:23:51,160
reapplied to to the llm world speaking

907
00:23:51,160 --> 00:23:53,080
about

908
00:23:53,080 --> 00:23:56,140
data give us a sense of i don't

909
00:23:56,140 --> 00:23:57,200
know how you measure the

910
00:23:57,200 --> 00:23:58,360
sort of magnitude of data you've already

911
00:23:58,360 --> 00:23:59,520
collected

912
00:23:59,520 --> 00:24:01,380
and how much you would like to collect

913
00:24:01,380 --> 00:24:01,880
to the next

914
00:24:01,880 --> 00:24:04,140
year not like i'm sure more is better

915
00:24:04,140 --> 00:24:05,270
but like what is the magnitude you're

916
00:24:05,270 --> 00:24:06,400
we're

917
00:24:06,400 --> 00:24:07,380
talking about yeah

918
00:24:08,100 --> 00:24:10,440
data is um it's one of those things

919
00:24:10,440 --> 00:24:11,320
that's actually fairly new ones it's not

920
00:24:11,320 --> 00:24:12,200
just

921
00:24:12,200 --> 00:24:12,980
a matter of quantity

922
00:24:12,980 --> 00:24:14,730
yeah quality obviously matters but also

923
00:24:14,730 --> 00:24:16,480
things like

924
00:24:16,480 --> 00:24:17,960
diversity and even when you think about

925
00:24:17,960 --> 00:24:19,440
the

926
00:24:19,440 --> 00:24:20,800
quality or diversity of robot data these

927
00:24:20,800 --> 00:24:22,160
are

928
00:24:22,160 --> 00:24:23,790
not very strictly defined terms um right

929
00:24:23,790 --> 00:24:25,420
like

930
00:24:25,420 --> 00:24:26,340
if you if

931
00:24:26,340 --> 00:24:27,920
you go for the same tasks in like

932
00:24:27,920 --> 00:24:30,480
10 different ways is this diverse data or

933
00:24:30,480 --> 00:24:31,680
not or how do you compare

934
00:24:31,680 --> 00:24:33,040
it to the diversity of the data if

935
00:24:33,040 --> 00:24:35,580
you go for like 10 different glasses right

936
00:24:35,580 --> 00:24:37,800
um so this is something

937
00:24:37,800 --> 00:24:39,340
that i don't think we as a community

938
00:24:39,340 --> 00:24:40,970
fully understand like how to characterize

939
00:24:40,970 --> 00:24:42,600
the data

940
00:24:42,600 --> 00:24:43,800
how to describe diversity how to describe

941
00:24:43,800 --> 00:24:45,000
the

942
00:24:45,000 --> 00:24:46,900
quality of the data how to make it

943
00:24:46,900 --> 00:24:48,520
very very rigorous

944
00:24:50,260 --> 00:24:54,080
and we're also finding out that uh those

945
00:24:54,080 --> 00:24:56,440
there are some aspects of the data of

946
00:24:56,440 --> 00:24:57,140
the data that really

947
00:24:57,140 --> 00:24:58,240
really matter like for instance if you

948
00:24:58,240 --> 00:24:59,340
want

949
00:24:59,340 --> 00:25:00,960
to get to a certain performance on a

950
00:25:00,960 --> 00:25:02,700
task you're not going

951
00:25:02,700 --> 00:25:03,710
together by just increasing the quantity

952
00:25:03,710 --> 00:25:04,720
of the

953
00:25:04,720 --> 00:25:05,950
data you already have uh we've been

954
00:25:05,950 --> 00:25:07,180
working

955
00:25:07,180 --> 00:25:08,100
on these

956
00:25:08,100 --> 00:25:10,540
three different tasks for the pi pi star

957
00:25:10,540 --> 00:25:11,880
6 release and we've noticed fairly early

958
00:25:11,880 --> 00:25:13,220
on

959
00:25:13,220 --> 00:25:14,120
that if we just

960
00:25:14,120 --> 00:25:16,020
keep on collecting more and more data the

961
00:25:16,020 --> 00:25:17,660
same way that we've been collecting so far

962
00:25:17,660 --> 00:25:18,420
the performance

963
00:25:18,420 --> 00:25:20,780
plateaus you're not going to just keep on

964
00:25:20,780 --> 00:25:22,840
getting better so you need to find either

965
00:25:22,840 --> 00:25:23,500
new ways of

966
00:25:23,500 --> 00:25:24,640
collecting it or you need to start

967
00:25:24,640 --> 00:25:25,780
thinking

968
00:25:25,780 --> 00:25:28,080
about what kind of data will result in

969
00:25:28,080 --> 00:25:28,780
better performance

970
00:25:29,340 --> 00:25:31,035
and this is where things like

971
00:25:31,035 --> 00:25:32,320
reinforcement learning

972
00:25:32,320 --> 00:25:34,240
and and things like this can really

973
00:25:34,240 --> 00:25:36,280
can really really help let's talk

974
00:25:36,280 --> 00:25:37,640
reinforcement learning

975
00:25:37,640 --> 00:25:39,640
and let's talk let's do it pi pi

976
00:25:39,640 --> 00:25:40,740
star 0.6

977
00:25:40,740 --> 00:25:43,320
is the star a nod to to q

978
00:25:43,320 --> 00:25:45,000
star or yeah okay effectively trying to

979
00:25:45,000 --> 00:25:46,680
get

980
00:25:46,680 --> 00:25:48,040
to like policy star actually

981
00:25:48,040 --> 00:25:49,560
optimal policy star okay wonderful okay

982
00:25:49,560 --> 00:25:51,080
maybe just

983
00:25:51,080 --> 00:25:52,380
say a word on what you guys are

984
00:25:52,380 --> 00:25:52,640
doing

985
00:25:53,420 --> 00:25:55,460
with pi star 0.6 and then we

986
00:25:55,460 --> 00:25:57,200
can dive into what rl means for your

987
00:25:57,200 --> 00:25:59,380
world yeah for sure so i mean i

988
00:25:59,380 --> 00:26:01,180
think the main if we want to contrast

989
00:26:01,180 --> 00:26:02,540
it to what we talked about earlier the

990
00:26:02,540 --> 00:26:03,420
main difference is that

991
00:26:03,960 --> 00:26:06,760
up to that point basically all of the

992
00:26:06,760 --> 00:26:08,020
robotics foundation model learning that

993
00:26:08,020 --> 00:26:09,280
that we've done

994
00:26:09,280 --> 00:26:12,028
was basically demonstration data um

995
00:26:12,028 --> 00:26:13,520
tele-operated going

996
00:26:13,520 --> 00:26:14,960
into the model the model is trained kind

997
00:26:14,960 --> 00:26:15,060
of

998
00:26:15,060 --> 00:26:18,060
like just imitate that data right and now

999
00:26:18,060 --> 00:26:20,620
with this new model pi star or six

1000
00:26:20,620 --> 00:26:21,760
what we're using is

1001
00:26:21,760 --> 00:26:23,640
basically um rl from um experience that

1002
00:26:23,640 --> 00:26:25,520
the

1003
00:26:25,520 --> 00:26:26,990
robot collects itself by actually running

1004
00:26:26,990 --> 00:26:28,460
a policy

1005
00:26:28,460 --> 00:26:29,060
so we

1006
00:26:29,060 --> 00:26:30,310
start with the initial policy is this

1007
00:26:30,310 --> 00:26:31,560
demonstration

1008
00:26:31,560 --> 00:26:33,560
trained policy and then you deploy it you

1009
00:26:33,560 --> 00:26:33,880
try to

1010
00:26:33,880 --> 00:26:36,100
actually have the robot solve the task and

1011
00:26:36,100 --> 00:26:37,450
then it additionally uh gets kind of

1012
00:26:37,450 --> 00:26:38,800
reward

1013
00:26:38,800 --> 00:26:39,660
signals given by

1014
00:26:39,660 --> 00:26:42,320
humans and it can also get corrections so

1015
00:26:42,320 --> 00:26:43,320
where the human intervenes and says oh

1016
00:26:43,320 --> 00:26:44,320
actually

1017
00:26:44,320 --> 00:26:44,680
you know what

1018
00:26:44,680 --> 00:26:46,280
this is not right let's let's do this

1019
00:26:46,280 --> 00:26:47,640
a little differently and that data that

1020
00:26:47,640 --> 00:26:49,000
process

1021
00:26:49,000 --> 00:26:49,380
basically

1022
00:26:49,380 --> 00:26:52,160
that data is collected gets comes back in

1023
00:26:52,160 --> 00:26:53,900
and the model kind of uses that data

1024
00:26:53,900 --> 00:26:54,900
to try and figure out

1025
00:26:54,900 --> 00:26:57,120
which of the data can i kind of

1026
00:26:57,120 --> 00:26:58,560
kind of like should i reinforce should i

1027
00:26:58,560 --> 00:26:59,660
do more of and which of it

1028
00:26:59,660 --> 00:27:01,880
should i do less of and uh and

1029
00:27:01,880 --> 00:27:03,401
basically improve itself over time

1030
00:27:03,401 --> 00:27:04,340
basically that's kind

1031
00:27:04,340 --> 00:27:04,840
of the big

1032
00:27:04,840 --> 00:27:06,820
distinction and having that stream of real

1033
00:27:06,820 --> 00:27:08,800
data

1034
00:27:08,800 --> 00:27:11,020
coming in is kind of the missing piece

1035
00:27:11,020 --> 00:27:11,680
that carol

1036
00:27:11,680 --> 00:27:13,740
was talking about that allows us to now

1037
00:27:13,740 --> 00:27:15,060
escape this plateau that would otherwise

1038
00:27:15,060 --> 00:27:16,380
we were

1039
00:27:16,380 --> 00:27:16,820
finding we

1040
00:27:16,820 --> 00:27:20,080
were kind of like getting to yeah and

1041
00:27:20,080 --> 00:27:22,320
i guess in my brain i i think

1042
00:27:22,320 --> 00:27:23,900
of rl is you know you're hill

1043
00:27:23,900 --> 00:27:25,940
climbing on your reward signal and so how

1044
00:27:25,940 --> 00:27:27,820
do you make sure you're how do you

1045
00:27:27,820 --> 00:27:28,740
make sure you're generalizing

1046
00:27:28,740 --> 00:27:30,500
as you as you hill climb on these

1047
00:27:30,500 --> 00:27:31,760
specific tasks the way we're thinking

1048
00:27:31,760 --> 00:27:33,020
about this

1049
00:27:33,020 --> 00:27:33,280
for

1050
00:27:33,280 --> 00:27:35,180
for this specific kind of problem is like

1051
00:27:35,180 --> 00:27:37,760
you have this sort of general model and

1052
00:27:37,760 --> 00:27:38,220
it achieves

1053
00:27:38,780 --> 00:27:40,050
some performance that isn't isn't great

1054
00:27:40,050 --> 00:27:41,320
and now

1055
00:27:41,320 --> 00:27:44,825
your first goal actually isn't to further

1056
00:27:44,825 --> 00:27:45,680
generalize

1057
00:27:45,680 --> 00:27:47,280
you want to kind of solve this specific

1058
00:27:47,280 --> 00:27:49,780
task first right like so we deploy it

1059
00:27:49,780 --> 00:27:50,660
and we have we've

1060
00:27:50,660 --> 00:27:52,420
picked like three four tasks so it has

1061
00:27:52,420 --> 00:27:53,640
to generalize across tasks nonetheless the

1062
00:27:53,640 --> 00:27:54,860
method has

1063
00:27:54,860 --> 00:27:55,600
to generalize

1064
00:27:55,600 --> 00:27:56,670
but when you're actually kind of deploying

1065
00:27:56,670 --> 00:27:57,740
it

1066
00:27:57,740 --> 00:27:59,600
and trying to start this rl process you

1067
00:27:59,600 --> 00:28:00,060
really care

1068
00:28:00,060 --> 00:28:02,580
about let's make sure i nail down this

1069
00:28:02,580 --> 00:28:04,800
task and i kind of nail it down

1070
00:28:04,800 --> 00:28:07,580
in a way where i can um where

1071
00:28:07,580 --> 00:28:07,700
i

1072
00:28:07,700 --> 00:28:08,990
can can solve it from many different

1073
00:28:08,990 --> 00:28:10,280
positions

1074
00:28:10,280 --> 00:28:11,920
and i can deal with all the long

1075
00:28:11,920 --> 00:28:13,080
tail of failures that i

1076
00:28:13,080 --> 00:28:14,250
that i will encounter right so and

1077
00:28:14,250 --> 00:28:15,420
sometimes

1078
00:28:15,420 --> 00:28:17,190
the the generalization and the performance

1079
00:28:17,190 --> 00:28:18,960
here may

1080
00:28:18,960 --> 00:28:19,480
seem at

1081
00:28:19,480 --> 00:28:20,640
odds when you look at it from like

1082
00:28:20,640 --> 00:28:22,140
oh wait but now you're like just doing

1083
00:28:22,140 --> 00:28:24,920
this one task but um but

1084
00:28:24,920 --> 00:28:27,040
really at the end of the day what

1085
00:28:27,040 --> 00:28:29,340
what we want to do is we have

1086
00:28:29,340 --> 00:28:31,260
the same method the same process that

1087
00:28:31,260 --> 00:28:33,080
deploys to each of these tasks and then

1088
00:28:33,080 --> 00:28:34,760
kind of gets the performance high and then

1089
00:28:34,760 --> 00:28:35,780
we can have all of

1090
00:28:35,780 --> 00:28:37,240
that data across all of these tasks and

1091
00:28:37,240 --> 00:28:38,150
we can bring that data back basically

1092
00:28:38,150 --> 00:28:39,060
right

1093
00:28:39,060 --> 00:28:40,900
so in in that sense

1094
00:28:40,900 --> 00:28:42,720
it's not actually at odds you know if

1095
00:28:42,720 --> 00:28:44,860
that makes sense yeah that makes sense how

1096
00:28:44,860 --> 00:28:46,160
much of the rl are you

1097
00:28:46,160 --> 00:28:48,100
doing it sounds like there's a there's an

1098
00:28:48,100 --> 00:28:51,020
in real life rl can you talk a

1099
00:28:51,020 --> 00:28:51,720
little bit about the approach

1100
00:28:51,720 --> 00:28:53,100
to how much rl you're doing in sim

1101
00:28:53,100 --> 00:28:56,280
versus in real life um so we have

1102
00:28:56,280 --> 00:28:59,200
taken a quite uh like real world

1103
00:28:59,200 --> 00:29:02,440
first approach as opposed to uh using sim

1104
00:29:02,440 --> 00:29:04,740
we are exploring sim of course uh as

1105
00:29:04,740 --> 00:29:06,880
well as uh as a research

1106
00:29:06,880 --> 00:29:09,120
tool but all the rl we've done for

1107
00:29:09,120 --> 00:29:11,140
the pi star six paper is actually on

1108
00:29:11,140 --> 00:29:12,900
real systems in the real world

1109
00:29:12,900 --> 00:29:14,740
and the reason for that is that it's

1110
00:29:14,740 --> 00:29:16,110
actually really really hard to model again

1111
00:29:16,110 --> 00:29:17,480
we

1112
00:29:17,480 --> 00:29:17,920
can we can

1113
00:29:17,920 --> 00:29:19,920
get back to the long tail of failures

1114
00:29:19,920 --> 00:29:21,260
that you see when you when you do

1115
00:29:21,260 --> 00:29:22,760
deployments i can give you a

1116
00:29:22,760 --> 00:29:24,640
lot of examples from the tasks that we've

1117
00:29:24,640 --> 00:29:25,900
actually looked at for this release where

1118
00:29:25,900 --> 00:29:27,160
there

1119
00:29:27,160 --> 00:29:27,560
were failure

1120
00:29:27,560 --> 00:29:29,820
modes that we we saw that if you

1121
00:29:29,820 --> 00:29:31,760
had just done done a simulation of it

1122
00:29:31,760 --> 00:29:32,720
you might not have seen it

1123
00:29:32,720 --> 00:29:35,300
so to give you an example um we

1124
00:29:35,300 --> 00:29:37,340
have this one task which is uh you

1125
00:29:37,340 --> 00:29:38,620
have to build a box right so this

1126
00:29:38,620 --> 00:29:38,820
is an

1127
00:29:38,820 --> 00:29:40,360
actual deployment task where the goal is

1128
00:29:40,360 --> 00:29:41,900
um

1129
00:29:41,900 --> 00:29:43,600
we build these little uh cardboard boxes

1130
00:29:43,600 --> 00:29:45,300
to

1131
00:29:45,300 --> 00:29:45,840
put chocolate

1132
00:29:45,840 --> 00:29:48,100
into such that uh they can then be

1133
00:29:48,100 --> 00:29:51,000
packaged up and and and sent out basically

1134
00:29:51,000 --> 00:29:52,020
so that's building a

1135
00:29:52,020 --> 00:29:53,690
chocolate box basically um and building

1136
00:29:53,690 --> 00:29:55,360
this box

1137
00:29:55,360 --> 00:29:56,740
uh initially you know worked great and

1138
00:29:56,740 --> 00:29:58,120
then

1139
00:29:58,120 --> 00:29:58,700
there is

1140
00:29:58,700 --> 00:30:01,540
new shipments of boxes coming in and they

1141
00:30:01,540 --> 00:30:03,680
come in as like a flattened sheet of

1142
00:30:03,680 --> 00:30:05,320
cardboard and then these

1143
00:30:05,320 --> 00:30:06,300
cardboards that came in in this new

1144
00:30:06,300 --> 00:30:07,280
shipment

1145
00:30:07,280 --> 00:30:08,710
were kind of not perfectly perforated so

1146
00:30:08,710 --> 00:30:10,140
they

1147
00:30:10,140 --> 00:30:10,240
were

1148
00:30:10,240 --> 00:30:11,270
sticking together right and then the robot

1149
00:30:11,270 --> 00:30:12,300
starts

1150
00:30:12,300 --> 00:30:14,160
like grabbing them puts them on a table

1151
00:30:14,160 --> 00:30:15,020
to to to

1152
00:30:15,020 --> 00:30:16,160
try to build this box and like it

1153
00:30:16,160 --> 00:30:18,060
has two boxes suddenly on the table right

1154
00:30:18,060 --> 00:30:18,940
and this is something

1155
00:30:18,940 --> 00:30:20,380
that wouldn't happen in sim if you had

1156
00:30:20,380 --> 00:30:21,730
written like a nice simulator that where

1157
00:30:21,730 --> 00:30:23,080
you

1158
00:30:23,080 --> 00:30:23,640
would just get

1159
00:30:23,640 --> 00:30:25,160
individual cardboards and like fold them

1160
00:30:25,160 --> 00:30:26,680
um and

1161
00:30:26,680 --> 00:30:27,780
so now you have to deal with this

1162
00:30:27,780 --> 00:30:28,680
problem right and if

1163
00:30:28,680 --> 00:30:30,320
you just learn everything in sim and then

1164
00:30:30,320 --> 00:30:32,180
try to deploy it you wouldn't encounter it

1165
00:30:32,180 --> 00:30:33,060
so we encounter it

1166
00:30:33,060 --> 00:30:36,740
and then our um kind of method can

1167
00:30:36,740 --> 00:30:38,340
kind of figure out that oh actually what

1168
00:30:38,340 --> 00:30:39,140
i need to do is i need to

1169
00:30:39,140 --> 00:30:41,320
separate this and i can i need to

1170
00:30:41,320 --> 00:30:44,320
move that uh that uh second piece back

1171
00:30:44,320 --> 00:30:45,240
and and build the box

1172
00:30:45,240 --> 00:30:47,020
basically and we see a lot of successes

1173
00:30:47,020 --> 00:30:48,920
for a rel being applied in sim and

1174
00:30:48,920 --> 00:30:49,940
transferred to the real

1175
00:30:49,940 --> 00:30:52,050
world especially in locomotion and we we

1176
00:30:52,050 --> 00:30:54,160
haven't

1177
00:30:54,160 --> 00:30:55,620
really seen that kind of success in

1178
00:30:55,620 --> 00:30:57,080
manipulation

1179
00:30:57,660 --> 00:31:00,080
for for these kind of methods and i

1180
00:31:00,080 --> 00:31:02,060
think maybe one reason for that is that

1181
00:31:02,060 --> 00:31:03,540
with with locomotion

1182
00:31:03,540 --> 00:31:06,000
with trying to move around it seems that

1183
00:31:06,000 --> 00:31:07,800
the the biggest part of the problem is

1184
00:31:07,800 --> 00:31:08,480
modeling your own

1185
00:31:08,480 --> 00:31:10,620
body so if you can figure out how

1186
00:31:10,620 --> 00:31:13,440
to model you yourself as a robot you're

1187
00:31:13,440 --> 00:31:14,320
basically like almost

1188
00:31:14,320 --> 00:31:17,820
there so uh you can do this modeling

1189
00:31:17,820 --> 00:31:19,330
simulation exercise once because you only

1190
00:31:19,330 --> 00:31:20,840
can do

1191
00:31:20,840 --> 00:31:21,660
it you only have

1192
00:31:21,660 --> 00:31:23,620
to do it for you yourself for this

1193
00:31:23,620 --> 00:31:24,670
one robot and then you're basically done

1194
00:31:24,670 --> 00:31:25,720
if

1195
00:31:25,720 --> 00:31:26,220
you do it really

1196
00:31:26,220 --> 00:31:28,435
really well it should transfer with

1197
00:31:28,435 --> 00:31:29,700
manipulation however

1198
00:31:29,700 --> 00:31:31,180
the problem is not how you move your

1199
00:31:31,180 --> 00:31:31,340
own

1200
00:31:31,340 --> 00:31:33,300
body it's how the world reacts to it

1201
00:31:33,300 --> 00:31:34,690
you're actually changing the world around

1202
00:31:34,690 --> 00:31:36,080
you it's

1203
00:31:36,080 --> 00:31:36,740
not difficult to

1204
00:31:36,740 --> 00:31:38,040
figure out how to move your hand from

1205
00:31:38,040 --> 00:31:39,940
a to b it's difficult to figure out

1206
00:31:39,940 --> 00:31:41,620
how this affects the objects

1207
00:31:41,620 --> 00:31:42,880
you're interacting with and now the

1208
00:31:42,880 --> 00:31:44,140
problem is

1209
00:31:44,140 --> 00:31:46,740
no longer just modeling your own robot you

1210
00:31:46,740 --> 00:31:47,480
have to model

1211
00:31:47,480 --> 00:31:48,740
the entire world right like every single

1212
00:31:48,740 --> 00:31:50,000
object

1213
00:31:50,000 --> 00:31:50,990
that you might be interacting with every

1214
00:31:50,990 --> 00:31:51,980
single

1215
00:31:51,980 --> 00:31:54,360
task you can think of and that's where

1216
00:31:54,360 --> 00:31:57,380
we see scaling problems and that's i think

1217
00:31:57,380 --> 00:31:58,140
why we haven't

1218
00:31:58,140 --> 00:32:00,460
seen those kind of methods be as effective

1219
00:32:00,460 --> 00:32:02,160
in in manipulation what was the headline

1220
00:32:02,160 --> 00:32:03,860
of

1221
00:32:03,860 --> 00:32:04,320
the results

1222
00:32:04,320 --> 00:32:07,720
from pi star 0.6 and you know

1223
00:32:07,720 --> 00:32:09,580
where where did you see the model get

1224
00:32:09,580 --> 00:32:11,320
after rl on the on the test that

1225
00:32:11,320 --> 00:32:13,100
you cared about and what do you think

1226
00:32:13,100 --> 00:32:14,170
that means about your overall training

1227
00:32:14,170 --> 00:32:15,240
recipe going

1228
00:32:15,240 --> 00:32:15,540
forward

1229
00:32:15,540 --> 00:32:18,500
right yeah so i think for me the

1230
00:32:18,500 --> 00:32:19,780
most impressive thing honestly for me

1231
00:32:19,780 --> 00:32:21,060
personally to

1232
00:32:21,060 --> 00:32:21,720
see was just

1233
00:32:21,720 --> 00:32:24,100
have these models run for hours at a

1234
00:32:24,100 --> 00:32:25,660
time recover from lots of different

1235
00:32:25,660 --> 00:32:27,220
failures and

1236
00:32:27,220 --> 00:32:27,760
and basically

1237
00:32:27,760 --> 00:32:29,960
just keep going and at the same time

1238
00:32:29,960 --> 00:32:32,380
do that at a at a at a

1239
00:32:32,380 --> 00:32:34,660
rate that is actually much better than

1240
00:32:34,660 --> 00:32:35,560
the initial model that we started with

1241
00:32:35,560 --> 00:32:36,460
right

1242
00:32:36,460 --> 00:32:37,640
so the headline figures where we increase

1243
00:32:37,640 --> 00:32:38,820
kind

1244
00:32:38,820 --> 00:32:38,980
of

1245
00:32:38,980 --> 00:32:41,700
throughput of the policies by over 2x on

1246
00:32:41,700 --> 00:32:43,520
on these three tasks so there's one task

1247
00:32:43,520 --> 00:32:44,080
was this box

1248
00:32:44,080 --> 00:32:44,940
building task i already talked about one

1249
00:32:44,940 --> 00:32:45,800
was

1250
00:32:45,800 --> 00:32:48,820
the making a coffee with an actual kind

1251
00:32:48,820 --> 00:32:49,280
of industrial

1252
00:32:49,280 --> 00:32:50,900
scale espresso machine and the other one

1253
00:32:50,900 --> 00:32:52,520
was

1254
00:32:52,520 --> 00:32:55,460
kind of like folding laundry and so for

1255
00:32:55,460 --> 00:32:55,880
each of them we

1256
00:32:55,880 --> 00:32:57,860
managed to like make the base policy that

1257
00:32:57,860 --> 00:32:59,000
was trained just from demonstrations much

1258
00:32:59,000 --> 00:33:00,140
much faster

1259
00:33:00,700 --> 00:33:03,020
and also make it be able to recover

1260
00:33:03,020 --> 00:33:04,670
from failures much much better and so

1261
00:33:04,670 --> 00:33:06,320
seeing

1262
00:33:06,320 --> 00:33:08,060
that actually in action

1263
00:33:08,060 --> 00:33:10,140
when you you just you sit there right

1264
00:33:10,140 --> 00:33:11,760
we have if you go to our website

1265
00:33:11,760 --> 00:33:13,220
you you can look at the videos

1266
00:33:13,840 --> 00:33:17,100
we have the robot soft coffee for 13

1267
00:33:17,100 --> 00:33:20,140
hours in a row or fold laundry for

1268
00:33:20,140 --> 00:33:21,880
four hours things like that

1269
00:33:21,880 --> 00:33:23,750
um actually seeing that life changes the

1270
00:33:23,750 --> 00:33:25,620
way

1271
00:33:25,620 --> 00:33:27,130
you think about these models you know

1272
00:33:27,130 --> 00:33:28,640
changes

1273
00:33:28,640 --> 00:33:29,440
the way at

1274
00:33:29,440 --> 00:33:32,220
least i think about um it actually being

1275
00:33:32,220 --> 00:33:33,290
realistic that we can deploy them that

1276
00:33:33,290 --> 00:33:34,360
that

1277
00:33:34,360 --> 00:33:35,280
we can do it in a way

1278
00:33:35,280 --> 00:33:37,840
where it's not just a toy demo which

1279
00:33:37,840 --> 00:33:39,960
is shown once but is actually kind of

1280
00:33:39,960 --> 00:33:41,480
doing the real thing fully

1281
00:33:41,480 --> 00:33:43,680
and and that's been really a challenge in

1282
00:33:43,680 --> 00:33:44,480
robotics that i don't think many people

1283
00:33:44,480 --> 00:33:45,140
are

1284
00:33:45,140 --> 00:33:45,600
aware of

1285
00:33:45,600 --> 00:33:47,140
yeah like you know you see so many

1286
00:33:47,140 --> 00:33:49,700
videos of robots doing cool things and you

1287
00:33:49,700 --> 00:33:50,540
know we post these videos

1288
00:33:50,540 --> 00:33:51,880
too they're like there's basically like

1289
00:33:51,880 --> 00:33:53,220
anything you

1290
00:33:53,220 --> 00:33:54,080
want robot to do there's probably already

1291
00:33:54,080 --> 00:33:54,940
a

1292
00:33:54,940 --> 00:33:55,140
video

1293
00:33:55,140 --> 00:33:58,440
of a robot doing that um but you

1294
00:33:58,440 --> 00:33:59,720
know you can take as many takes as

1295
00:33:59,720 --> 00:34:01,780
you will as you want you can you

1296
00:34:01,780 --> 00:34:02,760
keep on recording until you get the

1297
00:34:02,760 --> 00:34:03,740
perfect

1298
00:34:03,740 --> 00:34:06,880
shot um and the problem that i think

1299
00:34:06,880 --> 00:34:08,060
everybody encounters

1300
00:34:08,060 --> 00:34:09,320
is the reliability of these models how

1301
00:34:09,320 --> 00:34:10,580
performant

1302
00:34:10,580 --> 00:34:12,240
they are how fast they can they can

1303
00:34:12,240 --> 00:34:13,100
go about the

1304
00:34:13,100 --> 00:34:15,120
task how how for how long you can

1305
00:34:15,120 --> 00:34:16,750
actually deploy them without failure and i

1306
00:34:16,750 --> 00:34:18,380
think

1307
00:34:18,380 --> 00:34:19,340
this is the biggest

1308
00:34:19,340 --> 00:34:20,480
bottleneck in terms of deploying these

1309
00:34:20,480 --> 00:34:21,620
models in

1310
00:34:21,620 --> 00:34:23,600
the real world because you know if you

1311
00:34:23,600 --> 00:34:24,860
if if they break

1312
00:34:24,860 --> 00:34:26,210
every every other trial they're not really

1313
00:34:26,210 --> 00:34:27,560
deployable

1314
00:34:27,560 --> 00:34:30,080
right and this is this is i think

1315
00:34:30,080 --> 00:34:30,400
the most

1316
00:34:30,400 --> 00:34:31,520
important breakthrough for us with this pi

1317
00:34:31,520 --> 00:34:32,640
star

1318
00:34:32,640 --> 00:34:35,900
or six release that we can actually start

1319
00:34:35,900 --> 00:34:36,460
getting to

1320
00:34:36,460 --> 00:34:37,590
a place where they are deployable yeah

1321
00:34:37,590 --> 00:34:38,720
where

1322
00:34:38,720 --> 00:34:40,340
we use these robots in our office to

1323
00:34:40,340 --> 00:34:41,460
serve us coffee or we

1324
00:34:41,460 --> 00:34:43,420
can give them to to people at pi

1325
00:34:43,420 --> 00:34:45,400
to fold laundry in their home or we

1326
00:34:45,400 --> 00:34:47,260
can deploy them uh and have them

1327
00:34:47,260 --> 00:34:50,020
fold boxes for real and that is really

1328
00:34:50,020 --> 00:34:51,380
really exciting should we think about what

1329
00:34:51,380 --> 00:34:52,740
you

1330
00:34:52,740 --> 00:34:53,100
guys are doing

1331
00:34:53,100 --> 00:34:54,530
with reinforcement learning as primarily a

1332
00:34:54,530 --> 00:34:55,960
you know

1333
00:34:55,960 --> 00:34:59,790
a customer deployment reliability uh

1334
00:34:59,790 --> 00:35:00,960
points then

1335
00:35:00,960 --> 00:35:02,220
like you can now make sure that you

1336
00:35:02,220 --> 00:35:04,840
can you know go reliably deploy the the

1337
00:35:04,840 --> 00:35:06,060
coffee making model on a

1338
00:35:06,060 --> 00:35:07,800
customer site and it's it's going to be

1339
00:35:07,800 --> 00:35:09,900
fast enough it's it's not going to fail

1340
00:35:09,900 --> 00:35:11,100
over long time horizons

1341
00:35:11,600 --> 00:35:13,400
um so it's it's more of a customer

1342
00:35:13,400 --> 00:35:15,612
deployment innovations versus like a

1343
00:35:15,612 --> 00:35:16,780
fundamental kind of

1344
00:35:16,780 --> 00:35:17,680
capability

1345
00:35:17,680 --> 00:35:20,480
um innovation or is it both i think

1346
00:35:20,480 --> 00:35:22,460
it's both i think i mean carol you

1347
00:35:22,460 --> 00:35:23,260
said this a little bit

1348
00:35:23,260 --> 00:35:26,580
earlier i think um to some extent the

1349
00:35:26,580 --> 00:35:27,600
robots that we really really want right

1350
00:35:27,600 --> 00:35:28,620
the

1351
00:35:28,620 --> 00:35:29,380
robot that you want

1352
00:35:29,380 --> 00:35:31,600
at home which can do your laundry do

1353
00:35:31,600 --> 00:35:34,120
your dishes cook for you drive around and

1354
00:35:34,120 --> 00:35:34,900
also the robot that

1355
00:35:34,900 --> 00:35:36,160
people want in these smaller businesses

1356
00:35:36,160 --> 00:35:37,420
maybe solving

1357
00:35:37,420 --> 00:35:39,440
a real problem that they have that they

1358
00:35:39,440 --> 00:35:40,040
don't want

1359
00:35:40,040 --> 00:35:40,840
to automate in the classical way because

1360
00:35:40,840 --> 00:35:41,620
it's

1361
00:35:41,620 --> 00:35:42,990
too expensive like building a chocolate

1362
00:35:42,990 --> 00:35:44,360
box those

1363
00:35:44,360 --> 00:35:44,620
are

1364
00:35:44,620 --> 00:35:47,100
things where the robot has to be reliable

1365
00:35:47,100 --> 00:35:48,580
it has to be good and it has

1366
00:35:48,580 --> 00:35:49,860
to have the capability to do

1367
00:35:49,860 --> 00:35:52,260
a new task that it hasn't seen in

1368
00:35:52,260 --> 00:35:54,208
initial training stages i think it's

1369
00:35:54,208 --> 00:35:55,020
unrealistic for

1370
00:35:55,020 --> 00:35:55,620
us to assume

1371
00:35:55,620 --> 00:35:59,180
that you know we can just go with

1372
00:35:59,180 --> 00:36:00,540
like more and more human data collection

1373
00:36:00,540 --> 00:36:01,900
go

1374
00:36:01,900 --> 00:36:03,060
bigger bigger bigger we will

1375
00:36:03,060 --> 00:36:04,800
do that but there is always going to

1376
00:36:04,800 --> 00:36:06,640
be a limit to to how good and

1377
00:36:06,640 --> 00:36:08,320
how much data you can you can get

1378
00:36:08,320 --> 00:36:09,940
and how good the initial policy is going

1379
00:36:09,940 --> 00:36:11,680
to be so i think it is that

1380
00:36:11,680 --> 00:36:13,060
what what you said in terms of

1381
00:36:13,060 --> 00:36:15,700
we we want deployment we need this but

1382
00:36:15,700 --> 00:36:17,210
also i think increasingly over the next

1383
00:36:17,210 --> 00:36:18,720
years

1384
00:36:18,720 --> 00:36:19,080
we will

1385
00:36:19,080 --> 00:36:21,300
i expect we will see that we will

1386
00:36:21,300 --> 00:36:22,270
do this deployment and that data will

1387
00:36:22,270 --> 00:36:23,240
actually

1388
00:36:23,240 --> 00:36:24,260
become really valuable

1389
00:36:24,260 --> 00:36:27,320
as a source for pre-training for making

1390
00:36:27,320 --> 00:36:28,940
our models better themselves and we'll

1391
00:36:28,940 --> 00:36:30,560
rely more

1392
00:36:30,560 --> 00:36:31,180
and more on

1393
00:36:31,180 --> 00:36:32,673
autonomous data collection is my

1394
00:36:32,673 --> 00:36:33,560
prediction at least

1395
00:36:33,560 --> 00:36:36,400
uh over the next coming years to kind

1396
00:36:36,400 --> 00:36:37,360
of build that

1397
00:36:37,360 --> 00:36:40,260
a host of data that convex hull of

1398
00:36:40,260 --> 00:36:42,500
all the tasks that we want robots uh

1399
00:36:42,500 --> 00:36:44,260
eventually to do such that

1400
00:36:44,260 --> 00:36:45,910
the models like ingest this and and

1401
00:36:45,910 --> 00:36:47,560
becomes

1402
00:36:47,560 --> 00:36:49,760
good at doing them and interpolating and i

1403
00:36:49,760 --> 00:36:50,120
think of it

1404
00:36:50,120 --> 00:36:52,180
as a new capability we haven't so far

1405
00:36:52,180 --> 00:36:53,960
figured out how to learn from your own

1406
00:36:53,960 --> 00:36:55,500
experience or there's been

1407
00:36:55,500 --> 00:36:57,240
many attempts but i don't think we've seen

1408
00:36:57,240 --> 00:37:00,160
it done at scale uh to like a

1409
00:37:00,160 --> 00:37:02,320
very to to the extent that i

1410
00:37:02,320 --> 00:37:03,450
actually shows a convincing result that

1411
00:37:03,450 --> 00:37:04,580
allows you

1412
00:37:04,580 --> 00:37:07,620
to deploy something yeah and this is why

1413
00:37:07,620 --> 00:37:07,860
this

1414
00:37:07,860 --> 00:37:08,930
result was was really really important to

1415
00:37:08,930 --> 00:37:10,000
us

1416
00:37:10,000 --> 00:37:11,400
we wanted to get to the point where

1417
00:37:11,400 --> 00:37:12,140
they can learn from

1418
00:37:12,140 --> 00:37:13,540
their own experience uh because you know

1419
00:37:13,540 --> 00:37:14,940
similarly

1420
00:37:14,940 --> 00:37:16,940
to to how we learn you know you

1421
00:37:16,940 --> 00:37:18,060
can learn a little

1422
00:37:18,060 --> 00:37:19,570
bit from watching videos and practice and

1423
00:37:19,570 --> 00:37:21,080
then

1424
00:37:21,080 --> 00:37:23,220
you know maybe learning from others but at

1425
00:37:23,220 --> 00:37:23,520
some point

1426
00:37:23,520 --> 00:37:25,220
you need to learn on the job you

1427
00:37:25,220 --> 00:37:26,780
need to try the thing yourself you need

1428
00:37:26,780 --> 00:37:27,800
to see how your actions

1429
00:37:27,800 --> 00:37:28,880
impact what you actually want to achieve

1430
00:37:28,880 --> 00:37:29,960
yeah

1431
00:37:29,960 --> 00:37:32,240
and make your own conclusions and try to

1432
00:37:32,240 --> 00:37:32,860
learn that way

1433
00:37:32,860 --> 00:37:34,320
yeah and i think this is the first

1434
00:37:34,320 --> 00:37:35,380
step towards that you're reminding me of

1435
00:37:35,380 --> 00:37:36,440
the

1436
00:37:36,440 --> 00:37:37,420
uh do you guys read

1437
00:37:37,420 --> 00:37:39,680
the rich satin age of experience yeah for

1438
00:37:39,680 --> 00:37:41,420
this year i love i thought it was

1439
00:37:41,420 --> 00:37:43,600
very profound um do you think

1440
00:37:43,600 --> 00:37:46,659
that this unlocks kind of continual

1441
00:37:46,659 --> 00:37:47,620
learning in

1442
00:37:47,620 --> 00:37:49,640
robotics real will this be part of that

1443
00:37:49,640 --> 00:37:50,820
it kind of

1444
00:37:50,820 --> 00:37:52,040
depends what people mean by continual

1445
00:37:52,040 --> 00:37:53,260
learning i

1446
00:37:53,260 --> 00:37:55,612
think it's um it's definitely more

1447
00:37:55,612 --> 00:37:56,580
continual than

1448
00:37:56,580 --> 00:37:57,040
what

1449
00:37:57,040 --> 00:37:58,580
we've done in the past where you know

1450
00:37:58,580 --> 00:38:01,080
you have like a big pre-training mixture

1451
00:38:01,080 --> 00:38:01,820
and maybe like

1452
00:38:01,820 --> 00:38:04,580
a post-training mixture and you like you

1453
00:38:04,580 --> 00:38:06,400
know you you you sit down you work

1454
00:38:06,400 --> 00:38:07,340
really really hard and

1455
00:38:07,340 --> 00:38:09,220
then you come up with an artifact and

1456
00:38:09,220 --> 00:38:10,100
like that's it yeah right like the

1457
00:38:10,100 --> 00:38:10,980
artifact

1458
00:38:10,980 --> 00:38:12,320
is done and there's

1459
00:38:12,320 --> 00:38:13,500
not much you can do to change it

1460
00:38:13,500 --> 00:38:16,400
now this is a much more of a

1461
00:38:16,400 --> 00:38:18,820
living thing right like we we start

1462
00:38:18,820 --> 00:38:21,320
with a process similar to this but then

1463
00:38:21,320 --> 00:38:23,140
you deploy it and then it keeps on

1464
00:38:23,140 --> 00:38:24,840
learning right so it's much

1465
00:38:24,840 --> 00:38:27,160
more continual in that sense that it tries

1466
00:38:27,160 --> 00:38:29,060
new things it tries to learn from its

1467
00:38:29,060 --> 00:38:29,640
own experience

1468
00:38:29,640 --> 00:38:32,620
and it keeps on getting better yeah now

1469
00:38:32,620 --> 00:38:34,840
i i think there is still room to

1470
00:38:34,840 --> 00:38:35,960
for it to be much more

1471
00:38:35,960 --> 00:38:37,380
continual where it can acquire new skills

1472
00:38:37,380 --> 00:38:38,800
that

1473
00:38:38,800 --> 00:38:41,800
way or it can be even much faster

1474
00:38:41,800 --> 00:38:43,620
in doing this yeah um

1475
00:38:43,620 --> 00:38:44,840
it can probably reason throughout this

1476
00:38:44,840 --> 00:38:46,060
process so

1477
00:38:46,060 --> 00:38:48,760
i i think there is a spectrum of

1478
00:38:48,760 --> 00:38:49,920
like how much you

1479
00:38:49,920 --> 00:38:52,560
can learn on the job and this is

1480
00:38:52,560 --> 00:38:53,360
really promising because it shows that you

1481
00:38:53,360 --> 00:38:54,160
can

1482
00:38:54,160 --> 00:38:55,220
do it but i think

1483
00:38:55,220 --> 00:38:57,920
we can make it much much better yeah

1484
00:38:57,920 --> 00:38:59,380
i would agree i would say we're at

1485
00:38:59,380 --> 00:39:01,140
the very beginning of of this

1486
00:39:01,140 --> 00:39:03,220
right and it's not it's not con it's

1487
00:39:03,220 --> 00:39:04,530
definitely not continual learning in the

1488
00:39:04,530 --> 00:39:05,840
classical sense

1489
00:39:05,840 --> 00:39:06,020
that

1490
00:39:06,020 --> 00:39:07,440
people would have thought about it of like

1491
00:39:07,440 --> 00:39:09,280
data streams and then the the whole thing

1492
00:39:09,280 --> 00:39:09,880
churns and it

1493
00:39:09,880 --> 00:39:13,040
just uh ultimately leads leads all the way

1494
00:39:13,040 --> 00:39:14,600
to i don't know agi or something like

1495
00:39:14,600 --> 00:39:16,060
this yeah but you know

1496
00:39:16,060 --> 00:39:17,780
it's it's a first step i i would

1497
00:39:17,780 --> 00:39:18,580
say and we're moving in the right

1498
00:39:18,580 --> 00:39:19,360
direction

1499
00:39:19,360 --> 00:39:19,800
there and there's

1500
00:39:19,800 --> 00:39:21,220
lots more to be done and i think

1501
00:39:21,220 --> 00:39:23,680
i will say from even from this release

1502
00:39:23,680 --> 00:39:25,920
like i was personally impressed

1503
00:39:25,920 --> 00:39:28,860
and to some extent you know shocked how

1504
00:39:28,860 --> 00:39:30,250
good these models actually are at picking

1505
00:39:30,250 --> 00:39:31,640
up

1506
00:39:31,640 --> 00:39:32,580
little things that

1507
00:39:32,580 --> 00:39:34,240
you put back into the data i was

1508
00:39:34,240 --> 00:39:35,640
surprised that even with just like human

1509
00:39:35,640 --> 00:39:37,040
corrections

1510
00:39:37,040 --> 00:39:38,840
for um there was

1511
00:39:38,840 --> 00:39:41,640
one example for uh for tamping when when

1512
00:39:41,640 --> 00:39:43,980
we do so tamping is a specific part

1513
00:39:43,980 --> 00:39:45,340
of making an espresso

1514
00:39:45,340 --> 00:39:46,920
right you like put the the beans and

1515
00:39:46,920 --> 00:39:48,780
then you have to tamp down the best

1516
00:39:48,780 --> 00:39:50,360
part yeah the best part you

1517
00:39:50,360 --> 00:39:52,340
have to tamp tamp down i don't get

1518
00:39:52,340 --> 00:39:55,320
it myself so there you go see i'm

1519
00:39:55,320 --> 00:39:57,620
not another skill issue

1520
00:39:58,200 --> 00:40:00,540
i'm gonna get it just right that's right

1521
00:40:00,540 --> 00:40:02,460
and so our robot in the beginning like

1522
00:40:02,460 --> 00:40:03,560
tamped way too hard

1523
00:40:03,560 --> 00:40:06,080
because uh it's just happened to be the

1524
00:40:06,080 --> 00:40:07,040
case that you know the initial human

1525
00:40:07,040 --> 00:40:08,000
demonstrations

1526
00:40:08,000 --> 00:40:09,680
were just making sure that you know let's

1527
00:40:09,680 --> 00:40:11,180
make sure the coffee grounds are flat so

1528
00:40:11,180 --> 00:40:11,820
we can put it in

1529
00:40:11,820 --> 00:40:13,880
um and then the robot was like tamping

1530
00:40:13,880 --> 00:40:14,690
really hard and like almost lifting itself

1531
00:40:14,690 --> 00:40:15,500
off

1532
00:40:15,500 --> 00:40:16,000
the table when

1533
00:40:16,000 --> 00:40:17,860
we looked at it that's that's a bit

1534
00:40:17,860 --> 00:40:19,940
much and so with just i don't know

1535
00:40:19,940 --> 00:40:22,280
it was i think 34 to 50 episodes

1536
00:40:22,280 --> 00:40:23,969
there's a really small range of

1537
00:40:23,969 --> 00:40:24,840
corrections that

1538
00:40:24,840 --> 00:40:26,800
humans did and we feed that data back

1539
00:40:26,800 --> 00:40:27,220
and the model

1540
00:40:27,220 --> 00:40:28,120
actually starts like being much more

1541
00:40:28,120 --> 00:40:29,020
gentle and

1542
00:40:29,020 --> 00:40:30,880
doing the correct thing and i was really

1543
00:40:30,880 --> 00:40:31,240
surprised

1544
00:40:31,240 --> 00:40:32,740
by that because you you think you know

1545
00:40:32,740 --> 00:40:34,480
this model has been pre-trained on these

1546
00:40:34,480 --> 00:40:35,780
millions and

1547
00:40:35,780 --> 00:40:36,580
millions of episodes and now you're just

1548
00:40:36,580 --> 00:40:37,300
doing

1549
00:40:37,300 --> 00:40:38,470
a little correction and that actually

1550
00:40:38,470 --> 00:40:39,640
works so

1551
00:40:39,640 --> 00:40:41,800
seeing that happen was was a thing that

1552
00:40:41,800 --> 00:40:42,920
i think is pointing towards this continued

1553
00:40:42,920 --> 00:40:44,040
learning

1554
00:40:44,040 --> 00:40:44,640
part

1555
00:40:44,640 --> 00:40:46,720
which i find impressive can i ask though

1556
00:40:46,720 --> 00:40:49,520
and then the thing i'm still hung up

1557
00:40:49,520 --> 00:40:50,740
on is generalization so

1558
00:40:50,740 --> 00:40:53,360
as i learn how to tamp better does

1559
00:40:53,360 --> 00:40:55,100
that make me better at folding boxes or

1560
00:40:55,100 --> 00:40:55,320
not

1561
00:40:56,160 --> 00:41:00,860
uh in this specific case no but the

1562
00:41:00,860 --> 00:41:03,300
mechanism is the same that you can also

1563
00:41:03,300 --> 00:41:05,500
employ to fix the oh

1564
00:41:05,500 --> 00:41:06,980
i have two boxes in front of me

1565
00:41:06,980 --> 00:41:08,860
that i sort of stuck together and i

1566
00:41:08,860 --> 00:41:10,160
need to pull them apart right

1567
00:41:10,160 --> 00:41:13,000
because you can get 30 corrections for the

1568
00:41:13,000 --> 00:41:14,240
stamping part you get 30 corrections for

1569
00:41:14,240 --> 00:41:15,480
the

1570
00:41:15,480 --> 00:41:16,380
pulling boxes

1571
00:41:16,380 --> 00:41:19,820
apart yeah but you get 30 corrections for

1572
00:41:19,820 --> 00:41:22,200
oh you know this box wasn't like neatly

1573
00:41:22,200 --> 00:41:23,320
folded together and

1574
00:41:23,320 --> 00:41:24,430
all of this accumulates together to then

1575
00:41:24,430 --> 00:41:25,540
give

1576
00:41:25,540 --> 00:41:27,350
you this more generalized improvement okay

1577
00:41:27,350 --> 00:41:29,160
so it's

1578
00:41:29,160 --> 00:41:29,220
a

1579
00:41:29,220 --> 00:41:30,791
repeatable recipe but they don't

1580
00:41:30,791 --> 00:41:31,920
necessarily cross cross

1581
00:41:31,920 --> 00:41:34,820
pollinate yeah i mean we i would expect

1582
00:41:34,820 --> 00:41:35,140
that

1583
00:41:35,140 --> 00:41:37,220
as we scale this up we might see

1584
00:41:37,220 --> 00:41:38,730
also things actually kind of transfer from

1585
00:41:38,730 --> 00:41:40,240
from

1586
00:41:40,240 --> 00:41:41,060
a to b if there

1587
00:41:41,060 --> 00:41:43,720
is motions that are kind of similar across

1588
00:41:43,720 --> 00:41:45,200
tasks but at this point yeah i would

1589
00:41:45,200 --> 00:41:45,840
say it's more like a

1590
00:41:45,840 --> 00:41:48,400
repeatable recipe yeah and and yeah we we

1591
00:41:48,400 --> 00:41:49,620
see a lot of generalization from

1592
00:41:49,620 --> 00:41:50,840
pre-training

1593
00:41:50,840 --> 00:41:51,480
where you train on

1594
00:41:51,480 --> 00:41:53,140
more and more tasks more and more data

1595
00:41:53,140 --> 00:41:55,320
you see that it's much easier to onboard

1596
00:41:55,320 --> 00:41:56,980
a new task or you see

1597
00:41:56,980 --> 00:41:57,920
tasks that appear zero shot that you

1598
00:41:57,920 --> 00:41:58,860
didn't

1599
00:41:58,860 --> 00:42:00,900
expect before and this keeps on improving

1600
00:42:00,900 --> 00:42:02,940
we

1601
00:42:02,940 --> 00:42:04,240
uh we kick off

1602
00:42:04,240 --> 00:42:06,680
a pre-training run at certain cadence and

1603
00:42:06,680 --> 00:42:08,820
every single time we start seeing that the

1604
00:42:08,820 --> 00:42:09,220
model keeps

1605
00:42:09,220 --> 00:42:10,170
on getting better because there's more

1606
00:42:10,170 --> 00:42:11,120
data being

1607
00:42:11,120 --> 00:42:12,230
fed in there's more improvements that

1608
00:42:12,230 --> 00:42:13,340
we're making

1609
00:42:13,340 --> 00:42:13,520
to

1610
00:42:13,520 --> 00:42:15,940
the pre-training process and so on and

1611
00:42:15,940 --> 00:42:18,020
i also suspect that as we have more

1612
00:42:18,020 --> 00:42:19,400
and more of these models deployed

1613
00:42:19,400 --> 00:42:20,470
doing all kinds of different tasks they

1614
00:42:20,470 --> 00:42:21,540
also

1615
00:42:21,540 --> 00:42:24,680
bring data back in and i think one

1616
00:42:24,680 --> 00:42:25,120
way where

1617
00:42:25,120 --> 00:42:27,640
we where i'm quite certain where we'll see

1618
00:42:27,640 --> 00:42:29,170
more generalization is from that process

1619
00:42:29,170 --> 00:42:30,700
that as

1620
00:42:30,700 --> 00:42:31,200
you

1621
00:42:31,200 --> 00:42:32,740
deploy these models the the data comes

1622
00:42:32,740 --> 00:42:34,280
back

1623
00:42:34,280 --> 00:42:36,000
the models get better you can deploy them

1624
00:42:36,000 --> 00:42:36,300
more

1625
00:42:36,300 --> 00:42:38,480
then the the models get better you can

1626
00:42:38,480 --> 00:42:40,420
deploy them more and so on yeah and

1627
00:42:40,420 --> 00:42:41,840
i think maybe it's worthwhile

1628
00:42:41,840 --> 00:42:43,800
for this point that you brought up we

1629
00:42:43,800 --> 00:42:46,176
haven't really talked about one like

1630
00:42:46,176 --> 00:42:47,100
crucial detail

1631
00:42:47,100 --> 00:42:47,720
aspect of

1632
00:42:47,720 --> 00:42:49,500
this five star or six recipe which is

1633
00:42:49,500 --> 00:42:51,020
that the model has kind of two parts

1634
00:42:51,020 --> 00:42:52,240
one is the policy that

1635
00:42:52,240 --> 00:42:53,610
is trying to like improve right via

1636
00:42:53,610 --> 00:42:54,980
corrections

1637
00:42:54,980 --> 00:42:57,100
and and rl feedback and the other part

1638
00:42:57,100 --> 00:42:57,880
is how do you

1639
00:42:57,880 --> 00:42:58,930
actually get this rl feedback right so

1640
00:42:58,930 --> 00:42:59,980
we've

1641
00:42:59,980 --> 00:43:00,990
talked a little bit i've mentioned like

1642
00:43:00,990 --> 00:43:02,000
you

1643
00:43:02,000 --> 00:43:02,660
know humans might

1644
00:43:02,660 --> 00:43:03,750
correct and that's the human correction

1645
00:43:03,750 --> 00:43:04,840
part and

1646
00:43:04,840 --> 00:43:07,280
the rl feedback part is is a little

1647
00:43:07,280 --> 00:43:07,960
different and it's

1648
00:43:07,960 --> 00:43:10,460
kind of and already has some of these

1649
00:43:10,460 --> 00:43:11,760
aspects of of generalization that i think

1650
00:43:11,760 --> 00:43:13,060
you're

1651
00:43:13,060 --> 00:43:13,900
you're like trying to

1652
00:43:13,900 --> 00:43:15,920
search for which is that the way we

1653
00:43:15,920 --> 00:43:19,000
do this is we we first basically get

1654
00:43:19,000 --> 00:43:21,500
humans to uh to to tell us

1655
00:43:21,500 --> 00:43:23,120
basically whether a specific attempt of

1656
00:43:23,120 --> 00:43:24,740
making the

1657
00:43:24,740 --> 00:43:27,140
coffee or doing the box was uh successful

1658
00:43:27,140 --> 00:43:27,700
or not so

1659
00:43:27,700 --> 00:43:28,580
there will be like human labels provided

1660
00:43:28,580 --> 00:43:29,460
with

1661
00:43:29,460 --> 00:43:30,680
these episodes and then we train something

1662
00:43:30,680 --> 00:43:31,900
which

1663
00:43:31,900 --> 00:43:32,120
is called

1664
00:43:32,120 --> 00:43:33,660
a value function to try and predict

1665
00:43:33,660 --> 00:43:35,200
basically

1666
00:43:35,200 --> 00:43:37,640
from my given point of where i am

1667
00:43:37,640 --> 00:43:39,520
in my in the task will i

1668
00:43:39,520 --> 00:43:41,560
likely be succeeding or failing basically

1669
00:43:41,560 --> 00:43:43,600
and this

1670
00:43:43,600 --> 00:43:45,780
value function is then used as kind of

1671
00:43:45,780 --> 00:43:46,900
a baseline to

1672
00:43:46,900 --> 00:43:48,610
to decide whether for this data point

1673
00:43:48,610 --> 00:43:50,320
should

1674
00:43:50,320 --> 00:43:52,220
i like bump that up or should i

1675
00:43:52,220 --> 00:43:53,480
bump that down depending on

1676
00:43:53,480 --> 00:43:56,800
whether i expect that i will be uh

1677
00:43:56,800 --> 00:43:58,230
moving towards success or or i'm more

1678
00:43:58,230 --> 00:43:59,660
likely

1679
00:43:59,660 --> 00:44:00,700
to move towards failure

1680
00:44:00,700 --> 00:44:02,840
and one thing that we saw when we

1681
00:44:02,840 --> 00:44:03,850
trained these value functions so those are

1682
00:44:03,850 --> 00:44:04,860
trained

1683
00:44:04,860 --> 00:44:05,920
basically from the same

1684
00:44:05,920 --> 00:44:08,480
kind of backbone the same kind of model

1685
00:44:08,480 --> 00:44:10,110
but they're pre-trained before the actual

1686
00:44:10,110 --> 00:44:11,740
policy

1687
00:44:11,740 --> 00:44:12,140
is trained

1688
00:44:12,140 --> 00:44:14,300
that that actually runs the task when we

1689
00:44:14,300 --> 00:44:15,950
train these value functions we see that

1690
00:44:15,950 --> 00:44:17,600
adding

1691
00:44:17,600 --> 00:44:18,140
more data

1692
00:44:18,140 --> 00:44:19,580
from different tasks actually helps there

1693
00:44:19,580 --> 00:44:21,020
and the

1694
00:44:21,020 --> 00:44:22,470
model starts being actually really quite

1695
00:44:22,470 --> 00:44:23,920
good at

1696
00:44:24,600 --> 00:44:26,700
at least for for certain tasks and knowing

1697
00:44:26,700 --> 00:44:29,340
when it will fail beforehand and before it

1698
00:44:29,340 --> 00:44:30,980
is obvious for me

1699
00:44:30,980 --> 00:44:32,460
for example when i look at a video

1700
00:44:32,460 --> 00:44:35,780
of it trying to insert uh the um

1701
00:44:35,780 --> 00:44:38,900
uh the porter filter thank you

1702
00:44:38,900 --> 00:44:41,720
see i'm i'm not good at making it's

1703
00:44:41,720 --> 00:44:43,700
trying to insert a porter filter into the

1704
00:44:43,700 --> 00:44:44,980
the coffee machine it kind

1705
00:44:44,980 --> 00:44:47,220
of knows that it doesn't quite have the

1706
00:44:47,220 --> 00:44:49,620
right angle before that happens so like 30

1707
00:44:49,620 --> 00:44:50,820
40 steps before that

1708
00:44:50,820 --> 00:44:51,860
actually happens the value function kind

1709
00:44:51,860 --> 00:44:52,900
of if

1710
00:44:52,900 --> 00:44:54,540
you look at the prediction drops and and

1711
00:44:54,540 --> 00:44:55,120
saying oh this

1712
00:44:55,120 --> 00:44:57,220
is not good in this specific episode so

1713
00:44:57,220 --> 00:44:59,282
i i shouldn't include this data

1714
00:44:59,282 --> 00:45:00,280
interesting and

1715
00:45:00,280 --> 00:45:00,620
this gets

1716
00:45:00,620 --> 00:45:02,580
better with more data and more tasks and

1717
00:45:02,580 --> 00:45:03,480
so this is an interesting counterpoint to

1718
00:45:03,480 --> 00:45:04,380
the

1719
00:45:04,380 --> 00:45:05,320
the carpathy

1720
00:45:05,320 --> 00:45:06,620
like slurping bits from a straw thing

1721
00:45:06,620 --> 00:45:07,920
right

1722
00:45:07,920 --> 00:45:08,720
because you're not you're not waiting for

1723
00:45:08,720 --> 00:45:09,460
that

1724
00:45:09,460 --> 00:45:09,900
final bits

1725
00:45:09,900 --> 00:45:13,120
at the end you're you're actually yes i

1726
00:45:13,120 --> 00:45:16,060
think a rel is just like a such

1727
00:45:16,060 --> 00:45:17,480
a vast field and there's so

1728
00:45:17,480 --> 00:45:19,150
many different approaches to it and people

1729
00:45:19,150 --> 00:45:20,820
often

1730
00:45:20,820 --> 00:45:22,220
associate a rel with something like a

1731
00:45:22,220 --> 00:45:23,620
policy

1732
00:45:23,620 --> 00:45:23,940
gradient

1733
00:45:23,940 --> 00:45:27,880
method or um you know very specific on

1734
00:45:27,880 --> 00:45:32,100
policy learning approaches and to me a rel

1735
00:45:32,100 --> 00:45:32,440
is more

1736
00:45:32,440 --> 00:45:34,500
of a problem definition and there is many

1737
00:45:34,500 --> 00:45:35,710
many approaches that get around the

1738
00:45:35,710 --> 00:45:36,920
problem that

1739
00:45:36,920 --> 00:45:37,180
you're

1740
00:45:37,180 --> 00:45:39,000
referring to which is that you know you

1741
00:45:39,000 --> 00:45:40,440
only get the reward at the very very

1742
00:45:40,440 --> 00:45:41,620
end and it's not really

1743
00:45:41,620 --> 00:45:43,030
scalable for very long horizon tasks there

1744
00:45:43,030 --> 00:45:44,440
are

1745
00:45:44,440 --> 00:45:45,410
things like value functions there are

1746
00:45:45,410 --> 00:45:46,380
things like

1747
00:45:46,380 --> 00:45:47,520
temporal difference learning that try to

1748
00:45:47,520 --> 00:45:48,660
get around

1749
00:45:48,660 --> 00:45:49,820
this problem where you constantly make

1750
00:45:49,820 --> 00:45:50,980
predictions

1751
00:45:50,980 --> 00:45:52,940
and you do it in a sequential way

1752
00:45:52,940 --> 00:45:56,380
and this is maybe another one of these

1753
00:45:56,380 --> 00:45:57,640
one of these things where

1754
00:45:57,640 --> 00:46:00,480
i think robotics can really help the the

1755
00:46:00,480 --> 00:46:02,000
broader ai community because we don't have

1756
00:46:02,000 --> 00:46:03,520
the

1757
00:46:03,520 --> 00:46:04,320
advantage of

1758
00:46:04,320 --> 00:46:05,660
having a perfect language simulator where

1759
00:46:05,660 --> 00:46:07,000
you can

1760
00:46:07,000 --> 00:46:09,680
run as many simulations as you would like

1761
00:46:09,680 --> 00:46:10,620
instead

1762
00:46:10,620 --> 00:46:11,500
you need to do it in the real

1763
00:46:11,500 --> 00:46:12,860
world so you need to make more efficient

1764
00:46:12,860 --> 00:46:14,260
methods and therefore you need

1765
00:46:14,260 --> 00:46:15,260
to learn value functions and things like

1766
00:46:15,260 --> 00:46:16,260
this

1767
00:46:16,260 --> 00:46:18,220
and i think this will this will be

1768
00:46:18,220 --> 00:46:19,260
really valuable everywhere

1769
00:46:19,260 --> 00:46:21,800
yeah can i push a little bit on

1770
00:46:21,800 --> 00:46:23,430
i'd love to understand you know internet

1771
00:46:23,430 --> 00:46:25,060
video

1772
00:46:25,060 --> 00:46:25,540
seems like

1773
00:46:25,540 --> 00:46:27,000
it's part of the recipe but not a

1774
00:46:27,000 --> 00:46:29,300
huge focus right now as i see it

1775
00:46:29,300 --> 00:46:30,580
like do you think that there's gold

1776
00:46:30,580 --> 00:46:32,480
left to be mined in internet video and

1777
00:46:32,480 --> 00:46:34,680
then if you look at what's happening in

1778
00:46:34,680 --> 00:46:35,860
video models right now

1779
00:46:35,860 --> 00:46:40,260
uh world models um to what extent do

1780
00:46:40,260 --> 00:46:42,320
you think that's going to be a you

1781
00:46:42,320 --> 00:46:43,720
know discontinuous jump in

1782
00:46:43,720 --> 00:46:44,680
model capabilities and you know an

1783
00:46:44,680 --> 00:46:45,640
important part

1784
00:46:45,640 --> 00:46:48,940
of your your model uh pipeline yeah um

1785
00:46:48,940 --> 00:46:49,980
i think maybe

1786
00:46:49,980 --> 00:46:51,560
there are two questions there one is about

1787
00:46:51,560 --> 00:46:52,920
the data like how do you bootstrap

1788
00:46:52,920 --> 00:46:54,280
yourself

1789
00:46:54,280 --> 00:46:55,000
to the point where

1790
00:46:55,000 --> 00:46:57,560
you can start deploying um and the other

1791
00:46:57,560 --> 00:46:59,760
question is you know what about what about

1792
00:46:59,760 --> 00:47:00,640
video models and

1793
00:47:00,640 --> 00:47:02,520
kind of the world model aspects of it

1794
00:47:02,520 --> 00:47:06,260
um so on the data point i i

1795
00:47:06,260 --> 00:47:08,920
think we are now in this bootstrap phase

1796
00:47:08,920 --> 00:47:11,368
where basically anything goes like

1797
00:47:11,368 --> 00:47:12,520
whatever you you

1798
00:47:12,520 --> 00:47:14,420
can figure out how to like add to

1799
00:47:14,420 --> 00:47:14,920
the model

1800
00:47:15,460 --> 00:47:17,860
and to to to to its benefit i

1801
00:47:17,860 --> 00:47:19,760
think it's good whether you can add sim

1802
00:47:19,760 --> 00:47:20,780
whether you can add human

1803
00:47:20,780 --> 00:47:22,530
videos some kind of handheld devices human

1804
00:47:22,530 --> 00:47:24,280
tell

1805
00:47:24,280 --> 00:47:25,460
operations i think it kind of doesn't

1806
00:47:25,460 --> 00:47:26,640
matter

1807
00:47:26,640 --> 00:47:26,840
you

1808
00:47:26,840 --> 00:47:28,380
just need to figure out some way to

1809
00:47:28,380 --> 00:47:29,490
bootstrap yourself to the point where you

1810
00:47:29,490 --> 00:47:30,600
can

1811
00:47:30,600 --> 00:47:31,080
deploy these

1812
00:47:31,080 --> 00:47:33,340
models because i think in the long term

1813
00:47:33,340 --> 00:47:34,390
there's going to be this bootstrap phase

1814
00:47:34,390 --> 00:47:35,440
but

1815
00:47:35,440 --> 00:47:35,860
then there's going

1816
00:47:35,860 --> 00:47:38,800
going to be the deployment phase and i

1817
00:47:38,800 --> 00:47:40,180
think deployment phase will be will

1818
00:47:40,180 --> 00:47:41,560
provide much

1819
00:47:41,560 --> 00:47:41,740
much

1820
00:47:41,740 --> 00:47:43,500
more data than anything you could do in

1821
00:47:43,500 --> 00:47:45,520
the bootstrap phase so we're in this kind

1822
00:47:45,520 --> 00:47:45,840
of like

1823
00:47:45,840 --> 00:47:48,440
weird spot right now where we tried many

1824
00:47:48,440 --> 00:47:49,430
different things straight to see what what

1825
00:47:49,430 --> 00:47:50,420
sticks

1826
00:47:50,420 --> 00:47:51,060
to just get

1827
00:47:51,060 --> 00:47:52,920
us to the deployment threshold i see and

1828
00:47:52,920 --> 00:47:54,500
once you can deploy i think that will

1829
00:47:54,500 --> 00:47:56,520
vastly be be much greater

1830
00:47:56,520 --> 00:47:58,660
than than anything you can do uh before

1831
00:47:58,660 --> 00:48:01,580
that um so so that's also what we

1832
00:48:01,580 --> 00:48:02,740
are sprinting towards that's

1833
00:48:02,740 --> 00:48:03,540
why we want to start deploying these

1834
00:48:03,540 --> 00:48:04,100
models

1835
00:48:04,100 --> 00:48:05,660
that's why we want to do this up

1836
00:48:05,660 --> 00:48:06,860
you know with many

1837
00:48:06,860 --> 00:48:09,698
different tasks in in many different

1838
00:48:09,698 --> 00:48:10,880
environments so

1839
00:48:10,880 --> 00:48:12,820
that we can just have this very uh

1840
00:48:12,820 --> 00:48:13,560
powerful data

1841
00:48:13,560 --> 00:48:17,080
engine um now on the on the world

1842
00:48:17,080 --> 00:48:20,240
modeling side of things i think the world

1843
00:48:20,240 --> 00:48:21,440
models and aurel

1844
00:48:21,440 --> 00:48:22,700
approaches are kind of targeting the same

1845
00:48:22,700 --> 00:48:23,960
problem

1846
00:48:23,960 --> 00:48:25,700
the problem of counterfactuals of how do

1847
00:48:25,700 --> 00:48:27,440
you

1848
00:48:27,440 --> 00:48:27,940
or a

1849
00:48:27,940 --> 00:48:28,950
credit assignment problem right like how

1850
00:48:28,950 --> 00:48:29,960
do you

1851
00:48:29,960 --> 00:48:31,260
figure out which actions were the ones

1852
00:48:31,260 --> 00:48:32,560
that

1853
00:48:32,560 --> 00:48:32,900
actually

1854
00:48:32,900 --> 00:48:35,520
matter for your success and how would the

1855
00:48:35,520 --> 00:48:37,180
world have evolved had you had had you

1856
00:48:37,180 --> 00:48:37,720
taken a different

1857
00:48:37,720 --> 00:48:40,100
action and one way you can do this

1858
00:48:40,100 --> 00:48:41,090
is by predicting what would have happened

1859
00:48:41,090 --> 00:48:42,080
right

1860
00:48:42,080 --> 00:48:42,980
like rolling out a

1861
00:48:42,980 --> 00:48:45,320
full video of you know if i if

1862
00:48:45,320 --> 00:48:46,170
i put this portafilter a little bit

1863
00:48:46,170 --> 00:48:47,020
differently

1864
00:48:47,020 --> 00:48:48,820
you know where would i end up

1865
00:48:49,380 --> 00:48:50,920
and would this be a failure or a

1866
00:48:50,920 --> 00:48:52,290
success or you can do this through

1867
00:48:52,290 --> 00:48:53,660
reinforcement

1868
00:48:53,660 --> 00:48:54,020
learning

1869
00:48:54,880 --> 00:48:56,050
and it does it through a slightly

1870
00:48:56,050 --> 00:48:57,220
different

1871
00:48:57,220 --> 00:48:58,140
mechanism a little bit more implicitly but

1872
00:48:58,140 --> 00:48:59,060
it

1873
00:48:59,060 --> 00:49:02,072
fundamentally targets a very similar

1874
00:49:02,072 --> 00:49:03,160
problem uh we

1875
00:49:03,160 --> 00:49:04,600
are exploring all of those approaches

1876
00:49:04,600 --> 00:49:06,140
and try to see you know how to

1877
00:49:06,140 --> 00:49:09,307
how to really solve the counterfactual

1878
00:49:09,307 --> 00:49:10,140
problem um

1879
00:49:10,140 --> 00:49:11,440
i don't think there

1880
00:49:11,440 --> 00:49:14,360
is a an answer yet uh but we

1881
00:49:14,360 --> 00:49:16,300
see we see a lot of progress with

1882
00:49:16,300 --> 00:49:17,560
with reinforcement learning that we

1883
00:49:17,560 --> 00:49:19,420
that we've just shown with with pi star

1884
00:49:19,420 --> 00:49:21,540
with pi star of six but i think

1885
00:49:21,540 --> 00:49:22,780
there is probably room for for

1886
00:49:22,780 --> 00:49:24,430
many many other approaches too awesome can

1887
00:49:24,430 --> 00:49:26,080
we

1888
00:49:26,080 --> 00:49:27,700
talk about once you guys get past that

1889
00:49:27,700 --> 00:49:28,400
bootstrap phase

1890
00:49:28,400 --> 00:49:29,260
let's talk about customer deployments a

1891
00:49:29,260 --> 00:49:30,120
little bit

1892
00:49:30,120 --> 00:49:32,040
what do you bring to a customer what

1893
00:49:32,040 --> 00:49:32,320
do you sell

1894
00:49:32,320 --> 00:49:34,540
them and then um how do you imagine

1895
00:49:34,540 --> 00:49:35,860
that's going to evolve over time like are

1896
00:49:35,860 --> 00:49:36,360
you selling them a

1897
00:49:36,900 --> 00:49:38,537
fully vertically integrated robotic

1898
00:49:38,537 --> 00:49:39,660
solution are you selling

1899
00:49:39,660 --> 00:49:41,580
them a model that they have to figure

1900
00:49:41,580 --> 00:49:41,700
out

1901
00:49:41,700 --> 00:49:42,560
how to integrate into their operations

1902
00:49:42,560 --> 00:49:43,420
like how

1903
00:49:43,420 --> 00:49:45,960
does this all work uh the the the

1904
00:49:45,960 --> 00:49:46,660
real answer is we

1905
00:49:46,660 --> 00:49:49,700
don't know yet yeah um we are we

1906
00:49:49,700 --> 00:49:52,080
are still figuring that out yeah uh we

1907
00:49:52,080 --> 00:49:54,240
are still quite early in in the

1908
00:49:54,240 --> 00:49:56,540
technology as you can as you can tell

1909
00:49:56,540 --> 00:49:58,980
we are just starting to to even get

1910
00:49:58,980 --> 00:49:59,960
to the threshold where we

1911
00:49:59,960 --> 00:50:03,860
can start deploying these things um so we

1912
00:50:03,860 --> 00:50:05,480
believe we should focus on the on the

1913
00:50:05,480 --> 00:50:06,240
technology first

1914
00:50:06,240 --> 00:50:08,060
to figure out how to get it to

1915
00:50:08,060 --> 00:50:08,890
the point where it's actually easy to

1916
00:50:08,890 --> 00:50:09,720
deploy

1917
00:50:10,360 --> 00:50:11,560
and expand this aperture that we're

1918
00:50:11,560 --> 00:50:12,760
talking about

1919
00:50:12,760 --> 00:50:17,000
initially and robotics the history of of

1920
00:50:17,000 --> 00:50:20,960
robotic startups is as very often gets to

1921
00:50:20,960 --> 00:50:22,270
this point where you develop a technology

1922
00:50:22,270 --> 00:50:23,580
for

1923
00:50:23,580 --> 00:50:24,200
for some

1924
00:50:24,200 --> 00:50:26,120
period of time you started with this grand

1925
00:50:26,120 --> 00:50:28,060
vision of what it should be able to

1926
00:50:28,060 --> 00:50:29,220
enable how general

1927
00:50:29,220 --> 00:50:31,560
purpose it will be and as soon as

1928
00:50:31,560 --> 00:50:32,840
you pick an application that you want to

1929
00:50:32,840 --> 00:50:34,280
apply it to you're kind

1930
00:50:34,280 --> 00:50:35,570
of stuck you start cutting corners you

1931
00:50:35,570 --> 00:50:36,860
start

1932
00:50:36,860 --> 00:50:38,210
uh figuring out very special purpose

1933
00:50:38,210 --> 00:50:39,560
solutions

1934
00:50:39,560 --> 00:50:40,810
just for this application and very quickly

1935
00:50:40,810 --> 00:50:42,060
you

1936
00:50:42,060 --> 00:50:43,600
become you know uh an application company

1937
00:50:43,600 --> 00:50:45,140
that

1938
00:50:45,140 --> 00:50:46,310
just focuses on let's say warehouse pick

1939
00:50:46,310 --> 00:50:47,480
and

1940
00:50:47,480 --> 00:50:50,300
place robots and that's it uh and we

1941
00:50:50,300 --> 00:50:51,060
really want to avoid

1942
00:50:51,060 --> 00:50:53,220
that future we think we have a chance

1943
00:50:53,220 --> 00:50:55,410
to really solve physical intelligence and

1944
00:50:55,410 --> 00:50:57,600
the the

1945
00:50:57,600 --> 00:50:58,160
benefits of

1946
00:50:58,160 --> 00:50:59,660
doing this will far outweigh any single

1947
00:50:59,660 --> 00:51:01,160
applications

1948
00:51:01,160 --> 00:51:03,200
that we can focus on now so we

1949
00:51:03,200 --> 00:51:04,000
want to make sure that

1950
00:51:04,000 --> 00:51:05,040
the technology is as general as possible

1951
00:51:05,040 --> 00:51:06,080
as

1952
00:51:06,080 --> 00:51:07,360
easily deployable as possible this

1953
00:51:07,360 --> 00:51:08,640
aperture is as

1954
00:51:08,640 --> 00:51:09,140
wide as

1955
00:51:09,140 --> 00:51:10,860
possible and and then we'll start figuring

1956
00:51:10,860 --> 00:51:12,580
out

1957
00:51:12,580 --> 00:51:15,380
how to commercialize it and as you said

1958
00:51:15,380 --> 00:51:15,680
there could

1959
00:51:15,680 --> 00:51:17,360
be you know many different ways of doing

1960
00:51:17,360 --> 00:51:18,450
this uh there's probably ways that we

1961
00:51:18,450 --> 00:51:19,540
can't

1962
00:51:19,540 --> 00:51:20,120
think of just

1963
00:51:20,120 --> 00:51:22,020
yet because they will depend on how the

1964
00:51:22,020 --> 00:51:23,700
technology goes uh whether it's in uh

1965
00:51:23,700 --> 00:51:25,380
whether

1966
00:51:25,380 --> 00:51:26,020
you can be a model

1967
00:51:26,020 --> 00:51:27,140
provider fully vertical solution or you

1968
00:51:27,140 --> 00:51:28,260
sell robots

1969
00:51:28,260 --> 00:51:30,560
or or whatever else but i think it's

1970
00:51:30,560 --> 00:51:31,440
a little too

1971
00:51:31,440 --> 00:51:32,710
premature to answer this question it will

1972
00:51:32,710 --> 00:51:33,980
give

1973
00:51:33,980 --> 00:51:35,600
you a lot of comfort you know just

1974
00:51:35,600 --> 00:51:36,780
to like pick one of

1975
00:51:36,780 --> 00:51:38,400
people give alfred a lot of comfort yeah

1976
00:51:38,400 --> 00:51:40,240
i'll be happy with us but i think

1977
00:51:40,240 --> 00:51:40,980
it's just too early

1978
00:51:41,560 --> 00:51:44,080
no you guys have a grand grand vision

1979
00:51:44,080 --> 00:51:45,210
so thank you for working on physical

1980
00:51:45,210 --> 00:51:46,340
intelligence

1981
00:51:46,340 --> 00:51:47,060
it's a

1982
00:51:47,060 --> 00:51:50,122
wonderful wonderful improvement just for

1983
00:51:50,122 --> 00:51:51,040
pi star zero

1984
00:51:51,040 --> 00:51:53,500
six it's just a huge um sort of

1985
00:51:53,500 --> 00:51:54,040
breakthrough

1986
00:51:54,040 --> 00:51:55,410
and so congratulations on all the success

1987
00:51:55,410 --> 00:51:56,780
you've

1988
00:51:56,780 --> 00:51:59,640
had thank you can i follow up with

1989
00:51:59,640 --> 00:52:00,840
a spicy question

1990
00:52:00,840 --> 00:52:03,300
sure so as you said this vision is

1991
00:52:03,300 --> 00:52:05,580
so grand so broad you're doing all these

1992
00:52:05,580 --> 00:52:06,920
different things if i'm

1993
00:52:06,920 --> 00:52:09,347
i'm sure you've you've studied all

1994
00:52:09,347 --> 00:52:10,560
previous robotics

1995
00:52:10,560 --> 00:52:14,400
like um efforts and they've largely as you

1996
00:52:14,400 --> 00:52:14,620
said

1997
00:52:14,620 --> 00:52:16,100
applied an application to an application

1998
00:52:16,100 --> 00:52:17,580
and they

1999
00:52:17,580 --> 00:52:20,820
get narrower narrower and one of the most

2000
00:52:20,820 --> 00:52:21,580
successful

2001
00:52:21,580 --> 00:52:23,700
cases of a large application is

2002
00:52:23,700 --> 00:52:24,520
self-driving

2003
00:52:24,520 --> 00:52:27,050
and waymo or tesla have done enormously

2004
00:52:27,050 --> 00:52:29,580
well

2005
00:52:29,580 --> 00:52:31,660
but if i had to go back in

2006
00:52:31,660 --> 00:52:34,104
history you know i learned about

2007
00:52:34,104 --> 00:52:35,020
self-driving

2008
00:52:35,020 --> 00:52:36,360
when sebastian threnham

2009
00:52:36,360 --> 00:52:38,140
was on the stage of ted and i

2010
00:52:38,140 --> 00:52:43,540
think 2000 and 2009 2010 and he talked

2011
00:52:43,540 --> 00:52:45,400
about the thing where they won

2012
00:52:45,400 --> 00:52:47,470
the darpa challenge that was 2007 and

2013
00:52:47,470 --> 00:52:49,540
we're

2014
00:52:49,540 --> 00:52:52,600
in 2025 and the thing barely goes from

2015
00:52:52,600 --> 00:52:53,300
san francisco

2016
00:52:53,820 --> 00:52:55,720
down here they kind of can do it

2017
00:52:55,720 --> 00:52:58,060
now but they take local roads they can't

2018
00:52:58,060 --> 00:52:58,880
even get on the freeway

2019
00:52:58,880 --> 00:53:01,540
if you do such a generalized job how

2020
00:53:01,540 --> 00:53:04,480
long is the runway or the timeline that

2021
00:53:04,480 --> 00:53:05,160
you're thinking about

2022
00:53:05,160 --> 00:53:08,148
to build for generalization and

2023
00:53:08,148 --> 00:53:09,980
performance yeah so

2024
00:53:09,980 --> 00:53:11,880
there are some aspects of the problem that

2025
00:53:11,880 --> 00:53:12,080
make

2026
00:53:12,080 --> 00:53:14,240
it easier than self-driving and some that

2027
00:53:14,240 --> 00:53:17,420
make it harder yeah um one thing that

2028
00:53:17,420 --> 00:53:18,540
makes it easier is that

2029
00:53:19,260 --> 00:53:21,740
we don't need to deploy it only when

2030
00:53:21,740 --> 00:53:23,270
it's 100 reliable right there's many many

2031
00:53:23,270 --> 00:53:24,800
tasks

2032
00:53:24,800 --> 00:53:25,260
out there

2033
00:53:25,820 --> 00:53:27,500
that even if you're at 95 reliability

2034
00:53:27,500 --> 00:53:29,180
you're

2035
00:53:29,180 --> 00:53:30,940
totally fine if you have a robot in

2036
00:53:30,940 --> 00:53:31,220
your home

2037
00:53:31,220 --> 00:53:32,370
folding your laundry and every 100 bite

2038
00:53:32,370 --> 00:53:33,520
them

2039
00:53:33,520 --> 00:53:34,320
you know it doesn't fold it perfectly

2040
00:53:34,320 --> 00:53:35,080
you'll

2041
00:53:35,080 --> 00:53:35,420
be totally

2042
00:53:35,420 --> 00:53:37,800
fine you just call your your child to

2043
00:53:37,800 --> 00:53:41,100
go fold the that's right that's right we

2044
00:53:41,100 --> 00:53:42,040
still we still need

2045
00:53:42,040 --> 00:53:44,823
chores yeah exactly um and with

2046
00:53:44,823 --> 00:53:45,900
self-driving

2047
00:53:45,900 --> 00:53:47,380
that's not the case right like if you

2048
00:53:47,380 --> 00:53:48,820
fail every 100th time

2049
00:53:48,820 --> 00:53:51,022
catastrophically that's that's a big

2050
00:53:51,022 --> 00:53:51,940
problem yeah um

2051
00:53:51,940 --> 00:53:53,460
so i think in terms of deploying this

2052
00:53:53,460 --> 00:53:53,820
technology

2053
00:53:53,820 --> 00:53:57,420
it might be easier now we also benefit

2054
00:53:57,420 --> 00:53:59,960
from the fact that this is a different

2055
00:53:59,960 --> 00:54:01,320
era of technology

2056
00:54:01,320 --> 00:54:03,600
we we are at the era of vision

2057
00:54:03,600 --> 00:54:04,840
language models of foundation models that

2058
00:54:04,840 --> 00:54:06,080
that have

2059
00:54:06,080 --> 00:54:07,220
some some common

2060
00:54:07,220 --> 00:54:09,500
sense and we learn a lot of lessons

2061
00:54:09,500 --> 00:54:13,480
between what was it 2009 and 2025 and

2062
00:54:13,480 --> 00:54:14,480
we can benefit from all of

2063
00:54:14,480 --> 00:54:17,860
those um so i think that also really

2064
00:54:17,860 --> 00:54:18,820
really helps and these are much more

2065
00:54:18,820 --> 00:54:19,780
general

2066
00:54:19,780 --> 00:54:20,800
purpose solutions than

2067
00:54:20,800 --> 00:54:23,680
what we had in the past um at

2068
00:54:23,680 --> 00:54:25,780
the same time there are some things that

2069
00:54:25,780 --> 00:54:27,080
will be very challenging right

2070
00:54:27,080 --> 00:54:28,190
like there isn't just a single application

2071
00:54:28,190 --> 00:54:29,300
this

2072
00:54:29,300 --> 00:54:30,510
is a very general purpose solution that

2073
00:54:30,510 --> 00:54:31,720
can

2074
00:54:31,720 --> 00:54:32,100
be applied

2075
00:54:32,100 --> 00:54:33,410
to driving but also to manipulation and

2076
00:54:33,410 --> 00:54:34,720
locomotion

2077
00:54:34,720 --> 00:54:36,800
and flying and all kinds of other things

2078
00:54:36,800 --> 00:54:37,960
and i think

2079
00:54:37,960 --> 00:54:39,680
it's to be seen how much harder this

2080
00:54:39,680 --> 00:54:42,740
is so far based on what we've experienced

2081
00:54:42,740 --> 00:54:45,580
it doesn't seem to be that

2082
00:54:45,580 --> 00:54:47,720
much harder to be honest it seems that

2083
00:54:47,720 --> 00:54:51,980
if you if you tackle this with with

2084
00:54:51,980 --> 00:54:53,480
a very general purpose

2085
00:54:54,220 --> 00:54:56,460
kind of mindset from the get-go it

2086
00:54:56,460 --> 00:54:57,350
turns out that it can generalize fairly

2087
00:54:57,350 --> 00:54:58,240
well

2088
00:54:58,240 --> 00:54:59,400
and there is something

2089
00:54:59,400 --> 00:55:00,480
about physical intelligence that we don't

2090
00:55:00,480 --> 00:55:01,560
fully understand

2091
00:55:01,560 --> 00:55:03,040
that allows these models to generalize

2092
00:55:03,040 --> 00:55:05,180
between driving and making coffee and

2093
00:55:05,180 --> 00:55:07,320
flying a

2094
00:55:07,320 --> 00:55:08,710
drone and operating a surgical robot even

2095
00:55:08,710 --> 00:55:10,100
though

2096
00:55:10,100 --> 00:55:11,920
they seem so far apart from each other

2097
00:55:11,920 --> 00:55:13,280
and it seems that these should be all

2098
00:55:13,280 --> 00:55:14,160
different models and

2099
00:55:14,160 --> 00:55:15,867
different applications these models

2100
00:55:15,867 --> 00:55:16,940
somehow can make sense

2101
00:55:16,940 --> 00:55:19,220
out of all of that data and that

2102
00:55:19,220 --> 00:55:19,420
gives

2103
00:55:19,420 --> 00:55:20,640
me a lot of hope that maybe the

2104
00:55:20,640 --> 00:55:22,360
problem is not that much harder and it

2105
00:55:22,360 --> 00:55:23,320
might be actually easier

2106
00:55:24,860 --> 00:55:27,940
um so i think it's a fair question

2107
00:55:27,940 --> 00:55:29,480
but i also don't want to draw the

2108
00:55:29,480 --> 00:55:30,560
wrong conclusions from what

2109
00:55:30,560 --> 00:55:31,890
we've seen from from self-driving that's

2110
00:55:31,890 --> 00:55:33,220
beautiful

2111
00:55:33,220 --> 00:55:34,850
congratulations what results is impressed

2112
00:55:34,850 --> 00:55:36,480
you the

2113
00:55:36,480 --> 00:55:37,750
most outside of results it's a great

2114
00:55:37,750 --> 00:55:39,020
question

2115
00:55:39,020 --> 00:55:42,060
yeah it's a good question actually i can

2116
00:55:42,060 --> 00:55:42,700
start i've been

2117
00:55:42,700 --> 00:55:43,660
i've been really impressed by the video

2118
00:55:43,660 --> 00:55:44,620
models

2119
00:55:44,620 --> 00:55:47,980
what you mentioned earlier i saw them a

2120
00:55:47,980 --> 00:55:49,340
few years ago i worked

2121
00:55:49,340 --> 00:55:51,420
on on aspects of them a few years

2122
00:55:51,420 --> 00:55:54,060
ago and i didn't expect this trajectory to

2123
00:55:54,060 --> 00:55:55,320
be that the improvement to

2124
00:55:55,320 --> 00:55:57,193
be so steep like they're basically

2125
00:55:57,193 --> 00:55:58,460
indistinguishable right

2126
00:55:58,460 --> 00:55:59,490
now from reality and they can do

2127
00:55:59,490 --> 00:56:00,520
incredible

2128
00:56:00,520 --> 00:56:03,940
things um so that's been really really

2129
00:56:03,940 --> 00:56:04,840
impressive

2130
00:56:04,840 --> 00:56:07,520
and really surprising to me yeah i would

2131
00:56:07,520 --> 00:56:08,420
say i'm still

2132
00:56:08,420 --> 00:56:10,680
in awe to some extent that we've gotten

2133
00:56:10,680 --> 00:56:13,440
to this place where we do seem to

2134
00:56:13,440 --> 00:56:15,160
get models that do seem generally

2135
00:56:15,780 --> 00:56:17,290
intelligent to a level that i really

2136
00:56:17,290 --> 00:56:18,800
didn't

2137
00:56:18,800 --> 00:56:21,360
foresee coming out of uh out of just

2138
00:56:21,360 --> 00:56:22,260
next token prediction

2139
00:56:22,260 --> 00:56:24,300
i'm i'm still amazed with this and like

2140
00:56:24,300 --> 00:56:26,500
every little advance that i see you know

2141
00:56:26,500 --> 00:56:27,480
winning imo

2142
00:56:28,040 --> 00:56:29,970
math challenges or um you know applying

2143
00:56:29,970 --> 00:56:31,900
it's

2144
00:56:31,900 --> 00:56:35,240
to finding new stuff in science to me

2145
00:56:35,240 --> 00:56:36,260
yeah there are so

2146
00:56:36,260 --> 00:56:37,920
many things this year where i thought like

2147
00:56:37,920 --> 00:56:40,120
wow there's still there's still a lot of

2148
00:56:40,120 --> 00:56:41,180
progress to be made

2149
00:56:41,180 --> 00:56:42,700
even though it felt like at the beginning

2150
00:56:42,700 --> 00:56:44,660
of the year maybe this whole pre-training

2151
00:56:44,660 --> 00:56:45,660
business of llms

2152
00:56:45,660 --> 00:56:47,820
is kind of maybe uh petering out a

2153
00:56:47,820 --> 00:56:49,030
bit um yeah realizing that there's like

2154
00:56:49,030 --> 00:56:50,240
this

2155
00:56:50,240 --> 00:56:51,480
whole almost second

2156
00:56:51,480 --> 00:56:52,910
breath of uh yeah fresh air basically

2157
00:56:52,910 --> 00:56:54,340
coming

2158
00:56:54,340 --> 00:56:55,940
in yeah i would maybe add to this

2159
00:56:55,940 --> 00:56:56,760
just like the fact

2160
00:56:56,760 --> 00:56:58,660
that this whole thing works it's kind of

2161
00:56:58,660 --> 00:57:01,780
mind-blowing yeah i don't think we like

2162
00:57:01,780 --> 00:57:02,860
fully realize how

2163
00:57:02,860 --> 00:57:04,200
ridiculous this is right like you you

2164
00:57:04,200 --> 00:57:05,540
build

2165
00:57:05,540 --> 00:57:07,810
this like loosely brain inspired thing

2166
00:57:07,810 --> 00:57:10,080
that has

2167
00:57:10,080 --> 00:57:10,680
very general

2168
00:57:10,680 --> 00:57:12,120
purpose learning algorithm you feed it

2169
00:57:12,120 --> 00:57:13,560
data and

2170
00:57:13,560 --> 00:57:15,560
it somehow gets it and gets it way

2171
00:57:15,560 --> 00:57:15,960
better than

2172
00:57:15,960 --> 00:57:17,160
anything we've ever had before and this

2173
00:57:17,160 --> 00:57:18,360
applies

2174
00:57:18,360 --> 00:57:20,300
to robots and it applies to vision and

2175
00:57:20,300 --> 00:57:21,160
language and

2176
00:57:21,160 --> 00:57:24,040
sound and all kinds of other things and

2177
00:57:24,040 --> 00:57:26,260
like i think if you stop for a

2178
00:57:26,260 --> 00:57:27,760
second and just think about

2179
00:57:27,760 --> 00:57:30,500
it how it works and and that it

2180
00:57:30,500 --> 00:57:32,231
works it's just like absolutely

2181
00:57:32,231 --> 00:57:33,180
mind-blowing like

2182
00:57:33,180 --> 00:57:33,920
the fact that we can

2183
00:57:33,920 --> 00:57:35,320
have robots you can put it in a

2184
00:57:35,320 --> 00:57:37,060
home and it kind of knows what to

2185
00:57:37,060 --> 00:57:38,920
do in a home that it's never been

2186
00:57:38,920 --> 00:57:39,060
to

2187
00:57:39,060 --> 00:57:41,800
before or it can make coffee for 13

2188
00:57:41,800 --> 00:57:42,800
hours straight or you know things like

2189
00:57:42,800 --> 00:57:43,800
that

2190
00:57:43,800 --> 00:57:45,020
and this is from this

2191
00:57:45,020 --> 00:57:48,755
very general purpose thing that that

2192
00:57:48,755 --> 00:57:50,000
trains fully

2193
00:57:50,000 --> 00:57:51,840
end to end that we don't fully understand

2194
00:57:51,840 --> 00:57:52,640
but it

2195
00:57:52,640 --> 00:57:55,100
seems to start to get it that to

2196
00:57:55,100 --> 00:57:57,820
me is just mind-blowing we're in a

2197
00:57:57,820 --> 00:57:58,280
simulation

2198
00:58:00,540 --> 00:58:01,900
it's what that's what sonja believes that

2199
00:58:01,900 --> 00:58:03,260
we're

2200
00:58:03,260 --> 00:58:04,290
living in a simulation but it is

2201
00:58:04,290 --> 00:58:05,320
interesting

2202
00:58:05,320 --> 00:58:05,680
right like

2203
00:58:05,680 --> 00:58:07,160
science they teach you to take a big

2204
00:58:07,160 --> 00:58:08,920
problem and break it up into smaller and

2205
00:58:08,920 --> 00:58:09,820
smaller problems and

2206
00:58:09,820 --> 00:58:11,677
then basically somebody realizes that

2207
00:58:11,677 --> 00:58:12,480
that's maybe not

2208
00:58:12,480 --> 00:58:16,480
the best way to train machines or robots

2209
00:58:16,480 --> 00:58:17,020
of any

2210
00:58:17,020 --> 00:58:18,820
kind and to be honest the whole machine

2211
00:58:18,820 --> 00:58:19,910
learning like ai field made that same

2212
00:58:19,910 --> 00:58:21,000
mistake

2213
00:58:21,000 --> 00:58:21,520
actually to

2214
00:58:21,520 --> 00:58:23,520
some extent right we were working for a

2215
00:58:23,520 --> 00:58:24,650
long time people were working on solving

2216
00:58:24,650 --> 00:58:25,780
individual

2217
00:58:25,780 --> 00:58:26,480
problems

2218
00:58:26,480 --> 00:58:27,800
very deeply basically right and then over

2219
00:58:27,800 --> 00:58:29,120
time

2220
00:58:29,120 --> 00:58:32,140
there is this like notion of oh if

2221
00:58:32,140 --> 00:58:32,780
we can put it all

2222
00:58:32,780 --> 00:58:33,660
together and like do multitask learning if

2223
00:58:33,660 --> 00:58:34,540
we

2224
00:58:34,540 --> 00:58:36,260
could do that really really well we'd do

2225
00:58:36,260 --> 00:58:36,680
much better

2226
00:58:37,180 --> 00:58:39,020
and then but then the fact that that

2227
00:58:39,020 --> 00:58:40,300
all happened just because we switched to

2228
00:58:40,300 --> 00:58:41,580
this

2229
00:58:41,580 --> 00:58:43,260
you know general

2230
00:58:43,260 --> 00:58:44,100
pre-training objective and then it just

2231
00:58:44,100 --> 00:58:44,940
all

2232
00:58:44,940 --> 00:58:46,840
falls out that's the part that is the

2233
00:58:46,840 --> 00:58:47,640
surprising bit right

2234
00:58:47,640 --> 00:58:49,720
do you think it's like an accordion where

2235
00:58:49,720 --> 00:58:51,300
we go from one framework to the other

2236
00:58:51,300 --> 00:58:52,200
framework we take

2237
00:58:52,200 --> 00:58:53,920
big problems break them up into small and

2238
00:58:53,920 --> 00:58:55,580
what small and small small ones that work

2239
00:58:55,580 --> 00:58:56,400
for a period of time

2240
00:58:56,400 --> 00:58:57,270
then it stopped working and then we're

2241
00:58:57,270 --> 00:58:58,140
like

2242
00:58:58,140 --> 00:58:59,220
all right let's go back to the big

2243
00:58:59,220 --> 00:59:00,400
problem and try to solve it more

2244
00:59:00,400 --> 00:59:02,680
generally you can go back and forth i

2245
00:59:02,680 --> 00:59:04,880
don't see us going back yeah i don't

2246
00:59:04,880 --> 00:59:05,900
see us going back i think

2247
00:59:05,900 --> 00:59:08,400
there's a lot of approaches or a lot

2248
00:59:08,400 --> 00:59:09,720
of people saying that you know you need

2249
00:59:09,720 --> 00:59:11,020
the best of both worlds and

2250
00:59:11,020 --> 00:59:12,660
you need some kind of way of incorporating

2251
00:59:12,660 --> 00:59:14,660
the rules that you already know about like

2252
00:59:14,660 --> 00:59:15,080
you know

2253
00:59:15,080 --> 00:59:16,150
newtonian physics you don't need to learn

2254
00:59:16,150 --> 00:59:17,220
that

2255
00:59:17,220 --> 00:59:18,980
we already know how it works so can

2256
00:59:18,980 --> 00:59:19,920
you just like put

2257
00:59:19,920 --> 00:59:23,100
it somehow into the weights but uh from

2258
00:59:23,100 --> 00:59:25,300
what we've seen so far it doesn't work

2259
00:59:25,300 --> 00:59:26,680
if you try to do this you

2260
00:59:26,680 --> 00:59:28,380
kind of limit the ability to to learn

2261
00:59:28,380 --> 00:59:31,680
new things and i don't think there's the

2262
00:59:31,680 --> 00:59:32,520
best of both worlds

2263
00:59:32,520 --> 00:59:33,920
i think we just go all the way

2264
00:59:33,920 --> 00:59:35,180
learning and it's kind of interesting to

2265
00:59:35,180 --> 00:59:36,440
you

2266
00:59:36,440 --> 00:59:37,860
know how similarly to how

2267
00:59:37,860 --> 00:59:40,480
we learn you would think that if there

2268
00:59:40,480 --> 00:59:41,880
was a way to pre-bake all of

2269
00:59:41,880 --> 00:59:43,220
the intelligence the evolution

2270
00:59:43,220 --> 00:59:44,660
would have figured this out you would have

2271
00:59:44,660 --> 00:59:45,750
just been born you know knowing everything

2272
00:59:45,750 --> 00:59:46,840
there

2273
00:59:46,840 --> 00:59:47,100
is to

2274
00:59:47,100 --> 00:59:49,220
know and we see this with some other

2275
00:59:49,220 --> 00:59:52,180
species right like i think deer when they

2276
00:59:52,180 --> 00:59:53,120
when they get born

2277
00:59:53,120 --> 00:59:53,920
they're basically like as smart as they

2278
00:59:53,920 --> 00:59:54,560
will

2279
00:59:54,560 --> 00:59:56,760
ever be like they don't really learn much

2280
00:59:56,760 --> 00:59:57,040
throughout

2281
00:59:57,040 --> 00:59:58,850
their lifetime but for intelligent species

2282
00:59:58,850 --> 01:00:00,660
like like

2283
01:00:00,660 --> 01:00:01,740
humans but also i think crowds for

2284
01:00:01,740 --> 01:00:02,820
instance

2285
01:00:03,420 --> 01:00:05,344
they have these childhood periods the

2286
01:00:05,344 --> 01:00:06,280
adolescence period

2287
01:00:06,280 --> 01:00:09,580
where they're not very smart to begin with

2288
01:00:09,580 --> 01:00:11,220
but they have to learn from their own

2289
01:00:11,220 --> 01:00:12,540
experience and it doesn't come pre-baked

2290
01:00:12,540 --> 01:00:13,860
you

2291
01:00:13,860 --> 01:00:14,400
kind of have to

2292
01:00:14,400 --> 01:00:17,960
earn it on your own and um i

2293
01:00:17,960 --> 01:00:19,310
think there is something something to that

2294
01:00:19,310 --> 01:00:20,660
um

2295
01:00:20,660 --> 01:00:22,140
you need to just experience

2296
01:00:22,140 --> 01:00:24,520
the world and and learn from that and

2297
01:00:24,520 --> 01:00:25,390
i think that's the lesson we're learning

2298
01:00:25,390 --> 01:00:26,260
in

2299
01:00:26,260 --> 01:00:26,960
in machine

2300
01:00:26,960 --> 01:00:30,120
learning as well in ai that you know

2301
01:00:30,120 --> 01:00:32,100
we we think we know how we think

2302
01:00:32,100 --> 01:00:33,180
but we actually don't

2303
01:00:33,760 --> 01:00:36,440
and we just need to let the algorithm

2304
01:00:36,440 --> 01:00:38,620
learn it from data same thing with raising

2305
01:00:38,620 --> 01:00:39,980
our child i think

2306
01:00:39,980 --> 01:00:41,700
i know how my son is thinking but

2307
01:00:41,700 --> 01:00:44,500
i don't yeah yeah i have a i

2308
01:00:44,500 --> 01:00:46,920
have a small daughter and yeah it's

2309
01:00:46,920 --> 01:00:49,680
just so surprising like they learn so fast

2310
01:00:49,680 --> 01:00:51,020
they learn so fast and you don't know

2311
01:00:51,020 --> 01:00:51,760
where they get it from

2312
01:00:52,760 --> 01:00:55,517
hopefully from the parents hopefully she

2313
01:00:55,517 --> 01:00:56,620
definitely knows

2314
01:00:56,620 --> 01:00:57,820
some things that i didn't teach her

2315
01:00:58,980 --> 01:01:00,900
thank you guys so much it's a really

2316
01:01:00,900 --> 01:01:01,980
beautiful mission you're building after

2317
01:01:01,980 --> 01:01:03,060
thank you for

2318
01:01:03,060 --> 01:01:03,320
coming

2319
01:01:03,320 --> 01:01:05,380
to share thank you thanks for having us

2320
01:01:05,380 --> 01:01:05,820
thank you

2321
01:01:05,820 --> 01:01:35,800
thanks for having us

2322
01:01:35,800 --> 01:01:36,020
thank you

2323
01:01:36,020 --> 01:01:36,100
You
