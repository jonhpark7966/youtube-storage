1
00:00:04,880 --> 00:00:08,160
So, without further delay, let's get started. Today,

2
00:00:08,220 --> 00:00:10,560
I'm gonna talk about my work on robot

3
00:00:10,560 --> 00:00:13,720
motion learning with physics-based PDE priors.

4
00:00:15,600 --> 00:00:18,360
So, first, let me introduce, like, what is

5
00:00:18,360 --> 00:00:21,400
the problem of motion planning? And motion planning

6
00:00:21,400 --> 00:00:23,760
is a way for an agent to coordinate

7
00:00:23,760 --> 00:00:26,320
its behavior from a given start to a

8
00:00:26,320 --> 00:00:28,820
given goal while satisfying all the desired constraints.

9
00:00:28,820 --> 00:00:32,740
So, whenever a dynamical system or a robot

10
00:00:32,740 --> 00:00:35,440
needs to move, they need to solve this

11
00:00:35,440 --> 00:00:37,700
motion planning problem, okay?

12
00:00:38,080 --> 00:00:40,340
And it has application, or these are the

13
00:00:40,340 --> 00:00:42,840
applications that my lab focus on, like, ranging

14
00:00:42,840 --> 00:00:45,180
from full-body motion planning.

15
00:00:45,400 --> 00:00:48,500
Here, there is a mobile robot, mobile regular

16
00:00:48,500 --> 00:00:51,000
robot. It is moving an object from a

17
00:00:51,000 --> 00:00:52,560
given start to a given goal.

18
00:00:52,560 --> 00:00:55,840
Then, we also solve this problem in dynamic

19
00:00:55,840 --> 00:00:59,600
environment where we dynamically place an obstacle in

20
00:00:59,600 --> 00:01:00,560
front of the robot.

21
00:01:01,000 --> 00:01:04,240
Another area that we are very excited, interested

22
00:01:04,240 --> 00:01:06,380
in, is in reactive manipulation.

23
00:01:06,620 --> 00:01:09,260
While a robot is solving manipulation planning problems

24
00:01:09,260 --> 00:01:12,000
under constraint, they may experience some disturbances.

25
00:01:12,000 --> 00:01:15,920
How robots dynamically adapt to those disturbances and

26
00:01:15,920 --> 00:01:17,760
continue to solve the assigned task?

27
00:01:19,840 --> 00:01:22,540
Lastly, we are also exploring,

28
00:01:22,560 --> 00:01:26,340
applying these motion planning tools to reactive multi

29
00:01:26,340 --> 00:01:28,300
-agent planning, where you have large number of

30
00:01:28,300 --> 00:01:28,700
agents,

31
00:01:28,720 --> 00:01:31,940
they are performing their assigned task, and then

32
00:01:31,940 --> 00:01:34,840
they will have to reactively avoid cooling with

33
00:01:34,840 --> 00:01:35,280
each other.

34
00:01:35,980 --> 00:01:40,620
So, spreading across all these problems, the core

35
00:01:40,620 --> 00:01:43,460
issue is how to solve these motion planning

36
00:01:43,460 --> 00:01:43,780
problems,

37
00:01:43,880 --> 00:01:45,840
how to come up with tools that are

38
00:01:45,840 --> 00:01:51,040
efficient, and the focus my lab has is

39
00:01:51,040 --> 00:01:53,820
on, like, developing these tools that are real

40
00:01:53,820 --> 00:01:54,120
-time,

41
00:01:54,120 --> 00:01:57,420
that enable real-time coordination of robot movement

42
00:01:57,420 --> 00:02:01,200
in unstructured constrained environments with minimal pre-training

43
00:02:01,200 --> 00:02:02,000
or trial and error.

44
00:02:02,460 --> 00:02:05,680
I have been trying to solve or achieve

45
00:02:05,680 --> 00:02:07,280
this objective for quite some time.

46
00:02:07,520 --> 00:02:10,220
During my undergrad, I started with a sampling

47
00:02:10,220 --> 00:02:13,620
-based motion planning method, and my focus was

48
00:02:13,620 --> 00:02:16,140
on coming up with adaptive sampling techniques,

49
00:02:16,140 --> 00:02:18,960
so that these sampling-based methods can construct

50
00:02:18,960 --> 00:02:20,700
their tree as quickly as possible.

51
00:02:20,700 --> 00:02:22,800
Then one branch of that tree is your

52
00:02:22,800 --> 00:02:24,560
path solution from your start and goal.

53
00:02:25,320 --> 00:02:29,420
And then, during my PhD, I moved toward

54
00:02:29,420 --> 00:02:33,220
extending these methods to data-driven approaches.

55
00:02:33,460 --> 00:02:36,140
So, the issue with a classical sampling-based

56
00:02:36,140 --> 00:02:39,160
techniques were they were computationally very slow.

57
00:02:39,320 --> 00:02:41,680
As the robot dimension increases, like, let's say

58
00:02:41,680 --> 00:02:44,560
you are planning, uh, motion for a human

59
00:02:44,560 --> 00:02:45,000
-art robot,

60
00:02:45,160 --> 00:02:46,880
it's a huge degree of freedom.

61
00:02:46,880 --> 00:02:49,720
For those kind of systems, their computation time

62
00:02:49,720 --> 00:02:50,940
became very slow.

63
00:02:51,040 --> 00:02:53,460
So, we could not do many real-time

64
00:02:53,460 --> 00:02:56,600
applications because of the slow computational speed of

65
00:02:56,600 --> 00:02:57,060
those methods.

66
00:02:57,180 --> 00:03:00,560
Then I moved toward data-driven approaches.

67
00:03:02,020 --> 00:03:05,120
In, in 2018 or 19, before that, many

68
00:03:05,120 --> 00:03:07,340
people were trying to solve motion-turning problems

69
00:03:07,340 --> 00:03:08,940
with these, uh, neural networks,

70
00:03:08,980 --> 00:03:12,000
but they were missing one key piece.

71
00:03:12,000 --> 00:03:14,300
And in this, these papers, I gave the

72
00:03:14,300 --> 00:03:18,080
recipe that just having neural network is not

73
00:03:18,080 --> 00:03:18,540
sufficient.

74
00:03:18,540 --> 00:03:21,240
Like, you can do imitation learning, and still

75
00:03:21,240 --> 00:03:21,940
it won't learn.

76
00:03:22,100 --> 00:03:24,720
You need stochasticity in these models.

77
00:03:24,780 --> 00:03:27,600
And you can incorporate stochasticity in different ways.

78
00:03:27,900 --> 00:03:29,920
In our work, we used dropout.

79
00:03:30,360 --> 00:03:33,220
Then people moved, took up that idea, moved

80
00:03:33,220 --> 00:03:35,000
toward using variational autoencoder.

81
00:03:35,060 --> 00:03:36,800
Now you use the diffusion model.

82
00:03:36,980 --> 00:03:38,960
They, they have some sort of stochasticity.

83
00:03:38,960 --> 00:03:42,120
They start with some noise and then denoise

84
00:03:42,120 --> 00:03:42,760
it over time.

85
00:03:42,920 --> 00:03:45,820
So there is some sort of randomness incorporated

86
00:03:45,820 --> 00:03:48,940
into the process that helps these models plan

87
00:03:48,940 --> 00:03:49,980
motion.

88
00:03:50,340 --> 00:03:53,100
So the core recipe is, you need neural

89
00:03:53,100 --> 00:03:53,440
network.

90
00:03:53,620 --> 00:03:55,820
Then you also need some sort of, uh,

91
00:03:56,000 --> 00:03:58,780
stochasticity in the process so that, uh,

92
00:03:59,260 --> 00:04:01,860
because the neural network, they are approximating the

93
00:04:01,860 --> 00:04:03,980
solution, they can get stuck into local minima.

94
00:04:03,980 --> 00:04:06,820
There's a denoising process or starting with some

95
00:04:06,820 --> 00:04:08,700
multiple, uh, seeds.

96
00:04:09,000 --> 00:04:11,580
You basically help these neural network come out

97
00:04:11,580 --> 00:04:12,780
of those local minimas.

98
00:04:12,980 --> 00:04:13,520
Okay?

99
00:04:13,920 --> 00:04:16,720
But my main issue with these models were,

100
00:04:16,900 --> 00:04:20,120
like, the training cost.

101
00:04:20,400 --> 00:04:23,260
So offline, you, we had to run these

102
00:04:23,260 --> 00:04:25,480
classical methods to gather all the data.

103
00:04:25,480 --> 00:04:28,560
And then you were training these models on

104
00:04:28,560 --> 00:04:29,460
that data.

105
00:04:29,700 --> 00:04:32,080
And yes, during inference, it was giving fast

106
00:04:32,080 --> 00:04:32,440
inference.

107
00:04:33,160 --> 00:04:35,660
But if we think about it, were they

108
00:04:35,660 --> 00:04:39,180
really solving, like, uh, overcoming these, uh,

109
00:04:39,560 --> 00:04:42,480
slow computational, uh, speed of these methods?

110
00:04:42,580 --> 00:04:44,520
Like, because if you add the training time

111
00:04:44,520 --> 00:04:47,160
or time spent on getting the data

112
00:04:47,160 --> 00:04:48,980
and then combine it with inference time, you

113
00:04:48,980 --> 00:04:51,120
may think that it's not really beneficial.

114
00:04:51,120 --> 00:04:53,680
So when I started as a faculty at

115
00:04:53,680 --> 00:04:56,360
Purdue, I started looking at some other ways

116
00:04:56,360 --> 00:04:59,920
to train these neural networks without expert demonstration.

117
00:05:00,820 --> 00:05:03,460
And there are three features that my lab

118
00:05:03,460 --> 00:05:04,060
focus on.

119
00:05:04,240 --> 00:05:05,600
Like, one is inference efficiency.

120
00:05:05,880 --> 00:05:08,240
I want to develop methods that allow immediate

121
00:05:08,240 --> 00:05:10,760
execution, the infer plans as quickly as possible.

122
00:05:11,620 --> 00:05:13,900
Then second feature that we look for is

123
00:05:13,900 --> 00:05:14,680
training efficiency.

124
00:05:14,680 --> 00:05:17,700
We want to reduce model training cost.

125
00:05:17,840 --> 00:05:20,080
We want to eliminate expert, need for expert

126
00:05:20,080 --> 00:05:20,820
annotation.

127
00:05:21,440 --> 00:05:23,560
And this is cellular transferability.

128
00:05:23,820 --> 00:05:26,940
Like, right now, if you, whenever you talk

129
00:05:26,940 --> 00:05:28,700
to someone who is doing imitation learning

130
00:05:28,700 --> 00:05:30,560
or training very large models, the second question

131
00:05:30,560 --> 00:05:30,980
come up,

132
00:05:31,280 --> 00:05:33,820
can they transfer to a different environment or

133
00:05:33,820 --> 00:05:34,660
unseen environment?

134
00:05:34,720 --> 00:05:36,840
Because the issue is, when you move to

135
00:05:36,840 --> 00:05:37,800
a different environment,

136
00:05:37,800 --> 00:05:40,120
you may need to re-gather all the

137
00:05:40,120 --> 00:05:40,380
data.

138
00:05:40,380 --> 00:05:43,240
But if you have a model that, whose

139
00:05:43,240 --> 00:05:44,440
training cost is very low,

140
00:05:44,620 --> 00:05:47,340
and that eliminates needs for expert demonstration,

141
00:05:47,740 --> 00:05:50,060
then you can transfer that model very easily

142
00:05:50,060 --> 00:05:51,720
to, to a new domain.

143
00:05:52,740 --> 00:05:54,540
Third feature, which is very important.

144
00:05:54,740 --> 00:05:56,400
Like, we want to design these models so

145
00:05:56,400 --> 00:05:59,160
that they adapt to high degree of freedom,

146
00:05:59,340 --> 00:06:03,020
very complex brains, unknown environment, or, uh, very

147
00:06:03,020 --> 00:06:03,860
complex constraint,

148
00:06:03,900 --> 00:06:06,580
like involved in, uh, manipulation problem.

149
00:06:06,580 --> 00:06:08,940
And they should also scale to large number

150
00:06:08,940 --> 00:06:10,800
of agents so that we can deploy multiple

151
00:06:10,800 --> 00:06:11,860
robots operating in,

152
00:06:11,860 --> 00:06:13,660
uh, in a given environment.

153
00:06:13,800 --> 00:06:15,740
And then they can solve some task in

154
00:06:15,740 --> 00:06:19,000
a coordination or, or in a decentralization.

155
00:06:20,700 --> 00:06:23,640
So just to give a overview, like, where

156
00:06:23,640 --> 00:06:25,520
we stand in terms of these features.

157
00:06:25,880 --> 00:06:28,320
So we have optimization-based techniques.

158
00:06:29,300 --> 00:06:33,700
And these techniques, they have high inference efficiency.

159
00:06:33,920 --> 00:06:36,220
We have very nice optimization-based tools that

160
00:06:36,220 --> 00:06:39,520
can find a trajectory, uh, very efficiently.

161
00:06:39,520 --> 00:06:42,480
They have very high, uh, training efficiency.

162
00:06:42,480 --> 00:06:44,800
You don't need to re-, pre-train your

163
00:06:44,800 --> 00:06:45,500
optimizer.

164
00:06:45,700 --> 00:06:48,200
But they do not adapt to very complex

165
00:06:48,200 --> 00:06:48,480
scenarios.

166
00:06:48,600 --> 00:06:51,180
They are prone to, uh, local minima, and

167
00:06:51,180 --> 00:06:52,460
they can often get stuck there.

168
00:06:52,460 --> 00:06:56,600
Then we have, like, a classical, uh, tools

169
00:06:56,600 --> 00:06:59,040
for solving robot planning and control problem.

170
00:06:59,240 --> 00:07:02,820
We have, like, um, uh, discretization-based approaches.

171
00:07:03,000 --> 00:07:04,560
You may know ASTART. You should.

172
00:07:04,720 --> 00:07:07,280
And then there are sampling-based approaches.

173
00:07:07,580 --> 00:07:10,380
There are other classical tools within control, like

174
00:07:10,380 --> 00:07:13,240
random shooting method and, uh, techniques like that.

175
00:07:13,240 --> 00:07:18,580
These methods, they have low training efficiency, uh,

176
00:07:18,780 --> 00:07:20,460
high training efficiency.

177
00:07:20,640 --> 00:07:21,940
You do not need to train them.

178
00:07:22,440 --> 00:07:24,800
But their inference efficiency is very slow.

179
00:07:25,060 --> 00:07:27,960
Because these methods, they need to either discretize

180
00:07:27,960 --> 00:07:30,080
your entire space or construct a graph.

181
00:07:30,220 --> 00:07:32,440
And then, uh, find a path through that.

182
00:07:32,880 --> 00:07:35,740
Recent advancement, I, I should acknowledge that people

183
00:07:35,740 --> 00:07:37,980
are exploring, like, how can we use massive

184
00:07:37,980 --> 00:07:41,000
parallelization within these methods to speed up their

185
00:07:41,000 --> 00:07:41,460
performance.

186
00:07:41,460 --> 00:07:43,580
But it is, we still have to see

187
00:07:43,580 --> 00:07:47,780
how these methods care to complex, uh, kinematic

188
00:07:47,780 --> 00:07:48,240
constraints.

189
00:07:49,220 --> 00:07:51,780
Then we have data-driven approaches, like imitation

190
00:07:51,780 --> 00:07:53,900
learning or enforcement learning.

191
00:07:54,200 --> 00:07:56,600
We know they have, like, uh, very low

192
00:07:56,600 --> 00:07:57,840
training efficiency.

193
00:07:58,160 --> 00:08:01,000
But once trained, their inference efficiency is very

194
00:08:01,000 --> 00:08:01,260
high.

195
00:08:01,380 --> 00:08:04,000
And they also adapt to very complex scenarios.

196
00:08:04,440 --> 00:08:07,360
But can we have a method, like, I

197
00:08:07,360 --> 00:08:09,440
have mentioned all these three categories.

198
00:08:09,440 --> 00:08:13,260
They were missing either one or more of

199
00:08:13,260 --> 00:08:13,860
those features.

200
00:08:15,000 --> 00:08:17,800
Optimization-based, they could not adapt to complexity.

201
00:08:18,040 --> 00:08:20,840
Sampling or classical method, they had, like, uh,

202
00:08:21,120 --> 00:08:22,860
low, uh, inference efficiency.

203
00:08:23,060 --> 00:08:24,620
And then data-driven, they have, like, very

204
00:08:24,620 --> 00:08:25,860
low training efficiency.

205
00:08:25,960 --> 00:08:28,140
Can we have method that have all these

206
00:08:28,140 --> 00:08:28,780
three features?

207
00:08:29,320 --> 00:08:30,760
So our answer is yes.

208
00:08:30,760 --> 00:08:34,540
Like, if you incorporate some, uh, priors that

209
00:08:34,540 --> 00:08:36,880
are available to us from physics, you can

210
00:08:36,880 --> 00:08:38,640
achieve all these three features.

211
00:08:38,640 --> 00:08:41,000
And that will be the focus of my,

212
00:08:41,000 --> 00:08:42,820
uh, rest of this talk.

213
00:08:43,160 --> 00:08:45,900
So, one question that come up, like, when

214
00:08:45,900 --> 00:08:47,940
I say we use physics priors.

215
00:08:48,060 --> 00:08:49,720
Like, what physics priors do you use?

216
00:08:50,500 --> 00:08:50,980
Okay?

217
00:08:51,340 --> 00:08:53,840
Often people confuse this physics prior with a

218
00:08:53,840 --> 00:08:55,620
physics engine or a simulator.

219
00:08:55,620 --> 00:08:58,800
But here, in my talk, I specified very

220
00:08:58,800 --> 00:09:00,600
clearly, like, we use PDE priors.

221
00:09:00,600 --> 00:09:02,840
Because I was getting this question again and

222
00:09:02,840 --> 00:09:03,040
again.

223
00:09:03,140 --> 00:09:04,520
But where is the simulation here?

224
00:09:04,660 --> 00:09:06,240
So it's not a physics simulation.

225
00:09:06,240 --> 00:09:09,060
It's a PDE that we use as a

226
00:09:09,060 --> 00:09:09,260
prior.

227
00:09:09,600 --> 00:09:12,360
So when we discuss PDE, one PDE that

228
00:09:12,360 --> 00:09:15,040
is, you may have heard, is, uh, H

229
00:09:15,040 --> 00:09:15,740
-J-B PDE.

230
00:09:16,020 --> 00:09:18,160
Hamiltonian Jacobi Bellman equation.

231
00:09:18,540 --> 00:09:21,180
And it governs the motion of some dynamical

232
00:09:21,180 --> 00:09:21,520
systems.

233
00:09:21,800 --> 00:09:23,700
But that PDE is very hard to solve.

234
00:09:23,700 --> 00:09:26,940
It has, like, singularities and multimodal problems.

235
00:09:27,000 --> 00:09:29,920
And then when you apply both kinematic and

236
00:09:29,920 --> 00:09:33,100
dynamical constraints, it becomes very, uh, difficult to

237
00:09:33,100 --> 00:09:33,280
solve.

238
00:09:33,560 --> 00:09:35,920
Then we analyzed that equation and we said,

239
00:09:35,940 --> 00:09:38,520
if you assume trivial dynamics,

240
00:09:38,800 --> 00:09:42,340
that equation boils down to this econel PDE.

241
00:09:42,340 --> 00:09:46,100
So this econel PDE has two functions.

242
00:09:46,580 --> 00:09:48,020
One is this T.

243
00:09:48,340 --> 00:09:49,940
And other is that S.

244
00:09:50,760 --> 00:09:52,740
So T is an unknown function.

245
00:09:52,940 --> 00:09:54,660
And it is a value function.

246
00:09:54,660 --> 00:09:56,760
We want to solve this PDE to find

247
00:09:56,760 --> 00:09:57,980
this unknown function T.

248
00:09:58,700 --> 00:10:00,260
S is a known function.

249
00:10:00,480 --> 00:10:03,180
And it is basically, it defines your constraints.

250
00:10:03,400 --> 00:10:05,740
So it could be distance to obstacles.

251
00:10:06,060 --> 00:10:08,820
So given the configuration of the robot, let's

252
00:10:08,820 --> 00:10:09,440
say QS.

253
00:10:09,440 --> 00:10:12,220
This S will tell me how far my

254
00:10:12,220 --> 00:10:15,060
robot is from the nearest obstacle.

255
00:10:15,500 --> 00:10:16,360
Is that clear?

256
00:10:16,860 --> 00:10:18,960
Or I can even change that constraint to

257
00:10:18,960 --> 00:10:19,500
something else.

258
00:10:19,660 --> 00:10:22,220
Like, instead of having a distance to obstacle,

259
00:10:22,300 --> 00:10:24,380
it could be distance to nearest manifold.

260
00:10:24,920 --> 00:10:25,460
Okay?

261
00:10:25,820 --> 00:10:27,840
It could be manipulation manifold or something.

262
00:10:28,080 --> 00:10:29,740
So this S function is known.

263
00:10:30,080 --> 00:10:32,320
I want to solve this PDE to find

264
00:10:32,320 --> 00:10:34,840
this T, which is a value function.

265
00:10:34,840 --> 00:10:37,500
And once you solve this equation, it gives

266
00:10:37,500 --> 00:10:41,700
you these wave fronts using which robot can

267
00:10:41,700 --> 00:10:43,540
navigate from one point to another.

268
00:10:43,800 --> 00:10:46,460
So given the source point, you solve this,

269
00:10:46,460 --> 00:10:49,120
uh, PDE, it gives you this travel time

270
00:10:49,120 --> 00:10:51,540
function, which is this T.

271
00:10:51,880 --> 00:10:53,880
This travel time function is also a value

272
00:10:53,880 --> 00:10:54,200
function.

273
00:10:54,400 --> 00:10:56,500
So just following the gradient of this T,

274
00:10:56,640 --> 00:10:59,280
you can navigate to any point in the

275
00:10:59,280 --> 00:10:59,980
environment.

276
00:10:59,980 --> 00:11:03,640
So numerically, there is a method called FFM,

277
00:11:03,720 --> 00:11:04,800
fast marching method.

278
00:11:04,940 --> 00:11:07,560
It solves this PDE, but it's a numerical

279
00:11:07,560 --> 00:11:08,020
approach.

280
00:11:08,120 --> 00:11:10,340
It cannot scale beyond three dimensions.

281
00:11:10,380 --> 00:11:12,660
So when, uh, we started this PDE, we,

282
00:11:12,720 --> 00:11:15,340
our main interest was, can we scale it

283
00:11:15,340 --> 00:11:18,740
beyond three dimensions to actual complex robot systems?

284
00:11:20,040 --> 00:11:22,780
So neural network gave us, like, uh, a

285
00:11:22,780 --> 00:11:24,900
possible way, like we can, instead of using

286
00:11:24,900 --> 00:11:27,400
numerical solver, we can use neural network to

287
00:11:27,400 --> 00:11:29,800
solve this PDE in high dimension.

288
00:11:30,160 --> 00:11:33,120
So the first work that we did, you

289
00:11:33,120 --> 00:11:36,540
have this neural network that tries to solve

290
00:11:36,540 --> 00:11:38,040
this Econel PDE.

291
00:11:38,040 --> 00:11:40,700
So the input to this neural network, so

292
00:11:40,700 --> 00:11:43,200
this neural network is a black box, but

293
00:11:43,200 --> 00:11:45,480
we put structure into this neural network that

294
00:11:45,480 --> 00:11:48,820
respect the properties of, uh, this PDE.

295
00:11:48,880 --> 00:11:50,740
I will briefly discuss that, but if you

296
00:11:50,740 --> 00:11:53,480
are interested, check out the paper in order

297
00:11:53,480 --> 00:11:55,300
to understand the structure of this neural network.

298
00:11:55,380 --> 00:11:57,420
But for simplicity, I will assume it's a

299
00:11:57,420 --> 00:12:01,340
simple black box neural network that take robot

300
00:12:01,340 --> 00:12:05,600
start, QS, robot goal, QG, and environment perception

301
00:12:05,600 --> 00:12:06,300
as an input.

302
00:12:06,300 --> 00:12:09,080
The output is this travel time function.

303
00:12:09,600 --> 00:12:11,280
So this is an unknown function.

304
00:12:11,320 --> 00:12:13,280
So I want to train this neural network

305
00:12:13,280 --> 00:12:15,840
to solve this PDE so that once trained,

306
00:12:16,000 --> 00:12:19,220
I have this accurate or approximately accurate travel

307
00:12:19,220 --> 00:12:19,780
time function.

308
00:12:20,120 --> 00:12:23,500
Now, the way we train this model is

309
00:12:23,500 --> 00:12:26,860
you give this input and it, uh, predict

310
00:12:26,860 --> 00:12:27,680
this travel time.

311
00:12:27,680 --> 00:12:30,920
Then Econel PDE says if you take the

312
00:12:30,920 --> 00:12:33,700
gradient of this travel time with respect to

313
00:12:33,700 --> 00:12:37,060
input, QS in this case, this is equal

314
00:12:37,060 --> 00:12:38,860
to inverse of your constraint function.

315
00:12:39,440 --> 00:12:41,860
So this PDE is giving us some structure.

316
00:12:42,380 --> 00:12:44,340
So the training become very simple.

317
00:12:44,580 --> 00:12:47,320
So you, you sample a bunch of robot

318
00:12:47,320 --> 00:12:48,600
start and goal configurations.

319
00:12:48,600 --> 00:12:50,600
You have environment perception.

320
00:12:50,880 --> 00:12:51,460
You have environment perception.

321
00:12:51,460 --> 00:12:52,980
For each of these pairs, they go through

322
00:12:52,980 --> 00:12:53,600
neural network.

323
00:12:53,780 --> 00:12:55,020
You predict their travel time.

324
00:12:55,220 --> 00:12:59,700
Then you backprop to compute this approximated constraint

325
00:12:59,700 --> 00:13:02,120
function according to your Econel PDE.

326
00:13:02,320 --> 00:13:03,280
Then you're locked.

327
00:13:03,420 --> 00:13:03,600
Yes?

328
00:13:04,920 --> 00:13:05,540
I have a question.

329
00:13:05,960 --> 00:13:07,920
So how, how do you encode the problem

330
00:13:07,920 --> 00:13:08,860
in your efficiency?

331
00:13:09,120 --> 00:13:13,440
Uh, is it using, uh, SQ or, uh?

332
00:13:14,020 --> 00:13:14,900
That's a good question.

333
00:13:15,080 --> 00:13:16,020
I, I will come to that.

334
00:13:16,140 --> 00:13:16,420
Okay.

335
00:13:16,580 --> 00:13:17,100
In a moment.

336
00:13:17,380 --> 00:13:20,120
So QS is, in this case, is, so

337
00:13:20,120 --> 00:13:22,640
the motion planning problem is defined by robot

338
00:13:22,640 --> 00:13:24,900
start, goal, and environment perception.

339
00:13:25,680 --> 00:13:26,120
Right?

340
00:13:26,280 --> 00:13:28,340
Standard motion planning problem, you give it to

341
00:13:28,340 --> 00:13:30,220
classical method or optimizer.

342
00:13:30,400 --> 00:13:32,240
It take the start and goal and your

343
00:13:32,240 --> 00:13:35,140
environment, like distance to obstacle or whatever observation

344
00:13:35,140 --> 00:13:35,920
you have available.

345
00:13:36,300 --> 00:13:36,800
Right?

346
00:13:37,020 --> 00:13:38,400
So that's defined the problem.

347
00:13:39,120 --> 00:13:41,560
And in this case, we are giving only

348
00:13:41,560 --> 00:13:42,500
this problem set.

349
00:13:42,500 --> 00:13:45,780
So QS and QG and environment perception goes

350
00:13:45,780 --> 00:13:47,420
through neural network and you predict this

351
00:13:47,420 --> 00:13:47,620
T.

352
00:13:48,160 --> 00:13:51,140
Then the way we train this loss, uh,

353
00:13:51,340 --> 00:13:53,800
this neural network is through gradient matching loss

354
00:13:53,800 --> 00:13:54,160
function.

355
00:13:54,440 --> 00:13:57,620
So we backprop, compute this gradient with respect

356
00:13:57,620 --> 00:13:58,400
to QS.

357
00:13:58,680 --> 00:14:01,580
And then Econel PDE says inverse of this

358
00:14:01,580 --> 00:14:05,820
gradient norm is basically your constraint function.

359
00:14:07,140 --> 00:14:07,780
Okay?

360
00:14:07,780 --> 00:14:11,020
So we approximate this constraint function and compare

361
00:14:11,020 --> 00:14:13,280
it with ground truth constraint function.

362
00:14:13,420 --> 00:14:15,440
Like your ground truth distance to obstacle.

363
00:14:16,500 --> 00:14:17,460
Is that clear?

364
00:14:17,620 --> 00:14:20,740
So the loss function is on the gradients

365
00:14:20,740 --> 00:14:21,520
of the neural network.

366
00:14:21,640 --> 00:14:23,380
It's not on the forward path and then

367
00:14:23,380 --> 00:14:25,760
you compute some output and then you define.

368
00:14:25,760 --> 00:14:29,500
The loss function is on the gradient of

369
00:14:29,500 --> 00:14:30,820
the neural network.

370
00:14:31,260 --> 00:14:31,740
Yes.

371
00:14:31,980 --> 00:14:32,200
Okay.

372
00:14:32,380 --> 00:14:32,700
Question.

373
00:14:33,240 --> 00:14:34,920
Could you clarify about the output of the

374
00:14:34,920 --> 00:14:36,280
neural network case and how do we use

375
00:14:36,280 --> 00:14:36,700
the output

376
00:14:36,700 --> 00:14:39,080
to gather the desired, uh, poses of the

377
00:14:39,080 --> 00:14:39,440
robots?

378
00:14:39,740 --> 00:14:42,060
So, yeah, I will come to that shortly,

379
00:14:42,100 --> 00:14:43,460
but that's a very good question.

380
00:14:43,460 --> 00:14:46,560
So the output in this case is a

381
00:14:46,560 --> 00:14:48,960
travel time T in this case.

382
00:14:49,120 --> 00:14:50,260
It's a value of function.

383
00:14:50,560 --> 00:14:52,200
So in order to get the gradient, you

384
00:14:52,200 --> 00:14:54,780
just have to follow the gradient of that

385
00:14:54,780 --> 00:14:55,360
value of function

386
00:14:55,360 --> 00:14:56,700
and it will give you a trajectory.

387
00:14:57,200 --> 00:14:57,560
Okay?

388
00:14:58,320 --> 00:15:00,820
So we use this simple gradient matching loss

389
00:15:00,820 --> 00:15:01,100
function.

390
00:15:01,140 --> 00:15:02,880
So if you think about the only data

391
00:15:02,880 --> 00:15:04,960
that I need is randomly simple start and

392
00:15:04,960 --> 00:15:05,200
goal

393
00:15:06,640 --> 00:15:08,380
and their distance to obstacle.

394
00:15:09,200 --> 00:15:09,840
That's it.

395
00:15:09,840 --> 00:15:12,360
So this is your standard motion planning tool

396
00:15:12,360 --> 00:15:14,740
is like if you use, for example, sampling

397
00:15:14,740 --> 00:15:16,860
based method like RRT or RRT star,

398
00:15:17,100 --> 00:15:19,640
they require some client checker and way to

399
00:15:19,640 --> 00:15:21,120
randomly sample your configuration.

400
00:15:21,120 --> 00:15:23,560
And then they have some machinery to find

401
00:15:23,560 --> 00:15:24,740
the trajectory, right?

402
00:15:25,220 --> 00:15:26,200
Our data is similar.

403
00:15:26,380 --> 00:15:30,660
We are requiring randomly sample robot configurations and

404
00:15:30,660 --> 00:15:33,380
their distance to constraint or client in this

405
00:15:33,380 --> 00:15:33,600
case.

406
00:15:33,740 --> 00:15:36,740
And then we use that constraint function as

407
00:15:36,740 --> 00:15:39,280
an expert to train our model.

408
00:15:39,280 --> 00:15:44,220
Because over neural network gradient leads to approximation

409
00:15:44,220 --> 00:15:45,200
of constraint function.

410
00:15:45,360 --> 00:15:47,760
And then we compare this approximated constraint function

411
00:15:47,760 --> 00:15:48,320
with actual.

412
00:15:48,880 --> 00:15:49,480
Does that answer?

413
00:15:49,780 --> 00:15:54,200
So theoretically, it all sounds simple, but when

414
00:15:54,200 --> 00:15:55,260
we actually applied this,

415
00:15:55,400 --> 00:15:57,720
we could not scale this method beyond four

416
00:15:57,720 --> 00:15:58,060
dimension.

417
00:15:58,800 --> 00:16:02,440
So numerical solver was solving it for three

418
00:16:02,440 --> 00:16:02,740
dimension.

419
00:16:02,740 --> 00:16:04,860
We showed that, okay, we can do four

420
00:16:04,860 --> 00:16:07,520
dimension, but numerical method could also do four

421
00:16:07,520 --> 00:16:07,800
dimension.

422
00:16:07,960 --> 00:16:09,240
It was just a little bit faster.

423
00:16:09,640 --> 00:16:12,680
And then we started investigating, like, what's the

424
00:16:12,680 --> 00:16:13,040
issue?

425
00:16:13,540 --> 00:16:15,220
There were, and we found out there are

426
00:16:15,220 --> 00:16:16,860
two main limitations.

427
00:16:17,160 --> 00:16:20,720
One, there is, like, Econal PDE has multiple

428
00:16:20,720 --> 00:16:23,060
solution and our neural network is unable to

429
00:16:23,060 --> 00:16:24,380
capture those multiple solution.

430
00:16:24,380 --> 00:16:27,820
So, so it, it is suffering from, from

431
00:16:27,820 --> 00:16:29,400
that, uh, multi-model problem.

432
00:16:29,960 --> 00:16:33,320
Second, because I am training this model on

433
00:16:33,320 --> 00:16:35,020
randomly sample start and goal,

434
00:16:35,940 --> 00:16:40,260
the gradient between my consecutive configuration remains uncontrolled.

435
00:16:40,360 --> 00:16:43,400
But if you think about the trajectory, it's

436
00:16:43,400 --> 00:16:45,280
like you start from start, you go to

437
00:16:45,280 --> 00:16:46,140
next configuration,

438
00:16:46,360 --> 00:16:48,020
then you go to next configuration, and it

439
00:16:48,020 --> 00:16:48,760
gives you a trajectory.

440
00:16:48,760 --> 00:16:52,000
So if my gradient between my consecutive configuration

441
00:16:52,000 --> 00:16:54,800
remains uncontrolled, it can lead to error.

442
00:16:54,900 --> 00:16:56,800
And I will show you shortly, like, how,

443
00:16:56,800 --> 00:16:57,680
how that looks.

444
00:16:58,520 --> 00:17:00,740
So these were the two limitations we found

445
00:17:00,740 --> 00:17:04,380
that we thought is basically limiting our model

446
00:17:04,380 --> 00:17:04,580
for,

447
00:17:04,720 --> 00:17:07,100
from scaling beyond four, four dimension.

448
00:17:07,840 --> 00:17:10,720
So the first solution we explored, like, can

449
00:17:10,720 --> 00:17:13,840
we use viscosity Econal PDE?

450
00:17:14,040 --> 00:17:16,780
So one of the problem I highlighted, Econal

451
00:17:16,780 --> 00:17:18,080
PDE has multiple solution.

452
00:17:18,080 --> 00:17:21,460
So if you add this Laplacian, then this

453
00:17:21,460 --> 00:17:23,100
Econal PDE has a unique solution.

454
00:17:24,980 --> 00:17:28,080
And that did lead to, like, much better

455
00:17:28,080 --> 00:17:28,580
performance.

456
00:17:28,860 --> 00:17:31,120
With this model, we were able to scale

457
00:17:31,120 --> 00:17:33,120
it to up to, like, a six dwarf

458
00:17:33,120 --> 00:17:33,860
robot arm.

459
00:17:34,120 --> 00:17:36,440
And it could apply in motion in very

460
00:17:36,440 --> 00:17:37,060
narrow passage.

461
00:17:37,340 --> 00:17:41,180
But this, uh, viscosity Econal PDE came with

462
00:17:41,180 --> 00:17:41,600
a cost.

463
00:17:41,780 --> 00:17:45,060
So now I have this double derivative of

464
00:17:45,060 --> 00:17:46,300
neural network with respect.

465
00:17:46,300 --> 00:17:47,900
So I have this Laplacian.

466
00:17:48,080 --> 00:17:51,200
So that was very computationally expensive to compute.

467
00:17:51,580 --> 00:17:53,580
And training cost went very high.

468
00:17:53,780 --> 00:17:56,540
So that, again, was against the objective that

469
00:17:56,540 --> 00:17:59,040
I wanted some model that is very fast

470
00:17:59,040 --> 00:17:59,480
to train.

471
00:17:59,700 --> 00:18:03,600
But this viscosity Econal PDE did lead to

472
00:18:03,600 --> 00:18:04,620
better performance.

473
00:18:04,980 --> 00:18:08,640
However, we still did not do anything to

474
00:18:08,640 --> 00:18:12,100
regulate the gradient between my consecutive configuration.

475
00:18:12,100 --> 00:18:14,600
We still train this model on randomly sampled

476
00:18:14,600 --> 00:18:15,760
start and goal.

477
00:18:16,520 --> 00:18:19,240
There was another technique that we proposed along

478
00:18:19,240 --> 00:18:21,940
the way that you can approximate this Laplacian

479
00:18:21,940 --> 00:18:23,920
with Grishley energy minimization.

480
00:18:23,920 --> 00:18:26,000
I won't go into the details, but if

481
00:18:26,000 --> 00:18:28,800
you are interested, check out this paper.

482
00:18:29,060 --> 00:18:31,360
It's a recent IROS publication.

483
00:18:31,700 --> 00:18:34,780
So it discusses, like, how can you use

484
00:18:34,780 --> 00:18:38,940
Grishley energy minimization to approximate Laplacian as you

485
00:18:38,940 --> 00:18:39,760
train your model.

486
00:18:40,400 --> 00:18:44,780
That's a cheaper approximation of this Laplacian.

487
00:18:44,780 --> 00:18:46,920
Still, it takes a lot of iteration to

488
00:18:46,920 --> 00:18:49,940
train because you are, over time, approximating this

489
00:18:49,940 --> 00:18:50,420
Laplacian.

490
00:18:50,460 --> 00:18:52,240
So at the beginning, your model will perform

491
00:18:52,240 --> 00:18:52,700
very bad.

492
00:18:54,200 --> 00:18:58,880
So coming back to those properties, that it

493
00:18:58,880 --> 00:18:59,960
has multiple solutions.

494
00:19:01,340 --> 00:19:04,320
This, and it has, like, um, and the

495
00:19:04,320 --> 00:19:07,720
gradient between conductive, uh, configuration remains uncontrolled.

496
00:19:07,720 --> 00:19:10,780
We found out that solution to these problems

497
00:19:10,780 --> 00:19:14,480
rely on within the properties of Econal PDE.

498
00:19:14,740 --> 00:19:17,740
So Econal PDE is a, is a geodesic

499
00:19:17,740 --> 00:19:18,080
distance.

500
00:19:18,220 --> 00:19:21,180
The solution of Econal PDE is a geodesic

501
00:19:21,180 --> 00:19:21,780
function.

502
00:19:22,400 --> 00:19:25,300
So it should respect the properties of a

503
00:19:25,300 --> 00:19:27,360
geodesic distance, like triangular inequality,

504
00:19:27,360 --> 00:19:29,880
and there are different properties of those geodesic

505
00:19:29,880 --> 00:19:32,360
distances that it should satisfy.

506
00:19:32,880 --> 00:19:36,140
And geodesic distance, it also has, like, multiple

507
00:19:36,140 --> 00:19:36,620
solutions.

508
00:19:36,620 --> 00:19:40,500
There are, it covers, captures multiple geodesic, like,

509
00:19:40,600 --> 00:19:41,980
for example, if you have start and goal,

510
00:19:42,160 --> 00:19:43,760
I can either go this way or I

511
00:19:43,760 --> 00:19:44,800
can also go this way.

512
00:19:44,920 --> 00:19:48,940
So there are multiple solutions available, and all

513
00:19:48,940 --> 00:19:51,140
of these solutions may also be shorter,

514
00:19:51,380 --> 00:19:53,440
uh, or travel time solution.

515
00:19:53,680 --> 00:19:56,540
So there could be some symmetry in your

516
00:19:56,540 --> 00:19:58,000
configuration space or something.

517
00:19:58,120 --> 00:19:59,260
There could be multiple solutions.

518
00:19:59,680 --> 00:20:02,440
All of them can be equally relevant.

519
00:20:02,440 --> 00:20:06,380
Second property is that the solution of Econal

520
00:20:06,380 --> 00:20:07,920
PDE is a value function.

521
00:20:08,340 --> 00:20:11,540
So it should satisfy Bellman principle of optimality

522
00:20:11,540 --> 00:20:13,100
that I will discuss shortly.

523
00:20:13,300 --> 00:20:15,560
So let's start with, uh, first property.

524
00:20:15,800 --> 00:20:18,140
The solution of Econal PDE is a geodesic

525
00:20:18,140 --> 00:20:18,520
distance.

526
00:20:20,400 --> 00:20:24,100
So, so we should use a metric learning

527
00:20:24,100 --> 00:20:28,100
that enforce the prediction to a valid metric

528
00:20:28,100 --> 00:20:28,520
space,

529
00:20:28,520 --> 00:20:31,280
so that we respect all the properties of

530
00:20:31,280 --> 00:20:32,180
a geodesic distance.

531
00:20:32,180 --> 00:20:35,380
So we should ensure consistency with geodesic distances.

532
00:20:36,000 --> 00:20:38,660
Like, it has, uh, symmetry property.

533
00:20:38,980 --> 00:20:41,060
Uh, it has, uh, triangular inequality.

534
00:20:41,520 --> 00:20:45,620
Like your, your path, straight line path between

535
00:20:45,620 --> 00:20:46,340
start and goal,

536
00:20:46,540 --> 00:20:50,220
and your path through some middle point, the

537
00:20:50,220 --> 00:20:51,900
length of that path should be higher than

538
00:20:51,900 --> 00:20:52,540
the straight line.

539
00:20:53,020 --> 00:20:53,540
Okay?

540
00:20:53,580 --> 00:20:54,980
So that's the triangular inequality.

541
00:20:55,260 --> 00:20:58,660
So this geodesic distance, it should, neural network

542
00:20:58,660 --> 00:20:59,960
should satisfy that property.

543
00:20:59,960 --> 00:21:04,200
So we propose this, uh, structure for this

544
00:21:04,200 --> 00:21:04,880
neural network.

545
00:21:05,180 --> 00:21:07,780
What this structure is doing before we were

546
00:21:07,780 --> 00:21:08,240
doing this.

547
00:21:08,340 --> 00:21:09,620
So consider this problem.

548
00:21:09,760 --> 00:21:11,440
I have two paths from A to B.

549
00:21:13,020 --> 00:21:15,400
If I just use L2 norm in my

550
00:21:15,400 --> 00:21:17,500
loss function, it will squash them into this

551
00:21:17,500 --> 00:21:18,000
straight line.

552
00:21:19,300 --> 00:21:21,680
But if you use this loss function, this

553
00:21:21,680 --> 00:21:22,800
structure that we have,

554
00:21:22,940 --> 00:21:26,560
it is taking your QS, pushing them to

555
00:21:26,560 --> 00:21:27,480
some latent state,

556
00:21:27,480 --> 00:21:29,760
and then it is applying some max pooling

557
00:21:29,760 --> 00:21:30,100
on them.

558
00:21:30,680 --> 00:21:33,080
So what it is doing, it is piecewise

559
00:21:33,080 --> 00:21:34,480
approximating the solution.

560
00:21:34,640 --> 00:21:36,660
So you see, you get this diamond shape

561
00:21:36,660 --> 00:21:38,700
approximation of your path.

562
00:21:38,800 --> 00:21:41,640
Instead of these circles, you are piecewise approximating

563
00:21:41,640 --> 00:21:43,100
all those multiple solutions.

564
00:21:43,260 --> 00:21:46,020
So, so this metric learning here, it takes

565
00:21:46,020 --> 00:21:47,280
your QS and QG,

566
00:21:47,500 --> 00:21:49,380
pass them through some neural network,

567
00:21:49,380 --> 00:21:53,500
and then it does something with the latent

568
00:21:53,500 --> 00:21:55,840
features of those QS and QG,

569
00:21:55,840 --> 00:21:57,940
like it applied this max operation, and then

570
00:21:57,940 --> 00:22:01,140
it applies this, uh, infinite norm, uh,

571
00:22:01,340 --> 00:22:02,600
on that latent recording.

572
00:22:02,720 --> 00:22:05,200
So if you think about it, we move

573
00:22:05,200 --> 00:22:07,400
this start and go to some latent space,

574
00:22:07,400 --> 00:22:10,100
and then learn the geodesic distance in that

575
00:22:10,100 --> 00:22:10,860
latent space.

576
00:22:11,880 --> 00:22:12,780
Is that clear?

577
00:22:14,840 --> 00:22:15,360
Okay.

578
00:22:15,480 --> 00:22:17,040
So that was the first change we did.

579
00:22:17,700 --> 00:22:20,640
Second, the solution of this Econel PD should,

580
00:22:20,860 --> 00:22:21,900
is a value function.

581
00:22:21,900 --> 00:22:24,620
So it should respect Bellman principle of optimality.

582
00:22:25,200 --> 00:22:27,680
And then we found out this is actually

583
00:22:27,680 --> 00:22:28,180
solving,

584
00:22:28,400 --> 00:22:31,080
this can solve the problem of our gradient

585
00:22:31,080 --> 00:22:33,860
being uncontrolled between my consecutive point.

586
00:22:34,060 --> 00:22:36,540
So think of this simple Econel PD.

587
00:22:36,860 --> 00:22:39,200
So it is absolute function.

588
00:22:40,080 --> 00:22:42,200
So I have this absolute function,

589
00:22:42,200 --> 00:22:43,940
and the way I am training my neural

590
00:22:43,940 --> 00:22:46,660
network is to randomly sample those green points.

591
00:22:47,440 --> 00:22:50,280
So if I train my neural network on

592
00:22:50,280 --> 00:22:50,820
those points,

593
00:22:50,960 --> 00:22:53,200
it will only minimize loss function on those

594
00:22:53,200 --> 00:22:53,640
points.

595
00:22:53,880 --> 00:22:56,600
It won't do anything on those segments.

596
00:22:57,140 --> 00:23:01,300
So for that neural network, both functions are

597
00:23:01,300 --> 00:23:01,720
accurate,

598
00:23:03,240 --> 00:23:05,820
because my error on those green points is

599
00:23:05,820 --> 00:23:06,100
zero.

600
00:23:06,280 --> 00:23:08,420
But if I have a little bit jump

601
00:23:08,420 --> 00:23:09,340
in between them,

602
00:23:09,480 --> 00:23:11,540
my neural network is unaware of that,

603
00:23:11,540 --> 00:23:14,480
because I did not do anything to regulate

604
00:23:14,480 --> 00:23:17,460
the gradient between those consecutive points.

605
00:23:17,580 --> 00:23:19,780
But if you think of robot trajectory,

606
00:23:20,100 --> 00:23:22,400
it starts from one point and then you,

607
00:23:22,400 --> 00:23:23,360
you keep going.

608
00:23:23,640 --> 00:23:25,820
If you have these little errors in between,

609
00:23:26,220 --> 00:23:29,000
your trajectory can go away from your desired

610
00:23:29,000 --> 00:23:29,240
goal.

611
00:23:29,440 --> 00:23:30,440
Does that make sense?

612
00:23:32,080 --> 00:23:34,600
So we had to regulate this gradient so

613
00:23:34,600 --> 00:23:37,360
that these bumps that you are seeing,

614
00:23:37,380 --> 00:23:39,880
it should capture this absolute function.

615
00:23:41,360 --> 00:23:43,740
So the solution to this problem is,

616
00:23:43,880 --> 00:23:47,320
uh, by treating Econal PD solution as optimal

617
00:23:47,320 --> 00:23:48,480
value of function,

618
00:23:48,680 --> 00:23:52,060
and it must satisfy Bellman principle of optimality.

619
00:23:53,060 --> 00:23:56,200
So when we say it must satisfy Bellman

620
00:23:56,200 --> 00:23:57,360
principle of optimality,

621
00:23:57,560 --> 00:23:59,760
we have to do temporal difference learning.

622
00:24:02,500 --> 00:24:05,460
How many of you are aware of standard

623
00:24:05,460 --> 00:24:07,600
Q learning, deep Q learning?

624
00:24:09,300 --> 00:24:11,100
Some, like most of you are aware.

625
00:24:11,280 --> 00:24:13,080
So in Q learning, you have your reward

626
00:24:13,080 --> 00:24:13,480
function,

627
00:24:14,540 --> 00:24:17,680
Q function at your next state, next action,

628
00:24:17,980 --> 00:24:20,620
minus Q function at your current state, current

629
00:24:20,620 --> 00:24:21,300
action, right?

630
00:24:21,300 --> 00:24:22,940
So that's your Q learning.

631
00:24:24,120 --> 00:24:27,380
And it came from your temporal difference value,

632
00:24:27,540 --> 00:24:30,100
like value function, you have reward value at

633
00:24:30,100 --> 00:24:30,540
next state,

634
00:24:30,540 --> 00:24:33,260
minus value at your current state, right?

635
00:24:33,580 --> 00:24:35,300
So this equation is similar.

636
00:24:35,600 --> 00:24:38,700
We show complete derivation on how we arrive

637
00:24:38,700 --> 00:24:39,680
at this equation.

638
00:24:39,680 --> 00:24:42,720
But the main point is, this is a

639
00:24:42,720 --> 00:24:43,400
value function.

640
00:24:43,640 --> 00:24:45,260
So you have your Qs.

641
00:24:45,640 --> 00:24:48,600
We perturb that Qs towards some direction.

642
00:24:48,600 --> 00:24:50,860
So we have value at next state,

643
00:24:52,440 --> 00:24:54,440
plus some reward,

644
00:24:54,660 --> 00:24:58,200
and value at your next, uh, previous or

645
00:24:58,200 --> 00:24:59,160
your current state.

646
00:24:59,160 --> 00:25:01,060
So T is a value function.

647
00:25:01,980 --> 00:25:05,180
We perturb over Qs in some direction to

648
00:25:05,180 --> 00:25:06,220
get the next state.

649
00:25:06,560 --> 00:25:08,280
So this is value at your next state.

650
00:25:08,960 --> 00:25:10,780
That's value at your current state.

651
00:25:10,900 --> 00:25:13,100
And this is the cost function,

652
00:25:13,220 --> 00:25:15,800
which is inverse of your, uh, constraint,

653
00:25:15,900 --> 00:25:17,540
whatever you give, like it's a distance.

654
00:25:17,780 --> 00:25:20,740
So if I want to minimize or maximize

655
00:25:20,740 --> 00:25:21,900
distance to obstacle,

656
00:25:22,120 --> 00:25:24,120
so that's your reward function or the cost

657
00:25:24,120 --> 00:25:24,420
function.

658
00:25:26,740 --> 00:25:30,880
So when you combine this temporal difference learning,

659
00:25:30,980 --> 00:25:33,480
so in our paper, we show how you

660
00:25:33,480 --> 00:25:35,400
can analytically compute this U.

661
00:25:35,640 --> 00:25:38,180
So how can you perturb this Qs in

662
00:25:38,180 --> 00:25:38,720
a direction

663
00:25:38,720 --> 00:25:41,320
that will give you the next conservative state?

664
00:25:41,520 --> 00:25:44,440
So basically this U is, uh, short answer,

665
00:25:44,820 --> 00:25:47,660
just the gradient of your travel time.

666
00:25:47,700 --> 00:25:51,540
So you move a small step to,

667
00:25:51,540 --> 00:25:54,280
uh, in the direction of your gradient of

668
00:25:54,280 --> 00:25:55,120
your travel time.

669
00:25:55,220 --> 00:25:56,160
So that's your next state.

670
00:25:56,920 --> 00:25:57,440
Okay?

671
00:25:57,760 --> 00:26:00,160
And we can analytically compute that gradient.

672
00:26:01,540 --> 00:26:04,740
So then we combined over gradient matching loss

673
00:26:04,740 --> 00:26:06,000
with this 3D loss,

674
00:26:06,740 --> 00:26:10,640
and then this model was able to perform

675
00:26:10,640 --> 00:26:11,300
really well.

676
00:26:11,380 --> 00:26:13,060
We were able to scale it to very

677
00:26:13,060 --> 00:26:14,120
high dimension problems

678
00:26:14,120 --> 00:26:15,660
that I will show you shortly.

679
00:26:15,980 --> 00:26:19,040
So first, on a very simple problem,

680
00:26:19,580 --> 00:26:21,340
so this is maze-like environment.

681
00:26:21,340 --> 00:26:24,460
If you combine your, uh,

682
00:26:24,620 --> 00:26:27,120
over approach like gradient matching loss with 3D

683
00:26:27,120 --> 00:26:27,420
learning,

684
00:26:27,740 --> 00:26:29,320
you get these kind of contour,

685
00:26:29,380 --> 00:26:31,800
and you can see it is matching this

686
00:26:31,800 --> 00:26:35,580
expert, uh, FFM.

687
00:26:35,680 --> 00:26:36,960
It is a numerical approach.

688
00:26:37,060 --> 00:26:38,940
It can only go to three dimension,

689
00:26:39,120 --> 00:26:40,640
and if you have a very good computer,

690
00:26:40,760 --> 00:26:41,640
it can do four dimension.

691
00:26:41,940 --> 00:26:44,360
But you can see time contours are almost

692
00:26:44,360 --> 00:26:44,800
similar.

693
00:26:45,400 --> 00:26:49,120
So when you do this, uh, uh, neural

694
00:26:49,120 --> 00:26:49,780
network approach,

695
00:26:49,900 --> 00:26:51,160
it can capture similar solution.

696
00:26:51,320 --> 00:26:53,100
However, these are two method.

697
00:26:53,460 --> 00:26:54,780
It's our first method.

698
00:26:54,980 --> 00:26:57,280
It was without any 3D learning or metric

699
00:26:57,280 --> 00:26:57,620
learning.

700
00:26:57,620 --> 00:27:01,100
You can see the gradients at the source

701
00:27:01,100 --> 00:27:01,840
at the beginning

702
00:27:01,840 --> 00:27:02,520
are very good,

703
00:27:02,540 --> 00:27:04,820
but as you go far from your source

704
00:27:04,820 --> 00:27:05,100
point,

705
00:27:05,240 --> 00:27:07,120
the gradient start becoming very bad.

706
00:27:07,500 --> 00:27:10,120
So the error between your conductive state

707
00:27:10,120 --> 00:27:12,860
start propagating and everything goes wrong.

708
00:27:13,660 --> 00:27:16,260
And this is Viskowski Econel PDE.

709
00:27:16,500 --> 00:27:19,340
It still has better solution than this one,

710
00:27:19,500 --> 00:27:21,020
but still it could,

711
00:27:21,140 --> 00:27:22,940
it did not regularize, uh,

712
00:27:24,060 --> 00:27:26,020
gradient between my conductive state.

713
00:27:26,200 --> 00:27:29,380
So still there are some artifacts that you

714
00:27:29,380 --> 00:27:30,360
see in that plot.

715
00:27:30,720 --> 00:27:34,420
So combining gradient matching with TD learning leads

716
00:27:34,420 --> 00:27:34,600
to,

717
00:27:34,660 --> 00:27:36,220
like, much better result.

718
00:27:37,380 --> 00:27:39,780
So now I will discuss one by one

719
00:27:39,780 --> 00:27:41,580
inference efficiency,

720
00:27:41,580 --> 00:27:42,540
training efficiency,

721
00:27:42,900 --> 00:27:44,500
and adaptability of this model.

722
00:27:46,580 --> 00:27:48,640
So let's start with inference efficiency.

723
00:27:50,280 --> 00:27:52,060
So this is on a simple, uh,

724
00:27:52,240 --> 00:27:54,080
7DOF, uh, setup.

725
00:27:54,400 --> 00:27:55,700
So over, as you can see here,

726
00:27:55,760 --> 00:27:59,060
it's, like, take 0.07 seconds to find

727
00:27:59,060 --> 00:27:59,660
that plan.

728
00:28:00,320 --> 00:28:03,280
And this is, uh, MpyNet is, uh, from

729
00:28:03,280 --> 00:28:03,840
NVIDIA.

730
00:28:03,840 --> 00:28:06,660
It was trained on huge amount of data.

731
00:28:06,820 --> 00:28:07,480
I will show you.

732
00:28:07,660 --> 00:28:09,700
It took them several weeks to gather that

733
00:28:09,700 --> 00:28:09,980
data,

734
00:28:10,100 --> 00:28:11,720
and it took them one week to train

735
00:28:11,720 --> 00:28:12,260
that model.

736
00:28:12,900 --> 00:28:14,920
Compared to our model, it took us,

737
00:28:15,580 --> 00:28:17,440
I think I will show you less than,

738
00:28:17,680 --> 00:28:17,800
uh,

739
00:28:19,500 --> 00:28:20,860
less than a minute to gather data,

740
00:28:21,520 --> 00:28:23,920
less than an hour to train, like, uh,

741
00:28:24,140 --> 00:28:26,260
this model on 300 environments.

742
00:28:26,260 --> 00:28:29,300
So this is one model generalizing to 300

743
00:28:29,300 --> 00:28:31,040
different environments.

744
00:28:31,400 --> 00:28:33,500
Still MpyNet and, uh,

745
00:28:33,660 --> 00:28:35,480
over, you can see success rate are very

746
00:28:35,480 --> 00:28:35,900
similar.

747
00:28:36,600 --> 00:28:40,000
And planning time, uh, is much faster in

748
00:28:40,000 --> 00:28:40,560
our case.

749
00:28:40,840 --> 00:28:45,180
And for lazy PRM, these times only show

750
00:28:45,180 --> 00:28:46,500
graph query time.

751
00:28:46,820 --> 00:28:50,020
We did not count graph construction time.

752
00:28:50,680 --> 00:28:52,780
So we pre-constructed the graph

753
00:28:52,780 --> 00:28:54,960
and then use that graph to, uh, query

754
00:28:54,960 --> 00:28:55,380
the time.

755
00:28:58,960 --> 00:29:01,120
Then it, it also steered to, like,

756
00:29:01,240 --> 00:29:03,680
a very complex, uh, indoor environment.

757
00:29:03,700 --> 00:29:05,460
So this is multi-floor environment.

758
00:29:05,740 --> 00:29:08,440
And success rate, again, you can see are

759
00:29:08,440 --> 00:29:09,020
very high.

760
00:29:09,460 --> 00:29:11,280
And planning times are very low

761
00:29:11,280 --> 00:29:13,440
compared to, like, uh, other approaches.

762
00:29:13,780 --> 00:29:15,260
So there is a difference, like,

763
00:29:15,400 --> 00:29:16,680
because it's a value function,

764
00:29:16,980 --> 00:29:20,260
you can incorporate this value function into MPC

765
00:29:20,260 --> 00:29:21,180
or MPPI.

766
00:29:21,180 --> 00:29:25,520
So any, uh, available tool, uh, that can

767
00:29:25,520 --> 00:29:26,600
use your value function.

768
00:29:26,780 --> 00:29:29,160
You can even incorporate it into trajectory optimization.

769
00:29:29,500 --> 00:29:31,540
So we show if you combine it with

770
00:29:31,540 --> 00:29:32,180
MPPI,

771
00:29:32,460 --> 00:29:35,120
it perform, it is much faster,

772
00:29:35,120 --> 00:29:37,520
because then you don't need to compute the

773
00:29:37,520 --> 00:29:37,800
gradient.

774
00:29:37,960 --> 00:29:40,660
You just use the, uh, prediction directly,

775
00:29:40,940 --> 00:29:43,260
the cost to go or the value function

776
00:29:43,260 --> 00:29:44,120
output.

777
00:29:44,480 --> 00:29:47,160
But this gradient, you can also use the

778
00:29:47,160 --> 00:29:47,480
gradient

779
00:29:47,480 --> 00:29:49,280
of this travel time to find the trajectory

780
00:29:49,280 --> 00:29:49,700
still.

781
00:29:50,220 --> 00:29:54,040
Uh, uh, the computation time does not increase

782
00:29:54,040 --> 00:29:54,480
significantly,

783
00:29:55,000 --> 00:29:56,480
and the success rate is high.

784
00:29:57,940 --> 00:29:59,980
And then we were able to scale it

785
00:29:59,980 --> 00:30:01,060
to trial DOS.

786
00:30:01,200 --> 00:30:03,440
This is a very complex environment for these

787
00:30:03,440 --> 00:30:03,720
models

788
00:30:03,720 --> 00:30:05,640
because it has very thin obstacles,

789
00:30:05,860 --> 00:30:07,620
and these PD solutions struggle

790
00:30:07,620 --> 00:30:09,220
when you have these thin obstacles.

791
00:30:09,240 --> 00:30:11,060
So we specifically picked this environment

792
00:30:11,060 --> 00:30:14,580
to show it can nicely capture these thin

793
00:30:14,580 --> 00:30:14,920
obstacles

794
00:30:14,920 --> 00:30:16,560
and still, uh, do planning.

795
00:30:17,560 --> 00:30:19,140
This is 15 DOS,

796
00:30:20,980 --> 00:30:24,760
and this environment is particularly challenging for this

797
00:30:24,760 --> 00:30:24,960
robot.

798
00:30:25,060 --> 00:30:26,260
This robot is very huge,

799
00:30:26,280 --> 00:30:27,660
and this room was very small,

800
00:30:27,680 --> 00:30:29,380
so it's a very confined environment

801
00:30:29,380 --> 00:30:31,280
for this robot to be able to move

802
00:30:31,280 --> 00:30:33,000
from one point to another.

803
00:30:34,020 --> 00:30:36,460
So that's about, like, inference efficiency.

804
00:30:36,720 --> 00:30:38,640
I-I showed you these models, like,

805
00:30:38,760 --> 00:30:40,100
as you scale to high dimension,

806
00:30:40,280 --> 00:30:42,220
they retain their computational benefit.

807
00:30:42,860 --> 00:30:44,160
Now my favorite slide,

808
00:30:44,240 --> 00:30:46,080
I-I want to talk about training efficiency.

809
00:30:50,300 --> 00:30:52,340
So these are different environments,

810
00:30:52,480 --> 00:30:54,260
so if you just pick this 7-DOS

811
00:30:54,260 --> 00:30:54,920
environment,

812
00:30:56,460 --> 00:30:57,940
for that environment,

813
00:30:58,200 --> 00:31:00,100
it took, like, several, uh,

814
00:31:00,100 --> 00:31:02,460
like, uh, for us, it took us 50

815
00:31:02,460 --> 00:31:02,880
minutes

816
00:31:02,880 --> 00:31:04,120
to gather data.

817
00:31:04,360 --> 00:31:05,600
So per environment,

818
00:31:05,600 --> 00:31:06,980
it was taking a few seconds,

819
00:31:07,180 --> 00:31:08,640
so multiply by 50,

820
00:31:08,780 --> 00:31:10,040
it took us, like, 50 minutes.

821
00:31:10,460 --> 00:31:13,260
Training took, uh, 46 minutes compared to,

822
00:31:13,320 --> 00:31:15,220
and we compared it with EmpireNet,

823
00:31:15,380 --> 00:31:17,720
and these numbers are taken from their paper.

824
00:31:17,900 --> 00:31:19,520
It took them several weeks on a large

825
00:31:19,520 --> 00:31:19,880
amount,

826
00:31:20,040 --> 00:31:21,460
to gather a large amount of data,

827
00:31:21,480 --> 00:31:22,900
and then one week to train.

828
00:31:23,180 --> 00:31:25,640
We trained over model on one GPU,

829
00:31:26,340 --> 00:31:27,340
standard 3090,

830
00:31:28,000 --> 00:31:30,080
and, but EmpireNet was trained

831
00:31:30,100 --> 00:31:32,800
on, uh, eight NVIDIA Tesla GPUs.

832
00:31:32,960 --> 00:31:34,860
So it took several, uh,

833
00:31:34,940 --> 00:31:36,300
huge amount of compute power

834
00:31:36,300 --> 00:31:37,280
to train that model.

835
00:31:38,540 --> 00:31:39,460
And, uh,

836
00:31:39,780 --> 00:31:41,020
these Gibson environment,

837
00:31:41,260 --> 00:31:42,080
like you can see,

838
00:31:42,400 --> 00:31:44,380
uh, it, it takes 24 seconds

839
00:31:44,380 --> 00:31:45,160
to gather data,

840
00:31:45,260 --> 00:31:46,120
nine minutes to train.

841
00:31:46,260 --> 00:31:46,960
So what I'm,

842
00:31:46,980 --> 00:31:48,200
I want to highlight here,

843
00:31:48,340 --> 00:31:50,540
when you use these PDE priors,

844
00:31:52,380 --> 00:31:53,400
you have, like,

845
00:31:53,480 --> 00:31:55,100
much higher training efficiency.

846
00:31:55,840 --> 00:31:57,700
Like, the way I see,

847
00:31:58,660 --> 00:32:00,780
physicists gave us these physics models

848
00:32:01,320 --> 00:32:03,380
that govern some dynamical system.

849
00:32:03,680 --> 00:32:06,160
Now we are regathering the trajectories,

850
00:32:06,340 --> 00:32:07,400
ignoring these models,

851
00:32:07,620 --> 00:32:09,640
just to reproduce these models.

852
00:32:10,460 --> 00:32:10,980
Okay?

853
00:32:11,160 --> 00:32:12,640
So why not just use them?

854
00:32:12,740 --> 00:32:13,260
They are there,

855
00:32:13,300 --> 00:32:14,360
and if you use them,

856
00:32:14,520 --> 00:32:16,880
you will have very high training efficiency,

857
00:32:16,940 --> 00:32:19,040
you will have very high inference efficiency,

858
00:32:19,040 --> 00:32:20,860
and these models can still adapt to

859
00:32:20,860 --> 00:32:22,440
very complex environment.

860
00:32:22,640 --> 00:32:24,360
And these models are transferable.

861
00:32:24,820 --> 00:32:27,100
So when I started this research,

862
00:32:28,320 --> 00:32:29,880
our models were training,

863
00:32:29,900 --> 00:32:31,560
like, two days to train.

864
00:32:32,220 --> 00:32:33,960
Like, uh, training would go two days,

865
00:32:34,000 --> 00:32:36,460
because we were not satisfying properly

866
00:32:36,460 --> 00:32:37,880
the properties of these PDEs.

867
00:32:37,940 --> 00:32:39,780
But with these properties we satisfied,

868
00:32:40,040 --> 00:32:42,160
it came down to, like, less than an

869
00:32:42,160 --> 00:32:42,300
hour,

870
00:32:42,300 --> 00:32:44,320
and my lab is still pushing further

871
00:32:45,020 --> 00:32:46,260
to go beyond that.

872
00:32:46,800 --> 00:32:49,580
Like, uh, we, we've,

873
00:32:49,580 --> 00:32:51,600
we are still in preparation for a paper.

874
00:32:51,800 --> 00:32:53,420
I think our latest model, like,

875
00:32:53,620 --> 00:32:55,360
uh, on, on, on 12 DOF,

876
00:32:55,540 --> 00:32:57,720
it takes, like, less than five minutes to

877
00:32:57,720 --> 00:32:57,960
train.

878
00:32:58,860 --> 00:33:00,120
So it's much faster.

879
00:33:00,280 --> 00:33:00,500
Yes?

880
00:33:01,460 --> 00:33:03,680
Any constraints that you have in, like,

881
00:33:03,800 --> 00:33:06,260
the S, uh, in the S function,

882
00:33:06,440 --> 00:33:07,940
is that only just the travel time?

883
00:33:08,120 --> 00:33:09,220
Or you have other constraints?

884
00:33:09,220 --> 00:33:11,640
No, S is the constraint function.

885
00:33:11,820 --> 00:33:12,960
It's a distance to collegian.

886
00:33:13,200 --> 00:33:13,680
Yeah.

887
00:33:14,160 --> 00:33:15,240
So it's not a travel time.

888
00:33:15,360 --> 00:33:17,360
Travel time is the unknown function,

889
00:33:17,600 --> 00:33:19,200
given this constraint function.

890
00:33:19,340 --> 00:33:21,680
So we solved that PDE to find this

891
00:33:21,680 --> 00:33:22,200
travel time.

892
00:33:23,680 --> 00:33:25,440
And also, is the model architecture

893
00:33:25,740 --> 00:33:28,080
between, I guess, like, between, like,

894
00:33:28,200 --> 00:33:31,480
the MPI and your paper,

895
00:33:31,600 --> 00:33:33,060
how different model architecture?

896
00:33:33,180 --> 00:33:34,780
So our model architecture are very different.

897
00:33:35,040 --> 00:33:37,420
So our model architecture is designed

898
00:33:37,420 --> 00:33:39,760
to respect some properties of Econal PDE.

899
00:33:39,780 --> 00:33:41,420
For example, I will give you one property,

900
00:33:42,160 --> 00:33:44,160
like, it has the symmetry property.

901
00:33:44,360 --> 00:33:46,660
So travel time from your start to goal

902
00:33:46,660 --> 00:33:48,400
and travel time from your goal to start

903
00:33:48,400 --> 00:33:49,160
should be same.

904
00:33:49,540 --> 00:33:50,920
So it has the symmetry.

905
00:33:51,200 --> 00:33:53,100
And our architecture is designed

906
00:33:53,100 --> 00:33:54,480
to respect that symmetry.

907
00:33:54,740 --> 00:33:57,620
It enforces that this value function respect.

908
00:33:57,840 --> 00:33:59,580
And then, other thing I mentioned,

909
00:33:59,700 --> 00:34:01,660
our value function is a geodesic distance.

910
00:34:02,020 --> 00:34:03,660
So architecture is designed

911
00:34:03,660 --> 00:34:05,520
to respect those triangular, uh,

912
00:34:05,680 --> 00:34:06,960
inequality and those kind of things.

913
00:34:06,960 --> 00:34:09,680
Whereas MPI net is a, is a standard,

914
00:34:10,020 --> 00:34:14,140
um, standard architecture that we usually use

915
00:34:14,140 --> 00:34:15,300
for large models.

916
00:34:17,140 --> 00:34:17,720
Yes.

917
00:34:18,360 --> 00:34:20,420
Um, so I think it's a very good

918
00:34:20,420 --> 00:34:20,660
idea

919
00:34:20,660 --> 00:34:23,940
to apply Econal PDE for a manipulator task,

920
00:34:24,120 --> 00:34:26,440
uh, because I see in the Econal PDE

921
00:34:26,440 --> 00:34:29,680
you don't have the dynamical constraint, uh, in

922
00:34:29,680 --> 00:34:29,860
it.

923
00:34:29,860 --> 00:34:33,100
So in every state, you probably assume the

924
00:34:33,100 --> 00:34:33,820
manipulator

925
00:34:33,820 --> 00:34:35,540
can move good any direction.

926
00:34:35,940 --> 00:34:38,760
Uh, but in reality it still has some

927
00:34:38,760 --> 00:34:41,560
dynamical constraint and you have singularity

928
00:34:41,560 --> 00:34:42,500
in the manipulator.

929
00:34:42,800 --> 00:34:45,160
So have you experienced any?

930
00:34:45,160 --> 00:34:45,260
Econal PDE.

931
00:34:45,380 --> 00:34:46,780
So that's a very good question.

932
00:34:46,940 --> 00:34:49,400
So currently, uh, we, like, in this work

933
00:34:49,400 --> 00:34:50,540
we consider kinematic.

934
00:34:50,700 --> 00:34:53,240
We have a paper accepted at Neoreps this

935
00:34:53,240 --> 00:34:53,500
year

936
00:34:53,500 --> 00:34:56,100
where we saw the kinodynamic problem

937
00:34:56,100 --> 00:34:57,320
with these Econal PDE.

938
00:34:57,320 --> 00:35:01,080
And, uh, we basically show that this Econal

939
00:35:01,080 --> 00:35:01,700
PDE

940
00:35:01,700 --> 00:35:04,700
can still regular, regularize the solution

941
00:35:04,700 --> 00:35:05,840
to HJB PDE.

942
00:35:06,420 --> 00:35:08,660
So it can, you can think of precondition

943
00:35:08,660 --> 00:35:10,920
of warm start to some HJB PDE solver

944
00:35:10,920 --> 00:35:13,720
and we showed, like, some kinodynamic

945
00:35:13,720 --> 00:35:16,520
like, uh, on a humanoid task, like,

946
00:35:16,600 --> 00:35:19,840
how we can do contact-rich, uh, uh,

947
00:35:20,060 --> 00:35:20,620
locomotion.

948
00:35:20,780 --> 00:35:22,900
And we also showed manipulation, if I remember

949
00:35:22,900 --> 00:35:23,300
correctly.

950
00:35:23,300 --> 00:35:27,300
But in a second point, you pointed out

951
00:35:27,300 --> 00:35:27,960
to something else

952
00:35:27,960 --> 00:35:29,540
as well, like, uh, in manipulation,

953
00:35:29,620 --> 00:35:31,100
I'm coming to manipulation shortly.

954
00:35:31,840 --> 00:35:32,280
Yeah.

955
00:35:32,660 --> 00:35:32,900
Yes.

956
00:35:33,540 --> 00:35:34,500
Just, just wondering,

957
00:35:34,660 --> 00:35:36,380
wouldn't you need to do the data generation

958
00:35:36,380 --> 00:35:36,920
and training?

959
00:35:37,180 --> 00:35:39,800
Uh, see, uh, on a channel,

960
00:35:40,700 --> 00:35:41,520
a location,

961
00:35:41,720 --> 00:35:42,360
are we obstinate?

962
00:35:43,940 --> 00:35:45,360
So in this case, yes.

963
00:35:45,560 --> 00:35:48,240
So we have, uh, uh, I will discuss

964
00:35:48,240 --> 00:35:49,040
one more work.

965
00:35:49,200 --> 00:35:52,040
Like, we can selectively retrain neural network.

966
00:35:52,040 --> 00:35:53,280
Like, I will show you how you can

967
00:35:53,280 --> 00:35:54,100
select parameters

968
00:35:54,100 --> 00:35:55,460
that you need to retrain

969
00:35:55,460 --> 00:35:57,060
if some part of the environment has changed.

970
00:35:57,160 --> 00:35:59,160
You, you do not need to retrain everything.

971
00:35:59,400 --> 00:35:59,860
Cool, cool.

972
00:36:00,020 --> 00:36:02,300
And the powerful training, I...

973
00:36:02,300 --> 00:36:04,640
You can give the, the network

974
00:36:04,640 --> 00:36:06,760
arbitrary start and default location.

975
00:36:06,920 --> 00:36:07,060
Yeah, right.

976
00:36:07,180 --> 00:36:07,580
Okay, cool.

977
00:36:07,700 --> 00:36:07,880
Yeah.

978
00:36:09,500 --> 00:36:12,100
So, so far we have discussed training efficiency,

979
00:36:12,240 --> 00:36:13,520
adaptability to complexity.

980
00:36:13,700 --> 00:36:15,480
Like, I have shown you that it's scared

981
00:36:15,480 --> 00:36:17,100
to very high dimension, but I want to

982
00:36:17,100 --> 00:36:17,820
discuss, like,

983
00:36:17,880 --> 00:36:19,800
how it can steer to manipulation

984
00:36:19,800 --> 00:36:21,880
or, or very large environment.

985
00:36:22,020 --> 00:36:23,340
Neural network has this problem.

986
00:36:23,480 --> 00:36:25,120
Like, if you have a very large environment,

987
00:36:25,420 --> 00:36:26,420
it struggles.

988
00:36:26,580 --> 00:36:28,860
It, uh, suffer from spectral bias issue

989
00:36:28,860 --> 00:36:30,800
of, uh, your neural networks.

990
00:36:31,140 --> 00:36:34,300
So, first, to scale it to manifold

991
00:36:34,300 --> 00:36:35,580
or manipulation problem,

992
00:36:36,020 --> 00:36:38,380
all you have to change is your expert

993
00:36:38,380 --> 00:36:39,360
speed function.

994
00:36:39,640 --> 00:36:41,120
Instead of distance to obstacle,

995
00:36:41,520 --> 00:36:43,340
make a distance to constraint manifold.

996
00:36:43,340 --> 00:36:45,160
Like, if, for example, you are doing door

997
00:36:45,160 --> 00:36:45,840
opening tasks,

998
00:36:46,000 --> 00:36:46,880
that's one manifold.

999
00:36:47,320 --> 00:36:49,600
And if you can compute the distance of

1000
00:36:49,600 --> 00:36:50,400
robot configuration

1001
00:36:50,400 --> 00:36:51,340
to that manifold,

1002
00:36:51,540 --> 00:36:54,080
you can use that as a, uh, training

1003
00:36:54,080 --> 00:36:54,500
function.

1004
00:36:55,120 --> 00:36:58,020
And then we were able to solve this,

1005
00:36:58,180 --> 00:36:58,640
like, uh,

1006
00:36:58,900 --> 00:37:01,300
so this model is, like, opening door,

1007
00:37:01,320 --> 00:37:03,000
and then it will move that cup

1008
00:37:03,000 --> 00:37:05,520
without tilting from one point to another

1009
00:37:05,520 --> 00:37:07,200
in, in this confined space.

1010
00:37:08,280 --> 00:37:10,060
So, again, you can see, uh,

1011
00:37:10,200 --> 00:37:11,960
computation times are very low.

1012
00:37:12,120 --> 00:37:13,400
Success rate is very high.

1013
00:37:13,660 --> 00:37:16,020
And we compare it with C by RRT,

1014
00:37:16,140 --> 00:37:17,420
which is a sampling-based approach.

1015
00:37:17,900 --> 00:37:19,940
CompNet X is a data, like,

1016
00:37:20,100 --> 00:37:21,760
imitation learning-based approach.

1017
00:37:22,100 --> 00:37:24,640
So, the CompNet X I proposed during my

1018
00:37:24,640 --> 00:37:25,100
PhD,

1019
00:37:25,400 --> 00:37:27,700
uh, to solve these, uh, manipulation problem.

1020
00:37:27,820 --> 00:37:30,520
But you have to gather data using some

1021
00:37:30,520 --> 00:37:31,460
C by RRT

1022
00:37:31,460 --> 00:37:33,320
or classical planner to train that model.

1023
00:37:35,060 --> 00:37:36,940
And then question come, like,

1024
00:37:37,080 --> 00:37:38,980
how can we scale to multi-modal problem?

1025
00:37:39,140 --> 00:37:40,920
Like, for example, if you have this cup,

1026
00:37:40,960 --> 00:37:42,820
you are moving it, keeping it upright,

1027
00:37:43,000 --> 00:37:43,680
then you are tilting.

1028
00:37:43,800 --> 00:37:44,920
These are two different constraints.

1029
00:37:45,120 --> 00:37:46,980
And then this robot also need to open

1030
00:37:46,980 --> 00:37:47,440
cabinet,

1031
00:37:47,600 --> 00:37:48,240
retrieve something.

1032
00:37:48,700 --> 00:37:50,300
And if you are doing steering,

1033
00:37:50,760 --> 00:37:53,180
so that spoon motion is one manifold,

1034
00:37:53,400 --> 00:37:54,820
then steering is another manifold.

1035
00:37:55,040 --> 00:37:56,500
If you are doing hammering

1036
00:37:56,500 --> 00:37:58,080
or all your tool manipulation,

1037
00:37:58,300 --> 00:38:02,480
they are multi-modal, uh, uh, constraint problems.

1038
00:38:02,480 --> 00:38:05,440
So, how can we extend these methods

1039
00:38:05,440 --> 00:38:07,440
to solve those multi-modal constraint?

1040
00:38:07,780 --> 00:38:11,560
So, the, the solution relies, uh, in,

1041
00:38:11,780 --> 00:38:14,440
in, in classical PDE literature,

1042
00:38:14,660 --> 00:38:16,840
like, in, if you study classical PDE literature,

1043
00:38:17,080 --> 00:38:19,960
they used to represent PDE solution

1044
00:38:19,960 --> 00:38:22,260
as a sum of finite basis functions.

1045
00:38:23,360 --> 00:38:23,690
Okay?

1046
00:38:24,260 --> 00:38:26,540
So, if each of these basis function

1047
00:38:26,540 --> 00:38:28,340
represents a manifold,

1048
00:38:28,660 --> 00:38:30,820
then I can combine them to get my

1049
00:38:30,820 --> 00:38:31,760
global trajectory.

1050
00:38:31,760 --> 00:38:33,000
So, this is what we do.

1051
00:38:33,200 --> 00:38:36,240
So, we decompose our problem into,

1052
00:38:36,520 --> 00:38:38,280
so, this is just for depiction.

1053
00:38:38,720 --> 00:38:40,080
Think of this 2D environment.

1054
00:38:40,320 --> 00:38:43,000
I can break it down into multiple pieces.

1055
00:38:43,660 --> 00:38:45,360
And then for each piece,

1056
00:38:45,440 --> 00:38:47,160
I can learn some basis function.

1057
00:38:48,120 --> 00:38:50,520
And then I can combine the basis function

1058
00:38:50,520 --> 00:38:52,860
to get my global value function.

1059
00:38:53,040 --> 00:38:55,560
But there, there was a challenge there.

1060
00:38:55,560 --> 00:38:58,420
So, I want my value function to be

1061
00:38:58,420 --> 00:38:58,880
continuous,

1062
00:38:58,900 --> 00:39:00,460
like, fully spatially connected,

1063
00:39:00,520 --> 00:39:01,820
because in trajectories,

1064
00:39:02,000 --> 00:39:03,560
if you have the decomposition,

1065
00:39:04,160 --> 00:39:07,260
you can have singularities at all of these

1066
00:39:07,260 --> 00:39:07,840
partitions.

1067
00:39:08,500 --> 00:39:10,940
So, how can we get this global value

1068
00:39:10,940 --> 00:39:11,260
function

1069
00:39:11,260 --> 00:39:13,060
so that I can go from any point

1070
00:39:13,060 --> 00:39:13,780
to any point,

1071
00:39:13,900 --> 00:39:15,720
from this segment to that segment,

1072
00:39:15,860 --> 00:39:19,820
without experiencing any discontinuities or local minima?

1073
00:39:20,280 --> 00:39:21,540
So, that was the challenge.

1074
00:39:21,740 --> 00:39:23,620
And then we propose some architectures.

1075
00:39:24,100 --> 00:39:24,960
If you're interested,

1076
00:39:24,980 --> 00:39:26,960
you can go into the details there.

1077
00:39:27,400 --> 00:39:29,520
But, uh, this architecture basically,

1078
00:39:30,220 --> 00:39:32,220
decompose your problem into subdomains

1079
00:39:32,220 --> 00:39:34,620
and then learn this global function.

1080
00:39:34,780 --> 00:39:36,540
So, that addresses your question,

1081
00:39:36,640 --> 00:39:38,420
like, if some part of the environment change,

1082
00:39:39,080 --> 00:39:40,780
you don't need to retrain everything.

1083
00:39:40,920 --> 00:39:42,800
You just need to retrain that basis function.

1084
00:39:42,800 --> 00:39:44,180
And that's very fast.

1085
00:39:46,500 --> 00:39:48,180
So, we were able to scale it to

1086
00:39:48,180 --> 00:39:49,280
very large environments.

1087
00:39:50,160 --> 00:39:53,960
Uh, and, uh, it still retains, like, very

1088
00:39:53,960 --> 00:39:54,720
high success rate.

1089
00:39:54,840 --> 00:39:56,520
Another advantage of this decomposition,

1090
00:39:56,880 --> 00:40:01,500
you need fewer parameters compared to your end

1091
00:40:01,500 --> 00:40:02,120
-to-end function.

1092
00:40:02,280 --> 00:40:03,440
So, that's what we found.

1093
00:40:03,860 --> 00:40:06,200
And then this is, like, on a rail

1094
00:40:06,200 --> 00:40:07,620
over campus,

1095
00:40:07,660 --> 00:40:10,520
like, this robot is navigating these multiple narrow

1096
00:40:10,520 --> 00:40:11,000
passages

1097
00:40:11,000 --> 00:40:12,200
from one point to another,

1098
00:40:12,200 --> 00:40:15,660
and this entire environment was decomposed into, uh,

1099
00:40:16,000 --> 00:40:17,140
multiple basis functions.

1100
00:40:19,320 --> 00:40:22,000
And then the same idea applies to your

1101
00:40:22,000 --> 00:40:23,080
multi-modal manipulation.

1102
00:40:23,280 --> 00:40:25,980
You have multi-modal, multiple manifolds.

1103
00:40:26,200 --> 00:40:28,840
You can represent them as basis function.

1104
00:40:29,060 --> 00:40:31,200
You can combine them to get trajectories.

1105
00:40:31,280 --> 00:40:34,300
So, this is one neural model doing, uh,

1106
00:40:34,600 --> 00:40:35,160
door opening,

1107
00:40:35,180 --> 00:40:37,400
and then it will retrieve this cup without

1108
00:40:37,400 --> 00:40:37,920
tilting,

1109
00:40:37,960 --> 00:40:40,580
and then it will do this pouring task.

1110
00:40:48,220 --> 00:40:50,640
We recently moved to humanoid robots.

1111
00:40:50,820 --> 00:40:52,760
So, all these tasks are being solved by

1112
00:40:52,760 --> 00:40:53,220
humanoid.

1113
00:40:53,380 --> 00:40:57,460
So, this decomposition is also on the space.

1114
00:40:57,680 --> 00:40:59,500
So, a robot can move anywhere in the

1115
00:40:59,500 --> 00:40:59,860
environment.

1116
00:40:59,860 --> 00:41:02,640
So, that's, uh, decomposition on the plane.

1117
00:41:02,820 --> 00:41:04,840
Then we have decomposition on the manifolds.

1118
00:41:05,220 --> 00:41:08,160
So, all these, like, multi-modal problem is

1119
00:41:08,160 --> 00:41:08,860
being solved.

1120
00:41:09,020 --> 00:41:11,400
And this paper, hopefully, we plan to submit

1121
00:41:11,400 --> 00:41:13,660
to a conference very soon.

1122
00:41:13,660 --> 00:41:16,920
Uh, but we can solve multi-modal manipulation

1123
00:41:16,920 --> 00:41:18,080
problem that you see.

1124
00:41:18,540 --> 00:41:21,520
Very popular with imitation learning or data-driven

1125
00:41:21,520 --> 00:41:22,340
approaches nowadays.

1126
00:41:22,340 --> 00:41:25,020
We can solve all those problems, uh, with

1127
00:41:25,020 --> 00:41:25,600
these models.

1128
00:41:26,760 --> 00:41:29,660
Another area that we extended to, like, unknown

1129
00:41:29,660 --> 00:41:30,140
environment.

1130
00:41:30,320 --> 00:41:32,620
Right now, we assumed we know the environment,

1131
00:41:32,640 --> 00:41:34,040
and then from that environment,

1132
00:41:34,040 --> 00:41:36,440
we computed the, uh, distance to obstacle.

1133
00:41:36,620 --> 00:41:38,100
I need to speed up.

1134
00:41:38,600 --> 00:41:42,700
So, so, one thing that we think the

1135
00:41:42,700 --> 00:41:44,900
motion planning problem is computationally expensive

1136
00:41:44,900 --> 00:41:48,440
is because your mapping feature is not good

1137
00:41:48,440 --> 00:41:49,200
for motion planning.

1138
00:41:49,360 --> 00:41:52,220
There is a huge gap between your mapping

1139
00:41:52,220 --> 00:41:53,760
features and your motion planner.

1140
00:41:53,920 --> 00:41:55,740
Like, you have the sign-distance field or

1141
00:41:55,740 --> 00:41:59,780
occupancy map that necessitate the building

1142
00:41:59,780 --> 00:42:03,360
of some computationally expensive tools for motion planning.

1143
00:42:03,640 --> 00:42:06,400
Like, for example, to translate those map into

1144
00:42:06,400 --> 00:42:06,820
C-space,

1145
00:42:07,000 --> 00:42:08,780
you either have to use sampling-based technique

1146
00:42:08,780 --> 00:42:09,520
or optimization.

1147
00:42:09,760 --> 00:42:12,440
Then you find a trajectory in your C

1148
00:42:12,440 --> 00:42:12,680
-space.

1149
00:42:12,680 --> 00:42:15,320
So can we have a better mapping that

1150
00:42:15,320 --> 00:42:18,600
does not require this, uh, very complex, uh,

1151
00:42:19,020 --> 00:42:19,280
tools?

1152
00:42:19,440 --> 00:42:20,640
So answer is yes.

1153
00:42:20,840 --> 00:42:25,200
If you can learn, uh, maps as a

1154
00:42:25,200 --> 00:42:27,660
travel time function, then you don't need any

1155
00:42:27,660 --> 00:42:27,920
planner.

1156
00:42:27,980 --> 00:42:30,120
You just follow the gradient of that travel

1157
00:42:30,120 --> 00:42:32,320
time, and it will give you a trajectory.

1158
00:42:32,600 --> 00:42:36,120
So we, we investigated that.

1159
00:42:36,120 --> 00:42:38,340
So as your robot explores the environment, it

1160
00:42:38,340 --> 00:42:39,620
gets the depth perception,

1161
00:42:39,620 --> 00:42:43,060
and you can locally approximate your constraint function.

1162
00:42:43,640 --> 00:42:46,640
So as your data is coming, you can

1163
00:42:46,640 --> 00:42:47,520
train this model.

1164
00:42:47,680 --> 00:42:49,340
So you, uh, here, this video is showing

1165
00:42:49,340 --> 00:42:51,160
that robot is exploring the environment.

1166
00:42:52,240 --> 00:42:54,280
Perception is coming in stream, and it is

1167
00:42:54,280 --> 00:42:56,580
building this arrival time field map.

1168
00:42:59,380 --> 00:43:01,200
And then once you have this map, you

1169
00:43:01,200 --> 00:43:02,500
don't need any motion planning tool.

1170
00:43:02,600 --> 00:43:04,720
Just follow the gradient of this map.

1171
00:43:04,880 --> 00:43:09,100
It, it incorporates that geometrical representation that helps

1172
00:43:09,100 --> 00:43:10,580
robot navigate the environment.

1173
00:43:12,320 --> 00:43:16,800
And so over this paper, the mapping time

1174
00:43:16,800 --> 00:43:20,700
was twice than, uh, standard mapping, like, occupancy

1175
00:43:20,700 --> 00:43:21,040
maps.

1176
00:43:21,240 --> 00:43:23,200
But our latest model, we were able to

1177
00:43:23,200 --> 00:43:25,620
reduce this time by, like, 40%.

1178
00:43:25,620 --> 00:43:29,020
So, uh, each time, like, in each frame,

1179
00:43:29,200 --> 00:43:31,680
neural network just take two seconds to train

1180
00:43:31,680 --> 00:43:32,300
in this case.

1181
00:43:32,300 --> 00:43:34,360
But our latest model, I think it takes

1182
00:43:34,360 --> 00:43:36,220
less than one second to train as robot

1183
00:43:36,220 --> 00:43:37,240
explores the environment.

1184
00:43:37,740 --> 00:43:41,920
And it even scales to, like, uh, uh,

1185
00:43:43,080 --> 00:43:45,780
so this is a rare robot mapping this

1186
00:43:45,780 --> 00:43:46,260
environment.

1187
00:43:51,460 --> 00:43:53,380
So you can see as it is exploring,

1188
00:43:53,420 --> 00:43:55,460
it is training the model on the fly,

1189
00:43:55,480 --> 00:43:58,340
and, uh, to get those, uh, travel time.

1190
00:43:58,340 --> 00:44:00,180
So if we can get these maps in

1191
00:44:00,180 --> 00:44:02,980
almost same amount of time as your occupancy

1192
00:44:02,980 --> 00:44:03,260
map,

1193
00:44:03,460 --> 00:44:05,200
then you don't need any motion planner.

1194
00:44:05,420 --> 00:44:08,320
You can just deploy your robot anywhere in

1195
00:44:08,320 --> 00:44:09,140
unknown environment,

1196
00:44:09,200 --> 00:44:10,900
and it will figure out how to move

1197
00:44:10,900 --> 00:44:13,640
in that environment with these plug-and-play

1198
00:44:13,640 --> 00:44:14,160
models.

1199
00:44:16,000 --> 00:44:18,320
And another advantage of this, like, you can

1200
00:44:18,320 --> 00:44:19,700
even do manipulation with it.

1201
00:44:19,800 --> 00:44:21,940
You can equip robot with your in-hand

1202
00:44:21,940 --> 00:44:22,320
camera,

1203
00:44:22,340 --> 00:44:24,800
and it will explore and construct these arrival

1204
00:44:24,800 --> 00:44:26,400
time field maps in C space.

1205
00:44:27,200 --> 00:44:29,720
And still, uh, yet it can still, like,

1206
00:44:29,800 --> 00:44:30,180
navigate.

1207
00:44:30,440 --> 00:44:32,880
So we show that in our, uh, TRO

1208
00:44:32,880 --> 00:44:33,240
paper.

1209
00:44:33,580 --> 00:44:35,580
If you are interested, check this out.

1210
00:44:38,000 --> 00:44:38,480
Okay.

1211
00:44:39,780 --> 00:44:42,140
So this is, like, the robot arm setup

1212
00:44:42,140 --> 00:44:42,560
we had.

1213
00:44:42,660 --> 00:44:44,400
It was using this in-hand camera to

1214
00:44:44,400 --> 00:44:46,840
construct this arrival time field map in six

1215
00:44:46,840 --> 00:44:47,800
-dimension C space.

1216
00:44:49,900 --> 00:44:51,960
Another area we are interested in, like, how

1217
00:44:51,960 --> 00:44:54,220
can we solve these PDEs for, uh,

1218
00:44:55,560 --> 00:44:56,620
uh, multi-agent settings.

1219
00:44:56,900 --> 00:44:59,820
So basically, instead of, like, HGBPD, you basically

1220
00:44:59,820 --> 00:45:01,200
solve HGR.

1221
00:45:01,200 --> 00:45:04,200
You may know work from Sumel Benson here.

1222
00:45:04,200 --> 00:45:07,780
And, uh, the way we differ from his

1223
00:45:07,780 --> 00:45:09,280
work is, like, we want to push the

1224
00:45:09,280 --> 00:45:10,480
scalability of these methods

1225
00:45:10,480 --> 00:45:13,920
to very complex robot manipulator with very complex

1226
00:45:13,920 --> 00:45:15,420
geometry of obstacles.

1227
00:45:16,620 --> 00:45:18,880
And this is one of our work, like,

1228
00:45:18,960 --> 00:45:22,300
uh, uh, here robots are trying to reach

1229
00:45:22,300 --> 00:45:22,840
their target

1230
00:45:22,840 --> 00:45:24,440
while we actively awarding client.

1231
00:45:24,720 --> 00:45:28,200
We also scaled it to, like, uh, assembly

1232
00:45:28,200 --> 00:45:30,740
line tasks where multiple robots are performing their,

1233
00:45:30,900 --> 00:45:31,180
uh,

1234
00:45:32,320 --> 00:45:34,020
uh, their tasks while awarding client.

1235
00:45:34,160 --> 00:45:36,260
So, uh, if you are interested, like, check

1236
00:45:36,260 --> 00:45:37,060
out this work.

1237
00:45:37,060 --> 00:45:40,280
So in conclusion, if you should use physics

1238
00:45:40,280 --> 00:45:42,840
priors because it gives you all these three

1239
00:45:42,840 --> 00:45:43,300
features,

1240
00:45:43,480 --> 00:45:46,400
inference efficiency, training efficiency, adaptability.

1241
00:45:46,700 --> 00:45:50,080
In our future direction, we are, first, we

1242
00:45:50,080 --> 00:45:52,060
want to improve our training efficiency.

1243
00:45:52,320 --> 00:45:54,140
Our current models take, like, five minutes.

1244
00:45:54,160 --> 00:45:56,300
I want to achieve, like, real-time training.

1245
00:45:56,540 --> 00:45:59,000
So, so that this neural network will be

1246
00:45:59,000 --> 00:46:00,200
a plug-and-play model.

1247
00:46:00,760 --> 00:46:01,620
That's my vision.

1248
00:46:01,820 --> 00:46:03,280
Like, if you have this plug-and-play

1249
00:46:03,280 --> 00:46:06,500
model, transferability generalizing to new environment

1250
00:46:06,500 --> 00:46:08,920
won't be an issue because the robot can

1251
00:46:08,920 --> 00:46:10,600
just go there and train on, on the

1252
00:46:10,600 --> 00:46:10,860
fly

1253
00:46:10,860 --> 00:46:13,700
and perform all your manipulation motion planning problems.

1254
00:46:14,480 --> 00:46:16,860
And other areas that we are interested in

1255
00:46:16,860 --> 00:46:19,760
is reactive because these methods are very fast.

1256
00:46:20,220 --> 00:46:23,180
So if they can generalize to very different

1257
00:46:23,180 --> 00:46:26,220
settings, even if you disturb the environment,

1258
00:46:26,440 --> 00:46:28,300
they can still recover from it very quickly.

1259
00:46:30,480 --> 00:46:33,400
And this is, like, a multimodal problem, like,

1260
00:46:33,440 --> 00:46:36,240
where robots are planning for grasp and manipulation

1261
00:46:36,240 --> 00:46:38,420
together, so that's another area that we are

1262
00:46:38,420 --> 00:46:38,860
extending.

1263
00:46:39,640 --> 00:46:42,800
This is a new problem I recently got

1264
00:46:42,800 --> 00:46:43,580
interested into.

1265
00:46:43,800 --> 00:46:48,520
It's called assistive manipulation, where robots are manipulating

1266
00:46:48,520 --> 00:46:51,440
human body to do different tasks.

1267
00:46:51,560 --> 00:46:54,900
Like, for example, assisted dressing is a manipulation

1268
00:46:54,900 --> 00:46:55,320
problem.

1269
00:46:55,320 --> 00:46:58,500
You have to respect biomechanical constraint in order

1270
00:46:58,500 --> 00:46:59,360
to move human body.

1271
00:46:59,360 --> 00:47:01,400
I think it's a very nice motion planning

1272
00:47:01,400 --> 00:47:04,080
problem to study, and we are extending these

1273
00:47:04,080 --> 00:47:04,440
methods

1274
00:47:04,440 --> 00:47:05,880
to those domains as well.

1275
00:47:06,100 --> 00:47:09,140
So this is a bed-wiping task in

1276
00:47:09,140 --> 00:47:09,760
the simulation.

1277
00:47:10,000 --> 00:47:12,060
Like, robot is moving a human limb from

1278
00:47:12,060 --> 00:47:14,140
one point to another, and other robot is

1279
00:47:14,140 --> 00:47:15,780
wiping the body.

1280
00:47:16,340 --> 00:47:18,140
So with this, I will conclude.

1281
00:47:18,140 --> 00:47:19,320
I'm almost on time.

1282
00:47:19,580 --> 00:47:21,260
So this is my lab.

1283
00:47:21,440 --> 00:47:23,360
So without them, nothing would have been possible.

1284
00:47:23,360 --> 00:47:25,060
So if you are interested, check out our

1285
00:47:25,060 --> 00:47:25,720
lab website.

1286
00:47:27,860 --> 00:47:29,500
And that would be it.

1287
00:47:29,580 --> 00:47:29,940
Thank you.

1288
00:47:30,220 --> 00:47:30,820
Any questions?

1289
00:47:35,760 --> 00:47:36,280
Yes.

1290
00:47:37,720 --> 00:47:38,880
Thank you for the great talking.

1291
00:47:39,200 --> 00:47:41,700
I just wanted to ask you, how would

1292
00:47:41,700 --> 00:47:43,520
you compare, like, your method to, say, some

1293
00:47:43,520 --> 00:47:43,920
of the other

1294
00:47:44,740 --> 00:47:47,480
more recent motion planning method, like, say, geometric

1295
00:47:47,480 --> 00:47:48,920
pattern, or the drop from all

1296
00:47:48,920 --> 00:47:51,700
except, like, if you could, and it turns

1297
00:47:51,700 --> 00:47:53,040
out, like, say, .

1298
00:47:57,020 --> 00:48:00,240
So, so, graph of concept, like, I think

1299
00:48:00,240 --> 00:48:03,280
there are assumptions these methods are performing,

1300
00:48:03,280 --> 00:48:07,300
like, for example, having a convex obstacle.

1301
00:48:07,580 --> 00:48:09,560
So that's one of the assumptions.

1302
00:48:09,820 --> 00:48:13,060
Like, for example, if you see, what's the

1303
00:48:13,060 --> 00:48:13,740
name of that?

1304
00:48:14,180 --> 00:48:15,580
There's a, Kurobo.

1305
00:48:16,020 --> 00:48:18,840
If you see how Kurobo works, they assume

1306
00:48:18,840 --> 00:48:23,020
robot environment is represented with multiple spheres.

1307
00:48:23,380 --> 00:48:26,220
Then they solve motion planning problem very fast.

1308
00:48:26,560 --> 00:48:26,920
Okay?

1309
00:48:27,300 --> 00:48:30,280
And even these parallelization, like, their test work

1310
00:48:30,280 --> 00:48:33,260
on parallelization, they heavily rely on this parallelization.

1311
00:48:33,260 --> 00:48:36,060
Like, a spherical representation of the robot and

1312
00:48:36,060 --> 00:48:36,540
environment.

1313
00:48:36,840 --> 00:48:39,620
And they solve this motion planning problem in,

1314
00:48:39,620 --> 00:48:40,540
basically, in workspace.

1315
00:48:41,260 --> 00:48:43,120
But there's an inherent issue there.

1316
00:48:43,300 --> 00:48:45,320
Like, if you are doing, solving this problem

1317
00:48:45,320 --> 00:48:49,140
in workspace, a lot of current work, like,

1318
00:48:49,220 --> 00:48:50,040
in imitation learning,

1319
00:48:50,160 --> 00:48:51,780
they are solving this problem in workspace.

1320
00:48:52,420 --> 00:48:54,880
There is no guarantee that you can map

1321
00:48:54,880 --> 00:48:56,760
this trajectory into C-space trajectory.

1322
00:48:56,980 --> 00:48:58,820
Your robot may run into local minima.

1323
00:48:59,360 --> 00:49:01,960
Oftentimes, like, if you are performing very complex

1324
00:49:01,960 --> 00:49:05,200
tasks, you will see that you don't have

1325
00:49:05,200 --> 00:49:07,660
direct mapping from this workspace trajectory to C

1326
00:49:07,660 --> 00:49:07,880
-space.

1327
00:49:08,100 --> 00:49:11,280
Like, if you really study motion planning and

1328
00:49:11,280 --> 00:49:16,060
check out the literature from early 1990s, they

1329
00:49:16,060 --> 00:49:17,540
were doing workspace motion planning.

1330
00:49:17,540 --> 00:49:19,320
Then they figured out this is the problem,

1331
00:49:19,360 --> 00:49:21,240
and then they moved to C-space planning.

1332
00:49:21,820 --> 00:49:24,640
Unfortunately, we are going back to workspace planning.

1333
00:49:25,040 --> 00:49:27,900
So these latest methods, they are very fast,

1334
00:49:28,100 --> 00:49:31,880
but they rely on these assumptions, which eventually

1335
00:49:31,880 --> 00:49:33,860
will lead to problem of mapping to C

1336
00:49:33,860 --> 00:49:34,660
-space trajectories.

1337
00:49:34,660 --> 00:49:37,080
Yeah, I don't think either, or, and I'm

1338
00:49:37,080 --> 00:49:37,760
exposed to it as nice.

1339
00:49:38,800 --> 00:49:41,060
So, geometric fabric, I'm unaware of that.

1340
00:49:41,200 --> 00:49:42,640
But I think the other paper you mentioned,

1341
00:49:42,800 --> 00:49:44,720
they assume fair spherical representation.

1342
00:49:45,460 --> 00:49:45,660
No?

1343
00:49:46,180 --> 00:49:48,500
Maybe I'm thinking of some other paper there.

1344
00:49:49,040 --> 00:49:49,280
Yeah.

1345
00:49:49,560 --> 00:49:51,080
I am then not aware of that.

1346
00:49:51,320 --> 00:49:55,460
I guess, like, maybe for, like, geometrical systems

1347
00:49:55,460 --> 00:49:56,640
could be very sick.

1348
00:49:56,880 --> 00:49:57,160
Sorry?

1349
00:49:57,160 --> 00:50:01,180
So, basically, you model your system as a

1350
00:50:01,180 --> 00:50:03,560
dynamical system, and then you try to essentially

1351
00:50:03,560 --> 00:50:04,140
extract

1352
00:50:04,140 --> 00:50:05,540
load vector fields.

1353
00:50:05,660 --> 00:50:05,980
Yeah.

1354
00:50:06,080 --> 00:50:06,740
On and out.

1355
00:50:06,960 --> 00:50:08,800
Like, I guess maybe, in that sense, it

1356
00:50:08,800 --> 00:50:10,120
would also be an app.

1357
00:50:10,200 --> 00:50:10,680
Yeah, yeah.

1358
00:50:10,920 --> 00:50:11,300
So...

1359
00:50:11,300 --> 00:50:13,740
How does that converge class, say, trying to

1360
00:50:13,740 --> 00:50:14,880
take other functions?

1361
00:50:15,180 --> 00:50:17,560
Well, I think there's a very strong relevance.

1362
00:50:17,800 --> 00:50:21,240
Like, over recent work that we submitted to

1363
00:50:21,240 --> 00:50:24,980
Neoreps, it's basically on kinodynamic, like, how

1364
00:50:24,980 --> 00:50:27,400
can you come up with these travel time

1365
00:50:27,400 --> 00:50:29,580
fields in dynamic space?

1366
00:50:30,360 --> 00:50:32,440
I'm unaware of work that you are discussing,

1367
00:50:32,500 --> 00:50:35,140
so I cannot comment on their relation.

1368
00:50:35,560 --> 00:50:38,460
But, in general, we want to go toward

1369
00:50:38,460 --> 00:50:38,980
vector fear.

1370
00:50:39,220 --> 00:50:41,500
But we want to go toward that without

1371
00:50:41,500 --> 00:50:43,700
expert demonstration, without learning from expert

1372
00:50:43,700 --> 00:50:46,100
data, or just by solving those PDEs.

1373
00:50:46,580 --> 00:50:47,080
Okay?

1374
00:50:47,320 --> 00:50:49,220
I'm unaware of what the work.

1375
00:50:49,340 --> 00:50:50,880
Maybe you can share, and I will be

1376
00:50:50,880 --> 00:50:52,820
happy to get back to you.

1377
00:50:53,300 --> 00:50:53,520
Yeah.

1378
00:50:53,520 --> 00:50:55,140
Any other questions?

1379
00:50:59,560 --> 00:51:00,760
I have a question.

1380
00:51:02,080 --> 00:51:07,060
One problem I only have is that if

1381
00:51:07,060 --> 00:51:09,900
the ball is close to a constraint, then

1382
00:51:09,900 --> 00:51:10,520
the solution

1383
00:51:11,060 --> 00:51:12,060
can be pretty unstable.

1384
00:51:15,040 --> 00:51:18,060
During solving the process, the process is, like,

1385
00:51:18,360 --> 00:51:20,040
the force around the constraint.

1386
00:51:20,780 --> 00:51:23,180
Does your problem have a similar problem?

1387
00:51:23,720 --> 00:51:24,300
Yes.

1388
00:51:24,500 --> 00:51:27,080
So the way you sample data is very

1389
00:51:27,080 --> 00:51:27,560
important.

1390
00:51:28,540 --> 00:51:31,460
Like, I think it's, in my, in our

1391
00:51:31,460 --> 00:51:34,120
experience, like, creating a curriculum helps, like, starting

1392
00:51:34,120 --> 00:51:37,020
with a simpler problem and then slowly coming

1393
00:51:37,020 --> 00:51:38,520
up with start and goal that are very

1394
00:51:38,520 --> 00:51:40,000
far helps.

1395
00:51:40,340 --> 00:51:43,080
And then another thing that helps is, like,

1396
00:51:43,080 --> 00:51:46,600
having more samples that are near obstacles, because

1397
00:51:46,600 --> 00:51:48,540
those are the areas where you have sharp

1398
00:51:48,540 --> 00:51:50,480
features and you want your neural network to

1399
00:51:50,480 --> 00:51:51,240
learn those better.

1400
00:51:51,240 --> 00:51:54,700
So, yes, so we, we do suffer from

1401
00:51:54,700 --> 00:51:57,900
those problems and having some adaptive sampling helps.

1402
00:51:57,900 --> 00:51:58,000
Yes.

1403
00:51:58,120 --> 00:51:58,720
I see.

1404
00:51:58,820 --> 00:52:02,040
But after you finish your training successfully, that

1405
00:52:02,040 --> 00:52:04,160
means, uh, it's equally

1406
00:52:04,760 --> 00:52:07,220
cheaper to, uh, sample go up in your

1407
00:52:07,220 --> 00:52:07,740
off-store.

1408
00:52:09,560 --> 00:52:12,300
If you're following the gradients and because it's

1409
00:52:12,300 --> 00:52:14,580
an approximation, it can go to local minima.

1410
00:52:14,700 --> 00:52:16,460
But if you use this neural network as

1411
00:52:16,460 --> 00:52:19,060
a value function and incorporate within some MPPI,

1412
00:52:19,300 --> 00:52:20,220
then

1413
00:52:20,220 --> 00:52:23,020
it helps overcome those local minima issue and

1414
00:52:23,020 --> 00:52:24,400
it, it does better.

1415
00:52:24,560 --> 00:52:24,940
I see.

1416
00:52:25,240 --> 00:52:25,340
I see.

1417
00:52:25,580 --> 00:52:26,140
Of course.

1418
00:52:26,640 --> 00:52:26,760
Yes.

1419
00:52:26,880 --> 00:52:27,120
Thank you.

1420
00:52:27,300 --> 00:52:29,700
And there was...

1421
00:52:29,700 --> 00:52:30,260
Yeah.

1422
00:52:33,040 --> 00:52:35,320
Uh, do we know what methods the, uh,

1423
00:52:35,720 --> 00:52:36,440
commercial...

1424
00:52:39,580 --> 00:52:41,600
I see maybe, uh, usually they are, like,

1425
00:52:41,860 --> 00:52:44,280
I don't know what they are using, but

1426
00:52:44,280 --> 00:52:44,520
usually

1427
00:52:44,520 --> 00:52:47,460
it would be some classical technique or, or,

1428
00:52:47,700 --> 00:52:50,140
or some classical motion planner or something

1429
00:52:50,140 --> 00:52:50,500
like that.

1430
00:52:51,120 --> 00:52:52,960
I, I would assume that would be the

1431
00:52:52,960 --> 00:52:53,600
case, but I'd...

1432
00:52:53,600 --> 00:52:54,020
I'd...

1433
00:52:54,320 --> 00:52:55,020
I'd...

1434
00:52:55,080 --> 00:52:55,780
I'd...

1435
00:52:55,780 --> 00:52:56,300
I'd...

1436
00:52:59,300 --> 00:53:00,700
I'd...

1437
00:53:00,700 --> 00:53:00,780
I'd...

1438
00:53:00,780 --> 00:53:00,960
I'd...

