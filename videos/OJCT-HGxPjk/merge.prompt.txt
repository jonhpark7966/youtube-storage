# Merge chunk outputs into final Markdown

You are given multiple Markdown chunks from a transcript.
Merge them into a single, well-structured document.

Context:
- Title: Training General Robots for Any Task: Physical Intelligence’s Karol Hausman and Tobi Springenberg
- Description: Physical Intelligence’s Karol Hausman and Tobi Springenberg believe that robotics has been held back not by hardware limitations, but by an intelligence bottleneck that foundation models can solve. Their end-to-end learning approach combines vision, language, and action into models like π0 and π*0.6, enabling robots to learn generalizable behaviors rather than task-specific programs. The team prioritizes real-world deployment and uses RL from experience to push beyond what imitation learning alo
- Language: Korean

Rules:
- Output Markdown only.
- Use the same language as the chunks.
- Start with: `# Training General Robots for Any Task: Physical Intelligence’s Karol Hausman and Tobi Springenberg`
- Then include exactly 3 summary lines as a numbered list (1. 2. 3.).
- After that, organize content into chapters:
  `## Chapter N: <Topic> (<MM:SS>-<MM:SS>)`
- Under each chapter, use bullet points with timestamp tags:
  `- [MM:SS] <Detailed note>`
- Preserve all blockquotes (key statements) from the chunks:
  > "[MM:SS] Quote" — Speaker
- Remove duplicate content from overlapping regions.
- Maintain chronological order by timestamps.
- Do not omit important information; keep notes detailed.
- Do not add sections beyond summary and chapters.

Chunk outputs:
<<<
## 트랜스크립트 노트 (로보틱스 파운데이션 모델 / Physical Intelligence)

- [00:00] 범용 학습 알고리즘에 데이터를 넣으면 “어째서인지” 이해하고 이전 어떤 방식보다 더 잘해내는 현상이 매우 놀랍다고 언급
  - [00:17] 이 현상이 로봇뿐 아니라 비전·언어·소리 등 다양한 모달리티 전반에 적용된다고 강조
  - [00:25] “실제로 작동한다”는 사실 자체가 충격적이라고 말함
- > "[00:29] 그리고 실제로 작동한다는 것 자체가 정말로 충격적일 정도입니다" — (발언자 미상)

- [00:49] 에피소드 소개: 카롤·토비(Physical Intelligence)와 함께 “로보틱스를 위한 파운데이션 모델”을 만드는 접근을 다룸
  - [00:56] 로보틱스를 인식·계획·제어로 나누는 고전적 접근이 왜 근본적으로 잘못됐는지 논의 예고
  - [01:03] 엔드투엔드 강화학습 기반 학습이 실제 배치를 가능하게 만든다는 주장 예고
  - [01:09] 로봇이 13시간 커피를 만들게 한 사례, 전혀 다른 과업으로의 일반화, 수술 로봇·드론 비행까지의 확장 가능성을 언급
  - [01:20] π* 0.6(파이 스타 0.6)의 기술적 통찰 예고: “경험으로부터 학습”하고 강화학습을 활용하는 최신 모델

- [01:28] 진행자가 카롤·토비에게 감사 인사 및 대화 시작
- [01:39] 진행자 질문: Physical Intelligence가 무엇이며 어떤 미션을 추구하는지
- [01:43] (카롤 발언으로 보임) 회사 미션: “어떤 로봇이든 어떤 과업이든 수행”할 수 있는 로보틱 파운데이션 모델 개발
  - [01:57] 지난 약 1년 반 동안 구축을 시작했고, “확장 가능성”을 보여주는 올바른 구성요소들을 마련했다고 설명
  - [02:09] 다양한 로봇 폼팩터/여러 종류 로봇을 제어 가능함을 보였고, 새로운 환경으로 가져가도 일반화가 가능함을 시연했다고 말함
  - [02:22] 최근 출시한 π* 0.6이 “성능 수준까지 끌어올리는 방법”을 보여주며, 배포 가능한 수준에 도달하기 시작하는 것이 중요하다고 강조
  - [02:38] 로봇 행동 데이터는 인터넷의 “무료 데이터” 혜택을 누리기 어려워, 데이터셋을 직접 만들어야 한다는 제약을 설명

- [02:58] 진행자 질문: 로봇 제품(수직 통합) 대신 “파운데이션 모델”을 만들기로 한 이유 (가정용 로봇, 요리 로봇, 휴머노이드 등과 대비)
- [03:22] (토비 추정) 로봇공학의 역사에서 병목은 하드웨어가 아니라 “지능”이었다는 관점 제시
  - [03:31] 가정/산업 환경 모두에서 하드웨어는 이미 놀라운 일을 할 수 있었고, 10년+ 전에도 원격조종만 되면 집 청소가 가능했다는 예시
  - [03:47] 핵심 단서: “원격 조종일 때” — 즉 인간 두뇌가 뒤에 있으면 하드웨어가 다양한 일을 할 수 있다는 점을 강조
  - [04:02] 기존 회사들은 특정 로봇을 특정 작업/응용 하나에 맞춰 설계해 왔다고 지적
  - [04:10] 자신들은 분야에 가장 도움이 되는 “병목(지능)”에 집중하기 위해 회사를 세웠고, 그 병목을 해결해야 로봇을 현실화할 수 있다고 주장
  - [04:36] 지능 병목을 풀면 다양한 버티컬 제품으로 이어지고, 가정·산업 현장 등 사실상 어디에든 배포될 것이라고 전망

- [04:44] 진행자: 하드웨어 측면 추가 질문 예고(예: 옵티머스 손의 정교함을 언급하며 화제가 이어짐)
  - [04:50] 최근 영상에서 옵티머스 손이 “예술 작품” 같을 정도로 정교하다고 인상 표현

---

- [06:59] 앞에서 보여준 내용은 “기본적으로 가능하다”는 점을 시사함.
- [07:02] 핵심 전제: 어떤 작업이든, 어떤 로봇이든 데이터를 수집할 수만 있다면
  - [07:05] 그 작업을 자동화할 수 있고
  - [07:07] 모델이 그것을 학습할 수 있음.
- [07:10] 다음 과제는 “일반화(generalization)”이며 아직 열린 문제(open problem)라고 강조함.
- [07:14] 목표: 로봇이 제로샷(zero-shot)으로 바로 작동하는 수준.
  - [07:18] 예: 로봇을 “새 집”에 데려가도 그 집에서 어떻게 작동해야 하는지 알아야 함.
  - [07:23] 이 문제는 “정말로 매우 어려운 문제”라고 재강조함.
- [07:25] 새 집 환경에서 필요한 이해 요소들:
  - [07:28] 물건들이 어디에 있는지 파악해야 함.
  - [07:29] 조리대가 다르게 보일 수 있음.
  - [07:30] 조명이 과거에 본 것과 다를 수 있음.
  - [07:33] 등 다양한 변화가 존재함.
- [07:35] “해결됐다”고는 말하지 않지만,
  - [07:38] 어떻게 풀지에 대한 감을 잡기 시작했고
  - [07:40] 어떻게 확장(scale)되는지도 보고 있다고 말함.
- [07:43] 머신러닝에서 일반화의 “유일한 해답”으로 제시한 것:
  - [07:45] 데이터의 다양성(diversity of data).
  - [07:48] 서로 다른 다양한 데이터셋을 많이 보면
  - [07:50] 본 환경과 “유사한” 환경으로 일반화할 수 있어야 한다는 관점.
- [07:55] 이 가설을 `π0.5`(올해 4월 공개)에서 확인했다고 언급함.
- [07:58] 성과 진술(혼합 언어 포함):
  - [07:58] “that we we got to the point where”
  - [08:00] 로봇을 완전히 새로운, 처음 가보는 집으로 데려가도
  - [08:02] 그 집에서 실제로 작동할 수 있는 수준까지 왔다고 말함(아직 완벽하진 않음).
- [08:07] 현재 수준의 직관/상식:
  - [08:08] 간단한 작업(예: 주방 치우기)을 어떻게 할지 “일종의 상식”이 있음.
- [08:12] 남은 마지막 과제:
  - [08:15] “아직 완전히 해결되지 않은 성능 문제”.
  - [08:17] 실제 배포할 만큼 성능을 충분히 끌어올리는 것이 목표.
- [08:22] 배포(deployment)의 중요성:
  - [08:27] 계속 데이터를 모아야 하고
  - [08:29] 배포가 데이터 수집의 가장 확장 가능한 방법이 될 것이라 봄.
- [08:32] 배포가 데이터 수집을 “경제적으로” 바꾸는 논리:
  - [08:34] 세상 밖에서 경제적으로 가치 있는 일을 하는 로봇들이 생길 것이고
  - [08:37] 그러면 데이터 수집 비용이 사실상 “마이너스”가 됨.
  - [08:41] 더 많이/더 넓게 배포할수록 더 많은 데이터를 얻게 됨.
  - [08:47] 궁극적으로 인터넷 데이터보다 훨씬 큰 규모의 데이터 원천이 될 수 있다고 주장.
- [08:51] 질문(인터뷰어): 통제된 환경/가정/사무실 등 범위를 제한했을 때
  - [08:57] 배포 가능하다고 보는 일반화/성능 수준은 어느 정도인지 질문함.
- [09:12] 답변: 로봇 배포가 “꽤 가까워졌다”고 평가함.
  - [09:18] 이미 배포를 직접 시작했다고 말함.
  - [09:21] 원래는 상업 환경 배포까지 5년 정도 걸릴 것으로 봤지만
  - [09:32] “아마 두 달 전쯤 이미 해냈다”고 말함.
- [09:37] 현재 임계점(threshold) 진술:
  - [09:38] 모델이 충분히 유용하고
  - [09:40] 성능도 충분히 좋으며
  - [09:42] 충분히 다양한 작업을 수행할 수 있어 “실제로 쓸 만한 수준”이 됐다고 함.
  - [09:48] “정말 흥분되는 순간”, 임계점을 막 넘었다는 표현.
- [09:53] 단, 적용 범위(어디에 배포 가능한가)는 아직 더 지켜봐야 한다고 말함.
  - [09:57] 실패가 치명적일 수 있는 작업은 아직 이르다고 함.
  - [10:03] 일반화가 매우 많이 필요한 작업(예: 가정 배포)은
    - [10:07] 프라이버시/안전 문제 등도 있어 최적의 초기 배포처가 아닐 수 있다고 언급.
  - [10:14] 데이터를 더 모으고 모델이 더 좋아질수록 적용 범위는 계속 넓어진다고 전망.
- [10:22] 질문: 현재 실제로 배포 중인 적용 범위가 어느 정도인지.
- [10:27] 답변: 매우 어려운 질문이라고 전제함.
  - [10:32] 파운데이션 모델은 때때로 역량을 완전히 알기 어렵다고 설명.
  - [10:39] 대규모 언어 모델도 비슷하게, 학습/개선해도 최종 산출물 성능을 사전에 예측하기 어렵다고 함.
  - [10:52] 결국 “실제로 테스트를 해봐야” 하며, 로봇 모델도 지금 그 단계라고 함.
- [10:56] 오픈소스 공개 이유/효과:
  - [10:59] 자신들만 테스트하는 상황을 피하고
  - [11:03] 역량 파악에서 “병목”이 되지 않게 하려는 목적.
  - [11:08] 예상보다 훨씬 다양한 응용(예: 자율주행, 수술 로봇, 농업 등)이 나올 수 있다고 말함.
- [11:21] 결론적으로 적용 범위의 정확한 추정치는 없지만
  - [11:25] 예상보다 더 넓고
  - [11:29] 데이터가 늘수록 모델이 성숙하며 범위가 계속 넓어질 것이라고 전망.
- [11:34] 성능 관련 보완:
  - [11:41] 출발점(가능한 적용 범위)은 생각보다 넓지만
  - [11:45] 각 응용 분야에서 사람들이 “매일 운전하듯” 일상적으로 쓰려면
  - [11:56] 성능 측면에서 여전히 할 일이 크다고 말함.
- [12:00] 이번 릴리스(`π*0.6`로 지칭되는 맥락)에서의 진전:
  - [12:05] “경험으로부터 학습”에서 진전을 이뤘고
  - [12:06] 경험 데이터를 가져와 다시 반영해 모델을 더 좋게 만들었다고 함.
  - [12:09] 배포된 상태에서도(online/배포 후) 개선이 이뤄졌음을 시사.
- [12:12] 아직 남은 근본적 어려움:
  - [12:16] 정말 많은 상황이 잘못될 수 있는 “긴 꼬리(long tail)” 문제가 있고
  - [12:22] 이를 완전히 어떻게 해결할지 좋은 이해가 아직 없다고 솔직히 말함.
- [12:27] 질문(인터뷰어): 기술 아키텍처 개요와, 목표 달성을 위해
  - [12:45] 아키텍처가 거의 굳었는지 vs 계속 정립 중인지,
  - [12:50] 데이터만 엄청 모으면 되는지 vs 아키텍처 변화가 필요한지 질문함.
- [12:55] 답변: (둘 다) 열려 있으며, 먼저 “현재 어디까지 왔는지” 설명 후 변화 가능성을 말하겠다고 함.
- [13:04] 현재 아키텍처는 오늘날 VLM(비전-언어 모델) 구축 방식과 매우 유사하다고 설명.
  - [13:15] 예시: 텍스트 입력 + 이미지 입력 후 이미지에 무엇이 있는지 읽게 하는 상호작용과 유사.
  - [13:20] 자신들도 비슷한 출발점에서 시작했다고 함.
- [13:23] 학습 데이터 구성:
  - [13:25] 인터넷 규모 데이터로 학습된 모델을 바탕으로
  - [13:27] 이미지와 텍스트를 받아들이며
  - [13:30] 여기에 로보틱스 데이터를 추가.
  - [13:33] 현재는 주로 직접 수집한 로보틱스 데이터 기반.
  - [13:36] 인터넷 데이터도 약간 섞이지만 대부분은 로보틱스 데이터.
- [13:41] 모델 구성 요소:
  - [13:43] 비전-언어 모델(VLM)
  - [13:47] 옆에 “액션 모델/액션 익스퍼트”를 더함(로봇을 구동하는 부분).
  - [13:57] 이미지와 지시(instruction)를 받아
  - [14:00] 작업을 수행하며 로봇에 명령을 보내야 한다고 설명.
- [14:05] 모델 형태/규모:
  - [14:05] 전반적으로 트랜스포머(Transformer) 모델.
  - [14:07] 상당히 큰 모델이며
  - [14:09] 현재는 수십억 파라미터까지 사용.
- [14:12] 학습 절차:
  - [14:12] 사전학습(pretraining) 후
  - [14:13] 로보틱스 데이터와 인터넷 데이터로 학습.
  - [14:18] 초기에는 인간 시연(demonstration) 데이터로 학습.
  - [14:24] 사람이 원격조작으로 로봇을 움직이며 작업시키는 데이터라고 설명.
- [14:31] 스케일링 관점:
  - [14:32] 얻는 성과는 데이터 규모를 키우는 것에서 주로 나온다고 함.
  - [14:37] VLM 분야에서 온 것과 유사한 모델을 사용한다고 재언급.
- [14:39] 향후 아키텍처 변화 가능성은 “열린 질문”이라고 명확히 함.
  - [14:45] 모델에 더 많은 역량을 추가할 기회가 많다고 봄.
  - [14:53] 더 많은 컨텍스트를 넣고 싶을 수 있음.
  - [14:56] 더 많은 카메라를 로봇에 달아 모델이 활용하게 할 수도 있음.
  - [15:07] 물리 세계를 더 잘 이해(방 안의 구성, 무엇이 깨질 수 있는지/쉽게 움직이는지 등)하도록 하고 싶다고 말함.
  - [15:15] 역량 측면에서도, 아키텍처 측면에서도 할 일이 많다고 정리.
- [15:22] 5~6년 뒤에는
  - [15:27] 당시 사용하던 “모델 백본”이 VLM 계열에서 다른 것으로 바뀌었을 수도 있다고 전망.
  - [15:38] 시간에 따라 진화하겠지만
  - [15:41] 데이터 기반과 “그것을 모델에 넣는 방식”은 비슷하게 남을 수 있다고 봄.
- [15:50] 문제를 “픽셀/신호 입력 → 행동 출력”으로 보면 된다고 정리하며
  - [15:55] “하나의 아주 큰 신경망”, “하나의 큰 모델” 관점으로 설명.
- [15:59] 현재 입출력 형태:
  - [15:59] 이미지를 입력으로 받고
  - [16:01] 텍스트를 입력으로 받고
  - [16:02] 텍스트를 출력으로 내며
  - [16:03] 행동도 출력한다고 말함.
- [16:05] 질문(인터뷰어): 이동(mobility)과 조작(manipulation)을 구분한 스택이 있는지, 그리고 로보틱스 학습의 역사적 진화와 스택의 관련성을 묻고자 함.
- [16:21] 답변: 학습이 들어오기 전 로보틱스의 전통적 접근:
  - [16:28] 사람/엔지니어를 충분히 투입하면
  - [16:35] 로봇이 세상에서 무엇이든 하게 만드는 코드를 쓸 수 있다고 생각해 왔음.
  - [16:40] 사람들이 매우 열심히 그 방식으로 시도해 왔다고 함.
- [16:43] 하지만 결론:
  - [16:43] 세상은 너무 복잡함.
  - [16:46] 마주칠 모든 경우를 현실 세계에서 코드로 일일이 써둘 수 없어 그 방식은 작동하지 않았다고 함.
  - [16:54] 그 문제 버전에 대해 작업하던 동안, 결국 사람들은 늘 하던 대로 이 문제를(이후 발화는 다음 청크로 이어짐).

> "[07:43] 머신러닝에서 일반화에 대한 유일한 해답은 결국 데이터의 다양성입니다." — (발화자 미상)

> "[08:37] 그 데이터 수집 비용은 사실상 마이너스가 되며," — (발화자 미상)

> "[10:52] 실제로 테스트를 해봐야 하고," — (발화자 미상)

---

## 로봇 모델 스택(현재)과 확장 방향

- [14:00] 로봇이 작업을 수행하려면 로봇에 명령(행동)을 보내야 하며, 전반적 구조는 트랜스포머 기반의 큰 모델임.
  - [14:09] 모델 규모는 현재 수십억(빌리언) 파라미터까지 사용함.
- [14:12] 사전학습을 하고, 로보틱스 데이터와 인터넷 데이터로도 학습을 진행함.
  - [14:18] 초기 단계에서는 인간 시연 데이터(원격조작으로 로봇이 어떤 행동을 하도록 만든 데이터)로 학습함.
- [14:31] 스케일링(성능 향상)의 핵심은 데이터 규모를 키우는 데서 온다고 봄.
  - [14:37] VLM(비전-언어 모델) 분야에서 온 것과 유사한 모델을 사용하고 있음.
- [14:42] 앞으로 아키텍처가 어떻게 바뀔지는 “열린 질문”이지만, 모델 역량을 더 키울 기회가 많다고 봄.
  - [14:53] 더 많은 컨텍스트를 모델에 넣는 방향을 고려할 수 있음.
  - [14:56] 로봇에 더 많은 카메라를 달아 모델이 더 많은 시각 정보를 쓰게 할 수도 있음.
  - [15:07] 물리 세계를 더 잘 이해(방 안에 무엇이 있는지, 무엇이 깨질 수 있는지, 무엇이 쉽게 움직이는지 등)하도록 만드는 과제가 큼.
  - [15:16] 역량을 키우는 것뿐 아니라, 아키텍처를 바꾸는 측면에서도 할 일이 많다고 언급함.
- [15:22] 5~6년 뒤에는 당시의 모델 백본이(현재의 VLM 계열에서) 다른 무언가로 진화해 있을 수 있다고 전망함.
  - [15:41] 다만 “데이터의 기반”과 “그 데이터를 모델에 넣는 방식”은 계속 비슷하게 남을 가능성이 크다고 봄.
- [15:50] 문제를 “픽셀/신호 입력 → 행동 출력”으로 보는 관점: 아주 큰 단일 신경망이 입력(이미지, 텍스트)을 받고 출력(텍스트, 행동)을 내는 형태로 설명함.

> "[14:43] 열린 질문이라고 생각합니다." — (화자 미상)  
> "[15:23] 5~6년쯤 후에 우리가 돌아보며 '아, 아마 그때의 모델 백본이 … 이미 바뀌었을지도'…" — (화자 미상)

## 이동/조작 분리 여부와 로보틱스 접근의 역사적 흐름

- [16:05] 질문: 이동과 조작을 구분한 별도의 스택이 있는지, 그리고 로보틱스의 역사적 진화/학습의 여러 물결이 현재 스택과 어떻게 연결되는지 묻는 흐름으로 전환됨.
- [16:21] 학습이 들어오기 전의 오랜 기간에는 “충분한 엔지니어가 깊이 고민해 코드를 쓰면 로봇이 세상에서 무엇이든 하게 만들 수 있다”는 관점이 강했음.
  - [16:43] 하지만 현실 세계는 너무 복잡해서, 마주칠 모든 경우를 코드로 일일이 작성하는 방식은 작동하지 않았다고 설명함.
- [16:57] 그 결과 문제를 더 작은 하위 문제로 쪼개는 접근이 등장함.
  - [17:05] 인지(perception), 제어(control), 계획(planning) 등으로 분해했고, 각 분야가 별도 커뮤니티/학회로까지 분화했음.
- [17:21] 모든 규칙을 손으로 쓰는 것이 불가능하다는 걸 깨닫고 “데이터로부터 학습해야 한다”는 방향으로 이동함.
  - [17:34] 다만 이때도 하위 요소(인지 계층, 제어 계층, 플래너)를 분리해 각각 따로 학습하는 방식이 주로 시도됨.
  - [17:46] 이 방식은 어느 정도 진전은 있었지만, 결국 근본적으로는 한계가 드러났다고 말함.
- [17:58] 하위 구성요소로 분해하는 접근이 실제로 잘 작동하지 않는 이유: 인간은 “인지→계획→제어”를 단계적으로 의식하지 않고, 자연스럽게 바로 행동하기 때문이라는 비유를 듦.
  - [18:12] 파이프라인 접근(인지가 물체 위치를 주고, 플래너가 궤적을 주며, 제어가 실행하는 식의 미리 정의된 인터페이스)이 무너지는 지점이 있었고, 그 과정에서 “우리가 어떻게 작동하는지 안다고 생각했던 것들이 늘 틀렸다”는 결론으로 이어짐.

> "[16:43] 결국 세상은 너무나 복잡하다는 것이 드러났습니다." — (화자 미상)  
> "[18:00] 제가 이 잔을 집어 들려고 할 때 저는 그것을 인지하고 그다음 계획하고 그다음 제어한다고 생각하지 않고, 그냥 바로 손을 뻗어서 잔을 집어 듭니다." — (화자 미상)

---

## 하위 과제 분해와 행동 계획(플래닝)
- [20:59] 로봇/에이전트가 상위 지시를 받으면(예: “부엌을 청소해”) 스스로 첫 하위 과제를 고르고, 필요한 행동을 순서대로 떠올리는 식의 분해가 이미 가능하다고 봄.
  - [21:06] 예시로 “카운터로 이동 → 유리컵을 집기 → 싱크대로 옮기기”처럼 구체 행동을 단계화함.
- [21:20] 이런 과정은 상위 과제를 스스로 부여하고, 짧은 행동 지평(미래의 몇 단계 행동)을 예측하는 형태로 이해할 수 있음.
- [21:31] “추론을 위한 학습” 등 최근 발전이 로보틱스에도 자연스럽게 유입되며, 이런 능력(분해·예측)이 더 강화될 것으로 기대함.

> "[21:01] 예를 들어 ‘부엌을 청소해’라고 시키면" — 화자  
> "[21:08] 카운터로 이동해야 하고… 유리컵을 집어 싱크대로 옮겨야 한다" — 화자

## 텍스트 추론(RL) vs 물리적 지능의 차이
- [21:46] 수학 문제 같은 텍스트 기반 RL과 로보틱스/물리적 지능은 성격이 다를 수 있다고 봄.
- [21:52] 수학·코딩 같은 텍스트 문제는 인간에게 매우 쉬워 “머릿속에서 텍스트로 조작(공식 변형 → 결과)”하기가 편함.
- [22:07] 물리적 지능에서는 텍스트적 사고보다 “동작 자체”를 떠올리는 쪽에 가깝다고 설명함.
  - [22:14] 새 스포츠(예: 테니스)를 배울 때 “라켓을 잡고 여기로 옮기고…” 같은 문장형 계획보다, 몸의 움직임/감각을 중심으로 사고함.
  - [22:33] 물체의 궤적이 주변에서 어떻게 움직일지 머릿속으로 그리며 계획하는 느낌에 가깝다고 함.
- [22:40] 시간이 지나면서 이런 “동작·궤적 중심” 계획 방식이 모델에도 더 많이 반영될 것으로 봄.

## 로보틱스가 추론을 재정의할 가능성(멀티-스페이스 추론)
- [22:47] 현재는 비전-언어 모델(VLM)에서 큰 혜택을 보고 있지만, 장기적으로는 흐름이 “거꾸로” 될 수 있다고 전망함.
- [22:58] 오늘날 LLM의 한계 일부는 수학·코딩 같은 “텍스트 문제 중심” 최적화와 관련될 수 있다고 봄.
- [23:10] 로보틱스가 새로운 길을 제시해 “추론을 어떻게 생각할지”를 다시 고민하게 만들 것이라 주장함.
- [23:14] 추론은 단일(텍스트) 공간이 아니라 여러 추상 공간을 오가며 이뤄질 수 있음.
  - [23:20] 텍스트로도 일부 추론하고, 이미지로도 일부 추론하며, 궤적(trajectory) 같은 표현으로도 추론해 답에 도달할 수 있다는 관점.
- [23:28] 로보틱스는 물리 세계에 기반한 좋은 테스트베드이지만, 데이터가 아직 충분히 많지 않아 그에 따른 어려움도 함께 다뤄야 한다고 언급함.
- [23:45] 그 과정에서 나온 새로운 발견이 다시 LLM 세계에도 재적용될 것이라고 봄.

## 데이터 규모·품질·다양성: 정의의 어려움과 “더 많이”의 한계
- [23:49] 진행자가 데이터 규모를 어떻게 측정하는지, 이미 수집한 데이터는 어느 정도인지, 향후 1년(내년까지) 얼마나 더 모으려는지 감을 요청함.
- [24:08] 데이터가 최근 새로 주목받고 있으며, 단순히 “양”만의 문제가 아니라고 강조함.
- [24:12] 품질은 물론 중요하고, 다양성도 중요하지만 로봇 데이터에서 “품질/다양성”은 엄밀히 정의된 용어가 아니라고 지적함.
  - [24:26] 같은 작업을 10가지 방식으로 수행한 것이 다양성인지, 그리고 이를 “10개의 서로 다른 유리컵을 집는 경우” 같은 다른 다양성과 어떻게 비교할지 불명확함.
- [24:37] 커뮤니티 차원에서 데이터를 어떻게 특성화할지(다양성·품질을 엄밀하게 기술하는 방법 포함) 아직 완전히 이해하지 못했다고 말함.

## 성능 정체와 RL의 역할(π, π*0.6 맥락)
- [24:59] 어떤 작업에서 일정 성능에 도달하려면 “데이터 양만 늘린다고” 계속 좋아지지 않는 구간이 존재한다고 설명함.
- [25:04] 현재 가진 데이터만으로는 부족했고, 동일한 방식으로 더 수집해도 성능이 정체되어 더 이상 개선되지 않았다고 함.
- [25:08] π와 π*0.6 릴리스를 위해 서로 다른 3가지 과제로 작업하며 이런 점을 초반부터 체감했다고 언급함.
- [25:22] 따라서 새로운 방식으로 데이터를 수집하거나, “어떤 종류의 데이터가 더 나은 성능으로 이어지는지”로 사고를 전환해야 한다고 말함.
- [25:31] 이 지점에서 강화학습(RL) 같은 접근이 큰 도움이 된다고 연결함.
- [25:36] 진행자가 RL과 π*0.6을 본격적으로 이야기하자고 제안함.
  - [25:40] 진행자가 “스타(*)가 Q*를 의식한 것이냐”, “최적 정책(policy*)을 뜻하냐”를 확인하며 명명 의미를 질문함.
- [25:51] 진행자가 “π*0.6에서 무엇을 하고 있는지” 한마디로 설명해 달라고 요청하고, 이어서 그들의 세계에서 RL이 무엇을 의미하는지 들어가겠다고 함.
- [25:59] 답변자가 “아까 이야기한 것과 대비해 보면…”으로 다음 설명을 이어가려는 지점에서 구간이 끝남.

---

`videos/OJCT-HGxPjk/chunks/chunk_005.md:1` 생성했습니다 (타임스탬프 포함 상세 마크다운 노트, 인용문은 블록쿼트로 정리).

---

## 배포 혁신 vs 근본 역량

- [34:59] 질문: 커피 제조 같은 모델을 고객 현장에 **안정적으로 배포**(빠르고, 실패율 낮고, 장기간 안정)할 수 있게 만드는 것이 “배포 측면 혁신”인지, “근본 역량 혁신”인지(혹은 둘 다인지) 확인.
- [35:20] 답변: **둘 다**라는 입장(배포 가능성 자체가 역량과 연결됨).

## “우리가 정말 원하는 로봇”과 현장 요구

- [35:26] 목표 로봇 상: 집에서 **세탁/설거지/요리**, 돌아다니며 **운전**까지 하는 범용 로봇.
  - [35:34] 소규모 사업장에서도 사람들의 “실제 문제”를 해결하는 로봇 수요가 존재.
- [35:40] 전통적 자동화를 원치 않는 이유: **비용이 너무 비싸서**.
  - [35:41] 예시 과업: **초콜릿 상자 만들기** 같은 작업.
- [35:44] 이런 과업의 전제: 로봇이 **신뢰할 수 있어야** 하며,
  - [35:47] **성능**이 좋아야 하고,
  - [35:48] 초기 훈련에서 못 본 **새로운 과업**도 해낼 **일반화 역량**이 필요.

> "[35:40] 전통적인 방식으로 자동화하고 싶지 않은데, 그 이유는 그것이 너무 비싸기 때문입니다." — (발언자 미상)  
> "[35:48] 초기 훈련에서 보지 못한 새로운 과업을 해낼 수 있는 역량도 필요합니다." — (발언자 미상)

## “인간 데이터만 더 모아 크게”의 한계와 배포 데이터의 가치

- [35:54] 주장: **인간 데이터 수집만 계속 늘리고 모델을 더 키우는 것**만으로는 비현실적이라는 견해.
  - [36:04] 한계 1: “얼마나 좋아질 수 있는지”와 “얼마나 많은 데이터를 얻을 수 있는지”에 상한이 존재.
  - [36:08] 한계 2: **초기 정책(initial policy)** 품질에도 한계가 있음.
- [36:11] 배포는 필요하지만, 앞으로 몇 년 동안은 **배포로부터 얻는 데이터**가
  - [36:24] 모델을 더 좋게 만드는 **사전학습(pretraining) 원천**으로 “아주 가치 있어질 것”이라는 전망.
- [36:28] 예측: 시간이 갈수록 **자율 데이터 수집**(autonomous data collection)에 더 의존하게 될 것.
  - [36:37] 로봇이 결국 하길 원하는 모든 과업을 덮는 **“볼록 껍질(컨벡스 헐)”** 같은 방대한 데이터 구축을 지향.
  - [36:44] 그 데이터로 모델이 과업들을 **수행**하고 **보간(interpolate)** 할 수 있게 되는 것을 “지금까지 없던 새로운 역량”으로 봄.

> "[36:21] 이 배포를 하게 되고 그 데이터가 실제로 아주 가치 있어질 것이라고 생각합니다. 모델을 더 좋게 만드는 사전학습의 원천으로서요." — (발언자 미상)  
> "[36:37] 우리가 로봇이 결국 하길 원하는 모든 과업의 볼록 껍질(컨벡스 헐)이 되는 방대한 데이터를 구축해서," — (발언자 미상)

## 자기 경험으로부터 배우기: 아직 미해결이지만 “중요한 첫걸음”

- [36:52] 현황: 로봇이 **자기 경험으로부터 배우는 방법**을 아직 “완전히 알아내지 못했다”는 인정.
  - [36:55] 시도는 있었지만,
  - [36:57] **규모 있게** 수행되어 설득력 있는 결과(배포 가능한 수준)를 “본 적이 없다”고 언급.
- [37:07] 이번 결과의 의미: 로봇이 **자기 경험으로부터 학습 가능한 지점**으로 가는 것이 매우 중요했고, 그 방향을 보여줬다는 맥락.
- [37:13] 비유(인간 학습): 영상 보고 연습하거나 남에게 배우는 것도 가능하지만,
  - [37:23] 결국은 **현장에서 직접 해보며**,
  - [37:26] 내 행동이 목표 달성에 어떤 영향을 주는지 **피드백을 관찰**해야 한다는 논리.
  - [37:29] 스스로 결론을 내리고 다시 시도하는 방식이 핵심이며, 이번이 그 “첫걸음”이라는 평가.

> "[37:23] 어느 시점에는 결국 현장에서 배우셔야 하고, 직접 그 일을 해 보셔야 하며," — (발언자 미상)

## ‘Age of Experience’와 로보틱스의 “지속적 학습” 논의

- [37:36] 질문: 리치 서튼의 **‘Age of Experience’**를 언급하며, 이런 접근이 로보틱스에서 **지속적 학습(continual learning)**을 가능하게 하는지/일부인지 질의.
- [37:49] 답변 요지: “지속적 학습”의 정의에 따라 다르지만, **이전 방식보다 더 지속적**인 건 맞음.
  - [37:58] 과거 파이프라인: 큰 **사전학습 혼합 데이터** + (필요하면) **사후학습 혼합 데이터**로 열심히 학습해 “산출물”을 만들면,
  - [38:10] 산출물 완성 후에는 **바꾸기 어렵고** 사실상 끝나는 구조.
- [38:13] 현재 지향: 더 “살아 있는” 시스템에 가깝게,
  - [38:21] 배포 후에도 **계속 학습**하며,
  - [38:27] 새로운 것을 시도하고 **자기 경험에서 배우며** 지속적으로 개선.
  - [38:32] 다만 아직도 더 “지속적”으로 될 여지가 있고,
  - [38:37] 이런 방식으로 **새 기술을 더 빠르게 습득**할 수도 있다는 기대.
- [38:43] 추가 관점: 전 과정에서 **추론(inference/reasoning)**도 가능해질 수 있다고 보며,
  - [38:46] “직무 중에 얼마나 학습할 수 있느냐”는 **스펙트럼**이 존재.
  - [38:52] 이번은 “가능함을 보여줬다”는 점에서 유망하지만, **훨씬 더 개선** 가능하다고 평가.
- [38:57] 다른 발언자 동의: 지금은 **아주 시작 단계**이며,
  - [39:03] 고전적 의미의 지속적 학습(데이터 스트림을 가정하는 형태)과는 **확실히 다름**.
  - [39:16] 그래도 “첫걸음”이고 올바른 방향이며, 할 일이 많다고 언급.
  - [39:21] 이번 공개만 봐도 모델이 “작은 것들”을 잘 잡아내는 점이 인상적이었다고 평가.
  - [39:32] 특히 데이터를 다시 넣어주는 것뿐 아니라,
  - [39:34] **사람의 수정(human correction)**만으로도 성능이 개선되는 점을 강조하려는 흐름(후속 예시로 넘어감).

> "[38:21] 배포하고 나면 계속 학습하잖아요, 그래서 훨씬 그 의미에서 더 지속적이고," — (발언자 미상)  
> "[39:03] 고전적 의미의 지속적 학습은 확실히 아닙니다." — (발언자 미상)

---

- [41:58] 제로샷(Zero-shot) 성능도 나타나지만 계속 개선되는 중이라고 언급.
- [42:04] 일정 주기로 사전학습(pre-training) 런을 반복적으로 시작함.
  - [42:09] 매번 더 많은 데이터 투입과 개선으로 모델이 계속 좋아지는 것을 관찰.
  - [42:13] 사전학습 과정 자체의 개선도 포함된다고 설명.
- [42:18] 모델을 더 많이 배치(배포)해 다양한 작업을 수행할수록, 그 과정에서 데이터가 다시 수집되어 일반화가 더 늘어날 것이라고 확신.
  - [42:31] “배포 → 데이터 회수 → 모델 개선 → 더 많은 배포”의 선순환 루프를 강조.
- [42:47] 5~6단계 레시피의 중요한 디테일: 모델이 “두 부분”으로 구성됨.
  - [42:52] 하나는 정책(policy): 교정과 강화학습(RL) 피드백으로 개선하는 대상.
  - [42:57] 다른 하나는 RL 피드백을 “어떻게 실제로 얻는가”라는 메커니즘.
- [43:02] 인간이 교정할 수 있는 부분이 “인간 교정”이고, RL 피드백은 성격이 조금 다르며 어느 정도 일반화 측면을 이미 갖는다고 봄.
- [43:15] RL 피드백을 얻는 방식(사람 라벨 기반):
  - [43:19] 사람들에게 각 시도(에피소드)가 커피 만들기/상자 다루기 등의 작업에서 성공/실패했는지 라벨을 받음.
  - [43:29] 라벨된 에피소드들로 “가치 함수(value function)”를 학습.
- [43:32] 가치 함수의 목적: 현재 상태에서 작업 성공/실패 가능성을 예측.
  - [43:45] 이후 학습에서 기준선(baseline)처럼 쓰이며, 특정 데이터 포인트에서 값을 올릴지/내릴지(성공 쪽인지 실패 쪽인지) 판단에 활용된다고 설명.
- [43:59] (영어 구간) 가치 함수 학습 관찰:
  - [44:02] 정책 학습과 유사한 백본(backbone)에서 파생되지만, 실제 정책 학습 전에 가치 함수를 먼저 사전학습함.
  - [44:15] 서로 다른 작업에서 모은 데이터가 가치 함수 성능을 실제로 개선.
  - [44:24] 어떤 작업들에서는 실패를 “미리” 잘 알아채며, 명백해지기 전에도 실패 징후를 예측 가능.
- [44:30] (영어 예시) 포터필터(portafilter)를 커피 머신에 끼우는 작업:
  - [44:44] 올바른 각도가 아니어서 실패할 것을, 실제 실패가 발생하기 30~40스텝 전에 가치 함수 예측이 떨어지며 감지.
  - [44:54] 해당 에피소드가 “좋지 않다”고 판단해 데이터를 포함시키지 않는 의사결정에 연결된다고 설명.
- [45:00] 더 많은 데이터/더 많은 과제가 있을수록(다양성이 커질수록) 가치 함수가 더 좋아지는 점을 “흥미로운 대조”로 언급.
  - [45:04] 카르파티의 “빨대로 조금씩 빨아들이는” 비유를 연결(끝의 마지막 조각만 기다리는 게 아니라는 요지).
- [45:13] RL에 대한 관점 정리:
  - [45:20] RL을 정책 그래디언트/온-폴리시 같은 특정 방법으로만 보는 시각이 있지만, 본인에게 RL은 “문제 정의”에 더 가깝다고 설명.
  - [45:39] 보상이 끝에서만 주어지는 매우 긴 지평(long-horizon) 과제는 그대로는 확장 불가하므로,
    - [45:44] 가치 함수, 시간차(Temporal Difference) 학습 등으로 연속 예측을 통해 해결하려는 접근을 듦.
- [45:57] 로보틱스가 더 넓은 AI 커뮤니티에 기여할 수 있다는 주장:
  - [46:02] (영어) 언어처럼 “완벽한 시뮬레이터”에서 무한 시뮬레이션을 돌릴 수 있는 이점이 로봇에는 없어서,
  - [46:10] 실제 세계에서 해야 하므로 더 효율적인 방법이 필요하고, 그 결과 가치 함수 같은 것들을 학습하는 접근이 중요해지며 이것이 다른 분야에도 가치가 있을 것이라고 말함.
- [46:19] (질문 시작) “인터넷 비디오”가 레시피의 일부이긴 하지만 현재는 큰 초점이 아닌 것처럼 보이는데, 그 안에 ‘금(gold)’이 있다고 보는지 더 이해하고 싶다고 진행자가 질문을 던짐.

> “[42:31] 여러분이 이 모델들을 배포하면, 그 데이터가 돌아오고 모델은 더 좋아져서, 여러분은 더 많이 배포할 수 있으며… 이런 식입니다.” — (화자 미상)

---

- [48:59] (이전 논의의 연장선에서) 여러 접근법이 근본적으로 비슷한 문제를 겨냥하고 있으며, 다양한 방법을 탐색 중이라고 설명함.
  - [49:06] 특히 “반사실(카운터팩추얼) 문제”를 어떻게 실제로 풀 것인지가 핵심 난제로 남아 있고, 아직 정답이 있다고 말하긴 어렵다고 언급함.
  - [49:14] 그럼에도 강화학습 쪽에서 진전이 있었고, 방금 보여준 `π*`와 `π*0.6`에서도 그런 진전을 확인했다고 말함.
  - [49:21] 강화학습 외에도 다른 많은 접근 여지가 있을 수 있다고 덧붙임.
- [49:28] (질문) 부트스트랩 단계를 넘어 고객 배포를 할 때, 고객에게 “무엇을 가져가고 무엇을 판매”하는지(수직 통합 로봇 솔루션 vs 고객이 운영에 통합하는 모델 판매 등) 전반적인 GTM/상용화 형태를 질문함.
- [49:45] (답변) “진짜 답은 아직 모른다”고 솔직히 말하며, 지금도 알아가는 중이고 기술적으로도 아직 초기 단계라고 설명함.
  - [49:56] 이제 막 “배포가 가능해지는 임계치”에 도달해 배포를 시작할 수 있게 됐다고 말함.
  - [50:03] 우선순위는 기술 자체에 집중해 “정말로 쉽게 배포” 가능한 수준까지 끌어올리고, 적용 범위를 확장하는 것이라고 강조함.
- [50:12] 로봇 스타트업의 전형적 경로(범용 비전 → 특정 앱 선택 → 타협/특수 목적 최적화 → 결국 ‘애플리케이션 회사’가 됨)를 언급하며 경계함.
  - [50:45] 예시로 창고 “피킹 & 플레이스” 로봇에만 매몰되는 미래를 들고, 그런 미래를 “정말로 피하고 싶다”고 말함.
- [50:53] 자신들은 “물리적 지능(Physical Intelligence)” 자체를 정말로 해결할 기회가 있다고 보고, 그 가치가 단일 애플리케이션보다 훨씬 크다고 주장함.
  - [51:03] 따라서 기술이 가능한 한 “범용적”이고 “배포가 쉬우며”, 적용 범위를 최대한 넓히는 데 집중한 뒤 상용화를 고민하겠다고 함.
- [51:15] 상용화 방식은 여러 가지(모델 제공자, 완전 수직 통합 솔루션, 로봇 판매 등)가 가능하지만, 기술 발전 양상에 달려 있어 지금 답하기엔 이르다고 말함.
  - [51:35] 하나를 골라 말하면 심리적 안도감은 있겠지만(“알프레드에게도”), 아직은 너무 이르다고 재차 강조함.
- [51:41] (상대 발언) “거대한 비전”과 물리적 지능 연구 진전에 대해 칭찬하며, 특히 `π*0.6`을 큰 돌파구로 언급하고 축하함.
- [52:06] (질문) 과거 로봇공학 시도들이 응용을 덧대며 점점 좁아졌다는 점을 짚고, 자율주행(웨이모/테슬라) 사례를 들어 “일반화와 성능”의 타임라인을 얼마나 길게 보느냐고 질문함.
  - [52:43] DARPA 챌린지(2007) 이후 시간이 많이 지났지만 여전히 지리/도로 제약이 있는 현실을 언급하며, 일반화된 능력 달성까지의 시간 감각을 묻는 맥락을 제공함.
- [53:09] (답변) 이 문제는 어떤 측면은 자율주행보다 쉽고, 어떤 측면은 더 어렵다고 전제함.
  - [53:17] 더 쉬운 점으로 “100% 신뢰할 수 있을 때만 배포할 필요는 없다”는 점을 듦.
  - [53:23] 세상에는 신뢰도 95%만 되어도 충분히 유용한 작업이 많다고 설명함.
  - [53:29] 예로 집안 로봇이 빨래를 개다가 100번 중 1번 완벽히 못 개도 큰 문제가 아니고, 사람이(아이를 불러) 보완하면 된다고 말함.
  - [53:44] 반대로 자율주행은 100번 중 1번 “치명적으로 실패”하면 큰 문제가 되므로(배포 요구치가 훨씬 엄격) 성격이 다르다고 대비함.
- [49:45] > "[49:45] 진짜 답은 저희가 아직 모른다는 것입니다." — (발언자 미상)
- [53:21] > "[53:21] 우리가 100% 신뢰할 수 있을 때만 배포할 필요는 없다는 점입니다." — (발언자 미상)

---

## 메모

- [55:59] (화자) 최근 모델들이 보여주는 성과가 “정말 놀랍고 인상적”이라고 말하며, 우리가 여기까지 왔다는 사실 자체가 아직도 경이롭다고 느낌.
  - [56:15] 단순한 “다음 토큰 예측”에서 이렇게 지능적으로 보이는 모델들이 나온다는 게 여전히 믿기지 않는다고 강조.
  - [56:24] 작은 진전 하나하나가 충격적이라고 하며 예시로 IMO 우승, 수학 챌린지 우승, 과학에서 새로운 것 발견에의 적용 등을 언급.
  - [56:35] 올해도 “와” 했던 순간이 너무 많았고, 앞으로 더 발전할 여지가 크다고 봄.
  - [56:41] 연초엔 사전학습(LLM) 비즈니스가 시들해지는 듯 느꼈지만, 지금은 “두 번째 숨결/신선한 공기”가 들어오는 느낌이라고 함.
- [56:54] 무엇보다 “이 모든 게 실제로 작동한다”는 사실이 충격적이라고 반복해서 강조.
  > "[56:56] 이 모든 게 실제로 작동한다는 사실 자체가 정말 충격적입니다." — (화자 미상)
  - [57:05] 뇌에서 느슨하게 영감 받은 시스템에 범용 학습 알고리즘을 넣고 데이터를 주면, 어떤 식으로든 “이해”해 버리고 이전 어떤 것보다 잘해낸다고 설명.
  - [57:17] 이 접근이 로봇, 시각, 언어, 소리 등 다양한 영역에 두루 적용된다고 말함.
  - [57:26] 잠깐 멈춰 생각해보면 “어떻게 작동하는지”와 “실제로 작동한다”는 점이 완전히 믿기지 않을 정도로 놀랍다고 함.
  - [57:33] 로봇을 집에 들여놓고 한 번도 가본 적 없는 집에서도 무엇을 해야 하는지 알거나, 13시간 내내 커피를 내리는 것 같은 일이 가능해진다고 예시를 듦.
  - [57:48] 이런 능력이 “완전히 엔드투엔드로 학습”에서 나오며, 우리는 완전히 이해하진 못하지만 뭔가 이해하기 시작하는 듯 보인다고 말함.
- [57:57] “우리는 시뮬레이션 속에 살고 있습니다”라고 말하며, 소냐가 우리가 시뮬레이션에 산다고 믿는다는 언급을 덧붙임.
  > "[57:57] 우리는 시뮬레이션 속에 살고 있습니다." — (화자 미상)
- [58:05] 과학에서 큰 문제를 더 작은 문제로 쪼개라고 배우지만, 그 방식이 기계/로봇 훈련의 최선이 아닐 수 있다는 깨달음이 나온다고 설명.
  - [58:17] 머신러닝/AI 분야도 오랫동안 개별 문제를 매우 깊게 파고드는 “같은 실수”를 어느 정도 저질렀다고 자기비판.
  - [58:32] 그러다 “전부 합쳐 멀티태스크 학습을 정말 잘하면 더 나아질 것”이라는 생각으로 이어진다고 함.
  - [58:39] 특히 일반적인 사전학습 목표로 바꾸자마자 많은 것들이 “저절로 따라 나온다”는 점이 놀라운 지점이라고 강조.
- [58:47] (질문) 큰 문제를 쪼개는 방식 ↔ 다시 큰 문제로 돌아가 일반적으로 푸는 방식 사이를 “아코디언처럼” 오가게 되는지 묻는 흐름.
  - [59:00] (화자) “우리가 다시 돌아갈 것 같지는 않습니다”라고 단언하며, 더는 쪼개기 중심으로 회귀하지 않을 것 같다고 봄.
- [59:05] “양쪽의 장점”을 가져야 한다는 주장(예: 뉴턴 역학 같은 이미 아는 규칙을 가중치에 통합해 넣자)에 대해, 지금까지 본 바로는 잘 되지 않는다고 반박.
  - [59:25] 규칙을 억지로 넣으려 하면 오히려 새로운 것을 배우는 능력을 제한하기 쉽다고 말함.
  - [59:31] 그래서 “양쪽의 장점”은 존재하지 않는다고 보고, 끝까지 학습(learning)으로 가야 한다고 주장.
- [59:35] 이런 관점이 인간이 배우는 방식과 비슷하다고 연결.
  - [59:40] 만약 모든 지능을 미리 구워 넣는 방법이 있었다면 진화가 이미 찾았을 것이고, 그랬다면 우리는 태어날 때부터 모든 것을 알고 태어났을 것이라고 논증.
  - [59:49] 다른 종(예: 사슴)은 태어나자마자 거의 그들이 될 수 있는 만큼 똑똑하고, 평생 크게 배우지 않는다고 예시.
  - [01:00:00] 인간(그리고 “군중” 같은 지능 높은 종)에는 유년기/사춘기 같은 발달 단계가 있으며, 처음부터 완성된 지능이 아니라 자기 경험으로부터 배워야 한다고 설명.
  - [01:00:12] 어느 정도는 스스로 쟁취해야 하고, 그 점에 의미가 있다고 봄.
  - [01:00:20] 결국 “세상을 경험하고 거기서 배워야 한다”는 것이 교훈이라고 정리.
- [01:00:26] 머신러닝/AI도 마찬가지로, 우리는 우리가 어떻게 생각하는지 안다고 여기지만 사실은 모르므로 알고리즘이 데이터에서 그것을 배우게 해야 한다고 말함(아이를 키우는 것과 같다고 비유).
>>>
