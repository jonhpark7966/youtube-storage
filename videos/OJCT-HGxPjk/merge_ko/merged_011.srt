1
00:39:58,200 --> 00:40:00,540
제가 딱 제대로 해내겠습니다, 맞습니다.

2
00:40:00,540 --> 00:40:02,460
그래서 저희 로봇은 초반에는 그랬습니다.

3
00:40:02,460 --> 00:40:03,560
탬핑을 너무 세게 했습니다.

4
00:40:03,560 --> 00:40:06,080
왜냐하면, 음, 우연히도

5
00:40:06,080 --> 00:40:07,040
초기 인간

6
00:40:07,040 --> 00:40:08,000
시연이

7
00:40:08,000 --> 00:40:09,680
그러니까, '우선'

8
00:40:09,680 --> 00:40:11,180
커피 가루가 평평한지 확인해서

9
00:40:11,180 --> 00:40:11,820
그걸 넣을 수 있게 하려는 것이었기 때문입니다.

10
00:40:11,820 --> 00:40:13,880
음, 그러고 나서 로봇은

11
00:40:13,880 --> 00:40:14,690
정말 세게 탬핑해서 거의 스스로를

12
00:40:14,690 --> 00:40:15,500
들어 올릴 뻔했습니다.

13
00:40:15,500 --> 00:40:16,000
테이블에서

14
00:40:16,000 --> 00:40:17,860
저희가 보니, 그건 좀

15
00:40:17,860 --> 00:40:19,940
과했고, 그래서 그냥, 잘 모르겠지만

16
00:40:19,940 --> 00:40:22,280
제 생각에는 34에서 50 에피소드 정도였습니다.

17
00:40:22,280 --> 00:40:23,969
교정의 범위가 정말 작았습니다.

18
00:40:23,969 --> 00:40:24,840
사람들이 했던 교정이

19
00:40:24,840 --> 00:40:26,800
그 데이터를 다시 넣어 주면

20
00:40:26,800 --> 00:40:27,220
그리고 모델은

21
00:40:27,220 --> 00:40:28,120
실제로 훨씬 더

22
00:40:28,120 --> 00:40:29,020
부드러워지기 시작했고

23
00:40:29,020 --> 00:40:30,880
올바른 동작을 수행했으며, 저는 정말

24
00:40:30,880 --> 00:40:31,240
놀랐습니다.

25
00:40:31,240 --> 00:40:32,740
왜냐하면, 여러분도 아시다시피

26
00:40:32,740 --> 00:40:34,480
이 모델은 이런

27
00:40:34,480 --> 00:40:35,780
수백만, 그리고

28
00:40:35,780 --> 00:40:36,580
수백만 에피소드로 사전 학습되었는데, 이제는 그저

29
00:40:36,580 --> 00:40:37,300
조금

30
00:40:37,300 --> 00:40:38,470
교정을 하는 것뿐인데도

31
00:40:38,470 --> 00:40:39,640
그게 실제로 통하기 때문입니다, 그래서

32
00:40:39,640 --> 00:40:41,800
그런 일이 일어나는 것을 보는 것은

33
00:40:41,800 --> 00:40:42,920
이 계속되는

34
00:40:42,920 --> 00:40:44,040
학습

35
00:40:44,040 --> 00:40:44,640
이라는 부분을 가리킨다고 저는 생각했습니다.

36
00:40:44,640 --> 00:40:46,720
저는 그것이 인상적이지만, 그런데 질문 하나 드려도 되겠습니까.

37
00:40:46,720 --> 00:40:49,520
그리고 제가 아직도

38
00:40:49,520 --> 00:40:50,740
걸리는 것은 일반화입니다, 그래서

39
00:40:50,740 --> 00:40:53,360
제가 탬핑을 더 잘하게 되면

40
00:40:53,360 --> 00:40:55,100
상자를 접는 데도 더 잘하게 됩니까, 아니면

41
00:40:55,100 --> 00:40:55,320
그렇지 않습니까.

42
00:40:56,160 --> 00:41:00,860
음, 이 특정한 경우에는 그렇지 않지만,

43
00:41:00,860 --> 00:41:03,300
메커니즘은 같아서, 또

44
00:41:03,300 --> 00:41:05,500
그걸 활용해 '아,'

45
00:41:05,500 --> 00:41:06,980
제 앞에 상자 두 개가 있고

46
00:41:06,980 --> 00:41:08,860
그걸 제가 약간 붙여 버렸으며, 저는

47
00:41:08,860 --> 00:41:10,160
그것들을 떼어내야 합니다, 맞습니까.

48
00:41:10,160 --> 00:41:13,000
왜냐하면 탬핑 부분에서는 교정 30번을 받을 수 있고,

49
00:41:13,000 --> 00:41:14,240
탬핑 부분에서 교정 30번을 받고,

50
00:41:14,240 --> 00:41:15,480
또

51
00:41:15,480 --> 00:41:16,380
상자를 잡아당겨

52
00:41:16,380 --> 00:41:19,820
떼어내는 것에서도, 네, 교정 30번을 받지만

53
00:41:19,820 --> 00:41:22,200
'아, 아시다시피, 이 상자는' 예를 들어

54
00:41:22,200 --> 00:41:23,320
깔끔하게 접히지 않았고

55
00:41:23,320 --> 00:41:24,430
이 모든 것이 함께 누적되어 결국

56
00:41:24,430 --> 00:41:25,540
여러분에게

57
00:41:25,540 --> 00:41:27,350
더 일반화된 개선을 주는 거군요, 알겠습니다.

58
00:41:27,350 --> 00:41:29,160
그러면 이것은

59
00:41:29,160 --> 00:41:29,220
그러니까

60
00:41:29,220 --> 00:41:30,791
반복 가능한 레시피이지만, 서로

61
00:41:30,791 --> 00:41:31,920
반드시 교차, 교차

62
00:41:31,920 --> 00:41:34,820
수분되지는 않는다는 말씀이군요, 네, 저는

63
00:41:34,820 --> 00:41:35,140
하지만

64
00:41:35,140 --> 00:41:37,220
규모를 키우면, 저희가

65
00:41:37,220 --> 00:41:38,730
실제로 어떤 것들이 전이되는 것도

66
00:41:38,730 --> 00:41:40,240
어느 정도

67
00:41:40,240 --> 00:41:41,060
A에서 B로, 만약

68
00:41:41,060 --> 00:41:43,720
여러 작업에 걸쳐 동작이 어느 정도 비슷하다면

69
00:41:43,720 --> 00:41:45,200
보게 될 것이라고 기대합니다만, 현재로서는, 네, 저는

70
00:41:45,200 --> 00:41:45,840
그보다는

71
00:41:45,840 --> 00:41:48,400
반복 가능한 레시피에 더 가깝다고 말하겠습니다, 네, 그리고 저희는

72
00:41:48,400 --> 00:41:49,620
사전 학습에서 많은 일반화를

73
00:41:49,620 --> 00:41:50,840
보고 있습니다.

74
00:41:50,840 --> 00:41:51,480
즉, 학습을

75
00:41:51,480 --> 00:41:53,140
점점 더 많은 작업과 점점 더 많은 데이터로 할수록

76
00:41:53,140 --> 00:41:55,320
새 작업을 온보딩하는 것이 훨씬 쉬워진다는 것을

77
00:41:55,320 --> 00:41:56,980
보게 되거나, 또는

78
00:41:56,980 --> 00:41:57,920
여러분이

79
00:41:57,920 --> 00:41:58,860
예상하지 못했던 작업이

80
00:41:58,860 --> 00:42:00,900
제로샷으로 나타나기도 하는데, 이런 것은 계속 개선되고 있습니다.

81
00:42:00,900 --> 00:42:02,940
저희는

82
00:42:02,940 --> 00:42:04,240
음, 시작합니다,

83
00:42:04,240 --> 00:42:06,680
일정한 주기로 사전 학습 런을 시작하고,

84
00:42:06,680 --> 00:42:08,820
매번 시작할 때마다

85
00:42:08,820 --> 00:42:09,220
모델이 계속

86
00:42:09,220 --> 00:42:10,170
더 좋아지는 것을 보기 시작합니다, 왜냐하면 더 많은

87
00:42:10,170 --> 00:42:11,120
데이터가

88
00:42:11,120 --> 00:42:12,230
투입되고, 더 많은 개선을

89
00:42:12,230 --> 00:42:13,340
저희가 하고

90
00:42:13,340 --> 00:42:13,520
있기

91
00:42:13,520 --> 00:42:15,940
때문이며, 사전 학습 과정 등도 포함됩니다.

92
00:42:15,940 --> 00:42:18,020
그리고 저는 또한, 더

93
00:42:18,020 --> 00:42:19,400
많은 이런 모델이 배치될수록

94
00:42:19,400 --> 00:42:20,470
온갖 다른 작업을 하게 되면, 그들은

95
00:42:20,470 --> 00:42:21,540
또

96
00:42:21,540 --> 00:42:24,680
데이터를 다시 가져오고, 저는 한

97
00:42:24,680 --> 00:42:25,120
가지 방식으로

98
00:42:25,120 --> 00:42:27,640
즉 제가 꽤 확신하는 방식으로, 저희가

99
00:42:27,640 --> 00:42:29,170
그 과정에서 더 많은 일반화를 보게 될 것입니다.

100
00:42:29,170 --> 00:42:30,700
즉

101
00:42:30,700 --> 00:42:31,200
여러분이

102
00:42:31,200 --> 00:42:32,740
이 모델들을 배포하면, 그 데이터가

103
00:42:32,740 --> 00:42:34,280
돌아오고

104
00:42:34,280 --> 00:42:36,000
모델은 더 좋아져서, 여러분은 더 많이 배포할 수 있으며

105
00:42:36,000 --> 00:42:36,300
더 많이

106
00:42:36,300 --> 00:42:38,480
배포하면, 모델은 또 더 좋아지고, 여러분은

107
00:42:38,480 --> 00:42:40,420
더 많이 배포할 수 있고, 이런 식입니다, 네, 그리고

108
00:42:40,420 --> 00:42:41,840
제가 생각하기에, 아마도

109
00:42:41,840 --> 00:42:43,800
여러분이 제기하신 이 지점에서, 저희는

110
00:42:43,800 --> 00:42:46,176
아직 한 가지

111
00:42:46,176 --> 00:42:47,100
아주 중요한 세부

112
00:42:47,100 --> 00:42:47,720
요소에 대해

113
00:42:47,720 --> 00:42:49,500
이 다섯 단계 또는 여섯 단계 레시피에서

114
00:42:49,500 --> 00:42:51,020
모델이 두 부분으로 이루어진다는 점을

115
00:42:51,020 --> 00:42:52,240
충분히 이야기하지 않았습니다.

116
00:42:52,240 --> 00:42:53,610
하나는 정책으로, 그러니까

117
00:42:53,610 --> 00:42:54,980
교정을 통해

118
00:42:54,980 --> 00:42:57,100
또 강화학습(RL) 피드백으로 개선하려는 부분이며, 다른 한 부분은

119
00:42:57,100 --> 00:42:57,880
어떻게

120
00:42:57,880 --> 00:42:58,930
이 강화학습(RL) 피드백을 실제로 얻느냐는 것입니다, 그래서

121
00:42:58,930 --> 00:42:59,980
저희는

122
00:42:59,980 --> 00:43:00,990
조금 이야기했고, 제가 언급했듯이

123
00:43:00,990 --> 00:43:02,000
여러분도

124
00:43:02,000 --> 00:43:02,660
아시다시피 사람은

125
00:43:02,660 --> 00:43:03,750
교정할 수 있고, 그것이 인간 교정

126
00:43:03,750 --> 00:43:04,840
부분이며,

127
00:43:04,840 --> 00:43:07,280
강화학습(RL) 피드백 부분은 조금

128
00:43:07,280 --> 00:43:07,960
다르고, 또

129
00:43:07,960 --> 00:43:10,460
이미 이런

130
00:43:10,460 --> 00:43:11,760
일반화의 측면을 어느 정도 갖고 있다고 저는 생각합니다.

131
00:43:11,760 --> 00:43:13,060
여러분이

132
00:43:13,060 --> 00:43:13,900
지금

133
00:43:13,900 --> 00:43:15,920
찾으려고 하시는 것이 바로 이것인데, 저희가

134
00:43:15,920 --> 00:43:19,000
이를 하는 방식은, 먼저 기본적으로

135
00:43:19,000 --> 00:43:21,500
사람들에게, 어, 저희에게

136
00:43:21,500 --> 00:43:23,120
기본적으로 어떤 특정한 시도가

137
00:43:23,120 --> 00:43:24,740
그

138
00:43:24,740 --> 00:43:27,140
커피를 만들거나 상자를 다루는 것이 성공했는지

139
00:43:27,140 --> 00:43:27,700
아닌지를

140
00:43:27,700 --> 00:43:28,580
라벨로 제공받는 것입니다, 그래서

141
00:43:28,580 --> 00:43:29,460
이

142
00:43:29,460 --> 00:43:30,680
에피소드들에는 사람의 라벨이 함께 붙고, 그다음 저희는 어떤 것을 훈련합니다.

143
00:43:30,680 --> 00:43:31,900
그것은

144
00:43:31,900 --> 00:43:32,120
이른바

145
00:43:32,120 --> 00:43:33,660
가치 함수(value function)라고 하며, 이를 통해

146
00:43:33,660 --> 00:43:35,200
기본적으로

147
00:43:35,200 --> 00:43:37,640
제가 현재 어느 지점에 있는지에서

148
00:43:37,640 --> 00:43:39,520
작업에서 제가

149
00:43:39,520 --> 00:43:41,560
성공할 가능성이 큰지, 실패할 가능성이 큰지를

150
00:43:41,560 --> 00:43:43,600
예측하려고 합니다, 그리고 이

151
00:43:43,600 --> 00:43:45,780
가치 함수는 이후 일종의

152
00:43:45,780 --> 00:43:46,900
기준선으로

153
00:43:46,900 --> 00:43:48,610
사용되어, 이 데이터 포인트에 대해

154
00:43:48,610 --> 00:43:50,320
제가

155
00:43:50,320 --> 00:43:52,220
그 값을 올려야 하는지, 아니면

156
00:43:52,220 --> 00:43:53,480
내려야 하는지를

157
00:43:53,480 --> 00:43:56,800
제가

158
00:43:56,800 --> 00:43:58,230
성공 쪽으로 가고 있다고 예상하는지, 아니면 더

159
00:43:58,230 --> 00:43:59,660
가능성이

160
00:43:59,660 --> 00:44:00,700
실패 쪽으로 향하는지에 따라 결정합니다.

161
00:44:00,700 --> 00:44:02,840
그리고 저희가 이 가치 함수를 훈련할 때 본 한 가지는

162
00:44:02,840 --> 00:44:03,850
이 가치 함수들이

163
00:44:03,850 --> 00:44:04,860
훈련되는

164
00:44:04,860 --> 00:44:05,920
방식이 기본적으로 같은

165
00:44:05,920 --> 00:44:08,480
백본, 같은 종류의 모델에서 나오지만

166
00:44:08,480 --> 00:44:10,110
실제

167
00:44:10,110 --> 00:44:11,740
정책이

168
00:44:11,740 --> 00:44:12,140
훈련되기 전에

169
00:44:12,140 --> 00:44:14,300
즉 작업을 실제로 수행하는 정책을 훈련할 때, 저희는

170
00:44:14,300 --> 00:44:15,950
이 가치 함수를 훈련하면서

171
00:44:15,950 --> 00:44:17,600
추가로

172
00:44:17,600 --> 00:44:18,140
더 많은 데이터를

173
00:44:18,140 --> 00:44:19,580
서로 다른 작업에서 가져와 더하는 것이 실제로 도움이 된다는 것을 보았고

174
00:44:19,580 --> 00:44:21,020
그러면

175
00:44:21,020 --> 00:44:22,470
모델이 실제로 정말

176
00:44:22,470 --> 00:44:23,920
잘하게 되기 시작합니다.

177
00:44:24,600 --> 00:44:26,700
적어도 일부 작업에서는, 미리 알고

178
00:44:26,700 --> 00:44:29,340
언제 실패할지를 사전에, 그리고

179
00:44:29,340 --> 00:44:30,980
제게

180
00:44:30,980 --> 00:44:32,460
명백해지기 전부터 말입니다, 예를 들어 제가 영상을 볼 때

181
00:44:32,460 --> 00:44:35,780
그것이, 어, 그러니까,

182
00:44:35,780 --> 00:44:38,900
포터필터를, 감사합니다,

183
00:44:38,900 --> 00:44:41,720
보시다시피 저는 커피를 잘 만들지 못하는데,

184
00:44:41,720 --> 00:44:43,700
그것이 포터필터를

185
00:44:43,700 --> 00:44:44,980
커피 머신에 끼우려 할 때, 그것은

186
00:44:44,980 --> 00:44:47,220
각도가 완전히 맞지 않다는 것을

187
00:44:47,220 --> 00:44:49,620
그 일이 일어나기 전에 알고 있어서, 대략 30

188
00:44:49,620 --> 00:44:50,820
40 스텝 정도 전에

189
00:44:50,820 --> 00:44:51,860
실제로 그 일이 일어나기 전에 가치 함수의

190
00:44:51,860 --> 00:44:52,900
예측이

191
00:44:52,900 --> 00:44:54,540
떨어지는 것을 볼 수 있고, 또

192
00:44:54,540 --> 00:44:55,120
'아, 이건'

193
00:44:55,120 --> 00:44:57,220
이 특정 에피소드에서는 좋지 않다'라고 말하듯이,

194
00:44:57,220 --> 00:44:59,282
그래서 저는 이 데이터를 포함시키면 안 됩니다.

195
00:44:59,282 --> 00:45:00,280
흥미롭군요, 그리고

