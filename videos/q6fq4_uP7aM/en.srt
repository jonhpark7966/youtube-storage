1
00:00:00,320 --> 00:00:05,440
Hello and welcome to The Tech Download 
- a new CNBC Original podcast where we  

2
00:00:05,440 --> 00:00:08,000
unpack the tech stories that matter most.

3
00:00:08,000 --> 00:00:11,040
Each season, we dive into one 
big theme - and what it means for  

4
00:00:11,040 --> 00:00:15,680
your money - with insights from the 
industry's most influential voices.

5
00:00:15,680 --> 00:00:19,680
I've always thought that, in the end, it 
would be the most important technology we'll  

6
00:00:19,680 --> 00:00:24,640
ever invent. And it's sort of the natural 
progression, really, of the computer age.

7
00:00:24,640 --> 00:00:30,480
This season, we’re looking at Google DeepMind, 
the powerhouse driving the tech giant's AI push.

8
00:00:30,480 --> 00:00:34,240
We've been given rare access to key 
figures at the company - including  

9
00:00:34,240 --> 00:00:39,920
our guest for this episode DeepMind 
co-founder and CEO Demis Hassabis.

10
00:00:39,920 --> 00:00:42,320
I think there it's going to be 
like the industrial revolution,  

11
00:00:42,320 --> 00:00:46,400
but maybe 10 times bigger, 10 times faster. So,  

12
00:00:46,400 --> 00:00:52,240
it's incredible amount of transformation, 
but also disruption that's going to happen.

13
00:00:54,480 --> 00:00:59,920
Hey everyone, and welcome to The Tech download. 
Allow me to reintroduce myself. I'm Arjun Kharpal,  

14
00:00:59,920 --> 00:01:04,080
Senior Technology correspondent 
at CNBC based in London, and I've  

15
00:01:04,080 --> 00:01:09,280
got a very special new co host with me. 
 
Hey there, Arjun, yeah. Steve Kovach here,  

16
00:01:09,280 --> 00:01:14,480
I cover tech over here in New York. I mostly 
focus on Apple and Microsoft. But look,  

17
00:01:14,480 --> 00:01:19,680
I've been covering the tech industry for over 
15 years now. I kind of have a good grasp on  

18
00:01:19,680 --> 00:01:24,080
everything. I'm so excited to be here with you, 
Arjun, because I've just admired your work from  

19
00:01:24,080 --> 00:01:28,560
across the ocean for so long, and now we actually 
get to kind of collaborate and do this thing  

20
00:01:28,560 --> 00:01:32,720
together. I think it's gonna be a good time. 
 
It's going to be so fun. Steve. So between us,  

21
00:01:32,720 --> 00:01:37,040
we think we've got nearly three decades of 
experience covering tech, and the crazy thing is,  

22
00:01:37,040 --> 00:01:41,440
we've got so much to learn. And I think over 
the course of us doing this podcast, we're going  

23
00:01:41,440 --> 00:01:47,040
to learn so much, speak to so many interesting 
people, I’m so excited that this first series,  

24
00:01:47,040 --> 00:01:52,880
we're kicking off with an insight into Google Deep 
Mind, one of the world's leading AI labs as well,  

25
00:01:53,600 --> 00:01:59,120
just for our listeners and our viewers, a quick 
intro, I guess, to Google DeepMind. It was a  

26
00:01:59,120 --> 00:02:04,240
company founded in 2010 here in London, where I 
sit, as well. Very small company founded by three  

27
00:02:04,240 --> 00:02:09,920
people, Demis Hassabis, is Shane Legg and Mustafa 
Suleiman, who's at Microsoft now, right, yeah. 
  

28
00:02:09,920 --> 00:02:16,720
And in fact, I interviewed him, nearly a year 
ago now, Mustafa Suleiman, he's basically doing  

29
00:02:16,720 --> 00:02:21,360
what Demis is doing over at Google. And it's 
just kind of interesting to see how Google was  

30
00:02:21,360 --> 00:02:26,960
like this incubator, so to speak, for all of this 
top AI talent around the world, Demis obviously  

31
00:02:26,960 --> 00:02:31,760
stuck around. He's running Deep Mind over there. 
What I also think is really interesting, though,  

32
00:02:31,760 --> 00:02:37,600
is just this AI moment, Arjun, we've been living 
through for the last three years, and how three  

33
00:02:37,600 --> 00:02:42,480
years ago, chat GPT comes on the scene, and 
Google was kind of seen as under threat. They  

34
00:02:42,480 --> 00:02:47,600
went through this code red. They had to go through 
a bunch of reorganizations internally. Eventually,  

35
00:02:47,600 --> 00:02:54,320
Demis came out on top as the leader of AI. And 
guess what? 2025 was a really interesting year  

36
00:02:54,320 --> 00:03:00,560
for AI over at Google, they kind of caught up, 
and in some ways, even surpassed what chat GPT was  

37
00:03:00,560 --> 00:03:05,840
already doing. And this is really interesting 
because the fundamental technology for all this,  

38
00:03:05,840 --> 00:03:10,720
these large language models we've been talking 
about for so many years, started at Google,  

39
00:03:10,720 --> 00:03:16,800
and the perception was Google, let chat GPT kind 
of take that technology and run away with it. But  

40
00:03:16,800 --> 00:03:22,400
now, in my view, at least Gemini is pretty 
much on par, if not better, than chat GPT.
  

41
00:03:22,400 --> 00:03:27,840
and Google Deep Mind is integral for this. 
I mentioned it was founded in 2010 Google  

42
00:03:27,840 --> 00:03:33,360
actually acquired Deep Mind in 2014 I was 
very new into my career as a tech reporter  

43
00:03:33,360 --> 00:03:38,880
as well. Google paid around 400 million 
pounds for Deep Mind at the time in 2014  

44
00:03:38,880 --> 00:03:45,040
about $540 million. It's a stake this 
day that could be worth 10s of billions,  

45
00:03:45,040 --> 00:03:50,400
maybe hundreds of billions of dollars, according 
to some estimates today, and Deep Mind really is  

46
00:03:50,400 --> 00:03:57,120
very much responsible for Google's AI. We 
talk about Gemini, the chat bot, the AI  

47
00:03:57,120 --> 00:04:01,920
that Google's released to consumers. This 
is powered so much by the technology coming  

48
00:04:01,920 --> 00:04:06,480
out of Deep Mind. But even before all of this 
Deep Mind was having some big breakthroughs,  

49
00:04:06,480 --> 00:04:12,160
there was a big moment a few years ago when they 
released a system called Alpha Go. This was the  

50
00:04:12,160 --> 00:04:17,760
first computer program that was able to defeat a 
world champion in a game called Go. This is a very  

51
00:04:17,760 --> 00:04:24,240
complex game, and it was seen at the time as one 
of the grand challenges of AI because it was such  

52
00:04:24,240 --> 00:04:28,640
a complex game with so many different combinations 
available. The other big breakthrough, of course,  

53
00:04:28,640 --> 00:04:33,520
was was something called Alpha Fold. This was 
another AI system developed at DeepMind that  

54
00:04:33,520 --> 00:04:39,120
could accurately predict 3d models of protein 
structures. And the idea is, here is, if you  

55
00:04:39,120 --> 00:04:44,320
could do that, this may lead to some medical 
breakthrough. So this advancement of science  

56
00:04:44,320 --> 00:04:50,480
has been pretty core to what Deep Mind's been 
up to. And clearly it was a significant bet from  

57
00:04:50,480 --> 00:04:56,320
Google more than 10 years ago, because it's helped 
turn Google into an AI world leader today. 
  

58
00:04:56,320 --> 00:05:00,560
Yeah, that's exactly right now. What really 
struck me about Deep Mind, having watched them  

59
00:05:00,560 --> 00:05:05,040
for so many years, is how rooted in science 
they were. They weren't necessarily trying  

60
00:05:05,040 --> 00:05:10,000
to build consumer products like they do now. 
They were really trying to solve fundamental  

61
00:05:10,000 --> 00:05:16,880
problems in science and really usher in this 
era of AI powered drug discovery, of other big,  

62
00:05:16,880 --> 00:05:20,880
complex problems like climate change. I know 
Demis talks about that a lot, and he's going  

63
00:05:20,880 --> 00:05:26,160
to talk about that in your conversation as well. 
 
Arjun, absolutely. Steve, look, it's a great scene  

64
00:05:26,160 --> 00:05:33,440
set up for Deep Mind. So let's get into the 
conversation with its CEO, Demis Hassabis.
 

65
00:05:33,440 --> 00:05:36,560
Demis, thanks for joining me on 
the tech download. Appreciate it.

66
00:05:36,560 --> 00:05:37,680
Thanks for having us

67
00:05:37,680 --> 00:05:41,440
Demis, we're going to try to get through a lot in 
our time here. But I want to start first with the  

68
00:05:41,440 --> 00:05:46,400
technology itself. And we've been talking about 
AI, and we've been talking about the capabilities  

69
00:05:46,400 --> 00:05:51,520
and how they've been continuously improving as 
well. Now in the tech world, and there's a lot of  

70
00:05:51,520 --> 00:05:56,160
conversations about how good can these models get, 
how good can these systems get, and there's a lot  

71
00:05:56,160 --> 00:06:02,800
of debate around this idea of scaling laws for our 
for our listeners, you know, it's this idea of of  

72
00:06:02,800 --> 00:06:08,320
more compute, more data, bigger models eventually 
will lead to bigger systems as well. You said we  

73
00:06:08,320 --> 00:06:14,800
need to push scaling laws to the maximum. There's 
questions over now, are we hitting any kind of  

74
00:06:14,800 --> 00:06:18,800
walls in terms of progress of those scaling laws, 
in terms of the ability for these models to get  

75
00:06:18,800 --> 00:06:23,920
better, and just from you know, what you've been 
developing here at DeepMind, what are you seeing?

76
00:06:23,920 --> 00:06:31,440
Well, look, I think scaling laws are going 
very well, so we're definitely seeing increased  

77
00:06:31,440 --> 00:06:36,880
capabilities by putting in more compute, more 
data, and making these models generally larger,  

78
00:06:36,880 --> 00:06:43,520
so that trends continuing may not have been as 
fast as it was a couple of years ago. So there's  

79
00:06:43,520 --> 00:06:49,520
some talk of diminishing returns and but there's 
a big difference between sort of no returns and  

80
00:06:49,520 --> 00:06:53,680
exponential and I think we're somewhere in the 
middle where there's very good returns, and  

81
00:06:53,680 --> 00:06:59,200
that's worth doing. On top of that, if I you know 
in terms of, like, getting all the way to AGI,  

82
00:06:59,200 --> 00:07:05,040
artificial general intelligence, you know, maybe 
that there's one or two big innovations still  

83
00:07:05,040 --> 00:07:11,040
needed as well, and maybe missing, in addition 
to the scaling up of kind of the existing ideas

84
00:07:11,040 --> 00:07:15,200
We'll get on to AGI very shortly. 
But what are missing in your view?

85
00:07:15,200 --> 00:07:18,640
Well, if you look at, I mean, we've all, you 
know, played around with different chat bots,  

86
00:07:18,640 --> 00:07:25,200
and you can see that, you know, they can do 
very impressive things in some dimensions,  

87
00:07:25,200 --> 00:07:28,560
but they're kind of like jagged intelligences 
I like calling them in the sense of like,  

88
00:07:28,560 --> 00:07:32,480
they're very good at certain things. But there 
are other things that they don't do they're not  

89
00:07:32,480 --> 00:07:38,720
capable of at all. And and if you pose a question 
in a certain way, you find that they're flawed  

90
00:07:39,280 --> 00:07:44,400
and they can't do some relatively simple 
things. And so for a true general intelligence,  

91
00:07:44,400 --> 00:07:48,960
you shouldn't see that inconsistency should be 
consistent across the board. And also they're  

92
00:07:48,960 --> 00:07:52,880
things like it can't continually learn it 
can't learn new things online. It can't  

93
00:07:52,880 --> 00:07:57,920
truly create original things. So there's quite a 
few capabilities that you would like to see and  

94
00:07:57,920 --> 00:08:01,200
you would need for general intelligence 
that are missing from today's systems.

95
00:08:01,200 --> 00:08:05,520
That's really interesting. So what would be 
the sort of unlock to get to those Intelligent  

96
00:08:05,520 --> 00:08:09,280
Systems? I just want to quickly discuss 
the conversation I had with Thomas Wolfe,  

97
00:08:09,280 --> 00:08:13,840
who's the co founder over at Hugging Face. 
Yes, he was talking to me a few months back  

98
00:08:13,840 --> 00:08:17,440
about his view on LLMs, in particular, 
large language models. And just saying,  

99
00:08:17,440 --> 00:08:20,640
they're really great. And you know, you use 
these chat bots, and the chat bots say, hey,  

100
00:08:20,640 --> 00:08:25,920
great question, great idea. And here's, here's 
all the information you need to know. But what's  

101
00:08:25,920 --> 00:08:31,200
missing is the ability for these systems to 
come up with new and novel ideas, perhaps,  

102
00:08:31,200 --> 00:08:36,240
and particularly, I know you're so interested 
in science and what AI could do to unlock new  

103
00:08:36,240 --> 00:08:41,280
drugs or discover new diseases, etc, that 
actually maybe the LLMs limitations are  

104
00:08:41,280 --> 00:08:45,760
there that can't come up with these Nobel 
Prize winning ideas, these novel ideas.

105
00:08:45,760 --> 00:08:46,480
Yeah.

106
00:08:46,480 --> 00:08:49,120
So perhaps there needs to be some 
sort of new architecture. What's  

107
00:08:49,120 --> 00:08:51,120
your what's your thinking on that at the moment?

108
00:08:51,120 --> 00:08:56,240
Well, look, my passion for and my whole reason 
I spent my whole career on AI is, I think,  

109
00:08:56,240 --> 00:09:00,240
eventually will be the ultimate tool for science. 
And of course, we've shown that with things like  

110
00:09:00,240 --> 00:09:04,640
Alpha Fold and all of the science work we've been 
doing over the last decade. But there's still a  

111
00:09:04,640 --> 00:09:10,960
long way to go in terms of, can an AI actually 
come up with a new hypothesis itself, not just  

112
00:09:10,960 --> 00:09:15,920
solve a conjecture that is already out there, 
which would be already useful and impressive. But  

113
00:09:15,920 --> 00:09:21,680
can it actually come up with a new conjecture, a 
new a new idea about how the world might work? And  

114
00:09:21,680 --> 00:09:26,320
so far, these systems can't do that. They don't 
really have the capability to do that. So there  

115
00:09:26,320 --> 00:09:31,680
seems to be something missing. I think, some of 
the capabilities that required a kind of long term  

116
00:09:31,680 --> 00:09:38,240
planning, better reasoning, maybe also the idea of 
a world model. This idea of, like, you know, the  

117
00:09:38,240 --> 00:09:43,840
system actually understanding better the physics 
of the world, so that it can run simulations,  

118
00:09:44,800 --> 00:09:51,200
kind of in its mind to test its own hypotheses. 
You know, these are things that you know the best  

119
00:09:51,200 --> 00:09:56,880
scientists do, human scientists do. And so far, 
our AI systems, you know, are not able to do that.

120
00:09:56,880 --> 00:10:00,160
Can you just help us understand a bit more of 
this idea of world models? Because it may be  

121
00:10:00,160 --> 00:10:05,040
a term people are hearing for the first time. You 
know how that gets they different differ from LLMs

122
00:10:05,040 --> 00:10:10,240
So LLM's, and the models we use at the moment 
are, you know, mostly around text. Of course,  

123
00:10:10,240 --> 00:10:16,720
things like Gemini, our foundation model, can also 
cope with images and video and audio, so different  

124
00:10:16,720 --> 00:10:22,720
modalities. But it's still actually understanding 
the physics of the world, the causality of the  

125
00:10:22,720 --> 00:10:28,240
world. You know, how one thing affects another 
thing? Can you plan a long time into the future?  

126
00:10:28,240 --> 00:10:32,800
These are all related concepts, and if you 
really want to understand how the world works,  

127
00:10:32,800 --> 00:10:37,600
so that maybe you can invent something new in the 
world, or explain something about the world that  

128
00:10:37,600 --> 00:10:42,880
was not known before, which is basically what 
scientific theory does, then you have to have  

129
00:10:42,880 --> 00:10:48,560
this, this accurate model of how the world works, 
you know, starting with intuitive physics and  

130
00:10:48,560 --> 00:10:54,560
and how the physics of the world works, but all 
the way up to biology, you know, and economics.

131
00:10:55,120 --> 00:10:59,200
And do you envisage the world if we 
get of artificial general intelligence,  

132
00:10:59,200 --> 00:11:03,120
is sort of human level of intelligence, that 
that there will be a combination of llms and  

133
00:11:03,120 --> 00:11:07,600
world models working together, or will sort 
of world models supersede, in some sense, LLMs

134
00:11:07,600 --> 00:11:12,160
No, I think there'll be some convergence of these 
technologies. That's at least my betting is, is  

135
00:11:13,280 --> 00:11:18,640
there will be these LLMs, or foundation models, 
you know, like Gemini under the hood, that will  

136
00:11:18,640 --> 00:11:22,560
be a key component. I think the question, I think 
there's almost no doubt about that in my mind,  

137
00:11:22,560 --> 00:11:29,280
which is why we must try and scale those systems 
as as as big and as as powerful as we can. But  

138
00:11:29,280 --> 00:11:35,520
the question is, is, is it the only component 
that's needed for an AGI and that's where I think,  

139
00:11:35,520 --> 00:11:41,520
I suspect other types of technologies and other 
types of capabilities will be needed. And I think  

140
00:11:41,520 --> 00:11:48,240
these world model capabilities, and we're working 
on our versions called Genie and and we have video  

141
00:11:48,240 --> 00:11:53,280
models like VO, state of the art, video models 
that you can generate videos from, in from text,  

142
00:11:53,280 --> 00:11:59,360
and you can think of video models and interactive 
models like Genie as kind of, you know, early  

143
00:11:59,360 --> 00:12:06,000
embryonic world models, where, if you can generate 
something that's realistic about the world, then  

144
00:12:06,000 --> 00:12:10,080
in a sense, your model understands that about the 
world. Otherwise, how could it have generated it?

145
00:12:10,080 --> 00:12:13,680
Demis, you mentioned this, AGI, artificial 
general intelligence. I know there's various  

146
00:12:13,680 --> 00:12:18,000
definitions of it floating around. You've 
previously said you believe that reaching  

147
00:12:18,000 --> 00:12:23,520
AGI could be somewhere in the in the realm of 
five to 10 years away. Is this still your view,  

148
00:12:23,520 --> 00:12:27,920
given, I guess, some of the profound 
developments we've seen in 2025

149
00:12:27,920 --> 00:12:30,720
Yes, I think we're right on track from 
that. Actually, when we started DeepMind  

150
00:12:30,720 --> 00:12:35,760
back in 2010 we thought this would be 
a 20 year kind of mission to build AGI,  

151
00:12:35,760 --> 00:12:41,440
you know, a system that's capable exhibiting all 
the cognitive capabilities we have, including,  

152
00:12:41,440 --> 00:12:47,200
you know, things like true innovation and 
creativity and planning and reasoning and  

153
00:12:47,200 --> 00:12:52,400
things like that. And I think we're about 
five to 10 years away from that, but that's,  

154
00:12:52,400 --> 00:12:56,240
you know, pretty incredible, if you think 
about how transformative a technology this is

155
00:12:56,240 --> 00:12:59,120
You mentioned there might need to be some 
more technology breakthroughs. We're seeing  

156
00:12:59,120 --> 00:13:03,600
things like the models advancing. We're seeing 
the semiconductors advancing rapidly as well.  

157
00:13:03,600 --> 00:13:07,040
Are there any currently bottlenecks 
and things you need to figure out?  

158
00:13:07,040 --> 00:13:10,080
I know energy is something that's been 
brought up so much saying, Well, look,  

159
00:13:10,080 --> 00:13:13,920
we can keep advancing chips, we can keep 
advancing models, but at some point we're  

160
00:13:13,920 --> 00:13:18,720
just not going to have enough energy to run 
these data centers, to run these AI models.

161
00:13:18,720 --> 00:13:23,360
Yeah, yeah. Well, ook, there's, there's lots 
of physical constraints. So of course, there's,  

162
00:13:23,360 --> 00:13:26,880
you know, no one ever has enough chips. 
And you know, we're lucky that we have,  

163
00:13:26,880 --> 00:13:31,520
you know, our own TPU range, in addition 
to GPUs and but there just aren't enough  

164
00:13:31,520 --> 00:13:34,800
compute chips in the world, really, for 
the demand. And of course, in the end,  

165
00:13:34,800 --> 00:13:38,880
that comes down to energy as well. There's 
this idea of energy will be effectively is  

166
00:13:38,880 --> 00:13:44,560
synonymous with intelligence as we get into the 
era towards AGI. Now, the interesting thing is,  

167
00:13:44,560 --> 00:13:50,320
I think the AI itself will help here, in the 
sense of getting more efficiencies out of existing  

168
00:13:50,320 --> 00:13:55,040
infrastructure, but helping with things like 
material design better better solar materials,  

169
00:13:55,040 --> 00:13:58,320
but it could also help with new breakthrough 
technologies like fusion. We, you know,  

170
00:13:58,320 --> 00:14:03,680
we have a collaboration with Commonwealth fusion 
in the US to help contain plasma and fusion  

171
00:14:03,680 --> 00:14:09,120
reactors. And one of my pet projects is, can we 
come up with a room temperature superconductor  

172
00:14:09,120 --> 00:14:15,280
material using AI? So I think there are multiple 
breakthroughs that AI could come up with and help  

173
00:14:15,280 --> 00:14:19,840
us come up with that would help with the 
energy situation. In fact, indeed, that's,  

174
00:14:19,840 --> 00:14:23,760
I think that's one of the most promising use 
cases of AI. And then the other thing is,  

175
00:14:23,760 --> 00:14:28,640
as these systems are getting better, they're also 
getting, you know, 10x more efficient per year.  

176
00:14:28,640 --> 00:14:33,520
So if you look at our range of models, we have 
our kind of Lighthouse model, our Pro versions  

177
00:14:33,520 --> 00:14:37,680
of Gemini, but then we have our flash versions, 
which are way more efficient, and the sort of  

178
00:14:37,680 --> 00:14:42,400
workhorse models that are used for everything, 
and they use techniques like distillation, where  

179
00:14:42,400 --> 00:14:46,720
you have a big model that teaches a smaller model, 
and the smaller model is really, really efficient.  

180
00:14:46,720 --> 00:14:50,880
And I think there are more and more innovations 
and techniques like that that will keep bringing  

181
00:14:50,880 --> 00:14:56,800
the efficiency curve down, and so you get, you 
know, much better performance per per watt.

182
00:14:56,800 --> 00:15:00,800
We hear a lot about sort of AGI, and I think 
there's a lot of people wondering, technology,  

183
00:15:00,800 --> 00:15:05,440
sounds amazing, sounds great. There's also a 
lot of fear right around the proliferation of  

184
00:15:05,440 --> 00:15:09,600
this technology and the impact it's going to 
have on on people every day and their lives.  

185
00:15:09,600 --> 00:15:12,480
I guess for you, what are some 
of things we need to consider,

186
00:15:12,480 --> 00:15:12,800
yeah

187
00:15:12,800 --> 00:15:16,480
from from that perspective, in terms of the 
impact on society, whether it's around jobs,  

188
00:15:16,480 --> 00:15:21,360
whether it's around kind of what we're going to 
do with our time if we reach this goal, versus,  

189
00:15:21,360 --> 00:15:25,520
I guess, the benefits that you believe this 
technology is going to bring for humanity?

190
00:15:25,520 --> 00:15:29,040
Well, of course, you know, I believe that 
overall, AI is going to be one of the most  

191
00:15:29,040 --> 00:15:35,440
beneficial technologies humanity ever invented. 
That's why I spent my whole career working on it.  

192
00:15:35,440 --> 00:15:40,480
But it's only, you know, it's not a given. It's 
a dual purpose technology. I dream about using  

193
00:15:40,480 --> 00:15:45,360
AI for things like curing diseases. We have a 
spin out called isomorphic that builds it on,  

194
00:15:45,360 --> 00:15:50,960
on Alpha fold work on protein folding, work 
that we did a few years ago to accelerate drug  

195
00:15:50,960 --> 00:15:55,440
discovery and try and solve all disease. I think 
that's now, you know, within reach, that type of  

196
00:15:55,440 --> 00:16:01,600
thing in the next decade or two. We've discussed 
energy. There's many benefits, I think AI is going  

197
00:16:01,600 --> 00:16:05,920
incredible benefits AI is going to bring. But 
there are also risks. Obviously, there's kind  

198
00:16:05,920 --> 00:16:11,520
of economic disruption, and I think there it's 
going to be like the industrial revolution, but  

199
00:16:11,520 --> 00:16:17,760
maybe 10 times bigger, 10 times faster. So, you 
know, it's incredible amount of transformation,  

200
00:16:17,760 --> 00:16:22,480
but also disruption that's going to happen. 
And you know, we need some new economic models,  

201
00:16:22,480 --> 00:16:28,880
probably for that. And then on terms of the the 
worries about the usage of AI, I have two which I  

202
00:16:28,880 --> 00:16:33,600
think are worth worrying about. One is bad actors 
repurposing these general purpose technologies,  

203
00:16:33,600 --> 00:16:39,360
AI technologies, for harmful ends. And then the 
second one is AI itself, as it we get towards  

204
00:16:39,360 --> 00:16:44,560
AGI and agent based systems. So these are systems 
that are able to do things more autonomously than  

205
00:16:44,560 --> 00:16:50,480
than today's systems. They can, you know, what 
are the guardrails around that? How do we make  

206
00:16:50,480 --> 00:16:57,040
sure we can keep them doing the things that we 
want them to do, and not veer off into something  

207
00:16:57,040 --> 00:17:03,200
that we didn't expect. And so those are the two 
kind of risks that are kind of that I foresee.

208
00:17:03,200 --> 00:17:04,640
Do you feel that you've 
got systems that, or you're  

209
00:17:04,640 --> 00:17:07,360
developing systems that you can be in control of?

210
00:17:07,360 --> 00:17:11,760
I think we're, we're very confident about 
that. You know, we've had and thought about  

211
00:17:11,760 --> 00:17:16,640
responsibility and safety and security of 
these systems in the very beginning. You know,  

212
00:17:16,640 --> 00:17:20,800
we started DeepMind back in 2010 almost 
no one was working on AI back then. But  

213
00:17:20,800 --> 00:17:25,040
we planned for success, and we knew success 
would mean these extremely powerful systems.  

214
00:17:25,040 --> 00:17:30,080
So we also understood the the other side of 
the coin of that. So from the very beginning,  

215
00:17:30,080 --> 00:17:33,920
we've tried to be very thoughtful use the 
scientific method and a scientific approach  

216
00:17:33,920 --> 00:17:38,560
to try and understand as much about our systems 
we're building before we deploy them. Of course,  

217
00:17:38,560 --> 00:17:41,200
that doesn't mean we won't make any 
mistakes. There's two, it's, it's,  

218
00:17:41,200 --> 00:17:46,720
it's such a incredible and fast moving technology. 
But I think with with something like AI,  

219
00:17:46,720 --> 00:17:52,960
we need to be, you know, I call myself a kind of 
cautious optimist. I'm, I'm very big believer in  

220
00:17:52,960 --> 00:17:57,600
human ingenuity. I think given enough time and 
care, we'll get this right as scientists and  

221
00:17:57,600 --> 00:18:03,600
as a society. But it's, it's not a given, and 
so we shouldn't be sort of rushing into this

222
00:18:03,600 --> 00:18:04,160
yeah

223
00:18:04,160 --> 00:18:06,400
and we need to go into it with our eyes open.

224
00:18:06,400 --> 00:18:10,160
Because, I guess the reason I asked, because I 
know you've spoken to people like Yoshua, Bengio,  

225
00:18:10,160 --> 00:18:15,280
Max Tegmark, and these are people I've also spoken 
to and and they're of this cohort that please do  

226
00:18:15,280 --> 00:18:20,800
do we need to be rushing so quickly into a world 
of AGI and agentic systems? Maybe we need more  

227
00:18:20,800 --> 00:18:26,960
tool based AI AI to solve specific things, 
rather than these all purpose or general  

228
00:18:26,960 --> 00:18:32,400
purpose kind of systems? And I know they've 
called for, for perhaps a slowdown to the  

229
00:18:32,400 --> 00:18:38,560
development of of these AGI systems. In your 
view, do you think you should be slowing down?

230
00:18:38,560 --> 00:18:42,240
Well, I've had lots of you know, I know 
them very well, Yoshua And Max, we've had  

231
00:18:42,240 --> 00:18:46,400
many discussions and many others. And actually, I 
have some sympathy for that view, that, you know,  

232
00:18:46,400 --> 00:18:51,920
building a tool based AI is, you know, thinking 
of AI as a tool, or the ultimate tool for,  

233
00:18:51,920 --> 00:18:58,480
say, science is the right way to build AI in the 
initial stages. And certainly that's the way we're  

234
00:18:58,480 --> 00:19:05,440
viewing it, and the kinds of things we apply AI 
to, like Alpha Fold. But the thing is, you know,  

235
00:19:05,440 --> 00:19:11,520
it's a very complex geopolitical and corporate 
system that we're in. And it isn't just about,  

236
00:19:11,520 --> 00:19:15,520
you know, there are many companies trying to build 
this. There are also many nations trying to build  

237
00:19:15,520 --> 00:19:21,840
it. And it's, there's a sort of race dynamic, 
which I ideally wouldn't be there. So in an  

238
00:19:21,840 --> 00:19:26,800
ideal case, this would be a scientific endeavor, 
and it will be very carefully, each step would be  

239
00:19:26,800 --> 00:19:31,760
carefully considered. But unfortunately, the the 
prac that the real world isn't isn't like that,  

240
00:19:31,760 --> 00:19:36,880
and we have to kind of be pragmatic about where 
we are. So what we're trying to do is be good  

241
00:19:36,880 --> 00:19:42,480
role models for Yes, being on the frontier, 
pushing that the benefits of that as quickly  

242
00:19:42,480 --> 00:19:48,880
as we can and as broadly as we can, but also try 
and be as responsible as possible with that along  

243
00:19:48,880 --> 00:19:52,880
the way and thoughtful as possible. And I think 
we've got that balance pretty, pretty good right  

244
00:19:52,880 --> 00:19:56,640
now. And hopefully that's a bit of a role model 
to the rest of the field in the industry, too.

245
00:19:56,640 --> 00:19:59,280
Yeah I want to address some of those 
dynamics as well. But just just first,  

246
00:19:59,280 --> 00:20:02,000
I guess, just from a personal point 
of view. Have you ever you said you  

247
00:20:02,000 --> 00:20:05,120
sort of started this mission of Deep Mind? 
You know, you believe in the technology,  

248
00:20:05,120 --> 00:20:09,600
but has there ever been any moments in your 
career when you're like, should we be doing this?

249
00:20:09,600 --> 00:20:16,560
Look you when you look at how powerful the 
technology is, I really think that there  

250
00:20:16,560 --> 00:20:22,800
are so many challenges confronting society 
today, not to do with AI, climate, poverty,  

251
00:20:22,800 --> 00:20:28,320
you know, the access to water, there's 
a there's just so many issues health,  

252
00:20:28,320 --> 00:20:36,240
aging, population, disease. So like, you know, 
energy we talked about earlier. So if a some,  

253
00:20:36,240 --> 00:20:40,720
if I if there wasn't a technology 
transformative as AI coming down the road,  

254
00:20:40,720 --> 00:20:45,360
I'd be really worried about society's 
ability to deal with these challenges.  

255
00:20:45,360 --> 00:20:49,600
So interestingly, AI itself is one of those 
challenges, maybe one of the greatest ones,  

256
00:20:49,600 --> 00:20:56,240
but it's also one which can help us cope with 
and resolve and solve some of these other big,  

257
00:20:56,240 --> 00:21:02,080
grand challenges. So it's a very interesting one, 
right? It's sort of double edged, and I've always  

258
00:21:02,080 --> 00:21:09,040
believed in that. I've always thought that, in 
the end, it would be the most important technology  

259
00:21:09,040 --> 00:21:15,440
we'll ever invent. And I think it's sort of the 
natural progression, really, of the computer age.

260
00:21:15,440 --> 00:21:20,240
Demis, you just, just a quick aside, you 
started life in gaming, which is amazing.

261
00:21:20,240 --> 00:21:21,760
Yeah,
codeveloping theme park.

262
00:21:21,760 --> 00:21:22,200
Yes,

263
00:21:22,200 --> 00:21:26,320
fantastic, fantastic game as well. 
Did you ever do you still play games?

264
00:21:26,320 --> 00:21:31,600
Yes, I love games. It's my hobby really well, 
like these days, like League of Legends,  

265
00:21:31,600 --> 00:21:35,840
with my two boys and my brother and we have 
a little team. We've done it since lockdown.  

266
00:21:36,560 --> 00:21:39,837
But, yeah, I love games in all its 
forms from football to video games

267
00:21:39,837 --> 00:21:44,800
in such a high impact, stressful role as 
you have, potentially, is that your unwind?

268
00:21:44,800 --> 00:21:48,160
It is, it is, I would say so. 
And it's also, you know, it's,  

269
00:21:48,160 --> 00:21:52,480
it's a kind of in the past as well, has 
been a great creative endeavor for me,  

270
00:21:52,480 --> 00:21:56,560
you know. And it's how I learned programming 
and other things was, was through making games.

271
00:21:56,560 --> 00:22:00,480
I have nowhere near as stressful 
job as you but that's my unwind too,

272
00:22:00,480 --> 00:22:01,120
for sure.

273
00:22:01,120 --> 00:22:02,800
Get home, turn the console on.

274
00:22:02,800 --> 00:22:04,640
Exactly, exactly
 

275
00:22:07,120 --> 00:22:12,640
Just in that small segment alone, Steve, there's 
so much to unpack, and I want to focus on on two  

276
00:22:12,640 --> 00:22:17,840
kind of big buzz words right now. The first 
is artificial general intelligence, or AGI,  

277
00:22:17,840 --> 00:22:22,080
this idea, and I know there's so many different 
definitions of it, but broadly speaking, this  

278
00:22:22,080 --> 00:22:28,400
idea of AI that that is as smart or smarter than 
humans. And I think that so many of these big AI  

279
00:22:28,400 --> 00:22:35,520
labs, including Open AI, including Deep Mind, are 
pushing and hoping to get to this stage of AGI,  

280
00:22:35,520 --> 00:22:40,640
and so far, they've approached this with 
a technique called large language models,  

281
00:22:40,640 --> 00:22:45,360
these AI models that are trained on huge amounts 
of data, but mainly text. But there's this other  

282
00:22:45,360 --> 00:22:52,720
buzzword, right? World models, this idea of these 
AI models that understand the physical world.  

283
00:22:52,720 --> 00:22:56,240
And this is this. This buzzword is 
really growing in popularity, right? 
 

284
00:22:56,240 --> 00:23:01,520
Yeah. And I think this is going to be a big 
theme of AI going into the rest of 2026,  

285
00:23:01,520 --> 00:23:07,440
and even into next year. Because the idea here is 
that, LLMs, sure we got the language part down.  

286
00:23:07,440 --> 00:23:13,120
It can mimic the way humans talk and speak and 
write and things like that. But when it comes to  

287
00:23:13,120 --> 00:23:18,160
the physical world, you know, we talk so much 
about robotics and AI and physical AI, well,  

288
00:23:18,160 --> 00:23:23,600
they need to understand how the physical world 
works, how water flows, how air moves and things  

289
00:23:23,600 --> 00:23:28,800
of that nature, and what really struck out to me 
when you brought this up to Demis he said, Yeah,  

290
00:23:28,800 --> 00:23:34,480
we do need to start exploring that more. And in 
fact, he sees a world in which the LLM and those  

291
00:23:34,480 --> 00:23:39,920
world models start to converge. I think that was 
the word he used, converge into something more  

292
00:23:39,920 --> 00:23:46,080
unique and more powerful and capable. This is also 
a debate that's been playing out among AI leaders,  

293
00:23:46,080 --> 00:23:51,440
like on social media, you could fire up X or your 
favorite social media site, and what really struck  

294
00:23:51,440 --> 00:23:58,560
out to me is Yann LeCun. He was the head of AI for 
many years over at Meta. He recently left to start  

295
00:23:58,560 --> 00:24:03,600
his own thing, because he kind of got superseded 
by Alexander Wang and that whole big talent wars  

296
00:24:03,600 --> 00:24:09,600
that happened over last summer, he had a really 
interesting interview in the Financial Times,  

297
00:24:09,600 --> 00:24:14,640
he doesn't think LLMs are what's going to get 
us to AGI, to your point, that's what everyone's  

298
00:24:14,640 --> 00:24:20,320
chasing. The super intelligence AGI, whatever 
you want to call it. His thing is LLMs can only  

299
00:24:20,320 --> 00:24:25,520
get you part of the way. You need world models 
and all sorts of other things. And he kind of  

300
00:24:25,520 --> 00:24:31,200
harshly criticized meta for not thinking beyond 
the LLM and that seems to be part of the reason  

301
00:24:31,200 --> 00:24:35,760
why he left to do his own thing. And it's really 
interesting to see one of Meta's big competitors,  

302
00:24:35,760 --> 00:24:40,800
Gemini, just talk openly about it and say 
Demis saying, Yeah, we need to do this. We  

303
00:24:40,800 --> 00:24:46,640
need to start thinking about this. It enables so 
many things, from robotics, autonomous driving  

304
00:24:46,640 --> 00:24:51,520
and just a better understanding for these 
AI models and intelligent systems that we're  

305
00:24:51,520 --> 00:24:57,440
chatting with to get you that right answer.
 
Steve, do you ever use a chat bot and you  

306
00:24:57,440 --> 00:25:01,200
put something in and it will say, Hey, Steve, 
great question. That's a really clever thought
 

307
00:25:01,200 --> 00:25:04,160
All the time. That's all that's that. It's 
the sycophancy of all these chatbots, right,  

308
00:25:04,160 --> 00:25:08,480
where they're like, Oh, you're so smart and great 
at asking me these questions. Yeah, all the time,

309
00:25:08,480 --> 00:25:12,240
Exactly Because the reason I bring that up is 
partly to this point, this growing criticism  

310
00:25:12,240 --> 00:25:17,120
of LLMs is that actually, yes, they're great and 
they'll give you the information. But actually,  

311
00:25:17,120 --> 00:25:22,320
when it comes to LLMs as a foundation 
for being able to create new ideas,  

312
00:25:22,320 --> 00:25:26,480
novel ideas, there's limitations there, 
and I think that's partly what Demis was  

313
00:25:26,480 --> 00:25:30,960
speaking to and why this idea of world 
models is really growing in popularity.  

314
00:25:31,600 --> 00:25:35,520
It's going to be interesting to see how this plays 
out, as you mentioned, into this next phase of AI,  

315
00:25:35,520 --> 00:25:40,480
where it's key for things like robotics, 
driverless cars, and many other use cases too.
 

316
00:25:40,480 --> 00:25:45,600
Yeah, and you'll you'll notice, as we continue 
this podcast, I am incredibly cynical about the  

317
00:25:45,600 --> 00:25:50,960
robotics angle of this AI moment we're living 
in all that so many of the robots we're seeing,  

318
00:25:50,960 --> 00:25:56,080
they're literally puppets. They're tele operated. 
The best example, of course, is the Tesla Optimus  

319
00:25:56,080 --> 00:26:01,760
robot, which started out as a man in a body 
suit dancing around. Now it's a real robot,  

320
00:26:01,760 --> 00:26:07,200
but again, it's tele operated. There are literally 
people at a control room controlling it over the  

321
00:26:07,200 --> 00:26:11,920
internet and even using their voice to talk 
to you and things like that. So we are , the  

322
00:26:11,920 --> 00:26:16,320
robotics people I talked to, we had one in the 
office just a couple weeks ago, and they said the  

323
00:26:16,320 --> 00:26:21,440
hardest part isn't building the actual robot, it's 
training it, and that's where these world models  

324
00:26:21,440 --> 00:26:28,800
are going to come in, so they can actually operate 
autonomously, like we've been promised. Perfect.

325
00:26:28,800 --> 00:26:34,400
Demis, you mentioned some of the dynamics at play, 
right? And competition commercially, of course,  

326
00:26:34,400 --> 00:26:39,280
is one of those. We've got Open AI, we've got 
Anthropic, we've got all these different AI labs  

327
00:26:39,280 --> 00:26:45,360
out there. It's intense. And Gemini three has 
had such good reception so far. But there was  

328
00:26:45,360 --> 00:26:49,840
a point people were doubting Google as a 
whole and its ability to compete. And I'd  

329
00:26:49,840 --> 00:26:55,040
say a point. It was at some point in 2025 and it 
wasn't that long ago. And then, you know, Gemini  

330
00:26:55,040 --> 00:27:00,880
3 really came out and impressed a lot of people 
as well. But it's a space that's ever changing.  

331
00:27:00,880 --> 00:27:04,960
So how we how would you assess right now, the 
competitive environment? How do you feel it?

332
00:27:04,960 --> 00:27:09,920
Yeah, well, look, it's a ferocious, competitive 
environment at the moment. I mean, many people  

333
00:27:09,920 --> 00:27:14,000
were telling me, you know, being in tech for 
2030, years, say it's that it's the most intense  

334
00:27:14,000 --> 00:27:17,920
environment they've ever seen, perhaps, 
you know, ever in the technology industry,  

335
00:27:18,960 --> 00:27:23,920
and, and, and, you know, all the, I guess, 
most capable players, whether it's individual,  

336
00:27:23,920 --> 00:27:28,720
you know, tech Titans or big tech companies, and 
all the best startups, they're all involved in  

337
00:27:28,720 --> 00:27:32,880
this space now, because I think everyone has 
understood what we've known for 20 plus years  

338
00:27:32,880 --> 00:27:38,240
now that this is really the most important 
technology. So that's sort of to be expected,  

339
00:27:38,240 --> 00:27:44,640
but it's tough, but it's, it's also exciting. 
And, you know, going back to games, I sort of,  

340
00:27:44,640 --> 00:27:49,040
I've started playing chess when I was very young 
for the England Junior chess team. So I've kind of  

341
00:27:49,040 --> 00:27:53,360
been brought up in in competition. So, you know, 
I love competition, fortunately, in fact, many  

342
00:27:53,360 --> 00:27:58,720
ways I live for competition. So a lot of a big 
part of me sort of like, likes to lean into this.  

343
00:27:58,720 --> 00:28:02,160
But on the other hand, the only thing I would 
say is, at the back of my mind, I know there's  

344
00:28:02,160 --> 00:28:06,320
something much more important than individual 
competition between companies or even countries,  

345
00:28:06,320 --> 00:28:11,600
which is overall getting stewarding AGI well, for 
the world, for the whole, you know, for the all of  

346
00:28:11,600 --> 00:28:18,960
humanity. And I think that's incumbent of all of 
us who are leaders of the AI labs and and can have  

347
00:28:18,960 --> 00:28:23,760
an influence over this, is to have that sort of 
in the front of their minds, in amongst this sort  

348
00:28:23,760 --> 00:28:28,720
of ferocious capitalist competition that we're 
in as well. So both are true at the same time

349
00:28:28,720 --> 00:28:32,080
I mentioned, kind of the moment people were 
questioning what Google was going to do  

350
00:28:32,080 --> 00:28:36,800
with with AI at earlier in the year. 
Yeah. Did you do anything different?

351
00:28:36,800 --> 00:28:42,240
Yeah, I think I feel like, you know, if we go 
back over the last decade, actually, you know,  

352
00:28:42,240 --> 00:28:47,680
Google, Google Brain, specifically the research 
division in Google and DeepMind as it was.  

353
00:28:47,680 --> 00:28:52,720
Are sort of fairly independent. We kind 
of invented about 90% of the technologies  

354
00:28:52,720 --> 00:28:56,800
that everybody's using today, you know, whether 
it's transformers, of course, most famously,  

355
00:28:56,800 --> 00:29:01,360
the architecture behind all the LLMs or AlphaGo, 
you know, sort of introduced reinforcement  

356
00:29:01,360 --> 00:29:07,200
learning at scale on a really hard problem. So 
we've invented all this technology, but then  

357
00:29:07,200 --> 00:29:11,760
maybe we were, in hindsight, we were a little 
bit slow to commercialize it and scale it. And  

358
00:29:12,320 --> 00:29:16,640
you know, that's what Open AI and others did 
very well. And then the last two, three years,  

359
00:29:16,640 --> 00:29:23,760
I think we've had to come back to almost our 
startup or entrepreneurial roots and be scrappier,  

360
00:29:23,760 --> 00:29:29,920
be faster, ship things really quickly and 
and sort of make really rapid progress. And  

361
00:29:29,920 --> 00:29:34,480
I think what you're seeing over the last couple of 
years, culminating in Gemini, the Gemini series,  

362
00:29:34,480 --> 00:29:40,480
which we're very happy with Gemini three is, as 
you mentioned, our latest version has sort of put  

363
00:29:40,480 --> 00:29:45,280
us back, you know, near the top of, you know, the 
top of the leaderboards, where we feel we belong.

364
00:29:45,280 --> 00:29:46,960
And you feel like you can stay there.

365
00:29:46,960 --> 00:29:49,600
I feel like we can stay there, of course, yeah.

366
00:29:49,600 --> 00:29:56,320
Amid all this competition, there's obviously a 
lot of talk about bubbles in AI, yes, particularly  

367
00:29:56,320 --> 00:30:02,000
around valuations of certain companies, companies 
rating raising astronomical sums of money. The  

368
00:30:02,000 --> 00:30:07,360
tech giant spending hundreds of billions 
on infrastructure, and companies out there,  

369
00:30:07,360 --> 00:30:11,840
quite frankly, raising large sums of money 
with very little product, or even very little  

370
00:30:11,840 --> 00:30:17,040
profitability, if any. And so where do you 
think we are right now in terms of this, this  

371
00:30:17,040 --> 00:30:21,360
kind of bubble discussion? Do you think we're in 
a financial bubble when it comes to AI industry?

372
00:30:21,360 --> 00:30:25,440
I think, I think it's not a binary thing, 
this bubble discussion. I don't I think  

373
00:30:25,440 --> 00:30:29,440
some parts of the industry might be in a 
bubble. To me, that's what it looks like,  

374
00:30:29,440 --> 00:30:33,440
and others probably not. You know, fundamentally, 
AI is going to be the most transformative  

375
00:30:33,440 --> 00:30:38,880
technology ever invented. So that's that's that 
part that underpins everything. So in the end,  

376
00:30:38,880 --> 00:30:42,960
it's a bit like the internet bubble. In the 
end, the Internet was critical, and there were  

377
00:30:42,960 --> 00:30:48,800
some generational companies that were created in 
during that time, right? So I think, you know,  

378
00:30:48,800 --> 00:30:52,960
that's sort of almost inevitable. There'll be 
over exuberance, once everyone realizes how  

379
00:30:52,960 --> 00:30:59,600
transformative a specific technology is, and then 
there'll be a, probably a reckoning, and then the  

380
00:30:59,600 --> 00:31:05,120
things that are real will survive and flourish. 
Where, it seems to me, is, you know, maybe like  

381
00:31:05,120 --> 00:31:09,600
in the private markets, where there's sort of 
seed rounds, of 10s of billions of dollars,  

382
00:31:09,600 --> 00:31:14,400
where basically there's just almost nothing there 
yet, and that seems a little bit unsustainable  

383
00:31:14,400 --> 00:31:18,800
over the long run. As far as I'm concerned, I 
don't really worry about bubbles. My point of  

384
00:31:18,800 --> 00:31:24,320
view is sort of leading Google DeepMind. I've got 
to make sure that whichever way it goes, whether  

385
00:31:24,320 --> 00:31:28,960
it continues to go all rosy and exponential, like 
it is now, or there's a bubble that, you know,  

386
00:31:28,960 --> 00:31:34,240
there's some kind of bubble bursting, that we're 
in the right position to, to win either way,  

387
00:31:34,240 --> 00:31:38,640
and to take advantage of that either way. And I 
think we've got a good position, given Google's  

388
00:31:38,640 --> 00:31:44,720
underlying business and how AI fits with that, to 
to to benefit, whichever way it goes from here.

389
00:31:44,720 --> 00:31:48,640
Some I guess some of your biggest competitors 
are the ones who have managed to raise huge sums  

390
00:31:48,640 --> 00:31:52,640
of money in the private markets at this point. 
So do you feel confident that even if there is  

391
00:31:52,640 --> 00:31:56,720
some sort of correction at some point that, you 
know, you'll be able to weather it out I guess

392
00:31:56,720 --> 00:32:00,880
Yeah I mean, look, you know, that's the whole 
point of Google's balance sheet, and also all  

393
00:32:00,880 --> 00:32:06,640
the incredible products that and surfaces that, 
that we have, you know, I think it's, you know,  

394
00:32:06,640 --> 00:32:13,680
dozens of multibillion user products and and AI 
kind of naturally fits into all of those products,  

395
00:32:13,680 --> 00:32:19,200
whether it's, you know, email workspace or 
or, you know, new things like the Gemini app.

396
00:32:19,200 --> 00:32:23,680
Yeah, you mentioned dynamics at play as well. We 
talked competition. The other one is geopolitics,  

397
00:32:23,680 --> 00:32:27,440
which you mentioned as well, when huge 
discussions around China, of course,  

398
00:32:27,440 --> 00:32:31,840
in this kind of competition battle between 
China and the US. But there was a point where  

399
00:32:31,840 --> 00:32:38,080
people were discounting the ability of China 
and its companies to come up with strong AI  

400
00:32:38,080 --> 00:32:44,400
models and technologies. But actually we saw with 
kind of what Deep Seek did. It kind of brought a  

401
00:32:44,400 --> 00:32:48,480
bit of shock to our but actually, more than that, 
some of the big tech companies like Alibaba,  

402
00:32:48,480 --> 00:32:53,200
coming up with some very competitive open source 
models. So China's not out of this game, right?

403
00:32:53,200 --> 00:32:57,760
Not at all. And actually, you know, I think 
they are closer to the US front, you know,  

404
00:32:57,760 --> 00:33:02,560
US and West Frontier models, than maybe 
we thought one or two years ago. Maybe  

405
00:33:02,560 --> 00:33:06,880
they're only a matter of months behind 
at this point. The interesting thing is,  

406
00:33:06,880 --> 00:33:11,040
and they're very there's from very capable teams, 
of course, like the deep seek team and Alibaba you  

407
00:33:11,040 --> 00:33:18,400
mentioned. And the question is, is, can they 
innovate something new beyond the frontier?  

408
00:33:18,400 --> 00:33:23,200
So I think they've shown they can catch up, 
you know, and be very close to the frontier  

409
00:33:23,200 --> 00:33:28,720
and catch up very quickly. But can they actually 
innovate something new, like a new Transformers,  

410
00:33:29,280 --> 00:33:32,480
you know, that gets Beyond the Frontier? 
I don't think that's been shown yet.

411
00:33:32,480 --> 00:33:35,600
Is that going to be, in your 
view, difficult because of  

412
00:33:35,600 --> 00:33:39,200
restrictions on access to technology, 
like leading edge chips, for example?

413
00:33:39,200 --> 00:33:44,240
No, I think it's more a mentality issue, you 
know. So I think it's something that at least the  

414
00:33:44,240 --> 00:33:49,440
leading. Labs, the leading frontier labs in the 
West have nurtured, I can say for ourselves, you  

415
00:33:49,440 --> 00:33:55,600
know, we, you can think of DeepMind as a bit like 
a try to be a modern day Bell Labs and encourage  

416
00:33:55,600 --> 00:34:00,640
innovation and exploratory innovation, not just 
kind of, you know, scaling out what's what's known  

417
00:34:01,360 --> 00:34:04,400
today. And of course, that's already very 
difficult, because you need world class  

418
00:34:04,400 --> 00:34:10,320
engineering already to be able to do that. And 
China definitely have that. The question is,  

419
00:34:10,320 --> 00:34:15,440
is the scientific innovation part that's a lot 
harder to, you know, to invent something is about  

420
00:34:15,440 --> 00:34:21,200
100 times harder than it is to to copy it. So 
the question that's the next frontier release is,  

421
00:34:21,200 --> 00:34:27,680
and I haven't seen evidence of 
that yet, but it's very difficult.

422
00:34:27,680 --> 00:34:33,440
So one of the most striking parts of that part of 
the conversation for me, Steve was around China.  

423
00:34:33,440 --> 00:34:38,960
I used to live in China for just over 
three years. Report out of China for CNBC,  

424
00:34:38,960 --> 00:34:43,760
covering the tech sector there. And there was this 
growing view recently that actually China is so  

425
00:34:43,760 --> 00:34:50,560
far behind the US when it comes to AI for multiple 
reasons. One of those is that, oh, it may not be  

426
00:34:50,560 --> 00:34:55,120
able to get its hands on the most advanced chips 
so its industry could fall behind. One view is  

427
00:34:55,120 --> 00:34:59,680
that it's just not innovating, and it doesn't have 
the capital the way US companies do. But actually  

428
00:34:59,680 --> 00:35:04,800
what was really interesting from Demis is he said 
that he believes Chinese AI models are just months  

429
00:35:04,800 --> 00:35:12,080
behind where the US is, so actually not far 
behind. And remember when last year we had Deep  

430
00:35:12,080 --> 00:35:18,960
Seek really shock the world and markets. It showed 
I think China is in the game. And since then,  

431
00:35:18,960 --> 00:35:25,760
whilst Deep Seek hasn't quite made the waves, 
it did when it first kind of came out, Alibaba,  

432
00:35:25,760 --> 00:35:30,800
one of the world's biggest or one of China's 
biggest tech companies, has been a leader there.  

433
00:35:30,800 --> 00:35:36,000
It's developed some really interesting models, 
which, if you look at the opensource communities,  

434
00:35:36,000 --> 00:35:40,720
such as on a site called Hugging Face, you see 
Alibaba's models are amongst some of the most  

435
00:35:40,720 --> 00:35:45,680
popular experts who I've spoken to in the space 
say they're amongst some of the most advanced in  

436
00:35:45,680 --> 00:35:50,160
the world. So you are seeing there. And one of 
the things I can tell you, just from living and  

437
00:35:50,160 --> 00:35:56,320
working out there, is Chinese companies move fast. 
They have the expertise and they can innovate,  

438
00:35:56,320 --> 00:36:02,400
so you can't discount them out of this kind of AI 
race. But also, take Demis's point that he said,  

439
00:36:02,400 --> 00:36:06,800
whilst the Chinese companies are sort of 
catching up and are very much in this race,  

440
00:36:06,800 --> 00:36:11,440
one thing they haven't proven is their abilities 
to kind of make these big breakthroughs. So,  

441
00:36:11,440 --> 00:36:15,120
you know, I thought that was a really interesting 
and nuanced view. I guess the other part here,  

442
00:36:15,120 --> 00:36:20,000
Steve is something you picked up on is 
Demis's comments on bubbles and AI bubbles. 
  

443
00:36:20,000 --> 00:36:24,320
Yeah, that, by the way, just talking, let's go 
back to what he said first, about the months  

444
00:36:24,320 --> 00:36:29,760
thing. Deep Seek a year ago. It wasn't just about 
the fact that China can do it and make a really  

445
00:36:29,760 --> 00:36:34,320
good large language model or a chat bot. It was 
also the idea that they did it without the most  

446
00:36:34,320 --> 00:36:38,640
powerful Nvidia chips that kind of rattled the 
markets as well, and that's what we're seeing here  

447
00:36:38,640 --> 00:36:45,040
in the United States now Arjun is trying to limit 
China's ability to get those Nvidia chips. There's  

448
00:36:45,040 --> 00:36:49,760
all this talk about maybe they'll get those H200 
chips, which aren't the best chips, but they're  

449
00:36:49,760 --> 00:36:53,840
better, probably than what China has access to. 
And then you get into the whole smuggling thing.  

450
00:36:53,840 --> 00:37:00,240
But to Demis's point, you know, if they really are 
months behind without full access to these chips,  

451
00:37:00,240 --> 00:37:05,760
you know, that kind of questions Nvidia's 
prominence and dominance in the chip space as  

452
00:37:05,760 --> 00:37:11,920
well. But yes, what you said about the bubble is 
also super interesting too, because you asked him  

453
00:37:11,920 --> 00:37:16,080
about that, are we in a bubble? What do you think 
all this sort of things. And he basically said,  

454
00:37:16,080 --> 00:37:20,320
we're Google. We're rich. It doesn't matter. We 
have the money. We have the free cash flow to  

455
00:37:20,320 --> 00:37:25,680
spend this our balance sheet is our superpower. If 
for some reason we need to rein back the spending,  

456
00:37:25,680 --> 00:37:31,040
we can do it and we'll be fine. But guess who 
can't do that? That's OpenAI and Anthropic,  

457
00:37:31,040 --> 00:37:36,080
the other two leaders, X ai, we can throw them 
in here too. Their whole thing is they have to  

458
00:37:36,080 --> 00:37:41,600
raise money indefinitely in order to get to the 
point where they can finally show some revenue  

459
00:37:41,600 --> 00:37:48,720
and revenue growth to sustain themselves without 
continuous fundraising if things start to dry up,  

460
00:37:48,720 --> 00:37:54,960
open AI and anthropic are at extreme risk, 
Google, Microsoft, meta, they have the cash  

461
00:37:54,960 --> 00:37:58,960
flow to move on to another project. Meta has 
already done it with the metaverse. These  

462
00:37:58,960 --> 00:38:08,480
companies can pivot very easily because they 
had these big, high margin businesses already

463
00:38:08,480 --> 00:38:14,160
Demis lot of people, I guess, forget how much of 
Google's AI capabilities come out from DeepMind  

464
00:38:14,160 --> 00:38:18,640
and yourself and your teams. How do you work 
with Google? There's a lot of fascination around  

465
00:38:18,640 --> 00:38:23,680
that. Does Sundar Pichai call you up one day? Say, 
Hey, Demis, we need this thing, or we have this  

466
00:38:23,680 --> 00:38:29,040
idea for Gemini or for some other AI product. 
Can you build it? How is that relationship?

467
00:38:29,040 --> 00:38:33,040
Yeah, so the last three years, we've combined 
everything together as into Google Deep Mind this,  

468
00:38:33,040 --> 00:38:37,520
this one entity that that that all the AI 
research at Google goes on in and it's a kind  

469
00:38:37,520 --> 00:38:43,360
of combination of Google research, Google Brain 
and Deep Mind and and I run that group, and it's,  

470
00:38:43,360 --> 00:38:48,480
it's like the engine room of Google. You should 
think of it like that. So all the AI technologies  

471
00:38:48,480 --> 00:38:53,760
is done by this group, by our group, and then it's 
diffused across, you know, all of these incredible  

472
00:38:53,760 --> 00:38:59,120
products right across Google. And the last couple 
of years, we've been building that backbone,  

473
00:38:59,120 --> 00:39:03,520
so not just the models, but also almost in 
we architecting the entire infrastructure of  

474
00:39:03,520 --> 00:39:08,080
Google so that it can, you know, these things 
can ship incredibly quickly. These models,  

475
00:39:08,080 --> 00:39:12,880
it's almost sim ship to all the main surfaces. 
So, you know, when we release a new Gemini model,  

476
00:39:12,880 --> 00:39:18,160
it's there the next day or the same day in search 
and and that's been going really well. I think I  

477
00:39:18,160 --> 00:39:23,760
would say we really got into our groove with 
the 2.5 Gemini models. And for the last sort  

478
00:39:23,760 --> 00:39:30,160
of year that's becoming really a smooth process 
now, and I think you'll see that more over the  

479
00:39:30,160 --> 00:39:35,280
next next 12 months. And so, you know, we think 
of ourselves as the and describe ourselves sort  

480
00:39:35,280 --> 00:39:39,840
of as the engine room for that. And you know, 
Sundar and I pretty much talk every day about  

481
00:39:39,840 --> 00:39:46,240
strategic things and where should the technology 
go, and what does the wider Google need. And then,  

482
00:39:46,240 --> 00:39:50,640
you know, we adjust the roadmaps and 
the plans, you know, on a daily basis,  

483
00:39:50,640 --> 00:39:55,920
whilst keeping in mind the long term goals of, 
you know, getting to AGI first, fast and safely.

484
00:39:55,920 --> 00:40:00,160
So we should, we should expect more of the 
ability to come up with with new things,  

485
00:40:00,160 --> 00:40:04,080
new AI tools and that be shipped 
across the Google portfolio,  

486
00:40:04,080 --> 00:40:06,200
etc, because of that kind of change 
you've made in that relationship.

487
00:40:06,200 --> 00:40:11,840
Yes thats right. So it's an incredibly 
tight sort of iteration loop and and,  

488
00:40:11,840 --> 00:40:14,160
you know, we're all on the 
same tech stack and so on

489
00:40:14,160 --> 00:40:17,520
A lot of what you're building is going 
into Google products, but I know kind  

490
00:40:17,520 --> 00:40:21,200
of covering companies like Samsung. You help 
companies like Samsung to build out some of  

491
00:40:21,200 --> 00:40:26,000
the AI tools within their smartphones, for 
example, and that kind of thing as well.

492
00:40:26,000 --> 00:40:30,960
Well, look, we work with a lot of partners as you, 
as you mentioned, you know, we're very proud of  

493
00:40:30,960 --> 00:40:36,560
the fact that our technology selected by those 
partners because they see how capable it is and,  

494
00:40:36,560 --> 00:40:41,600
and actually, you know, it comes to Samsung and 
other devices, I think there's really interesting  

495
00:40:41,600 --> 00:40:47,600
way. I'm very interested in the idea of edge 
compute and and faster versions of these models  

496
00:40:47,600 --> 00:40:52,080
working on these edge devices, be those phones, 
but also new devices like glasses that we're  

497
00:40:52,080 --> 00:40:58,160
working on. And, you know, partners like Warby 
Parker and the idea of smart glasses, and I think  

498
00:40:58,160 --> 00:41:03,200
Google's worked on smart glasses for a long time, 
as you know, but I think that they, you know,  

499
00:41:03,200 --> 00:41:08,000
finally we have the killer app, I would say, for 
it, which is this idea of a universal assistant,  

500
00:41:08,000 --> 00:41:14,160
and, and, and sort of helping you in your 
everyday life. And I think all the, all the,  

501
00:41:14,160 --> 00:41:17,840
all the big device players are going to 
be interested in that type of technology.

502
00:41:17,840 --> 00:41:21,840
Demis. We've only got a few minutes left but 
I do want to ask a little bit about I was a  

503
00:41:21,840 --> 00:41:26,640
brand new tech reporter when Google bought 
Deep Mind 2014 I think it was a 400 million  

504
00:41:26,640 --> 00:41:30,640
pound 100 million pound deal back then. So 
many people didn't know what you what you  

505
00:41:30,640 --> 00:41:35,520
did. And why is Google buying this British 
company? What's going what's going on here?  

506
00:41:36,160 --> 00:41:40,240
Do you ever look back to that and and think, oh, 
maybe we should have stayed independent at all.

507
00:41:40,240 --> 00:41:42,080
Yeah
Or Are you happy with how things have turned out

508
00:41:42,080 --> 00:41:47,360
Well, look, we I knew it's funny. So, so the 
the head of search at the time Alan Eustace,  

509
00:41:47,360 --> 00:41:52,640
he was sort of in charge with Larry. Larry was 
sponsoring, Larry Page was sponsoring the deal,  

510
00:41:52,640 --> 00:41:56,800
as he was CEO at the time but Alan Eustace was 
delegated the head of search to kind of close  

511
00:41:56,800 --> 00:42:01,440
the deal. And I did tell Alan that this would be 
the most important acquisition Google ever made,  

512
00:42:01,440 --> 00:42:07,360
which is, which is quite something, given they've, 
you know, there's YouTube and AdWords and other  

513
00:42:07,360 --> 00:42:12,160
things that they previously acquired. But I kind 
of knew how important this was going to be, and  

514
00:42:12,160 --> 00:42:17,520
also how good a fit it was with Google's mission, 
which is organize the world's information,  

515
00:42:17,520 --> 00:42:22,960
and AI is a very natural fit to that and 
organizing and understanding information. I mean,  

516
00:42:22,960 --> 00:42:27,040
what better tool than AI for that. So I kind 
of knew that would be a natural fit. And we  

517
00:42:27,040 --> 00:42:32,640
sort of knew that this, you know, maybe it's now 
worth, I don't know, 100x 1,000x of, you know,  

518
00:42:32,640 --> 00:42:37,600
what, of what we sold it for. But the thing is, I 
wanted to get back to the science at the time and  

519
00:42:38,320 --> 00:42:43,360
push forward the research, which was still very 
nascent back in 2014 and, you know, fair play  

520
00:42:43,360 --> 00:42:47,200
to Google is they were one of the few companies 
in the world, I think that could recognize and  

521
00:42:47,200 --> 00:42:51,440
specifically Larry at the time, how important this 
technology was going to be, what it could become,  

522
00:42:51,440 --> 00:42:55,680
and what we see it for it today. And I don't 
think we could have done the great work we did  

523
00:42:55,680 --> 00:43:01,840
with AlphaGo and Alpha Fold and all the science 
we've done and if we hadn't had their backing and  

524
00:43:01,840 --> 00:43:07,040
the amount of compute that they could bring 
to play. So I don't have any regrets at all.

525
00:43:07,040 --> 00:43:12,080
So Tech CEOs, AI CEOs, the new rock stars of the 
world. I've seen Jensen Huang here in Europe,  

526
00:43:12,080 --> 00:43:17,760
and the CEO of Nvidia, being followed 
around by everyone as well. Jensen,  

527
00:43:17,760 --> 00:43:22,320
I think, said recently that you and him talk 
he had great things to say about nano banana,  

528
00:43:22,320 --> 00:43:26,160
the new image generation tool, as 
well. What do you guys discuss?

529
00:43:26,800 --> 00:43:30,400
I mean, Jensen's great, you know, 
incredible pioneer, also somebody,  

530
00:43:30,400 --> 00:43:36,320
you know, I admire him for sticking to his 
vision for 2030, years now, in fact, I first  

531
00:43:36,320 --> 00:43:42,960
started using GPUs in the 90s on for gaming, of 
course, for writing graphics engines and physics  

532
00:43:42,960 --> 00:43:48,240
engines. So it's funny that it's come full circle 
to me that that, you know, my early gaming days,  

533
00:43:48,240 --> 00:43:52,320
even the hardware that was pushed then, is 
now useful for AI, ironically. But yeah,  

534
00:43:52,320 --> 00:43:56,400
we talk about, he's very interested in science 
and AI for science. And actually, you know,  

535
00:43:56,400 --> 00:44:01,120
Alpha fold was trained on GPUs, so we and he 
loves Alpha fold and the work that we're doing,  

536
00:44:01,120 --> 00:44:06,000
you know, in drug discovery. So we 
most, mostly talk about AI for science.

537
00:44:06,000 --> 00:44:11,920
I know a lot of the data centers are built in 
Nvidia systems, but I know Google also has its  

538
00:44:11,920 --> 00:44:16,800
Tensor Processing Units, TPU chips. Is there 
any kind of competitive friendliness there?

539
00:44:17,520 --> 00:44:23,120
We're lucky. We have our own we love our TPUs. 
We generally use them internally for training our  

540
00:44:23,760 --> 00:44:30,160
our best models. And actually we found there's 
a big demand for that from the elite AI teams  

541
00:44:30,160 --> 00:44:36,960
who are trying to build large models or serve very 
large AI models. They're specifically built for  

542
00:44:36,960 --> 00:44:40,880
that. So TPUs are sort of they're a little bit 
more special case than GPUs. You can think of  

543
00:44:40,880 --> 00:44:46,720
GPUs as being more general. So, you know, maybe we 
would use a GPU when we're trying to explore some  

544
00:44:46,720 --> 00:44:52,880
new architecture, like alpha fold was, or some new 
application. But then once we're when we're trying  

545
00:44:52,880 --> 00:44:59,840
to sort of scale to the maximum, things we know, 
then, you know, custom silicon can be a lot more  

546
00:44:59,840 --> 00:45:05,680
efficient. So we're lucky. We have, we have both. 
We get to use both here at at Google and DeepMind,

547
00:45:05,680 --> 00:45:10,400
Great Demis. Just looking to the future. You're 
obviously so focused on science and the potential  

548
00:45:10,400 --> 00:45:16,720
for AI to create new drug breakthroughs. 
Do discover new diseases. Lots of potential  

549
00:45:16,720 --> 00:45:23,680
things there. You've also got isomorphic labs, of 
course, as well. Where are we on this path to your  

550
00:45:23,680 --> 00:45:29,680
your vision of AI unlocking all of these, these 
kind of breakthroughs in the world of science.

551
00:45:29,680 --> 00:45:35,520
Well, look, I love, I always point to Alpha fold 
as probably the best example so far of AI applied  

552
00:45:35,520 --> 00:45:39,840
to science. You know, I'm very proud of that 
project. And, you know, we solved a 50 Year  

553
00:45:39,840 --> 00:45:44,400
grand challenge in science of protein folding, 
how the structure of the structure of proteins,  

554
00:45:44,400 --> 00:45:48,960
and over 3 million researchers around the 
world are using it in their critical work.  

555
00:45:48,960 --> 00:45:55,440
So I can't imagine a more transformative sort of 
technology. And what I would love is to see have  

556
00:45:55,440 --> 00:46:01,040
be able to point to a dozen Alpha Folds, and you 
know, each of them revolutionizing their area of  

557
00:46:01,040 --> 00:46:05,520
science or mathematics. And I think we're well 
on the way to that. And we're working on half  

558
00:46:05,520 --> 00:46:12,080
a dozen projects like that, in material science, 
in physics, in in maths, in weather prediction and  

559
00:46:12,080 --> 00:46:16,400
and I think that the next 10 years, if, 
if AI, goes well and progress as well,  

560
00:46:16,400 --> 00:46:21,760
and we use it in the right way, could usher 
in a new golden age of scientific discovery.

561
00:46:21,760 --> 00:46:26,000
What do you think are going to be the big 
things in AI in 2026 any big breakthroughs,  

562
00:46:26,000 --> 00:46:28,160
any big progresses that you think will happen?

563
00:46:28,160 --> 00:46:30,960
Agentic system, systems able 
to do things more autonomously,  

564
00:46:30,960 --> 00:46:35,760
are going to start becoming reliable enough 
to be useful. I think we're going to see some  

565
00:46:35,760 --> 00:46:39,280
really interesting things in robotics in the 
next 12 to 18 months, we're working really  

566
00:46:39,280 --> 00:46:44,160
hard on some very ambitious projects with 
Gemini robotics. And then finally, maybe,  

567
00:46:44,960 --> 00:46:50,560
you know, AI systems on devices, I think we're 
going to start seeing them really useful in the  

568
00:46:50,560 --> 00:46:55,840
real world. And then maybe the thing I'm most 
excited about is advancing world models further,  

569
00:46:55,840 --> 00:47:00,320
making them more efficient so they can actually 
be used, maybe for planning in our general models.

570
00:47:00,320 --> 00:47:04,720
Great. Demis, I'm going to take that last answer 
as a sort of teaser trailer for the next time you  

571
00:47:04,720 --> 00:47:08,960
and I get to catch up, hopefully at some point 
this year. Thank you so much for joining me.

572
00:47:08,960 --> 00:47:12,211
Thank you. Thanks for having me
 
That's good. Then we'll get back  

573
00:47:12,211 --> 00:47:13,600
into the chat. Great. There's just 
the final part, yeah, yeah, yeah, and
 

574
00:47:13,600 --> 00:47:17,600
So Steve, just in that final part of the 
conversation, I thought what was interesting  

575
00:47:17,600 --> 00:47:24,000
is the relationship between kind of the Deep Mind 
entity and the broader Google business. And there  

576
00:47:24,000 --> 00:47:29,680
was a part where Demis was saying he speaks to 
Sundar Pichai, the CEO of Google, or Alphabet,  

577
00:47:29,680 --> 00:47:36,800
every day and and how sort of more integrated 
they've become, I think, if I'm thinking about  

578
00:47:36,800 --> 00:47:43,600
that this AI race, what that signals to me is 
that Google has clearly. Figured out how to become  

579
00:47:43,600 --> 00:47:48,640
speedy at getting AI products to market. But also 
you got to think about all these Google products  

580
00:47:48,640 --> 00:47:54,640
right, whether it's Chrome, whether it's Gmail, 
whatever it might be they are wanting, whatever  

581
00:47:54,640 --> 00:47:59,840
Google AI is being developed to spread all across, 
all across those products that gives them an  

582
00:47:59,840 --> 00:48:05,680
absolutely mammoth user base to kind of almost 
instantly tap into with some of these products.  

583
00:48:05,680 --> 00:48:10,000
And I've always, I've said this for a while 
now, I think one of Google's biggest strengths,  

584
00:48:10,000 --> 00:48:15,360
really, is that when you think about the Android 
operating system and and you know how large it is,  

585
00:48:15,360 --> 00:48:21,680
70% odd market share globally, you know that 
is a huge amount of people and devices where  

586
00:48:21,680 --> 00:48:26,560
Google AI could be instantly, effectively 
installed on and used quickly. So they're  

587
00:48:26,560 --> 00:48:32,480
in a good position in terms of going to market, 
I think. And clearly, this relationship between  

588
00:48:32,480 --> 00:48:37,200
Deep Mind and the broader Google business is 
going to be integral for Google to sustain  

589
00:48:37,200 --> 00:48:42,320
any success over the over the longer run here
 
Yeah, and on the Android front alone, I mean,  

590
00:48:42,320 --> 00:48:46,000
Samsung, the biggest manufacturer of Android 
phones, they're already putting Gemini is  

591
00:48:46,000 --> 00:48:50,560
their main chat bot. Gemini is their main AI. 
I was a little surprised. Samsung didn't try  

592
00:48:50,560 --> 00:48:54,720
to build their own, which, like they have in 
the past, but No, they've completely gone all  

593
00:48:54,720 --> 00:49:01,200
in on Gemini. They're partnering with Google 
on those the new mixed reality headset that  

594
00:49:01,200 --> 00:49:06,080
they have. There are some upcoming glasses 
that they're working on in partnership, also  

595
00:49:06,080 --> 00:49:11,840
with companies like Warby Parker to design them. 
So yeah, Samsung is, like, really adopted this,  

596
00:49:11,840 --> 00:49:19,120
and that is a huge platform for Gemini, just just 
that, just the Samsung angle of it, just that huge  

597
00:49:19,120 --> 00:49:23,920
market share they already have is great. And then 
let's talk about Apple. Gemini is actually going  

598
00:49:23,920 --> 00:49:29,760
to be the engine that powers this new version of 
Siri we're expecting in just a couple months time.  

599
00:49:29,760 --> 00:49:36,560
He did talk about his excitement to see Gemini 
kind of spread on more devices. So I think it's  

600
00:49:36,560 --> 00:49:41,680
a really smart move by Apple to kind of realize 
it can't build this on its own and honestly do  

601
00:49:41,680 --> 00:49:46,960
what Samsung is doing, and say, Okay, let's just 
integrate this proven technology. We already have  

602
00:49:46,960 --> 00:49:50,720
a great relationship with Google. And this is 
honestly a different kind of Google that I've  

603
00:49:50,720 --> 00:49:55,600
been seeing, that I've seen for so many years, 
where you had so many different groups kind of  

604
00:49:55,600 --> 00:50:01,280
working on the same thing. I mean, before this 
big reorg, and Demis got all that control over  

605
00:50:01,280 --> 00:50:06,720
all of AI. There were multiple groups within 
Google working on artificial intelligence, kind  

606
00:50:06,720 --> 00:50:12,160
of bumping against each other. And Sudar Pichai 
was really smart saying we got to, this is a huge  

607
00:50:12,160 --> 00:50:19,840
moment. We got to reorganize everything. He folded 
everything under Demis, and put it into Deep Mind,  

608
00:50:19,840 --> 00:50:25,760
and that's where we are now. And it's really 
paid off in 2025 in a big way with Gemini three.
 

609
00:50:26,320 --> 00:50:32,000
Yeah, and that consumer space really is getting 
more and more intense when it comes to the the AI  

610
00:50:32,000 --> 00:50:35,760
side of things, particularly, as you know, 
you mentioned before when you were talking  

611
00:50:35,760 --> 00:50:41,280
about some some of the talk about bubbles, these 
competitors, like Open AI, you know, Google has  

612
00:50:42,160 --> 00:50:46,800
big balance sheet, strong cash flow, and it 
has a huge user base of users, and continues  

613
00:50:46,800 --> 00:50:51,760
to innovate. And I think this really does, given 
that kind of, that reorg, and this kind of speed  

614
00:50:51,760 --> 00:50:56,640
you're seeing now from Google, I think this 
is adding, going to add a lot of competitive  

615
00:50:56,640 --> 00:51:04,240
pressure onto open AI, particularly on the 
consumer side in 2026 so it's all up for grabs.

616
00:51:04,240 --> 00:51:08,800
Yeah, and we're going to see a lot of different 
stuff. I anticipate from open AI this year.  

617
00:51:08,800 --> 00:51:12,320
They're going to throw all the spaghetti 
at the wall they can to see what sticks,  

618
00:51:12,320 --> 00:51:17,040
because they've put enormous pressure on 
themselves to generate enormous amounts of  

619
00:51:17,040 --> 00:51:23,040
revenue in order to fulfill all of these promises 
they made about capital expenditure build out of  

620
00:51:23,040 --> 00:51:27,120
these big data centers with Oracle and 
all these sorts of things like that,  

621
00:51:27,120 --> 00:51:32,320
it cannot happen all these committed spending 
they have unless they productize it better and  

622
00:51:32,320 --> 00:51:35,920
more effectively. But like to your point, 
we're seeing this with meta. By the way,  

623
00:51:35,920 --> 00:51:41,280
Meta has a huge opportunity to leverage its user 
base. And it hasn't figured out how to do that  

624
00:51:41,280 --> 00:51:46,560
in the way Google has. So right now, Google 
feels like they're kind of on top of things.

625
00:51:46,560 --> 00:51:50,720
Well, look, part two of this miniseries 
on Deep Mind is going to be out next week,  

626
00:51:50,720 --> 00:51:56,560
and we're speaking to Lila Ibrahim, who is 
the COO over at DeepMind. So catch that. And  

627
00:51:56,560 --> 00:52:01,760
if you've got any comments or thoughts about 
this episode, please reach out to us. You can  

628
00:52:01,760 --> 00:52:06,305
reach us pretty much everywhere. I think 
You're on multiple social media platforms

629
00:52:06,305 --> 00:52:07,840
I'm a blue sky guy. I'm a blue sky guy

630
00:52:07,840 --> 00:52:09,200
Yeah, we're all over the place.
 

631
00:52:09,840 --> 00:52:13,360
I quit Instagram seven and a half 
years ago, and I do not regret it.
 

632
00:52:13,360 --> 00:52:16,400
Wow, that's amazing. Yeah, no 
more Doom scrolling. Love it.

633
00:52:16,400 --> 00:52:19,280
No more Doom scrolling for this guy

634
00:52:19,280 --> 00:52:32,851
Thank you all for listening and 
watching. We'll catch you next time you.

