WEBVTT

00:00:00.000 --> 00:00:01.540
그냥 이 모든 게

00:00:01.540 --> 00:00:04.920
작동한다는 사실만으로도 정말 믿기지 않을 정도입니다, 그렇죠

00:00:04.920 --> 00:00:05.340
그러니까요, 당신이

00:00:05.340 --> 00:00:07.220
뇌에서 느슨하게 영감을 받은 이런 걸 만들고

00:00:07.220 --> 00:00:09.100
어떤 것을요

00:00:09.100 --> 00:00:10.590
아주 범용적인 학습

00:00:10.590 --> 00:00:12.080
알고리즘을 가진

00:00:12.080 --> 00:00:14.600
데이터를 넣어주면, 어째서인지

00:00:14.600 --> 00:00:16.480
그걸 이해하고, 어떤 것보다도 훨씬 더 잘해냅니다

00:00:16.480 --> 00:00:17.460
우리가 이전에 가졌던 그 무엇보다요

00:00:17.460 --> 00:00:19.720
그리고 이것은 로봇에도 적용되고

00:00:19.720 --> 00:00:22.320
비전, 언어, 소리 같은 모든 것에도 적용되며

00:00:22.320 --> 00:00:22.640
여러

00:00:22.640 --> 00:00:25.220
다른 것들에도 해당합니다, 그리고 만약

00:00:25.220 --> 00:00:27.560
잠깐 멈춰서 이것을

00:00:27.560 --> 00:00:29.000
어떻게 작동하는지 생각해보면

00:00:29.700 --> 00:00:30.650
그리고 실제로 작동한다는 것 자체가

00:00:30.650 --> 00:00:31.600
정말로

00:00:31.600 --> 00:00:32.240
충격적일 정도입니다

00:00:49.220 --> 00:00:51.240
이번 에피소드에서는 카롤과

00:00:51.240 --> 00:00:52.460
피지컬 인텔리전스(Physical Intelligence)의 토비와 함께,

00:00:52.460 --> 00:00:53.680
로보틱스를 위한 파운데이션 모델을 만드는 회사의

00:00:53.680 --> 00:00:55.320
카롤과 토비가

00:00:55.320 --> 00:00:56.960
설명해주십니다

00:00:56.960 --> 00:00:58.480
로보틱스를 인식, 계획, 제어로

00:00:58.480 --> 00:00:59.770
나누는 고전적 접근이

00:00:59.770 --> 00:01:01.060
왜

00:01:01.060 --> 00:01:03.100
근본적으로 잘못됐는지, 그리고 엔드투엔드

00:01:03.100 --> 00:01:04.587
강화학습 기반 학습이

00:01:04.587 --> 00:01:05.540
마침내 실제 배치를 가능하게 만드는지도요

00:01:05.540 --> 00:01:07.540
또 그들이 어떻게

00:01:07.540 --> 00:01:09.516
견고한 실제 환경 성능을 달성했는지도 듣게 됩니다

00:01:09.516 --> 00:01:10.400
로봇이

00:01:10.400 --> 00:01:12.700
13시간 내내 커피를 만들게 한 일과,

00:01:12.700 --> 00:01:12.880
이

00:01:12.880 --> 00:01:14.564
모델들이 완전히

00:01:14.564 --> 00:01:16.000
다른 과업들로 일반화하는 방식,

00:01:16.000 --> 00:01:17.880
수술 로봇부터 드론 비행까지,

00:01:17.880 --> 00:01:19.260
우리가 완전히 이해하지 못하는 방식으로요, 또

00:01:19.260 --> 00:01:20.640
더불어

00:01:20.640 --> 00:01:22.310
파이 스타 0.6(π* 0.6) 뒤에 있는 기술적 통찰도

00:01:22.310 --> 00:01:23.980
이는

00:01:23.980 --> 00:01:24.120
즉

00:01:24.120 --> 00:01:25.864
피지컬 인텔리전스의 최신 모델로,

00:01:25.864 --> 00:01:26.800
경험으로부터 학습하며

00:01:26.800 --> 00:01:28.940
강화학습을 활용합니다. 그럼

00:01:28.940 --> 00:01:32.700
쇼를 즐겨주시기 바랍니다. 카롤, 토비, 오늘 이렇게

00:01:32.700 --> 00:01:34.300
함께해 주셔서 정말 감사합니다. 초대해 주셔서

00:01:34.300 --> 00:01:35.220
감사합니다. 대화를 나눌 수 있어 기대됩니다.

00:01:35.220 --> 00:01:37.694
피지컬 인텔리전스, 범용

00:01:37.694 --> 00:01:39.240
로봇공학 등입니다. 들어가기 전에,

00:01:39.240 --> 00:01:40.460
시청자분들을 위해

00:01:40.460 --> 00:01:41.660
피지컬 인텔리전스가 무엇인지

00:01:41.660 --> 00:01:42.550
그리고 여러분이 추구하시는 미션이

00:01:42.550 --> 00:01:43.440
무엇인지

00:01:43.440 --> 00:01:43.640
말씀해 주시겠습니까.

00:01:43.640 --> 00:01:45.290
네, 피지컬 인텔리전스에서는

00:01:45.290 --> 00:01:46.940
로보틱 파운데이션 모델을

00:01:46.940 --> 00:01:48.630
개발하고 있습니다. 이는

00:01:48.630 --> 00:01:50.320
원칙적으로

00:01:50.320 --> 00:01:51.780
마땅히, 그리고 가능해야 할 것은

00:01:51.780 --> 00:01:53.240
어떤 로봇이든

00:01:53.240 --> 00:01:57.280
어떤 과업이든 수행할 수 있어야 하는 모델입니다. 그리고 지난

00:01:57.280 --> 00:01:58.200
약 1년 반 동안

00:01:58.200 --> 00:02:02.320
저희는 이를 구축하기 시작했고, 저희는

00:02:02.320 --> 00:02:03.690
이 모델들이 확장될 수 있음을 보여주는 올바른 구성요소들을 마련했습니다.

00:02:03.690 --> 00:02:05.060
이를 통해

00:02:05.060 --> 00:02:06.080
이 모델들이 어떻게

00:02:06.080 --> 00:02:09.160
확장될 수 있는지 보여드렸고, 또한

00:02:09.160 --> 00:02:10.781
다양한 로봇 폼

00:02:10.781 --> 00:02:11.800
팩터와 여러

00:02:11.800 --> 00:02:12.220
종류의

00:02:12.220 --> 00:02:13.310
로봇을 제어할 수 있음을 보였으며, 또한

00:02:13.310 --> 00:02:14.400
또

00:02:14.400 --> 00:02:15.290
일반화할 수 있음을 보였습니다. 즉, 이를

00:02:15.290 --> 00:02:16.180
완전히

00:02:16.180 --> 00:02:17.060
새로운 환경으로 가져가도

00:02:17.060 --> 00:02:19.740
어떻게 일반화하는지, 그리고 일반화하려면 무엇이 필요한지요.

00:02:19.740 --> 00:02:22.000
그리고 이번에 막 출시한

00:02:22.000 --> 00:02:23.600
파이 스타 0.6이라는 모델은

00:02:23.600 --> 00:02:24.940
이에 대해서도 더 말씀드리고 싶었는데요,

00:02:24.940 --> 00:02:27.780
저희가 이 모델들을 어떻게 성능 수준까지 끌어올릴 수 있는지도 보여줍니다.

00:02:27.780 --> 00:02:30.800
충분히 좋은 성과를 내서 그들이

00:02:30.800 --> 00:02:32.460
배포 가능한 수준이 되기 시작하고, 이것은

00:02:32.460 --> 00:02:34.120
정말

00:02:34.120 --> 00:02:35.520
저희에게 중요합니다. 왜냐하면 저희는

00:02:35.520 --> 00:02:36.020
이 기술이

00:02:36.020 --> 00:02:37.140
실제로 현실 세계에 배포되기를 바라지만

00:02:37.140 --> 00:02:38.260
또한

00:02:38.260 --> 00:02:40.030
왜냐하면 저희는

00:02:40.030 --> 00:02:41.800
누릴 수 없기 때문인데,

00:02:41.800 --> 00:02:44.200
인터넷에 있는 무료 데이터의

00:02:44.200 --> 00:02:47.640
혜택을 누릴 수 없기 때문입니다. 로봇 행동에 대한 데이터는

00:02:47.640 --> 00:02:49.260
없어서, 저희가 데이터세트를

00:02:49.260 --> 00:02:51.280
직접 만들어야 합니다. 그래서 저희는

00:02:51.280 --> 00:02:52.490
피지컬 인텔리전스라는 문제를,

00:02:52.490 --> 00:02:53.700
그리고

00:02:53.700 --> 00:02:54.890
로봇을 위한 파운데이션 모델을 만드는

00:02:54.890 --> 00:02:56.080
문제를

00:02:56.720 --> 00:02:58.480
풀고 있고, 꽤 많은 진전을 이루었습니다.

00:02:58.480 --> 00:03:01.120
훌륭합니다. 그런데 왜 파운데이션

00:03:01.120 --> 00:03:02.060
모델을 만들기로 한 결정이,

00:03:02.060 --> 00:03:03.180
그러니까 아시다시피

00:03:03.180 --> 00:03:04.300
완전히 수직 통합된 로봇

00:03:04.300 --> 00:03:05.420
제품을 만드는

00:03:05.420 --> 00:03:06.540
회사들과 비교했을 때

00:03:06.540 --> 00:03:09.200
왜 그런 선택이었는지 여쭤봐도 될까요? 그러니까

00:03:09.200 --> 00:03:11.140
지난달 선데이 런치가

00:03:11.140 --> 00:03:11.840
머릿속에 떠오르는데, 이제

00:03:11.840 --> 00:03:12.910
귀여운 작은 로봇 도우미를

00:03:12.910 --> 00:03:13.980
가정에서 살 수 있고,

00:03:13.980 --> 00:03:15.200
요리 로봇을 만드는 회사도 있고,

00:03:15.200 --> 00:03:16.420
또

00:03:16.420 --> 00:03:17.550
물론 휴머노이드 회사들도 있습니다. 그런데 왜

00:03:17.550 --> 00:03:18.680
굳이

00:03:18.680 --> 00:03:20.843
파운데이션 모델을 만들고 로봇을 직접

00:03:20.843 --> 00:03:21.720
만들기보다 그 길을 택하셨나요? 네.

00:03:22.320 --> 00:03:23.780
그래서 제 생각에는, 로봇공학의

00:03:23.780 --> 00:03:25.320
역사를 보면 아주 분명합니다.

00:03:25.320 --> 00:03:26.860
저에게도 그렇고 많은

00:03:26.860 --> 00:03:27.840
로봇공학자들에게도, 우리는 늘

00:03:27.840 --> 00:03:29.770
지능에서 병목이 걸려왔습니다.

00:03:29.770 --> 00:03:31.360
지능이 병목이었고,

00:03:31.360 --> 00:03:34.100
이미 놀라운 일들을 해낼 수 있는 로봇들이 있었고,

00:03:34.100 --> 00:03:35.180
그것이

00:03:35.180 --> 00:03:36.260
가정에서든

00:03:36.260 --> 00:03:39.263
산업 환경에서든 마찬가지였습니다. 우리는

00:03:39.263 --> 00:03:40.180
로봇을

00:03:40.180 --> 00:03:40.480
10년도

00:03:40.480 --> 00:03:43.640
더 전에 봤는데, 원격 조종만 된다면

00:03:43.640 --> 00:03:47.400
집 전체를 청소할 수 있었고, 그리고

00:03:47.400 --> 00:03:47.920
정말 중요한

00:03:47.920 --> 00:03:50.920
단서는 '원격 조종일 때'라는 점입니다. 그러니까

00:03:50.920 --> 00:03:53.180
뒤에 인간의 두뇌가 있다면, 분명

00:03:53.180 --> 00:03:53.780
하드웨어는

00:03:53.780 --> 00:03:55.200
다양한 일을 할 수 있다는 것입니다.

00:03:55.200 --> 00:03:56.620
그리고

00:03:56.620 --> 00:03:58.120
아주 오랜 시간 동안 로봇공학 회사들은

00:03:58.120 --> 00:03:59.620
당신이

00:03:59.620 --> 00:03:59.780
설명하신 방식으로

00:03:59.780 --> 00:04:00.970
말씀하신 방식처럼, 보통은

00:04:00.970 --> 00:04:02.160
대체로

00:04:02.160 --> 00:04:03.180
특정 로봇을 만드는 것을

00:04:03.180 --> 00:04:04.200
생각하고,

00:04:04.200 --> 00:04:04.820
그 로봇을

00:04:04.820 --> 00:04:06.420
단 하나의 작업이나 단 하나의

00:04:06.420 --> 00:04:08.330
응용만 하도록 설계합니다. 그런데 저희는

00:04:08.330 --> 00:04:10.240
오히려

00:04:10.240 --> 00:04:11.260
이 분야에 정말 도움이 될

00:04:11.260 --> 00:04:13.940
것은 병목에 집중하는 것이라고

00:04:13.940 --> 00:04:14.970
생각했고, 그 병목이 지능에 있다고 보고 그래서

00:04:14.970 --> 00:04:16.000
회사를

00:04:16.000 --> 00:04:16.700
세워

00:04:16.700 --> 00:04:17.890
그 병목에 집중했습니다. 왜냐하면 저희는 이것이

00:04:17.890 --> 00:04:19.080
바로

00:04:19.080 --> 00:04:21.400
그 병목을 해결하면 저희가

00:04:21.400 --> 00:04:22.100
실제로

00:04:22.100 --> 00:04:25.220
로봇을 현실화할 수 있다고 생각하기 때문입니다. 그리고 어떤 다른

00:04:25.220 --> 00:04:26.530
방식으로 하면 기본적으로 그만큼

00:04:26.530 --> 00:04:27.840
많은

00:04:27.840 --> 00:04:28.900
진전을 그 병목에서

00:04:28.900 --> 00:04:30.840
이룰 수 없다고 봤습니다. 그래서 저희는

00:04:30.840 --> 00:04:34.260
이 문제를 정면으로 겨냥해

00:04:34.260 --> 00:04:35.000
지능에 집중하기로 했고,

00:04:35.000 --> 00:04:36.340
그렇게 할 수 있다면 그 결과는

00:04:36.340 --> 00:04:37.630
여러 다양한 버티컬 제품으로 이어질 것이며,

00:04:37.630 --> 00:04:38.920
또한

00:04:38.920 --> 00:04:40.160
로봇이

00:04:40.160 --> 00:04:41.750
가정에서도, 또

00:04:41.750 --> 00:04:43.340
산업

00:04:43.340 --> 00:04:44.550
현장에서도, 사실상 어디에든 배포될 것입니다. 그런데 제가

00:04:44.550 --> 00:04:45.760
그 부분을

00:04:45.760 --> 00:04:46.180
조금

00:04:46.180 --> 00:04:48.180
더 따져보고 싶습니다. 음, 하드웨어

00:04:48.180 --> 00:04:50.260
측면에서는, 예를 들어 최근 영상들을

00:04:50.260 --> 00:04:51.760
보면 옵티머스

00:04:51.760 --> 00:04:53.780
손이 정말 정교해서,

00:04:53.780 --> 00:04:56.920
예술 작품 같더라고요. 음, 그리고 저는

00:04:56.920 --> 00:04:58.620
사람들이

00:04:58.620 --> 00:04:59.750
원격 조종 로봇으로 집을 청소하던 영상을 10

00:04:59.750 --> 00:05:00.880
년 전에는 보지는 못했습니다만

00:05:00.880 --> 00:05:02.340
그런데 지금 막 가능해질 듯한

00:05:02.340 --> 00:05:03.100
작업들의

00:05:03.100 --> 00:05:04.760
범주가 있는지 궁금합니다. 예컨대 지금이 막 문턱에 있는

00:05:04.760 --> 00:05:06.310
요리 같은 것들이요.

00:05:06.310 --> 00:05:07.860
또는

00:05:07.860 --> 00:05:08.260
예를 들면

00:05:08.260 --> 00:05:10.800
양파를 까서 잘게 써는 일을

00:05:10.800 --> 00:05:12.000
예전 하드웨어로는

00:05:12.000 --> 00:05:13.200
도저히

00:05:13.200 --> 00:05:13.840
할 수 없었는데,

00:05:13.840 --> 00:05:15.360
지금은 가능해지는 것들 말입니다. 그래서 '왜 지금인가'에서

00:05:15.360 --> 00:05:16.680
하드웨어가 '왜 지금인가'에 얼마나

00:05:16.680 --> 00:05:19.160
중요한지 여쭙고 싶습니다. 하드웨어에는 많은

00:05:19.160 --> 00:05:21.257
진전이 있었고, 특히

00:05:21.257 --> 00:05:22.220
휴머노이드 하드웨어에서요.

00:05:22.220 --> 00:05:24.620
예를 들어 말씀하신 것처럼 정교한 손 같은 것들이

00:05:24.620 --> 00:05:26.180
저는

00:05:26.180 --> 00:05:27.740
훨씬 더 좋아졌다고

00:05:27.740 --> 00:05:29.220
생각합니다. 불과 몇 년 전보다도

00:05:29.220 --> 00:05:31.400
더 낫습니다. 네. 음, 하지만

00:05:31.400 --> 00:05:32.490
그것만으로는 병목을 해결하지는 못합니다. 사실 저희는

00:05:32.490 --> 00:05:33.580
예전에도

00:05:33.580 --> 00:05:35.825
로봇을 작동시켜

00:05:35.825 --> 00:05:37.080
채소를 썰게 하거나

00:05:37.080 --> 00:05:38.870
단순한 그리퍼로도 요리를 하게

00:05:38.870 --> 00:05:40.660
할 수 있었을 것입니다.

00:05:40.660 --> 00:05:43.100
문제는 저희가 그

00:05:43.100 --> 00:05:43.460
지능을

00:05:43.460 --> 00:05:44.260
갖추지 못했다는 점입니다, 이런 로봇들을 운용할 지능입니다. 그리고

00:05:44.260 --> 00:05:44.810
하드웨어가 더

00:05:44.810 --> 00:05:46.160
복잡해질수록

00:05:46.160 --> 00:05:48.290
음, 하드웨어가 복잡해져도 사실

00:05:48.290 --> 00:05:50.420
그것이

00:05:50.420 --> 00:05:50.600
그

00:05:50.600 --> 00:05:53.160
병목을 해결하진 못합니다. 더 많은 일을 하게

00:05:53.160 --> 00:05:55.000
할 수 있게는 할지 모르지만, 여전히

00:05:55.000 --> 00:05:56.060
병목은

00:05:56.060 --> 00:05:57.380
로봇이 지능적이지 않다는 근본적인 문제에

00:05:57.380 --> 00:05:58.700
가로막혀 있습니다.

00:05:58.700 --> 00:06:00.860
알겠습니다. 그러면 하드웨어는

00:06:00.860 --> 00:06:01.140
가능한 것의

00:06:01.140 --> 00:06:03.540
상한을 올릴 수는 있지만, 그 능력

00:06:03.540 --> 00:06:04.400
하한은 아직 거기에도 못 미친다는 말씀이십니까.

00:06:04.400 --> 00:06:05.260
맞습니다.

00:06:05.260 --> 00:06:06.180
그래서 아주 단순한

00:06:06.180 --> 00:06:07.700
로봇으로도 저희는 아직

00:06:07.700 --> 00:06:10.740
인간 조작자의 수준에 못 미칩니다. 그러면 한계는

00:06:10.740 --> 00:06:12.280
지능 계층에 있다는 것인데, 그

00:06:12.280 --> 00:06:13.620
지능을 개발하는 데의 한계는 무엇인가요?

00:06:13.620 --> 00:06:14.960
즉 데이터

00:06:14.960 --> 00:06:18.600
수집과 그것을 저렴하게 수행하는 것이 한계인가요. 왜냐하면

00:06:19.220 --> 00:06:20.240
아시다시피 문제를 쪼개 주셨고

00:06:20.240 --> 00:06:21.260
저희는

00:06:21.260 --> 00:06:22.900
계속 '왜'를 묻고 또 묻고

00:06:22.900 --> 00:06:23.860
더 깊이 파고들겠습니다.

00:06:23.860 --> 00:06:25.540
그래서 다음 단계로,

00:06:25.540 --> 00:06:27.598
좋습니다, 지능을 해결하는 데의 병목은

00:06:27.598 --> 00:06:29.060
일반화인가요?

00:06:29.640 --> 00:06:31.940
좋은 질문입니다. 음, 그래서

00:06:31.940 --> 00:06:33.900
저희는 이를 세 가지

00:06:33.900 --> 00:06:35.920
요인으로 생각했고, 이를

00:06:35.920 --> 00:06:38.897
역량, 일반화, 그리고

00:06:38.897 --> 00:06:41.780
성능이라고 부릅니다. 역량에 관해서는 저희

00:06:41.780 --> 00:06:44.620
의 목표가

00:06:44.620 --> 00:06:44.740
어디까지냐면,

00:06:44.740 --> 00:06:46.560
어떤 작업이든

00:06:46.560 --> 00:06:48.540
작업이나

00:06:48.540 --> 00:06:49.740
로봇에 대해 데이터를 수집할 수만 있다면,

00:06:49.740 --> 00:06:51.020
그것을

00:06:51.020 --> 00:06:52.540
복제해 해당 작업을 자동화할 수 있는 모델을 갖추는 것입니다.

00:06:52.540 --> 00:06:54.060
이것은

00:06:54.060 --> 00:06:54.580
저희가

00:06:54.580 --> 00:06:57.520
비교적 빠르게 도달한 부분입니다. 음, 이것이

00:06:57.520 --> 00:06:59.520
약 1년 전의 π0 공개에서

00:06:59.520 --> 00:07:01.360
보여드린 바이고,

00:07:01.360 --> 00:07:02.390
기본적으로 가능하다는 것을, 즉

00:07:02.390 --> 00:07:03.420
데이터를

00:07:03.420 --> 00:07:05.360
어떤 작업이든 어떤 로봇이든 수집할 수 있다면

00:07:05.360 --> 00:07:05.860
그것을

00:07:05.860 --> 00:07:07.060
자동화할 수 있고, 모델이

00:07:07.060 --> 00:07:10.400
그것을 학습할 수 있다는 점입니다. 음, 다음 과제는

00:07:10.400 --> 00:07:11.700
일반화이고, 이것은

00:07:11.700 --> 00:07:14.180
여전히 열린 문제입니다. 그래서 저희는

00:07:14.180 --> 00:07:16.160
로봇이

00:07:16.160 --> 00:07:17.420
제로샷으로 바로 작동할 수 있는 수준에

00:07:17.420 --> 00:07:18.440
가고 싶었습니다. 예를 들어 새

00:07:18.440 --> 00:07:20.540
집에 데려가도, 그 집에서 어떻게

00:07:20.540 --> 00:07:21.440
작동해야 하는지 알아야 합니다.

00:07:22.040 --> 00:07:23.010
그리고 이것은 정말로 매우 어려운

00:07:23.010 --> 00:07:23.980
문제입니다.

00:07:23.980 --> 00:07:25.920
그렇죠. 예를 들어

00:07:25.920 --> 00:07:26.920
로봇을 새로운 집에 두면,

00:07:26.920 --> 00:07:28.000
로봇은

00:07:28.000 --> 00:07:29.080
여러 물건들이

00:07:29.080 --> 00:07:30.390
어디에 있는지 이해해야 하고, 조리대도 다르게 보이며

00:07:30.390 --> 00:07:31.700
조명도

00:07:31.700 --> 00:07:32.500
예전에 보았던 것과

00:07:32.500 --> 00:07:33.240
다릅니다.

00:07:33.240 --> 00:07:35.280
등등이 있습니다. 그래서 저는 이 문제가

00:07:35.280 --> 00:07:36.260
해결됐다고는 말하지 않겠습니다.

00:07:36.260 --> 00:07:38.780
하지만 저희는

00:07:38.780 --> 00:07:40.780
어떻게 해결할지에 대한 감을 잡기 시작했고,

00:07:40.780 --> 00:07:43.260
어떻게 확장되는지도 보고 있습니다. 그리고 저희가 아는

00:07:43.260 --> 00:07:44.170
머신러닝에서 일반화에 대한 유일한 해답은

00:07:44.170 --> 00:07:45.080
결국

00:07:45.080 --> 00:07:47.560
데이터의 다양성입니다. 그래서

00:07:47.560 --> 00:07:48.360
많은

00:07:48.360 --> 00:07:49.460
서로 다른 다양한 데이터셋을 보게 되면

00:07:49.460 --> 00:07:50.560
당연히

00:07:50.560 --> 00:07:51.640
그와 유사한 환경으로

00:07:51.640 --> 00:07:52.720
일반화할 수

00:07:52.720 --> 00:07:53.080
있어야 합니다,

00:07:53.080 --> 00:07:54.120
즉 당신이 본 환경과 비슷한 곳으로 일반화하는 것입니다. 그리고 이것은

00:07:54.120 --> 00:07:55.160
저희가

00:07:55.160 --> 00:07:57.400
올해 4월에 공개한 π0.5에서

00:07:57.400 --> 00:07:57.820
확인한 바입니다.

00:07:58.340 --> 00:08:00.000
저희는 마침내

00:07:58.340 --> 00:08:00.000
that we we got to the point where

00:08:00.000 --> 00:08:01.280
로봇을 완전히 새로운

00:08:01.280 --> 00:08:02.640
처음 가보는 집으로 데려가도

00:08:02.640 --> 00:08:04.880
그 집에서 실제로 작동할 수 있다는

00:08:04.880 --> 00:08:07.120
수준까지 왔습니다, 아직 완벽하진 않지만 적어도

00:08:07.120 --> 00:08:08.140
일종의

00:08:08.140 --> 00:08:09.780
상식이 있어서 어떻게

00:08:09.780 --> 00:08:10.890
예를 들어 주방을 치우는 것 같은 간단한 일을

00:08:10.890 --> 00:08:12.000
어떻게 할지

00:08:12.000 --> 00:08:12.560
같은 것들을

00:08:12.560 --> 00:08:15.100
알고 있다는 것이고, 마지막 과제는

00:08:15.100 --> 00:08:16.480
아직 완전히 해결되지 않은 성능 문제입니다

00:08:16.480 --> 00:08:17.860
그래서

00:08:17.860 --> 00:08:18.480
어떻게 하면

00:08:18.480 --> 00:08:19.500
이 모델들을

00:08:19.500 --> 00:08:20.520
성능이

00:08:20.520 --> 00:08:22.060
실제로 배포할 수 있을 만큼 충분히 좋아지게

00:08:22.060 --> 00:08:22.300
만들 수 있겠습니까

00:08:22.300 --> 00:08:24.562
그렇습니다, 그리고 여기서 배포는 정말

00:08:24.562 --> 00:08:25.540
정말 중요합니다

00:08:25.540 --> 00:08:27.920
왜냐하면 앞서 말씀드렸듯이 우리도

00:08:27.920 --> 00:08:28.000
또

00:08:28.000 --> 00:08:29.960
데이터를 모아야 하고, 그것이

00:08:29.960 --> 00:08:31.700
데이터 수집의 가장 확장 가능한 방법이 될

00:08:31.700 --> 00:08:32.500
것이라고 생각하기 때문입니다

00:08:32.500 --> 00:08:33.340
왜냐하면 세상에는

00:08:33.340 --> 00:08:34.180
밖에서

00:08:34.180 --> 00:08:36.948
경제적으로 가치 있는 일을 하는 로봇들이 있을 것이고

00:08:36.948 --> 00:08:37.800
그렇게 되면

00:08:37.800 --> 00:08:39.320
그 데이터 수집 비용은

00:08:39.320 --> 00:08:41.020
사실상 마이너스가 되며, 더 많이

00:08:41.020 --> 00:08:42.720
더 넓게

00:08:42.720 --> 00:08:43.000
이 기술을

00:08:43.000 --> 00:08:43.890
배포할수록 더 많은 데이터를

00:08:43.890 --> 00:08:44.780
얻게 될 것입니다, 그리고

00:08:44.780 --> 00:08:46.760
궁극적으로는 그것이

00:08:46.760 --> 00:08:47.620
결국

00:08:47.620 --> 00:08:48.940
가장 큰 데이터 원천이 될 것이라고

00:08:48.940 --> 00:08:50.130
생각합니다, 예컨대 인터넷 데이터보다 훨씬

00:08:50.130 --> 00:08:51.320
더

00:08:51.320 --> 00:08:51.880
큰 규모로 말입니다

00:08:51.880 --> 00:08:53.600
그렇다면 우리가

00:08:53.600 --> 00:08:55.488
일반화나

00:08:55.488 --> 00:08:56.460
어떤 성능 수준에

00:08:56.460 --> 00:08:56.740
도달하기까지

00:08:57.340 --> 00:08:58.680
예를 들어 통제된 환경이든, 아니면

00:08:58.680 --> 00:09:00.020
가정이나

00:09:00.020 --> 00:09:01.490
사무실 같은 일반적인 환경이든

00:09:01.490 --> 00:09:02.960
다만

00:09:02.960 --> 00:09:05.320
전 세계 전체는 아니고, 그렇게 범위를 제한한다면

00:09:05.320 --> 00:09:07.097
어느 정도에서

00:09:07.097 --> 00:09:08.240
일반화와

00:09:08.240 --> 00:09:09.120
성능이

00:09:09.820 --> 00:09:12.860
어느 수준이어야 배포가 가능하다고

00:09:12.860 --> 00:09:15.580
보십니까? 저는 이런 로봇의 배포가

00:09:15.580 --> 00:09:16.580
사실 꽤 가까워졌다고

00:09:16.580 --> 00:09:18.027
생각합니다, 저희는 이미 배포를

00:09:18.027 --> 00:09:19.080
직접 시작했습니다

00:09:19.080 --> 00:09:21.940
처음에는 이것이

00:09:21.940 --> 00:09:22.740
대략 5년 정도는

00:09:22.740 --> 00:09:23.540
걸릴

00:09:23.540 --> 00:09:25.320
기술이 실제로

00:09:25.320 --> 00:09:25.740
상업적 환경에서

00:09:25.740 --> 00:09:27.720
로봇을 배포할 준비가 되고

00:09:27.720 --> 00:09:28.670
그곳에서

00:09:28.670 --> 00:09:29.620
무언가

00:09:29.620 --> 00:09:31.400
가치 있는 일을 하게 만들 수 있을 때까지

00:09:31.400 --> 00:09:33.200
걸릴 거라고 생각했지만, 아마 두 달 전쯤

00:09:33.200 --> 00:09:37.420
이미 해냈습니다, 그래서 이제

00:09:37.420 --> 00:09:38.780
그 임계점에

00:09:38.780 --> 00:09:40.110
모델들이 충분히 유용하고

00:09:40.110 --> 00:09:41.440
성능도

00:09:41.440 --> 00:09:42.620
충분히 좋으며, 또 충분히 많은

00:09:42.620 --> 00:09:43.800
다양한

00:09:43.800 --> 00:09:45.180
작업을

00:09:45.180 --> 00:09:48.260
수행할 수 있어 실제로 쓸 만한 수준이 되었습니다, 그래서 이는 정말

00:09:48.260 --> 00:09:50.900
정말 흥분되는 순간입니다, 저희는

00:09:50.900 --> 00:09:51.540
방금 그

00:09:51.540 --> 00:09:53.820
임계점을 넘었다고 생각합니다, 다만 아직

00:09:53.820 --> 00:09:55.220
적용 범위가 어디까지인지

00:09:55.220 --> 00:09:56.620
즉

00:09:56.620 --> 00:09:57.360
어디에 배포할 수 있는지는

00:09:57.360 --> 00:09:59.480
더 지켜봐야 합니다; 실패가

00:09:59.480 --> 00:10:00.400
정말 치명적일 수 있는 작업도 있는데, 이런 것들은

00:10:00.400 --> 00:10:01.320
아직

00:10:01.320 --> 00:10:01.500
최선의

00:10:01.500 --> 00:10:03.460
배포 대상 시험으로 보기에는 이르고, 또

00:10:03.460 --> 00:10:04.420
일반화가 매우 많이 필요한 작업도 있습니다

00:10:04.420 --> 00:10:05.380
예를 들어

00:10:05.380 --> 00:10:05.820
가정에

00:10:05.820 --> 00:10:07.740
배포하는 경우처럼, 아시다시피

00:10:07.740 --> 00:10:08.990
프라이버시 문제나 안전 문제 등이 있을 수 있고

00:10:08.990 --> 00:10:10.240
그런 것들입니다

00:10:10.240 --> 00:10:11.100
그래서 이런 곳들은

00:10:11.100 --> 00:10:12.580
아직 배포하기에 가장 좋은 장소가 아닐 수도 있지만

00:10:12.580 --> 00:10:14.940
저는

00:10:14.940 --> 00:10:16.600
우리가 데이터를 더 모으고

00:10:16.600 --> 00:10:17.430
이 모델들이 더 좋아질수록 적용 범위가

00:10:17.430 --> 00:10:18.260
계속 넓어진다고

00:10:18.260 --> 00:10:19.820
생각합니다, 그래서 점점 더 많은

00:10:19.820 --> 00:10:21.880
환경에 배포할 수 있게 되고

00:10:21.880 --> 00:10:22.890
우리가 이제 거기에 다가가고 있다고 생각합니다

00:10:22.890 --> 00:10:23.900
그럼

00:10:23.900 --> 00:10:25.120
현재 실제로 배포하고 계신 적용 범위는

00:10:25.120 --> 00:10:26.340
어느 정도입니까

00:10:27.160 --> 00:10:29.900
음, 그래서 사실 이건 정말

00:10:29.900 --> 00:10:31.190
답하기가 매우 어려운 질문입니다

00:10:31.190 --> 00:10:32.480
왜냐하면

00:10:32.480 --> 00:10:32.640
이런

00:10:32.640 --> 00:10:35.378
파운데이션 모델은 때때로

00:10:35.378 --> 00:10:36.340
그 역량을 완전히 알기 어렵기 때문입니다, 음

00:10:36.340 --> 00:10:39.620
그래서 큰 틀에서는

00:10:39.620 --> 00:10:40.500
대규모

00:10:40.500 --> 00:10:43.520
언어 모델도 마찬가지로, 아시다시피 학습을 시키고

00:10:43.520 --> 00:10:45.460
이 모델을 내부에서

00:10:45.460 --> 00:10:46.480
일종의 ‘조리’하듯 만들면서

00:10:46.480 --> 00:10:48.460
가능한 한 최선을 다하지만, 그리고

00:10:48.460 --> 00:10:50.640
맨 마지막에 이 아티팩트를 얻게 되면

00:10:50.640 --> 00:10:51.540
그것이 얼마나

00:10:51.540 --> 00:10:52.840
좋을지 미리 예측하기는 어렵습니다, 그래서

00:10:52.840 --> 00:10:55.800
실제로 테스트를 해봐야 하고, 그게

00:10:55.800 --> 00:10:56.840
이 모델들도 지금 있는 단계입니다

00:10:56.840 --> 00:10:59.740
그래서 예를 들어 저희는 이를 오픈소스로 공개해서

00:10:59.740 --> 00:11:02.120
저희만

00:11:02.120 --> 00:11:03.360
테스트하는 상황이 되지 않게 하고, 또

00:11:03.360 --> 00:11:05.379
그 역량을 파악하는 데

00:11:05.379 --> 00:11:06.500
저희가 병목이 되지 않도록 합니다, 그리고

00:11:06.500 --> 00:11:08.000
오픈소스로 공개하면 실제로

00:11:08.000 --> 00:11:08.500
적용되는 사례를

00:11:08.500 --> 00:11:09.530
우리가

00:11:09.530 --> 00:11:10.560
상상했던 것보다 훨씬 더 많은 응용 분야에서

00:11:10.560 --> 00:11:14.756
예컨대 자율주행이나 수술

00:11:14.756 --> 00:11:15.700
로봇 같은 것들, 또는

00:11:17.500 --> 00:11:21.380
농업 같은 분야 등에서도 볼 수 있습니다, 그래서 저는

00:11:21.380 --> 00:11:23.220
적용 범위가 어디까지인지에 대한

00:11:23.220 --> 00:11:24.040
정확한 추정치는 갖고 있지 않습니다

00:11:24.040 --> 00:11:25.840
다만 제가

00:11:25.840 --> 00:11:28.220
예상했던 것보다 더 넓고, 앞으로도

00:11:28.220 --> 00:11:29.440
시간이 지날수록

00:11:29.440 --> 00:11:31.420
이 모델들이 더 많은 데이터를 얻을수록

00:11:31.420 --> 00:11:33.360
더 성숙해지고 적용 범위는

00:11:33.360 --> 00:11:34.040
계속 넓어질 것입니다

00:11:34.520 --> 00:11:36.860
성능 측면에서도 덧붙이자면

00:11:36.860 --> 00:11:39.820
말씀하신 대로 적용 범위가

00:11:39.820 --> 00:11:40.640
아마 더 넓을 수는 있습니다

00:11:41.240 --> 00:11:42.090
출발점이 우리가

00:11:42.090 --> 00:11:42.940
생각했던 것보다 더 넓지만

00:11:42.940 --> 00:11:44.580
동시에 물론

00:11:44.580 --> 00:11:45.360
실제로 원한다면

00:11:45.360 --> 00:11:46.510
각각의 출발점에서

00:11:46.510 --> 00:11:47.660
출발해서

00:11:47.660 --> 00:11:49.380
각 응용 분야가

00:11:49.380 --> 00:11:49.880
사람들이

00:11:49.880 --> 00:11:52.620
이것을

00:11:52.620 --> 00:11:55.180
일상적으로, 예를 들어 매일 운전하듯

00:11:55.180 --> 00:11:56.640
업무에 활용하고 싶을 정도의 수준이 되려면

00:11:56.640 --> 00:11:57.700
아마 아직도 꽤

00:11:57.700 --> 00:11:58.760
큰

00:11:58.760 --> 00:12:00.400
성능 측면에서 해야 할 일이 있지요, 그래서

00:12:00.400 --> 00:12:01.340
이번

00:12:01.340 --> 00:12:02.500
릴리스에 대해서도 조금

00:12:02.500 --> 00:12:03.980
잠시 뒤에 더 말씀드리겠지만, 아마

00:12:03.980 --> 00:12:05.220
파이 스타 식스에서 저희는

00:12:05.220 --> 00:12:06.650
경험으로부터 학습하는 부분에서 진전을 이뤘고

00:12:06.650 --> 00:12:08.080
경험 데이터를 가져와

00:12:08.080 --> 00:12:09.720
다시 반영하고 모델을 더 좋게 만들었습니다

00:12:09.720 --> 00:12:12.960
배포된 상태에서도요, 음; 하지만 여전히

00:12:12.960 --> 00:12:14.960
많은 것들에 대해서는 제가

00:12:14.960 --> 00:12:16.460
순진하게 상상해도

00:12:16.460 --> 00:12:17.830
정말 많은 상황들이

00:12:17.830 --> 00:12:19.200
정말

00:12:19.200 --> 00:12:21.120
잘못될 수 있는 것들의 긴 꼬리가 있거나

00:12:21.120 --> 00:12:22.240
또는

00:12:22.240 --> 00:12:24.900
맞닥뜨릴 수 있는 것들이 있는데, 저희는 아직

00:12:24.900 --> 00:12:25.850
그것을 완전히 어떻게

00:12:25.850 --> 00:12:26.800
해결할지에 대한 좋은 이해가 없습니다

00:12:26.800 --> 00:12:27.620
라고도 말씀드리고 싶습니다

00:12:27.620 --> 00:12:29.460
그리고 여러분은

00:12:29.460 --> 00:12:30.830
많은 투명성을 가지고 결과를

00:12:30.830 --> 00:12:32.200
공개해 오셨고

00:12:32.200 --> 00:12:33.940
오픈 소스로도 공개하셨지요, 음, 그래서

00:12:33.940 --> 00:12:35.680
여러분이

00:12:35.680 --> 00:12:36.600
편하게 공유하실 수 있는 범위에서, 말씀해 주실 수 있습니까,

00:12:36.600 --> 00:12:37.520
즉

00:12:37.520 --> 00:12:38.910
전반적인 기술 아키텍처가

00:12:38.910 --> 00:12:40.300
말하자면

00:12:40.300 --> 00:12:43.480
어떤지, 그리고 그 아키텍처가

00:12:43.480 --> 00:12:43.740
이

00:12:43.740 --> 00:12:45.240
약속된 목표 지점에 도달하기 위해

00:12:45.240 --> 00:12:47.120
거의 이미 굳어져 있고, 앞으로는

00:12:47.120 --> 00:12:48.900
지금의 접근을 변형하는 정도일지

00:12:48.900 --> 00:12:50.260
그리고 우리는 그저

00:12:50.260 --> 00:12:52.140
엄청난 양의 데이터를 모으면 되는지, 아니면

00:12:52.140 --> 00:12:53.420
아키텍처 자체가

00:12:53.420 --> 00:12:55.960
아직도 계속 정립되는 중이라고 보십니까.

00:12:55.960 --> 00:12:57.920
그렇다고 말씀드릴 것 같고, 그래서

00:12:57.920 --> 00:12:58.440
조금

00:12:58.440 --> 00:13:00.180
현재 우리가 어디에 와 있는지부터 말씀드리고

00:13:00.180 --> 00:13:01.580
그다음에 세부로

00:13:01.580 --> 00:13:02.640
즉 그것이 어떻게

00:13:02.640 --> 00:13:04.940
변할 수 있는지로 들어가겠습니다. 현재는,

00:13:04.940 --> 00:13:06.580
아키텍처가

00:13:06.580 --> 00:13:08.220
음,

00:13:08.220 --> 00:13:09.820
여러분이 아시는 VLM이

00:13:09.820 --> 00:13:11.250
오늘날 만들어지는 방식과 매우 유사합니다. 아마

00:13:11.250 --> 00:13:12.680
대부분

00:13:12.680 --> 00:13:14.220
여러분이 일상에서

00:13:14.220 --> 00:13:15.080
매일 상호작용하는 것들처럼요, 예를 들어

00:13:15.080 --> 00:13:16.840
텍스트를 입력하고 이미지를 넣은 뒤

00:13:16.840 --> 00:13:18.220
그 이미지에 무엇이 있는지 읽어 달라고 요청하고

00:13:18.220 --> 00:13:20.020
등등이지요. 그리고 저희도

00:13:20.020 --> 00:13:20.140
어느 정도

00:13:20.140 --> 00:13:21.970
같은 출발점에서 시작했습니다

00:13:21.970 --> 00:13:23.800
즉

00:13:23.800 --> 00:13:25.520
학습된 모델이 하나 있고

00:13:25.520 --> 00:13:25.760
인터넷

00:13:25.760 --> 00:13:28.860
규모 데이터로 학습됐으며, 음, 이미지 데이터를 받아들였고

00:13:28.860 --> 00:13:30.780
텍스트도 함께 받아들였고, 여기에

00:13:30.780 --> 00:13:31.460
로보틱스 데이터를 추가하고 있습니다

00:13:31.460 --> 00:13:33.020
그리고 저희 학습은 실제로 주로

00:13:33.020 --> 00:13:34.580
지금은

00:13:34.580 --> 00:13:35.510
로보틱스 데이터, 즉 저희가

00:13:35.510 --> 00:13:36.440
직접 수집한 데이터에 기반합니다

00:13:36.440 --> 00:13:39.180
직접 수집했지요. 인터넷 데이터도 약간은

00:13:39.180 --> 00:13:41.260
섞여 있지만, 대부분은

00:13:41.260 --> 00:13:41.980
로보틱스

00:13:41.980 --> 00:13:43.370
데이터입니다. 아키텍처는

00:13:43.370 --> 00:13:44.760
비전

00:13:44.760 --> 00:13:47.460
언어 모델이고, 여기에

00:13:47.460 --> 00:13:48.120
옆에 무언가를 더하는데

00:13:48.120 --> 00:13:51.540
저희는 이를 액션 모델, 액션

00:13:51.540 --> 00:13:53.740
익스퍼트라고 부르는, 즉 모델의

00:13:53.740 --> 00:13:54.540
실제로

00:13:54.540 --> 00:13:56.140
로봇을 구동해야 하는 부분입니다, 그래서 기본적으로

00:13:56.140 --> 00:13:57.740
이 부분은

00:13:57.740 --> 00:13:58.760
이미지와 지시를

00:13:58.760 --> 00:13:59.780
받아서

00:13:59.780 --> 00:14:00.600
그리고

00:14:00.600 --> 00:14:03.260
작업을 수행하며, 로봇에 명령을

00:14:03.260 --> 00:14:05.680
보내야 합니다. 전반적으로는

00:14:05.680 --> 00:14:07.580
트랜스포머 모델입니다

00:14:07.580 --> 00:14:09.720
상당히 큰 모델로

00:14:09.720 --> 00:14:10.970
현재는 수십억 개 파라미터까지도

00:14:10.970 --> 00:14:12.220
사용합니다

00:14:12.220 --> 00:14:13.180
또한 이를 사전학습하고

00:14:13.180 --> 00:14:15.180
저희 로보틱스 데이터와 인터넷

00:14:15.180 --> 00:14:18.360
데이터로도 학습합니다, 음, 그리고 대체로

00:14:18.360 --> 00:14:20.260
초기에는 인간

00:14:20.260 --> 00:14:21.520
시연 데이터로 학습합니다, 캐롤이 앞서

00:14:21.520 --> 00:14:22.780
조금

00:14:22.780 --> 00:14:24.700
말씀드렸듯이 저희는 이런 시연 데이터가 있고

00:14:24.700 --> 00:14:26.070
사람이 원격조작으로

00:14:26.070 --> 00:14:27.440
로봇을

00:14:27.440 --> 00:14:29.840
무언가 하게 하려는 데이터입니다. 이것이

00:14:29.840 --> 00:14:30.500
현재의

00:14:30.500 --> 00:14:31.470
아키텍처이고, 대략적인

00:14:31.470 --> 00:14:32.440
스케일링은

00:14:32.440 --> 00:14:35.820
음, 저희가 얻는 것은 데이터 규모를

00:14:35.820 --> 00:14:37.040
키우는 데서 나오며, 저희는

00:14:37.040 --> 00:14:39.500
VLM 분야에서 온 것과 유사한 모델을

00:14:39.500 --> 00:14:42.100
사용합니다. 음, 이것이 어떻게 바뀔지는

00:14:42.100 --> 00:14:43.080
열린

00:14:43.080 --> 00:14:45.843
질문이라고 생각합니다. 저는 많은

00:14:45.843 --> 00:14:46.900
기회가

00:14:46.900 --> 00:14:48.500
이 모델들에 더 많은 역량을

00:14:48.500 --> 00:14:50.100
추가하는 데

00:14:50.100 --> 00:14:50.600
있다고

00:14:50.600 --> 00:14:51.920
또한 탐색하고 있습니다. 예를 들면

00:14:51.920 --> 00:14:53.240
음,

00:14:53.240 --> 00:14:55.960
더 많은 컨텍스트를

00:14:55.960 --> 00:14:56.700
이 모델들에 넣고 싶으실 수도 있습니다

00:14:56.700 --> 00:15:00.600
더, 음, 더 많은 카메라를

00:15:00.600 --> 00:15:02.980
모델이 사용할 수 있도록 로봇에

00:15:02.980 --> 00:15:04.080
추가로 달고

00:15:04.540 --> 00:15:07.760
싶으실 수도 있고, 더

00:15:07.760 --> 00:15:08.950
물리 세계를 더 잘 이해하고 싶으실 수도 있습니다

00:15:08.950 --> 00:15:10.140
그런

00:15:10.140 --> 00:15:11.620
의미에서, 그러니까

00:15:11.620 --> 00:15:12.720
방 안에 무엇이 있는지 정확히 이해하고

00:15:12.720 --> 00:15:13.820
무엇이

00:15:13.820 --> 00:15:15.860
깨질 수 있는지, 무엇이 쉽게 움직이는지 등등을

00:15:15.860 --> 00:15:16.620
그래서 할 일이 정말

00:15:16.620 --> 00:15:18.860
많다고 생각합니다, 역량 측면에서도

00:15:18.860 --> 00:15:20.290
그리고 아키텍처를 바꾸는 측면에서도요

00:15:20.290 --> 00:15:21.720
그리고 저는

00:15:21.720 --> 00:15:22.180
또

00:15:22.180 --> 00:15:24.020
5~6년쯤 후에

00:15:24.020 --> 00:15:27.080
우리가 돌아보며 '아,

00:15:27.080 --> 00:15:29.820
아마 그때의 모델 백본이

00:15:29.820 --> 00:15:31.720
당시에 사용하던 모델의

00:15:31.720 --> 00:15:33.160
지금은 이런 VLM 쪽에서 온 것이

00:15:33.160 --> 00:15:34.600
이미

00:15:34.600 --> 00:15:35.600
바뀌었을지도 모르고, 우리는

00:15:35.600 --> 00:15:37.840
더 나아가서, 음, 다른 무언가를

00:15:37.840 --> 00:15:38.760
조금 다르게 쓰게 될 것이라고 생각합니다, 그것은

00:15:38.760 --> 00:15:39.680
시간이 지나며

00:15:39.680 --> 00:15:41.560
진화하겠지만, 저는

00:15:41.560 --> 00:15:45.700
데이터의 기반과

00:15:45.700 --> 00:15:47.380
그것을 모델에 어떻게 넣는지는

00:15:47.380 --> 00:15:48.440
아마도 계속

00:15:48.440 --> 00:15:50.080
비슷하게 남을 것 같습니다, 그리고 이것을

00:15:50.080 --> 00:15:52.880
픽셀이나 신호를 입력으로 넣고

00:15:52.880 --> 00:15:55.260
행동을 출력으로 내는 것으로 생각하면 되는지요, 네, 그리고

00:15:55.260 --> 00:15:57.220
마치 하나의 아주 큰 신경망처럼

00:15:57.220 --> 00:15:59.760
하나의 큰 모델입니다, 네, 사실은

00:15:59.760 --> 00:16:01.060
기본적으로 이미지를 입력으로 받고

00:16:01.060 --> 00:16:03.800
텍스트를 입력으로 받고, 음, 텍스트를 출력으로 내고, 그리고 행동도

00:16:03.800 --> 00:16:05.400
지금은 그렇게 출력합니다, 네, 그리고 혹시

00:16:05.400 --> 00:16:07.460
제가 여쭙고 싶은데요, 별도로

00:16:07.460 --> 00:16:10.027
이동과 조작을

00:16:10.027 --> 00:16:11.040
구분한 스택이 있으신지요, 그리고 아마

00:16:11.040 --> 00:16:12.740
지금이 그 이야기를

00:16:12.740 --> 00:16:13.200
해보기에 좋은 시점인 것 같습니다.

00:16:13.200 --> 00:16:14.420
로보틱스의 역사적 진화와

00:16:14.420 --> 00:16:15.640
그리고

00:16:15.640 --> 00:16:16.940
로보틱스에서 나타난 여러 학습의

00:16:16.940 --> 00:16:18.240
다양한 물결을

00:16:18.240 --> 00:16:18.780
음

00:16:18.780 --> 00:16:21.440
그리고 그것이 여러분의 스택과 어떻게 관련되는지요, 네.

00:16:21.440 --> 00:16:23.880
그래서 오랫동안, 학습이

00:16:23.880 --> 00:16:25.440
여기에 들어오기 전부터 사람들은

00:16:25.440 --> 00:16:26.770
로보틱스가 이런 종류의

00:16:26.770 --> 00:16:28.100
문제라고 생각했습니다.

00:16:28.100 --> 00:16:29.820
즉 충분한 사람을 투입하면

00:16:29.820 --> 00:16:30.740
충분한 엔지니어를 붙이면

00:16:31.300 --> 00:16:33.880
그들이 그것을 정말 깊이 고민해서

00:16:33.880 --> 00:16:34.850
결국, 그러니까,

00:16:34.850 --> 00:16:35.820
말하자면

00:16:35.820 --> 00:16:36.460
로봇이

00:16:36.460 --> 00:16:38.390
세상에서 무엇이든 하게 만드는 코드를 쓸 수 있다고 생각했습니다, 음,

00:16:38.390 --> 00:16:40.320
그리고

00:16:40.320 --> 00:16:42.000
사람들은 정말 정말 열심히 그렇게 하려고

00:16:42.000 --> 00:16:42.480
이 방식으로 해왔습니다.

00:16:43.020 --> 00:16:44.260
그런데 결국 세상은

00:16:44.260 --> 00:16:46.340
너무나 복잡하다는 것이 드러났습니다, 네, 그렇습니다, 예를 들면

00:16:46.340 --> 00:16:46.960
그냥

00:16:46.960 --> 00:16:48.060
여러분이 마주칠 모든, 모든 경우를

00:16:48.060 --> 00:16:49.160
일일이

00:16:49.160 --> 00:16:52.120
현실 세계에서 코드로 써둘 수는 없어서, 그 방식은 작동하지 않았고,

00:16:52.120 --> 00:16:52.580
또한

00:16:52.580 --> 00:16:54.180
저희가, 아시다시피, 그

00:16:54.180 --> 00:16:56.760
문제의 그 버전에 대해 작업하는 동안

00:16:56.760 --> 00:16:57.700
결국 벌어진 일은

00:16:57.700 --> 00:17:00.240
사람들이 늘 하던 대로, 이 문제를

00:17:00.240 --> 00:17:01.040
더 작은

00:17:01.040 --> 00:17:01.840
하위

00:17:01.840 --> 00:17:02.460
문제로 쪼개려고 했다는 점입니다, 그래서

00:17:02.460 --> 00:17:03.260
전체

00:17:03.260 --> 00:17:03.980
로보틱스를

00:17:03.980 --> 00:17:05.020
문제로 다루기보다는, 예를 들어

00:17:05.020 --> 00:17:06.060
인지

00:17:06.060 --> 00:17:07.270
부분이 있고, 제어

00:17:07.270 --> 00:17:08.480
부분이 있고,

00:17:08.480 --> 00:17:09.370
또 계획

00:17:09.370 --> 00:17:10.260
부분도

00:17:10.260 --> 00:17:10.360
그

00:17:10.360 --> 00:17:11.400
문제에 포함된다고 했고, 이것이 거의

00:17:11.400 --> 00:17:12.440
서로 다른

00:17:12.440 --> 00:17:13.510
커뮤니티로까지 성장했습니다, 계획 커뮤니티가 있고

00:17:13.510 --> 00:17:14.580
또

00:17:14.580 --> 00:17:15.670
제어 커뮤니티가 있으며, 각자

00:17:15.670 --> 00:17:16.760
자기들만의 학회가 있고

00:17:16.760 --> 00:17:18.420
자기들만의 문제 의식 등 모든 것이 따로 있었습니다.

00:17:19.520 --> 00:17:21.380
그래서 그러다가, 아시다시피,

00:17:21.380 --> 00:17:22.360
이 규칙들을 모두 손으로

00:17:22.360 --> 00:17:23.340
전부

00:17:23.340 --> 00:17:24.020
일일이 써넣는 것은 사실상 불가능하다는 것을 깨닫고

00:17:24.560 --> 00:17:25.690
사람들은 그것들을 학습해야 한다고 생각했습니다.

00:17:25.690 --> 00:17:26.820
즉

00:17:26.820 --> 00:17:28.100
데이터로부터 학습해야 한다는 것이고,

00:17:28.100 --> 00:17:29.920
이는 정말 좋은 생각처럼 보입니다, 그렇습니다, 이것은

00:17:29.920 --> 00:17:32.900
저희도 그렇게 배웁니다, 음, 그런데

00:17:32.900 --> 00:17:34.080
결국 어떻게 되었냐면

00:17:34.080 --> 00:17:35.170
그 하위 요소들을 하나하나

00:17:35.170 --> 00:17:36.260
학습하기 시작했습니다.

00:17:36.260 --> 00:17:38.320
이렇게, 이렇게 쪼개진 구성요소들을

00:17:38.320 --> 00:17:39.790
서로 분리해서 따로따로 학습한 것입니다, 네, 그래서

00:17:39.790 --> 00:17:41.260
예를 들면

00:17:41.260 --> 00:17:42.390
완전히 학습된 인지 계층을

00:17:42.390 --> 00:17:43.520
두고

00:17:43.520 --> 00:17:43.900
어쩌면

00:17:43.900 --> 00:17:44.700
학습된 제어 계층도

00:17:44.700 --> 00:17:45.260
두고

00:17:45.260 --> 00:17:46.060
어쩌면 학습된 플래너도

00:17:46.060 --> 00:17:46.620
두는 식입니다.

00:17:46.620 --> 00:17:49.000
그런 방식은

00:17:49.000 --> 00:17:51.160
어느 정도의 진전을 보여주었고, 이전에

00:17:51.160 --> 00:17:53.280
저희가 갖고 있던 것보다 나았습니다, 네, 하지만 결국

00:17:53.280 --> 00:17:54.000
이 문제를

00:17:54.000 --> 00:17:55.210
이런 하위 구성요소로 나누는 것이, 그러니까

00:17:55.210 --> 00:17:56.420
그것이

00:17:56.420 --> 00:17:57.510
실제로는 작동하지 않는 부분이라는 것이

00:17:57.510 --> 00:17:58.600
드러났습니다, 왜냐하면

00:17:58.600 --> 00:17:59.320
아시다시피

00:17:59.320 --> 00:18:00.920
제가 이

00:18:00.920 --> 00:18:02.620
잔을 집어 들려고 할 때 저는 그것을

00:18:02.620 --> 00:18:04.340
인지하고 그다음 계획하고

00:18:04.340 --> 00:18:06.520
그다음 제어한다고 생각하지 않고, 그냥

00:18:06.520 --> 00:18:08.020
바로 손을 뻗어서 잔을 집어 듭니다.

00:18:08.020 --> 00:18:09.380
그 모든 것이 매우 자연스럽습니다.

00:18:10.140 --> 00:18:12.480
그래서 결국 이

00:18:12.480 --> 00:18:14.477
파이프라인 접근, 즉 이런

00:18:14.477 --> 00:18:15.580
미리 정의된 인터페이스를 두는 접근에서는

00:18:15.580 --> 00:18:16.750
예를 들어 인지가

00:18:16.750 --> 00:18:17.920
물체의 위치를

00:18:17.920 --> 00:18:19.800
주고, 그다음 플래너가

00:18:19.800 --> 00:18:20.360
궤적을 주며

00:18:20.360 --> 00:18:22.298
제어가 그것을 실행한다는

00:18:22.298 --> 00:18:23.120
그 인터페이스들이

00:18:23.120 --> 00:18:24.220
바로 무너진 지점이었습니다, 그래서

00:18:24.220 --> 00:18:25.320
저희가

00:18:25.320 --> 00:18:28.200
저희가 어떻게 작동하는지 알고 있다고 생각했던 모든 것이

00:18:28.200 --> 00:18:31.520
늘 틀렸던 것입니다, 그래서 저희는

00:18:31.520 --> 00:18:32.420
다음 단계에 이르렀고

00:18:32.420 --> 00:18:33.340
그때 '아마도 단순히 이 문제를

00:18:33.340 --> 00:18:34.260
쪼개는 것 자체가

00:18:34.260 --> 00:18:36.100
처음부터 잘못된 생각이었을지도 모른다'고

00:18:36.100 --> 00:18:37.480
말했습니다, 네, 그래서

00:18:37.480 --> 00:18:39.280
전체를 엔드투엔드로 학습시키자고 했습니다.

00:18:39.280 --> 00:18:42.900
즉 어떤 것이든, 음, 음, 그러니까

00:18:42.900 --> 00:18:44.140
감각

00:18:44.140 --> 00:18:46.040
입력을 네트워크의 입력으로 넣고

00:18:46.040 --> 00:18:47.680
출력으로는 행동을 내도록 하자는 것이며, 이것을 저희는

00:18:47.680 --> 00:18:48.500
엔드

00:18:48.500 --> 00:18:50.440
투 엔드 접근이라고 부르며,

00:18:50.440 --> 00:18:51.820
픽셀에서 행동으로 바로 가게 하려는 것입니다, 그리고

00:18:51.820 --> 00:18:53.200
저희는

00:18:53.200 --> 00:18:53.800
네트워크가

00:18:53.800 --> 00:18:54.960
스스로 알아내게 하거나, 학습 알고리즘이

00:18:54.960 --> 00:18:56.120
알아내게 해서

00:18:56.120 --> 00:18:57.080
이것을 여러

00:18:57.080 --> 00:18:58.040
구성요소로 어떻게 나눌지

00:18:58.040 --> 00:18:58.340
만약

00:18:58.340 --> 00:19:02.420
그것이 가능하다면 말입니다, 음, 그리고 그렇게 하는 동안

00:19:02.420 --> 00:19:03.330
저희는 그것이

00:19:03.330 --> 00:19:04.240
실제로

00:19:04.240 --> 00:19:04.980
엄청나게 많은

00:19:04.980 --> 00:19:08.520
데이터가 필요하고, 또한 종종 작동이 깨진다는 점을

00:19:08.520 --> 00:19:10.860
어떤 종류의 상식이 필요할 때 말입니다.

00:19:10.860 --> 00:19:12.060
그리고 그 상식을

00:19:12.060 --> 00:19:14.060
1인칭 행동을 통해, 그러니까 직접 수행한 행동을 통해 모으는 것은

00:19:14.060 --> 00:19:16.060
데이터셋으로 모으는 일이

00:19:16.060 --> 00:19:16.860
정말 정말 어렵습니다, 왜냐하면 여러분은

00:19:16.860 --> 00:19:17.640
필요로

00:19:17.640 --> 00:19:17.740
하게

00:19:17.740 --> 00:19:18.580
세상의 모든 일을 하나도 빠짐없이 경험해야

00:19:18.580 --> 00:19:19.420
하기

00:19:19.420 --> 00:19:22.540
때문입니다, 그리고 그때 저희가 발견한 것이

00:19:22.540 --> 00:19:23.160
비전

00:19:23.160 --> 00:19:24.410
언어 행동 모델이며, 여기서 저희는

00:19:24.410 --> 00:19:25.660
모델을

00:19:25.660 --> 00:19:26.910
인터넷 데이터로 사전학습된

00:19:26.910 --> 00:19:28.160
모델을

00:19:28.160 --> 00:19:28.420
이미

00:19:28.420 --> 00:19:29.370
세상이 어떻게

00:19:29.370 --> 00:19:30.320
작동하는지에 대해

00:19:30.320 --> 00:19:34.040
꽤 잘 이해하고 있다고 보고, 음, 저희는 그 지식을 활용할 수 있습니다.

00:19:34.040 --> 00:19:34.760
그래서

00:19:34.760 --> 00:19:36.050
모든 것을

00:19:36.050 --> 00:19:37.340
직접 경험할 필요가 없고, 여러분은

00:19:37.340 --> 00:19:39.320
그 위에 몇 가지 행동 구성요소를 그냥 얹기만 하면

00:19:39.320 --> 00:19:39.460
그

00:19:39.460 --> 00:19:40.540
공통의 세계 이해를 갖게 되고

00:19:40.540 --> 00:19:41.620
또

00:19:41.620 --> 00:19:42.510
그것을 실제로

00:19:42.510 --> 00:19:43.400
일을 수행하는 방법과

00:19:43.400 --> 00:19:45.580
현실 세계에서 연결할 수 있게 되며, 이것이 대략

00:19:45.580 --> 00:19:48.280
오늘날 저희가 있는 지점입니다, 알겠습니다, 음, 그러면

00:19:48.280 --> 00:19:50.020
피지컬 인텔리전스에서는 저희가

00:19:50.020 --> 00:19:52.160
몇 가지 다른 것도 알아냈는데, 어떻게

00:19:52.160 --> 00:19:53.460
확장하십니까, 이 모델들을 어떻게 확장하기 시작하십니까

00:19:53.460 --> 00:19:54.400
이 모델들이

00:19:54.400 --> 00:19:56.100
일반화하도록 어떻게 만드십니까, 그리고 어떻게

00:19:56.100 --> 00:19:57.860
훨씬 더 잘 수행하게 만드십니까, 또 어떻게

00:19:57.860 --> 00:19:58.780
훨씬 더 빠르게 움직이게 하십니까

00:19:58.780 --> 00:20:00.100
어떻게 해야 그 지점까지 도달하게 할 수 있을까요

00:20:00.100 --> 00:20:02.160
현장에 배치할 수 있는 단계까지 어떻게 끌어올리느냐인데, 저는

00:20:02.160 --> 00:20:03.380
대체로 우리는 아직도

00:20:03.380 --> 00:20:05.420
여전히 ‘어떻게 해야 하느냐’의 시대에 있다고 봅니다.

00:20:05.420 --> 00:20:06.380
상식적인 지식을 어떻게 가져오느냐,

00:20:06.380 --> 00:20:07.340
인터넷

00:20:07.340 --> 00:20:08.400
사전학습에서 말입니다.

00:20:08.840 --> 00:20:10.620
어떻게 이런 모델들을 매우 범용적으로 만들고

00:20:10.620 --> 00:20:12.140
어떤 로봇에서도 작동하게 하며

00:20:12.140 --> 00:20:13.120
동작을 수행하게 하느냐입니다.

00:20:13.760 --> 00:20:15.320
그리고 추론 같은 것에 대해서도 여쭤봐도 되겠습니까

00:20:15.320 --> 00:20:16.410
요즘 정말 많은 일이

00:20:16.410 --> 00:20:17.500
일어나고 있는데,

00:20:17.500 --> 00:20:18.060
아시다시피

00:20:18.060 --> 00:20:18.940
대규모 언어 모델의 추론 측면에서

00:20:18.940 --> 00:20:19.820
말입니다.

00:20:19.820 --> 00:20:22.320
그런 이점을 얻고 계십니까

00:20:22.320 --> 00:20:23.660
그것이

00:20:23.660 --> 00:20:24.670
VLA 백본의 일부로서

00:20:24.670 --> 00:20:25.680
추론이

00:20:25.680 --> 00:20:27.840
자연스럽게 나타나는 것입니까

00:20:27.840 --> 00:20:28.180
그 과정에서,

00:20:28.180 --> 00:20:29.540
엔드투엔드로 학습할 때 나타나는 것입니까, 아니면

00:20:29.540 --> 00:20:31.200
아니면, 또 한편으로는

00:20:31.200 --> 00:20:31.860
지금

00:20:31.860 --> 00:20:33.540
LLM 세계에서 일어나는 일들의 이점이

00:20:33.540 --> 00:20:35.740
여러분에게 도움이 되는지 아닌지, 저는

00:20:35.740 --> 00:20:37.040
분명히 그렇다고 봅니다.

00:20:37.040 --> 00:20:40.380
오늘날 우리가 가진 모델들은 이미

00:20:40.380 --> 00:20:42.620
행동을 계획하고 있는데, 단지

00:20:42.620 --> 00:20:43.160
즉각적인

00:20:43.160 --> 00:20:45.580
행동이 무엇인지뿐 아니라

00:20:45.580 --> 00:20:47.440
앞으로 제가 해야 할

00:20:47.440 --> 00:20:49.180
다음 50가지 행동까지요.

00:20:49.180 --> 00:20:51.020
즉 다음 50개의

00:20:51.020 --> 00:20:53.220
시간 스텝을 보는 건데, 이는 대략

00:20:53.220 --> 00:20:54.660
1~2초 정도의 아주 짧은 지평입니다.

00:20:54.660 --> 00:20:56.550
그리고 또

00:20:56.550 --> 00:20:58.440
과제를

00:20:58.440 --> 00:20:59.970
언어 공간에서 하위 과제로 분해하기도 합니다.

00:20:59.970 --> 00:21:01.500
이미 그런 면이 있어서,

00:21:01.500 --> 00:21:03.740
예를 들어 ‘부엌을 청소해’라고 시키면

00:21:03.740 --> 00:21:05.310
첫 번째 하위 과제로는 아마

00:21:05.310 --> 00:21:06.880
먼저 무엇을 할지 골라서

00:21:06.880 --> 00:21:08.060
‘아, 제가

00:21:08.060 --> 00:21:09.620
카운터로 이동해야 하고, 그리고

00:21:09.620 --> 00:21:12.280
음, 그

00:21:12.280 --> 00:21:13.820
유리컵을 집어 싱크대로 옮겨야 한다’ 같은 식입니다.

00:21:13.820 --> 00:21:18.100
그래서 이미 그런 측면이 있습니다.

00:21:18.100 --> 00:21:20.300
어떤 의미에서는 그렇습니다. 즉

00:21:20.300 --> 00:21:21.440
과제를 하위 과제로 분해하는 셈입니다.

00:21:21.440 --> 00:21:23.820
스스로에게 상위 과제를 부여하고

00:21:23.820 --> 00:21:25.660
그리고 약간의

00:21:25.660 --> 00:21:26.860
행동 지평을

00:21:26.860 --> 00:21:28.580
예측하기도 합니다. 그래서 이런 것들 중 일부는 이미

00:21:28.580 --> 00:21:31.460
이미 갖추고 있다고 생각합니다. 그리고 저는

00:21:31.460 --> 00:21:33.420
미래에는 아마 더 많아질 것이라고

00:21:33.420 --> 00:21:36.400
전적으로 기대합니다. 그리고

00:21:36.400 --> 00:21:38.280
추론을 위한 학습 같은 모든 발전들이

00:21:38.280 --> 00:21:39.040
앞으로도

00:21:39.040 --> 00:21:40.780
결국

00:21:40.780 --> 00:21:43.580
로보틱스에도 그대로 들어올 것이라고 봅니다.

00:21:43.580 --> 00:21:44.220
이것이 흥미롭다고

00:21:44.220 --> 00:21:46.960
생각하는데, 왜냐하면 이것은 아마

00:21:46.960 --> 00:21:50.760
예를 들어 수학 문제를 위한 RL과는 조금 다르기 때문입니다.

00:21:50.760 --> 00:21:51.440
사람들이 하는 것과

00:21:51.440 --> 00:21:52.670
비교하면 그렇습니다, 왜냐하면 저는

00:21:52.670 --> 00:21:53.900
그것들이

00:21:53.900 --> 00:21:56.580
우리 인간에게 매우, 매우 쉽다고

00:21:56.580 --> 00:21:57.680
느껴지기 때문입니다.

00:21:58.720 --> 00:21:59.780
텍스트 문제로는 생각하기가 쉬워서,

00:21:59.780 --> 00:22:00.840
머릿속에서

00:22:00.840 --> 00:22:03.660
텍스트로

00:22:03.660 --> 00:22:05.580
‘이 공식을

00:22:05.580 --> 00:22:07.200
이렇게 바꾸면 이런 결과가 나온다’고 생각하곤 합니다.

00:22:07.200 --> 00:22:08.840
반면 물리적 지능 쪽에서는

00:22:08.840 --> 00:22:09.980
그것이

00:22:09.980 --> 00:22:11.880
아마 그것보다는 조금 더일 것이라고 생각합니다.

00:22:11.880 --> 00:22:13.560
즉, 조금은

00:22:13.560 --> 00:22:14.880
다를 텐데요, 예를 들어

00:22:14.880 --> 00:22:17.080
새로운 스포츠를 배우려고 할 때인데, 제가

00:22:17.080 --> 00:22:19.680
최근에

00:22:19.680 --> 00:22:21.300
테니스를 치는 법을 배우기 시작했을 때를 보면

00:22:21.300 --> 00:22:22.840
저는 머릿속에서

00:22:22.840 --> 00:22:24.720
‘이제 라켓을 잡아야 하고

00:22:24.720 --> 00:22:26.420
여기로 옮겨야 하고, 그리고

00:22:26.420 --> 00:22:26.560
또

00:22:26.560 --> 00:22:28.200
이것을 해야 한다’라고 생각하기보다는, 더

00:22:28.200 --> 00:22:29.370
동작 자체를 생각하게 됩니다.

00:22:29.370 --> 00:22:30.540
네, 그렇습니다.

00:22:30.540 --> 00:22:31.920
예를 들면,

00:22:31.920 --> 00:22:33.720
몸이 어떻게 움직이는지, 어떻게

00:22:33.720 --> 00:22:36.960
어쩌면 어떤 의미에서는 계획이

00:22:36.960 --> 00:22:38.340
물체들의 궤적을

00:22:38.340 --> 00:22:40.200
주변에서 어떻게 움직일지 머릿속으로 그리며 생각하게 됩니다.

00:22:40.200 --> 00:22:42.040
그런 것들이 시간이 지나면서

00:22:42.040 --> 00:22:43.120
모델에도 더 많이 반영될 것이라고 봅니다.

00:22:43.120 --> 00:22:47.460
네, 저도 시간이 지나면 그렇게 될 거라고 생각합니다, 지금은

00:22:47.460 --> 00:22:49.100
우리가 비전-언어 모델에서

00:22:49.100 --> 00:22:50.340
상당한 혜택을 보고 있는데,

00:22:50.340 --> 00:22:52.330
하지만 장기적으로는

00:22:52.330 --> 00:22:54.320
그 흐름이

00:22:54.320 --> 00:22:56.160
거꾸로 될 가능성이 매우 높다고 봅니다.

00:22:56.160 --> 00:22:58.000
즉

00:22:58.000 --> 00:22:58.580
많은

00:22:58.580 --> 00:23:00.800
오늘날 LLM에서 보는 한계들은

00:23:00.800 --> 00:23:04.360
어느 정도는 내재되어 있거나, 우리가

00:23:04.360 --> 00:23:05.880
집중하고 있는

00:23:05.880 --> 00:23:06.960
텍스트 문제, 예를 들면 수학이나

00:23:06.960 --> 00:23:08.040
코딩 같은 문제 때문에

00:23:08.040 --> 00:23:10.360
네, 그리고 로보틱스가 아마

00:23:10.360 --> 00:23:11.320
이런

00:23:11.320 --> 00:23:13.220
새로운 길을 제시해서, 일종의

00:23:13.220 --> 00:23:14.990
추론을 어떻게 생각할지 다시 생각하게 만들 것 같습니다.

00:23:14.990 --> 00:23:16.760
추론은

00:23:16.760 --> 00:23:17.260
아마도

00:23:17.260 --> 00:23:18.670
어떤 추상적인 공간에서 일어나야 하고

00:23:18.670 --> 00:23:20.080
그곳에서

00:23:20.080 --> 00:23:21.640
아시다시피, 텍스트로도 조금 추론하고

00:23:21.640 --> 00:23:22.340
또

00:23:22.340 --> 00:23:23.880
이미지로도 조금 추론하며, 어쩌면

00:23:23.880 --> 00:23:26.360
궤적 같은 것들로도 추론할 수 있고, 그러니까

00:23:26.360 --> 00:23:27.100
온갖 다른

00:23:27.100 --> 00:23:28.640
공간을 오가며 답에 도달할 수 있는데,

00:23:28.640 --> 00:23:30.180
로보틱스는

00:23:30.180 --> 00:23:32.680
정말 좋은 테스트베드를 제공해서

00:23:32.680 --> 00:23:35.180
음

00:23:35.180 --> 00:23:36.280
물리 세계에 기반해 있고

00:23:36.280 --> 00:23:39.080
음, 아직 데이터가

00:23:39.080 --> 00:23:41.500
그렇게 많지 않아서, 어느 정도는

00:23:41.500 --> 00:23:42.720
그에 따른

00:23:42.720 --> 00:23:43.960
몇 가지 어려움들도 다뤄야 하지만, 저는

00:23:43.960 --> 00:23:45.200
생각하기에

00:23:45.200 --> 00:23:48.600
그 과정에서 새로운 발견들이

00:23:48.600 --> 00:23:49.240
나올 것이며, 그 발견들이

00:23:49.240 --> 00:23:51.160
다시 LLM 세계에도 재적용될 것이라고 봅니다. 데이터 이야기로

00:23:51.160 --> 00:23:53.080
넘어가서,

00:23:53.080 --> 00:23:56.140
데이터에 대해 감을 좀 주시면 좋겠습니다, 저는 잘

00:23:56.140 --> 00:23:57.200
모르겠는데, 이미 수집한 데이터의

00:23:57.200 --> 00:23:58.360
규모를 어떻게 측정하고,

00:23:58.360 --> 00:23:59.520
또

00:23:59.520 --> 00:24:01.380
그리고 향후 1년 동안 얼마나 더 수집하고 싶으신지,

00:24:01.380 --> 00:24:01.880
그러니까 내년까지

00:24:01.880 --> 00:24:04.140
1년을 기준으로 말씀드리면, 물론 더 많으면 좋겠지만

00:24:04.140 --> 00:24:05.270
대략 어느 정도 규모를

00:24:05.270 --> 00:24:06.400
상정하고

00:24:06.400 --> 00:24:07.380
말씀하시는 것입니까, 네.

00:24:08.100 --> 00:24:10.440
데이터는, 음, 그런 것들 중 하나입니다.

00:24:10.440 --> 00:24:11.320
사실 비교적 최근에 새로 주목받기 시작했고, 단지

00:24:11.320 --> 00:24:12.200
그저

00:24:12.200 --> 00:24:12.980
양의 문제만은 아닙니다.

00:24:12.980 --> 00:24:14.730
네, 품질이 당연히 중요하지만, 또한

00:24:14.730 --> 00:24:16.480
예를 들어

00:24:16.480 --> 00:24:17.960
다양성 같은 것도 중요하고, 더 나아가

00:24:17.960 --> 00:24:19.440
그

00:24:19.440 --> 00:24:20.800
로봇 데이터의 품질이나 다양성을 생각해 봐도, 이것들은

00:24:20.800 --> 00:24:22.160
사실

00:24:22.160 --> 00:24:23.790
아주 엄밀하게 정의된 용어가 아닙니다.

00:24:23.790 --> 00:24:25.420
예컨대

00:24:25.420 --> 00:24:26.340
만약

00:24:26.340 --> 00:24:27.920
같은 작업을

00:24:27.920 --> 00:24:30.480
10가지 다른 방식으로 수행하면 이것이 다양한 데이터인지

00:24:30.480 --> 00:24:31.680
아닌지, 그리고 어떻게

00:24:31.680 --> 00:24:33.040
그것을 다른 종류의 데이터 다양성과 비교해야 하는지,

00:24:33.040 --> 00:24:35.580
예를 들어 10개의 서로 다른 유리컵을 집는 경우와 비교하면 어떻겠습니까.

00:24:35.580 --> 00:24:37.800
음, 그래서 이런 부분은

00:24:37.800 --> 00:24:39.340
저희가 커뮤니티 차원에서 아직

00:24:39.340 --> 00:24:40.970
완전히 이해하지 못한다고 생각합니다, 데이터를 어떻게 특성화할지

00:24:40.970 --> 00:24:42.600
데이터를

00:24:42.600 --> 00:24:43.800
다양성을 어떻게 설명할지,

00:24:43.800 --> 00:24:45.000
또

00:24:45.000 --> 00:24:46.900
데이터의 품질을 어떻게 설명할지,

00:24:46.900 --> 00:24:48.520
이를 매우 엄밀하게 만드는 방법까지 말입니다.

00:24:50.260 --> 00:24:54.080
그리고 또, 어, 알아가고 있는 점은,

00:24:54.080 --> 00:24:56.440
데이터에는

00:24:56.440 --> 00:24:57.140
정말로

00:24:57.140 --> 00:24:58.240
중요한 측면들이 있다는 것입니다, 예를 들어

00:24:58.240 --> 00:24:59.340
만약

00:24:59.340 --> 00:25:00.960
어떤 작업에서 일정 수준의 성능에 도달하려면

00:25:00.960 --> 00:25:02.700
그 작업은

00:25:02.700 --> 00:25:03.710
그냥 양을 늘리는 것만으로는

00:25:03.710 --> 00:25:04.720
계속 좋아지지 않습니다.

00:25:04.720 --> 00:25:05.950
지금 이미 가지고 있는

00:25:05.950 --> 00:25:07.180
데이터만으로는 안 됩니다, 어, 저희는

00:25:07.180 --> 00:25:08.100
지금까지

00:25:08.100 --> 00:25:10.540
파이와 파이 스타

00:25:10.540 --> 00:25:11.880
0.6 릴리스를 위해 서로 다른 세 가지 과제로

00:25:11.880 --> 00:25:13.220
작업해 왔는데, 초반부터

00:25:13.220 --> 00:25:14.120
알게 된 점이 있습니다. 그냥

00:25:14.120 --> 00:25:16.020
더 많은 데이터를 계속

00:25:16.020 --> 00:25:17.660
지금까지와 같은 방식으로 수집하기만 하면

00:25:17.660 --> 00:25:18.420
성능이

00:25:18.420 --> 00:25:20.780
정체되어서

00:25:20.780 --> 00:25:22.840
계속 좋아지지 않습니다, 그래서

00:25:22.840 --> 00:25:23.500
새로운 방식으로

00:25:23.500 --> 00:25:24.640
수집하거나, 아니면

00:25:24.640 --> 00:25:25.780
생각을

00:25:25.780 --> 00:25:28.080
어떤 종류의 데이터가

00:25:28.080 --> 00:25:28.780
더 나은 성능으로 이어지는지로

00:25:29.340 --> 00:25:31.035
돌려야 합니다. 그리고 이런 지점에서

00:25:31.035 --> 00:25:32.320
강화학습 같은 것과

00:25:32.320 --> 00:25:34.240
이런 접근들이 정말로

00:25:34.240 --> 00:25:36.280
큰 도움이 됩니다. 강화학습을

00:25:36.280 --> 00:25:37.640
이야기해 보지요.

00:25:37.640 --> 00:25:39.640
그리고 파이, 파이

00:25:39.640 --> 00:25:40.740
스타 0.6도 말입니다,

00:25:40.740 --> 00:25:43.320
여기서 스타는 Q*를

00:25:43.320 --> 00:25:45.000
의식한 것입니까, 네, 결국

00:25:45.000 --> 00:25:46.680
목표는

00:25:46.680 --> 00:25:48.040
정책 스타, 즉

00:25:48.040 --> 00:25:49.560
최적 정책 스타라는 뜻입니까. 좋습니다.

00:25:49.560 --> 00:25:51.080
그럼

00:25:51.080 --> 00:25:52.380
여러분이

00:25:52.380 --> 00:25:52.640
무엇을 하고 계신지

00:25:53.420 --> 00:25:55.460
파이 스타 0.6에 대해 한마디 해 주시고,

00:25:55.460 --> 00:25:57.200
그다음에 여러분의 세계에서 RL이

00:25:57.200 --> 00:25:59.380
무슨 의미인지 들어가 보겠습니다. 네, 물론입니다.

00:25:59.380 --> 00:26:01.180
아까 이야기한 것과 대비해 보면

00:26:01.180 --> 00:26:02.540
핵심 차이는

00:26:02.540 --> 00:26:03.420
이렇다고 생각합니다.

00:26:03.960 --> 00:26:06.760
그 전까지는 기본적으로

00:26:06.760 --> 00:26:08.020
저희가 해 온 로보틱스 파운데이션 모델 학습이

00:26:08.020 --> 00:26:09.280
대부분

00:26:09.280 --> 00:26:12.028
시연 데이터였고, 음,

00:26:12.028 --> 00:26:13.520
원격조작으로 얻은 데이터가

00:26:13.520 --> 00:26:14.960
모델로 들어가면, 모델은

00:26:14.960 --> 00:26:15.060
일종의

00:26:15.060 --> 00:26:18.060
그 데이터를 그대로 모방하도록 학습하는 방식이었습니다. 그런데 이제

00:26:18.060 --> 00:26:20.620
이 새로운 모델인 파이 스타 0.6에서는

00:26:20.620 --> 00:26:21.760
저희가 사용하는 것이

00:26:21.760 --> 00:26:23.640
기본적으로, 음, 경험으로부터의 RL입니다, 즉

00:26:23.640 --> 00:26:25.520
로봇이

00:26:25.520 --> 00:26:26.990
정책을 실제로 실행하면서

00:26:26.990 --> 00:26:28.460
스스로 수집한 경험을 말합니다.

00:26:28.460 --> 00:26:29.060
그래서 저희는

00:26:29.060 --> 00:26:30.310
초기 정책을, 그러니까

00:26:30.310 --> 00:26:31.560
시연으로

00:26:31.560 --> 00:26:33.560
학습된 정책으로 시작하고, 이를 배포해서

00:26:33.560 --> 00:26:33.880
실제로

00:26:33.880 --> 00:26:36.100
로봇이 과제를 해결하도록 시도합니다. 그리고

00:26:36.100 --> 00:26:37.450
추가로, 어, 일종의

00:26:37.450 --> 00:26:38.800
보상

00:26:38.800 --> 00:26:39.660
신호를

00:26:39.660 --> 00:26:42.320
사람으로부터 받기도 하고, 교정도 받을 수 있습니다. 그래서

00:26:42.320 --> 00:26:43.320
사람이 개입해서 '아,'

00:26:43.320 --> 00:26:44.320
사실

00:26:44.320 --> 00:26:44.680
말씀드리자면,

00:26:44.680 --> 00:26:46.280
이건 맞지 않으니, 이렇게

00:26:46.280 --> 00:26:47.640
조금 다르게 해 봅시다'라고 말합니다. 그런 데이터가

00:26:47.640 --> 00:26:49.000
그 과정에서

00:26:49.000 --> 00:26:49.380
기본적으로

00:26:49.380 --> 00:26:52.160
수집되어 다시 들어오고,

00:26:52.160 --> 00:26:53.900
모델이 그 데이터를 활용해

00:26:53.900 --> 00:26:54.900
무엇을 해야 할지

00:26:54.900 --> 00:26:57.120
어떤 데이터를

00:26:57.120 --> 00:26:58.560
강화해서

00:26:58.560 --> 00:26:59.660
더 많이 해야 하는지, 또 어떤 것은

00:26:59.660 --> 00:27:01.880
덜 해야 하는지를, 어, 그리고

00:27:01.880 --> 00:27:03.401
시간이 지나며 스스로 개선합니다.

00:27:03.401 --> 00:27:04.340
기본적으로, 이것이

00:27:04.340 --> 00:27:04.840
큰

00:27:04.840 --> 00:27:06.820
차이점이며, 이런 실제 데이터의 흐름이

00:27:06.820 --> 00:27:08.800
계속

00:27:08.800 --> 00:27:11.020
들어오는 것이 바로 빠져 있던 조각입니다.

00:27:11.020 --> 00:27:11.680
카롤이

00:27:11.680 --> 00:27:13.740
말한 부분인데, 이것이 이제 저희가

00:27:13.740 --> 00:27:15.060
그렇지 않으면 겪게 되는

00:27:15.060 --> 00:27:16.380
이

00:27:16.380 --> 00:27:16.820
정체를

00:27:16.820 --> 00:27:20.080
벗어날 수 있게 해 줍니다. 네, 그리고

00:27:20.080 --> 00:27:22.320
제 머릿속에서는, 저는

00:27:22.320 --> 00:27:23.900
RL을 보상 신호를 따라

00:27:23.900 --> 00:27:25.940
힐클라이밍하는 것으로 생각합니다. 그래서

00:27:25.940 --> 00:27:27.820
어떻게

00:27:27.820 --> 00:27:28.740
일반화가 되도록 보장하시는지,

00:27:28.740 --> 00:27:30.500
이런 특정 과제들에서 힐클라임을 하면서도 말입니다.

00:27:30.500 --> 00:27:31.760
이에 대해 저희가 생각하는 방식은

00:27:31.760 --> 00:27:33.020
이런 특정한 유형의 문제에서는

00:27:33.020 --> 00:27:33.280
말하자면

00:27:33.280 --> 00:27:35.180
일종의 범용 모델이 있고,

00:27:35.180 --> 00:27:37.760
그 모델이

00:27:37.760 --> 00:27:38.220
달성하는 성능은

00:27:38.780 --> 00:27:40.050
그리 좋지는 않은 수준입니다

00:27:40.050 --> 00:27:41.320
그리고 이제

00:27:41.320 --> 00:27:44.825
사실 첫 번째 목표는 더

00:27:44.825 --> 00:27:45.680
일반화하는 것이 아닙니다

00:27:45.680 --> 00:27:47.280
이 특정 과제를

00:27:47.280 --> 00:27:49.780
먼저 해결하는 것입니다. 그래서 이를 배포하고

00:27:49.780 --> 00:27:50.660
그리고 저희는

00:27:50.660 --> 00:27:52.420
대략 서너 개의 과제를 골랐기 때문에

00:27:52.420 --> 00:27:53.640
그럼에도 여러 과제에 걸쳐 일반화해야 합니다. 즉

00:27:53.640 --> 00:27:54.860
방법도

00:27:54.860 --> 00:27:55.600
일반화되어야 합니다

00:27:55.600 --> 00:27:56.670
하지만 실제로 배포해서

00:27:56.670 --> 00:27:57.740
이

00:27:57.740 --> 00:27:59.600
RL 과정을 시작하려고 할 때 저희가

00:27:59.600 --> 00:28:00.060
정말로 중요하게 생각하는 것은

00:28:00.060 --> 00:28:02.580
이 과제를 확실히 제대로 짚고

00:28:02.580 --> 00:28:04.800
그 과제를 어느 정도 확실히 정립하는 것입니다

00:28:04.800 --> 00:28:07.580
또 제가, 음, 제가 할 수 있는 방식으로

00:28:07.580 --> 00:28:07.700
제가

00:28:07.700 --> 00:28:08.990
다양한 위치에서 그것을 해결할 수 있고

00:28:08.990 --> 00:28:10.280
여러 자세에서도 가능합니다

00:28:10.280 --> 00:28:11.920
그리고 저는 그 모든 긴

00:28:11.920 --> 00:28:13.080
꼬리 형태의 실패들을

00:28:13.080 --> 00:28:14.250
제가 마주치게 될 텐데, 그렇습니다, 그래서

00:28:14.250 --> 00:28:15.420
그리고 때로는

00:28:15.420 --> 00:28:17.190
일반화와 성능이

00:28:17.190 --> 00:28:18.960
여기서는

00:28:18.960 --> 00:28:19.480
서로

00:28:19.480 --> 00:28:20.640
상충하는 것처럼 보일 수 있습니다, 예를 들면

00:28:20.640 --> 00:28:22.140
잠깐만, 그런데 지금은 그냥

00:28:22.140 --> 00:28:24.920
이 한 과제만 하고 있잖아요, 음, 하지만

00:28:24.920 --> 00:28:27.040
사실 결국에는

00:28:27.040 --> 00:28:29.340
저희가 하려는 것은

00:28:29.340 --> 00:28:31.260
같은 방법, 같은 프로세스를

00:28:31.260 --> 00:28:33.080
각각의 과제에 적용하고,

00:28:33.080 --> 00:28:34.760
그렇게 해서 성능을 높인 다음

00:28:34.760 --> 00:28:35.780
그 모든

00:28:35.780 --> 00:28:37.240
과제 전반의 데이터를 모아서

00:28:37.240 --> 00:28:38.150
기본적으로 그 데이터를 다시 가져올 수 있습니다

00:28:38.150 --> 00:28:39.060
그렇습니다

00:28:39.060 --> 00:28:40.900
그러니 그런 의미에서

00:28:40.900 --> 00:28:42.720
실제로는 상충하는 것이 아닙니다, 만약

00:28:42.720 --> 00:28:44.860
말이 된다면요, 네, 이해됩니다; 그런데

00:28:44.860 --> 00:28:46.160
RL은 얼마나

00:28:46.160 --> 00:28:48.100
하고 계신가요? 뭔가

00:28:48.100 --> 00:28:51.020
현실 세계에서의 RL이 있는 것 같은데,

00:28:51.020 --> 00:28:51.720
접근 방식에 대해 조금

00:28:51.720 --> 00:28:53.100
시뮬레이션에서 RL을 얼마나 하는지

00:28:53.100 --> 00:28:56.280
현실에서는 얼마나 하는지요; 음, 저희는

00:28:56.280 --> 00:28:59.200
꽤, 음, 현실 우선의

00:28:59.200 --> 00:29:02.440
접근을 택했고, 시뮬레이션을 사용하는 것과는 달리요

00:29:02.440 --> 00:29:04.740
물론 시뮬레이션도

00:29:04.740 --> 00:29:06.880
연구

00:29:06.880 --> 00:29:09.120
도구로도 탐색하고 있지만, 저희가

00:29:09.120 --> 00:29:11.140
pi star 0.6 논문에서 한 RL은 실제로

00:29:11.140 --> 00:29:12.900
현실 세계의 실제 시스템에서

00:29:12.900 --> 00:29:14.740
이뤄졌고, 그 이유는

00:29:14.740 --> 00:29:16.110
다시 말해 모델링하기가 정말 정말 어렵기 때문입니다

00:29:16.110 --> 00:29:17.480
저희는

00:29:17.480 --> 00:29:17.920
저희는, 저희는

00:29:17.920 --> 00:29:19.920
긴 꼬리의 실패로 다시 돌아가면

00:29:19.920 --> 00:29:21.260
배포를 할 때

00:29:21.260 --> 00:29:22.760
보게 되는 것들인데, 제가

00:29:22.760 --> 00:29:24.640
저희가 살펴본 작업들에서 많은 예를

00:29:24.640 --> 00:29:25.900
이 릴리스에서 실제로

00:29:25.900 --> 00:29:27.160
거기에는

00:29:27.160 --> 00:29:27.560
실패

00:29:27.560 --> 00:29:29.820
모드가 있었고, 만약

00:29:29.820 --> 00:29:31.760
그것을 시뮬레이션만 했더라면

00:29:31.760 --> 00:29:32.720
보지 못했을 수도 있습니다

00:29:32.720 --> 00:29:35.300
예를 들면, 음, 저희는

00:29:35.300 --> 00:29:37.340
이런 과제가 하나 있는데요, 즉

00:29:37.340 --> 00:29:38.620
상자를 만들어야 합니다, 그렇습니다; 이건

00:29:38.620 --> 00:29:38.820
하나의

00:29:38.820 --> 00:29:40.360
실제 배포 과제이고, 목표는

00:29:40.360 --> 00:29:41.900
음,

00:29:41.900 --> 00:29:43.600
작은, 음, 골판지 상자를 만드는 것입니다

00:29:43.600 --> 00:29:45.300
그걸

00:29:45.300 --> 00:29:45.840
초콜릿을

00:29:45.840 --> 00:29:48.100
넣을 수 있게 해서, 그 다음에

00:29:48.100 --> 00:29:51.000
포장하고, 그리고, 그리고, 기본적으로 발송할 수 있게 하는 것입니다

00:29:51.000 --> 00:29:52.020
그러니까 그것은

00:29:52.020 --> 00:29:53.690
기본적으로 초콜릿 상자를 만드는 것이고요; 음, 그리고

00:29:53.690 --> 00:29:55.360
이 상자를

00:29:55.360 --> 00:29:56.740
처음에는, 아시다시피, 아주 잘 됐습니다만

00:29:56.740 --> 00:29:58.120
그런데

00:29:58.120 --> 00:29:58.700
어느 순간

00:29:58.700 --> 00:30:01.540
새 상자 물량이 들어오면, 그것들이

00:30:01.540 --> 00:30:03.680
납작하게 펼친

00:30:03.680 --> 00:30:05.320
골판지 시트 형태로 오고, 또

00:30:05.320 --> 00:30:06.300
이번 새

00:30:06.300 --> 00:30:07.280
물량의 골판지는

00:30:07.280 --> 00:30:08.710
천공이 완벽하지 않아서

00:30:08.710 --> 00:30:10.140
서로

00:30:10.140 --> 00:30:10.240
좀

00:30:10.240 --> 00:30:11.270
붙어 있었던 것입니다; 그러면 로봇이

00:30:11.270 --> 00:30:12.300
시작해서

00:30:12.300 --> 00:30:14.160
그걸 집어 테이블 위에 올려놓고

00:30:14.160 --> 00:30:15.020
그, 그, 그

00:30:15.020 --> 00:30:16.160
이 상자를 만들려고 하는데, 그러다

00:30:16.160 --> 00:30:18.060
갑자기 테이블 위에 상자가 두 개가 있게 됩니다, 그렇습니다

00:30:18.060 --> 00:30:18.940
그리고 이것은

00:30:18.940 --> 00:30:20.380
시뮬레이션에서는, 만약

00:30:20.380 --> 00:30:21.730
좋은 시뮬레이터를 잘 만들었더라도

00:30:21.730 --> 00:30:23.080
여러분은

00:30:23.080 --> 00:30:23.640
그저

00:30:23.640 --> 00:30:25.160
개별 골판지만 받아서 접게 될 테니까요

00:30:25.160 --> 00:30:26.680
음, 그리고

00:30:26.680 --> 00:30:27.780
그래서 이제 이

00:30:27.780 --> 00:30:28.680
문제를 처리해야 합니다; 그리고 만약

00:30:28.680 --> 00:30:30.320
시뮬레이션에서만 모든 것을 학습한 뒤

00:30:30.320 --> 00:30:32.180
배포하려고 하면 이런 상황을 겪지 못했을 것입니다

00:30:32.180 --> 00:30:33.060
그런데 저희는 이것을 겪었고

00:30:33.060 --> 00:30:36.740
그리고 저희의, 음, 방법은

00:30:36.740 --> 00:30:38.340
어, 사실 무엇을

00:30:38.340 --> 00:30:39.140
해야 하는지, 즉 저는

00:30:39.140 --> 00:30:41.320
이것을 분리하고, 또

00:30:41.320 --> 00:30:44.320
그, 그 두 번째 조각을 뒤로 옮겨서

00:30:44.320 --> 00:30:45.240
그리고 상자를

00:30:45.240 --> 00:30:46.130
기본적으로 만들면 된다는 것을 알아냅니다; 그리고 저희는 많은 성공 사례를

00:30:46.130 --> 00:30:47.020
봅니다

00:30:47.020 --> 00:30:48.920
RL이 시뮬레이션에서 적용되고

00:30:48.920 --> 00:30:49.940
현실

00:30:49.940 --> 00:30:52.050
세계로 전이되는 경우를, 특히 이동에서는 그렇습니다; 그런데 저희는

00:30:52.050 --> 00:30:54.160
그런 것을

00:30:54.160 --> 00:30:55.620
그만큼의 성공을

00:30:55.620 --> 00:30:57.080
조작에서는

00:30:57.660 --> 00:31:00.080
이런 방식들에서는 보지 못했습니다, 그리고 저는

00:31:00.080 --> 00:31:02.060
그 이유 중 하나가 아마

00:31:02.060 --> 00:31:03.540
이동에서는

00:31:03.540 --> 00:31:06.000
여기저기 움직이려 할 때, 문제의 가장 큰 부분이

00:31:06.000 --> 00:31:07.800
사실은

00:31:07.800 --> 00:31:08.480
자기 자신의

00:31:08.480 --> 00:31:10.620
몸을 모델링하는 것이기 때문이고, 만약

00:31:10.620 --> 00:31:13.440
로봇으로서 자기 자신을 어떻게 모델링할지 알 수 있다면

00:31:13.440 --> 00:31:14.320
거의

00:31:14.320 --> 00:31:17.820
다 된 셈입니다; 그래서, 음, 이런 모델링

00:31:17.820 --> 00:31:19.330
그런 모델링 시뮬레이션을 한 번만 하면 되는데, 왜냐하면

00:31:19.330 --> 00:31:20.840
그것은

00:31:20.840 --> 00:31:21.660
여러분이 그저

00:31:21.660 --> 00:31:23.620
이 한 로봇에서 자기 자신에 대해서만

00:31:23.620 --> 00:31:24.670
하면, 기본적으로 끝이기 때문입니다

00:31:24.670 --> 00:31:25.720
만약

00:31:25.720 --> 00:31:26.220
정말

00:31:26.220 --> 00:31:28.435
정말 잘 하면, 그것이

00:31:28.435 --> 00:31:29.700
조작에도 전이되어야 합니다만

00:31:29.700 --> 00:31:31.180
문제는 여러분의

00:31:31.180 --> 00:31:31.340
자기

00:31:31.340 --> 00:31:33.300
몸을 어떻게 움직이느냐가 아니라, 세계가 그것에 어떻게 반응하느냐입니다

00:31:33.300 --> 00:31:34.690
여러분은 실제로 주변 세계를

00:31:34.690 --> 00:31:36.080
바꾸고 있고, 이것은

00:31:36.080 --> 00:31:36.740
그리 어렵지 않게

00:31:36.740 --> 00:31:38.040
손을

00:31:38.040 --> 00:31:39.940
A에서 B로 움직이는 방법은 알 수 있지만, 어려운 것은

00:31:39.940 --> 00:31:41.620
그것이 물체에

00:31:41.620 --> 00:31:42.880
여러분이 상호작용하는 물체에 어떻게 영향을 미치는지이고, 이제

00:31:42.880 --> 00:31:44.140
문제는

00:31:44.140 --> 00:31:46.740
더 이상 자기 로봇만 모델링하는 것이 아니라, 여러분은

00:31:46.740 --> 00:31:47.480
모델링해야 합니다

00:31:47.480 --> 00:31:48.740
전체 세계를요; 즉 모든

00:31:48.740 --> 00:31:50.000
물체

00:31:50.000 --> 00:31:50.990
여러분이 상호작용할 수 있는 모든

00:31:50.990 --> 00:31:51.980
단일

00:31:51.980 --> 00:31:54.360
과제까지도요, 그리고 거기서

00:31:54.360 --> 00:31:57.380
스케일링 문제가 나타나고, 그래서 저는

00:31:57.380 --> 00:31:58.140
왜 저희가

00:31:58.140 --> 00:32:00.460
seen those kind of methods be as effective

00:32:00.460 --> 00:32:02.160
in in manipulation what was the headline

00:32:02.160 --> 00:32:03.860
of

00:32:03.860 --> 00:32:04.320
the results

00:32:04.320 --> 00:32:07.720
from pi star 0.6 and you know

00:32:07.720 --> 00:32:09.580
where where did you see the model get

00:32:09.580 --> 00:32:11.320
after rl on the on the test that

00:32:11.320 --> 00:32:13.100
you cared about and what do you think

00:32:13.100 --> 00:32:14.170
that means about your overall training

00:32:14.170 --> 00:32:15.240
recipe going

00:32:15.240 --> 00:32:15.540
forward

00:32:15.540 --> 00:32:18.500
right yeah so i think for me the

00:32:18.500 --> 00:32:19.780
most impressive thing honestly for me

00:32:19.780 --> 00:32:21.060
personally to

00:32:21.060 --> 00:32:21.720
see was just

00:32:21.720 --> 00:32:24.100
have these models run for hours at a

00:32:24.100 --> 00:32:25.660
time recover from lots of different

00:32:25.660 --> 00:32:27.220
failures and

00:32:27.220 --> 00:32:27.760
and basically

00:32:27.760 --> 00:32:29.960
just keep going and at the same time

00:32:29.960 --> 00:32:32.380
그걸 그, 그, 그 속도로요

00:32:32.380 --> 00:32:34.660
사실 그 속도는 훨씬 더 좋았고

00:32:34.660 --> 00:32:35.560
우리가 시작했던 초기 모델보다요

00:32:35.560 --> 00:32:36.460
그렇죠

00:32:36.460 --> 00:32:37.640
그래서 핵심 수치는 우리가

00:32:37.640 --> 00:32:38.820
정책의

00:32:38.820 --> 00:32:38.980
처리량을

00:32:38.980 --> 00:32:41.700
이 세 가지 작업에서 2배 이상 높였다는 것입니다

00:32:41.700 --> 00:32:43.520
이 세 가지 작업인데요, 그중 하나는

00:32:43.520 --> 00:32:44.080
이 박스

00:32:44.080 --> 00:32:44.940
조립 작업이었고, 앞에서 말씀드린 것처럼

00:32:44.940 --> 00:32:45.800
또 하나는

00:32:45.800 --> 00:32:48.820
실제로

00:32:48.820 --> 00:32:49.280
산업용

00:32:49.280 --> 00:32:50.900
대형 에스프레소 머신으로 커피를 만드는 작업이었고, 다른 하나는

00:32:50.900 --> 00:32:52.520
바로

00:32:52.520 --> 00:32:55.460
빨래를 개는 것 같은 작업이었습니다, 그리고

00:32:55.460 --> 00:32:55.880
각각에 대해 우리는

00:32:55.880 --> 00:32:57.860
시연만으로 학습된 기본 정책을

00:32:57.860 --> 00:32:59.000
훨씬

00:32:59.000 --> 00:33:00.140
훨씬 더 빠르게 만들었고

00:33:00.700 --> 00:33:03.020
또 실패에서

00:33:03.020 --> 00:33:04.670
훨씬 더 잘 복구하게도 만들었습니다, 그래서

00:33:04.670 --> 00:33:06.320
직접

00:33:06.320 --> 00:33:08.060
그걸 실제로 작동하는 걸 보면

00:33:08.060 --> 00:33:10.140
그냥 거기 앉아서 보게 되잖아요, 그렇죠

00:33:10.140 --> 00:33:11.760
저희는 웹사이트에 가시면

00:33:11.760 --> 00:33:13.220
영상들을 보실 수 있는데요

00:33:13.840 --> 00:33:17.100
로봇이 13시간 연속으로 커피를 서빙하거나

00:33:17.100 --> 00:33:20.140
또는 빨래를

00:33:20.140 --> 00:33:21.880
4시간 동안 개는 것 같은 것들이 있습니다

00:33:21.880 --> 00:33:23.750
음, 그런 걸 라이브로 직접 보면

00:33:23.750 --> 00:33:25.620
정말

00:33:25.620 --> 00:33:27.130
이런 모델을 생각하는 방식이 바뀝니다, 아시겠지만

00:33:27.130 --> 00:33:28.640
바뀌고

00:33:28.640 --> 00:33:29.440
적어도

00:33:29.440 --> 00:33:32.220
제가 생각하기에는, 음, 실제로

00:33:32.220 --> 00:33:33.290
우리가 이를 배포할 수 있다는 게 현실적이고

00:33:33.290 --> 00:33:34.360
또

00:33:34.360 --> 00:33:35.280
우리가 그걸

00:33:35.280 --> 00:33:37.840
한 번 보여주는 장난감 데모가 아니라

00:33:37.840 --> 00:33:39.960
실제로는

00:33:39.960 --> 00:33:41.480
진짜 일을 완전히 수행한다는 점에서요

00:33:41.480 --> 00:33:43.680
그리고, 그리고 그건 로보틱스에서 정말 큰 도전이었는데

00:33:43.680 --> 00:33:44.480
많은 분들이

00:33:44.480 --> 00:33:45.140
잘

00:33:45.140 --> 00:33:45.600
모르시는 것 같습니다

00:33:45.600 --> 00:33:47.140
네, 그러니까 로봇이 멋진 일을 하는 영상이 정말 많고

00:33:47.140 --> 00:33:49.700
보시잖아요, 그리고

00:33:49.700 --> 00:33:50.540
저희도 이런 영상을 올리는데요

00:33:50.540 --> 00:33:51.880
기본적으로는

00:33:51.880 --> 00:33:53.220
여러분이

00:33:53.220 --> 00:33:54.080
로봇에게 시키고 싶은 거의 모든 일에 대해 이미

00:33:54.080 --> 00:33:54.940
하나의

00:33:54.940 --> 00:33:55.140
영상이

00:33:55.140 --> 00:33:58.440
로봇이 그걸 하는 영상이 있을 겁니다, 음, 하지만

00:33:58.440 --> 00:33:59.720
아시겠지만 원하는 만큼 다시 찍을 수 있고

00:33:59.720 --> 00:34:01.780
원하는 만큼 할 수 있고, 또

00:34:01.780 --> 00:34:02.760
완벽한 장면이 나올 때까지 계속 녹화할 수 있는데요

00:34:02.760 --> 00:34:03.740
완벽한 샷이 나올 때까지요, 음, 그리고 제가 보기엔 문제는

00:34:03.740 --> 00:34:06.880
모두가 마주치는 게

00:34:06.880 --> 00:34:08.060
이 모델들의 신뢰성입니다, 얼마나

00:34:08.060 --> 00:34:09.320
성능이

00:34:09.320 --> 00:34:10.580
좋은지, 얼마나 빨리

00:34:10.580 --> 00:34:12.240
작업을

00:34:12.240 --> 00:34:13.100
수행할 수 있는지, 또 얼마나 오래

00:34:13.100 --> 00:34:15.120
실패 없이 실제로 배치해 둘 수 있는지이고, 저는

00:34:15.120 --> 00:34:16.750
이게

00:34:16.750 --> 00:34:18.380
가장 큰

00:34:18.380 --> 00:34:19.340
병목이라고 생각합니다, 이런 모델을

00:34:19.340 --> 00:34:20.480
현실 세계에 배포하는 데 있어서의

00:34:20.480 --> 00:34:21.620
현실 세계에서요, 왜냐하면 아시겠지만

00:34:21.620 --> 00:34:23.600
만약, 만약 이들이

00:34:23.600 --> 00:34:24.860
시도 두 번에 한 번꼴로 망가진다면, 사실

00:34:24.860 --> 00:34:26.210
실사용이 불가능합니다

00:34:26.210 --> 00:34:27.560
그렇죠, 그리고 이건 이건 제 생각에

00:34:27.560 --> 00:34:30.080
가장

00:34:30.080 --> 00:34:30.400
중요한

00:34:30.400 --> 00:34:31.520
이 파이

00:34:31.520 --> 00:34:32.640
스타

00:34:32.640 --> 00:34:35.900
0.6 출시에서 우리가 실제로

00:34:35.900 --> 00:34:36.460
실사용 가능한 수준에

00:34:36.460 --> 00:34:37.590
도달하기 시작했다는 점입니다, 네

00:34:37.590 --> 00:34:38.720
즉

00:34:38.720 --> 00:34:40.340
저희 사무실에서 이 로봇들을 써서

00:34:40.340 --> 00:34:41.460
우리에게 커피를 제공하게 하거나

00:34:41.460 --> 00:34:43.420
PI의 사람들에게 주어서

00:34:43.420 --> 00:34:45.400
집에서 빨래를 개게 하거나, 혹은

00:34:45.400 --> 00:34:47.260
배치해서, 음, 로봇이

00:34:47.260 --> 00:34:50.020
박스를 실제로 접게 할 수 있다는 점이고, 그건 정말

00:34:50.020 --> 00:34:51.380
정말 흥분되는 일입니다, 여러분이

00:34:51.380 --> 00:34:52.740
여러분이

00:34:52.740 --> 00:34:53.100
하고 계신

00:34:53.100 --> 00:34:54.530
강화학습이 주로

00:34:54.530 --> 00:34:55.960
그러니까

00:34:55.960 --> 00:34:59.790
고객 배치에서의 신뢰성, 어

00:34:59.790 --> 00:35:00.960
그런 점들이 있고,

00:35:00.960 --> 00:35:02.220
예를 들면 이제는 여러분이

00:35:02.220 --> 00:35:04.840
이를 안정적으로 배포할 수 있도록,

00:35:04.840 --> 00:35:06.060
커피 제조 모델을

00:35:06.060 --> 00:35:07.800
고객 현장에 배포해도 그것이

00:35:07.800 --> 00:35:09.900
충분히 빠르고, 실패하지 않을 것이며

00:35:09.900 --> 00:35:11.100
장기간의 시간 범위에서도 그렇다는 것을

00:35:11.600 --> 00:35:13.400
음, 그래서 이는 더 고객

00:35:13.400 --> 00:35:15.612
배포 측면의 혁신에 가깝다는 말씀인지,

00:35:15.612 --> 00:35:16.780
근본적인

00:35:16.780 --> 00:35:17.680
역량

00:35:17.680 --> 00:35:20.480
음, 혁신인지 아니면 둘 다인지요? 저는

00:35:20.480 --> 00:35:22.460
둘 다라고 봅니다. 카롤, 아까

00:35:22.460 --> 00:35:23.260
조금 말씀하셨듯이,

00:35:23.260 --> 00:35:26.580
앞서 말씀하신 것처럼 어느 정도는 우리가

00:35:26.580 --> 00:35:27.600
정말로 정말로 원하는 로봇들, 즉

00:35:27.600 --> 00:35:28.620
그

00:35:28.620 --> 00:35:29.380
원하는 로봇은

00:35:29.380 --> 00:35:31.600
집에서 세탁도 하고

00:35:31.600 --> 00:35:34.120
설거지도 하고, 요리도 해 주고, 돌아다니며 운전도 하고,

00:35:34.120 --> 00:35:34.900
그리고 또

00:35:34.900 --> 00:35:36.160
소규모 사업장에서 사람들이 원하는 로봇도

00:35:36.160 --> 00:35:37.420
아마

00:35:37.420 --> 00:35:39.440
그들이 실제로 겪는 문제를 해결하는데,

00:35:39.440 --> 00:35:40.040
그들이

00:35:40.040 --> 00:35:40.840
전통적인 방식으로 자동화하고 싶지 않은데, 그 이유는

00:35:40.840 --> 00:35:41.620
그것이

00:35:41.620 --> 00:35:42.990
너무 비싸기 때문입니다. 예를 들어 초콜릿

00:35:42.990 --> 00:35:44.360
상자를 만드는 것 같은 것들이요,

00:35:44.360 --> 00:35:44.620
그런 것들은

00:35:44.620 --> 00:35:47.100
로봇이 신뢰할 수 있어야 하는 일들입니다.

00:35:47.100 --> 00:35:48.580
성능이 좋아야 하고, 또한

00:35:48.580 --> 00:35:49.860
초기 훈련에서 보지 못한

00:35:49.860 --> 00:35:52.260
새로운 과업을

00:35:52.260 --> 00:35:54.208
해낼 수 있는 역량도 필요합니다. 저는

00:35:54.208 --> 00:35:55.020
우리가

00:35:55.020 --> 00:35:55.620
그렇게 가정하는 것은 비현실적이라고 봅니다.

00:35:55.620 --> 00:35:59.180
즉, 그저

00:35:59.180 --> 00:36:00.540
더하고 더 많은 인간 데이터 수집으로

00:36:00.540 --> 00:36:01.900
계속

00:36:01.900 --> 00:36:03.060
더 크고 더 크고 더 크게 가는 것이고, 우리는

00:36:03.060 --> 00:36:04.800
그렇게 하겠지만, 항상

00:36:04.800 --> 00:36:06.640
얼마나 좋을 수 있는지와

00:36:06.640 --> 00:36:08.320
얼마나 많은 데이터를 얻을 수 있는지에는 한계가 있고,

00:36:08.320 --> 00:36:09.940
초기 정책이 얼마나 좋은지도

00:36:09.940 --> 00:36:11.680
한계가 있습니다. 그래서 저는

00:36:11.680 --> 00:36:13.060
배포에 관해 말씀하신

00:36:13.060 --> 00:36:15.700
우리는 배포를 원하고 필요하지만,

00:36:15.700 --> 00:36:17.210
또 앞으로 점점

00:36:17.210 --> 00:36:18.720
몇 년 동안

00:36:18.720 --> 00:36:19.080
우리는

00:36:19.080 --> 00:36:21.300
제가 보기에는 우리가

00:36:21.300 --> 00:36:22.270
이 배포를 하게 되고 그 데이터가

00:36:22.270 --> 00:36:23.240
실제로

00:36:23.240 --> 00:36:24.260
아주 가치 있어질 것이라고 생각합니다.

00:36:24.260 --> 00:36:27.320
모델을 더 좋게 만드는 사전학습의 원천으로서요.

00:36:27.320 --> 00:36:28.940
그리고 우리는

00:36:28.940 --> 00:36:30.560
더

00:36:30.560 --> 00:36:31.180
점점 더

00:36:31.180 --> 00:36:32.673
자율 데이터 수집에 의존하게 될 것이라는 것이 제

00:36:32.673 --> 00:36:33.560
예측입니다, 적어도.

00:36:33.560 --> 00:36:36.400
음, 앞으로 다가올 몇 년 동안 그런 방식으로

00:36:36.400 --> 00:36:37.360
그

00:36:37.360 --> 00:36:40.260
우리가 로봇이 결국 하길 원하는 모든 과업의 볼록 껍질(컨벡스 헐)이 되는

00:36:40.260 --> 00:36:42.500
방대한 데이터를

00:36:42.500 --> 00:36:44.260
구축해서,

00:36:44.260 --> 00:36:45.910
모델이 이를

00:36:45.910 --> 00:36:47.560
받아들이고

00:36:47.560 --> 00:36:49.760
그것들을 잘 수행하며 보간할 수 있게 되고, 저는

00:36:49.760 --> 00:36:50.120
이를

00:36:50.120 --> 00:36:52.180
지금까지 없었던 새로운 역량으로 봅니다. 우리는 아직

00:36:52.180 --> 00:36:53.960
자기 경험으로부터 배우는 방법을

00:36:53.960 --> 00:36:55.500
완전히 알아내지 못했고, 또

00:36:55.500 --> 00:36:57.240
여러 시도가 있었지만, 저는 우리가

00:36:57.240 --> 00:37:00.160
규모 있게 수행되는 것을, 그러니까

00:37:00.160 --> 00:37:02.320
제가

00:37:02.320 --> 00:37:03.450
정말 설득력 있는 결과를 보여주는 수준까지

00:37:03.450 --> 00:37:04.580
여러분이

00:37:04.580 --> 00:37:06.100
무언가를 배포할 수 있게 하는, 설득력 있는 결과를 실제로 본 적이 없다고

00:37:06.100 --> 00:37:07.620
생각합니다. 네, 그래서

00:37:07.620 --> 00:37:07.860
이

00:37:07.860 --> 00:37:08.930
결과는

00:37:08.930 --> 00:37:10.000
우리에게 정말 정말 중요했습니다.

00:37:10.000 --> 00:37:11.400
우리는 로봇이

00:37:11.400 --> 00:37:12.140
자기 경험으로부터

00:37:12.140 --> 00:37:13.540
배울 수 있는 지점까지 가고 싶었습니다. 왜냐하면

00:37:13.540 --> 00:37:14.940
비슷하게

00:37:14.940 --> 00:37:16.940
우리가 배우는 방식이 그렇듯, 여러분도

00:37:16.940 --> 00:37:18.060
조금은

00:37:18.060 --> 00:37:19.570
동영상을 보고 연습하면서 배울 수 있지만,

00:37:19.570 --> 00:37:21.080
그리고

00:37:21.080 --> 00:37:23.220
어쩌면 다른 사람에게서 배우기도 하지만, 어느 시점에는

00:37:23.220 --> 00:37:23.520
결국

00:37:23.520 --> 00:37:25.220
현장에서 배우셔야 하고,

00:37:25.220 --> 00:37:26.780
직접 그 일을 해 보셔야 하며,

00:37:26.780 --> 00:37:27.800
여러분의 행동이

00:37:27.800 --> 00:37:28.880
실제로 달성하고자 하는 것에 어떻게 영향을 미치는지 보셔야 합니다.

00:37:28.880 --> 00:37:29.960
네.

00:37:29.960 --> 00:37:32.240
그리고 스스로 결론을 내리고 그렇게 해 보려고

00:37:32.240 --> 00:37:32.860
그런 방식으로 배우려고 해 보세요.

00:37:32.860 --> 00:37:34.320
네, 그리고 제 생각에 이건 그걸 향한 첫

00:37:34.320 --> 00:37:35.380
걸음인 것 같고, 지금 말씀을 들으니

00:37:35.380 --> 00:37:36.440
그

00:37:36.440 --> 00:37:37.420
음, 여러분 읽어

00:37:37.420 --> 00:37:39.680
보셨나요, 리치 서튼의 'Age of Experience'요, 네.

00:37:39.680 --> 00:37:41.420
올해 읽었는데 정말 좋았고, 저는 그게

00:37:41.420 --> 00:37:43.600
아주 심오하다고 느꼈습니다, 음, 여러분은

00:37:43.600 --> 00:37:46.659
이게 일종의 지속적

00:37:46.659 --> 00:37:47.620
학습을

00:37:47.620 --> 00:37:49.640
로보틱스에서 가능하게 한다고 보시나요, 이게 그 일부가 될까요.

00:37:49.640 --> 00:37:50.820
그건 어느 정도

00:37:50.820 --> 00:37:52.040
사람들이 '지속적

00:37:52.040 --> 00:37:53.260
학습'을 무엇으로

00:37:53.260 --> 00:37:55.612
의미하느냐에 달려 있고요, 제 생각엔 음, 확실히 더

00:37:55.612 --> 00:37:56.580
지속적이긴 합니다,

00:37:56.580 --> 00:37:57.040
이전에

00:37:57.040 --> 00:37:58.580
우리가 해 왔던 방식에 비하면요, 아시다시피

00:37:58.580 --> 00:38:01.080
큰 사전학습 혼합 데이터가 있고

00:38:01.080 --> 00:38:01.820
아마

00:38:01.820 --> 00:38:04.580
사후학습 혼합 데이터도 있고, 그리고 여러분이

00:38:04.580 --> 00:38:06.400
앉아서 정말 정말 열심히

00:38:06.400 --> 00:38:07.340
일하고

00:38:07.340 --> 00:38:09.220
그러고 나서 하나의 산출물을 만들어 내면

00:38:09.220 --> 00:38:10.100
그걸로 끝이잖아요, 네, 그러니까 그

00:38:10.100 --> 00:38:10.980
산출물이

00:38:10.980 --> 00:38:12.320
완성되면

00:38:12.320 --> 00:38:13.500
바꿀 수 있는 게 별로 없다는 거죠.

00:38:13.500 --> 00:38:16.400
그런데 지금은 훨씬 더

00:38:16.400 --> 00:38:18.820
살아 있는 것에 가깝습니다, 그러니까 우리가

00:38:18.820 --> 00:38:21.320
이와 비슷한 과정으로 시작하지만 그다음에는

00:38:21.320 --> 00:38:23.140
배포하고 나면 계속

00:38:23.140 --> 00:38:24.840
학습하잖아요, 그래서 훨씬

00:38:24.840 --> 00:38:27.160
그 의미에서 더 지속적이고, 새로운 것들을

00:38:27.160 --> 00:38:29.060
시도하고 자기

00:38:29.060 --> 00:38:29.640
경험에서 배우려 하고

00:38:29.640 --> 00:38:32.620
계속 더 나아집니다, 네, 그런데 지금도

00:38:32.620 --> 00:38:34.840
저는 아직도 더

00:38:34.840 --> 00:38:35.960
지속적으로 될

00:38:35.960 --> 00:38:37.380
여지가 있다고 생각하고, 그렇게 해서 새로운 기술을

00:38:37.380 --> 00:38:38.800
그런

00:38:38.800 --> 00:38:41.800
방식으로 습득할 수도 있고, 더 훨씬 빠르게

00:38:41.800 --> 00:38:43.620
이걸 해낼 수도 있겠죠, 네, 음.

00:38:43.620 --> 00:38:44.840
아마 이 과정 전반에 걸쳐

00:38:44.840 --> 00:38:46.060
추론도 할 수 있을 테니,

00:38:46.060 --> 00:38:48.760
저는 어떤 스펙트럼이 있다고

00:38:48.760 --> 00:38:49.920
생각합니다, 직무 중에 얼마나

00:38:49.920 --> 00:38:52.560
학습할 수 있느냐에 대한 스펙트럼이요, 그리고 이건

00:38:52.560 --> 00:38:53.360
정말 유망한데, 왜냐하면 여러분이

00:38:53.360 --> 00:38:54.160
그렇게

00:38:54.160 --> 00:38:55.220
할 수 있다는 걸 보여 주기 때문이고, 하지만 저는

00:38:55.220 --> 00:38:57.920
우리가 이걸 훨씬 더 개선할 수 있다고 봅니다, 네.

00:38:57.920 --> 00:38:59.380
저도 동의합니다, 저는 우리가

00:38:59.380 --> 00:39:01.140
이것의 아주 시작 단계에

00:39:01.140 --> 00:39:03.220
있다고 말하겠고요, 그리고 이건, 이건

00:39:03.220 --> 00:39:04.530
고전적 의미의 지속적 학습은

00:39:04.530 --> 00:39:05.840
확실히 아닙니다.

00:39:05.840 --> 00:39:06.020
즉,

00:39:06.020 --> 00:39:07.440
사람들이 데이터 스트림 같은 걸로

00:39:07.440 --> 00:39:09.280
생각하던 방식과는 다르고, 전체가

00:39:09.280 --> 00:39:09.880
돌아가면서

00:39:09.880 --> 00:39:13.040
결국은, 음, 궁극적으로는

00:39:13.040 --> 00:39:14.600
모르겠지만 AGI 같은 데로까지

00:39:14.600 --> 00:39:16.060
이어진다든지 하는 거요, 네, 하지만 아시다시피

00:39:16.060 --> 00:39:17.780
이건 첫걸음이고, 저는

00:39:17.780 --> 00:39:18.580
그렇게 말하겠고, 우리는 올바른

00:39:18.580 --> 00:39:19.360
방향으로

00:39:19.360 --> 00:39:19.800
가고 있습니다, 그리고

00:39:19.800 --> 00:39:21.220
할 일이 훨씬 더 많고, 제 생각엔

00:39:21.220 --> 00:39:23.680
이 이번 공개만 보더라도

00:39:23.680 --> 00:39:25.920
개인적으로는 인상받았고

00:39:25.920 --> 00:39:28.860
어느 정도는, 아시다시피, 얼마나

00:39:28.860 --> 00:39:30.250
이 모델들이 실제로 작은 것들을

00:39:30.250 --> 00:39:31.640
잘

00:39:31.640 --> 00:39:32.580
잡아내는지에

00:39:32.580 --> 00:39:34.240
놀랐습니다, 데이터를 다시 넣어 주는 것만으로도요, 저는

00:39:34.240 --> 00:39:35.640
심지어 사람의 수정만으로도

00:39:35.640 --> 00:39:37.040
말입니다.

00:39:37.040 --> 00:39:38.840
음, 예를 들면

00:39:38.840 --> 00:39:41.640
탬핑에 대한 예시가 하나 있었는데요, 그러니까

00:39:41.640 --> 00:39:43.980
우리가 하는 탬핑은 에스프레소를 만들 때의 특정 과정입니다.

00:39:43.980 --> 00:39:45.340
에스프레소를 만드는 과정의 한 부분이죠.

00:39:45.340 --> 00:39:46.920
그러니까 원두를 넣고

00:39:46.920 --> 00:39:48.780
그다음에 눌러서 다져야 하잖아요, 가장

00:39:48.780 --> 00:39:50.360
좋은 부분이죠, 네, 그 가장 좋은 부분에서 여러분이

00:39:50.360 --> 00:39:52.340
탬핑해서 다져야 하는데, 저는

00:39:52.340 --> 00:39:55.320
직접 해 보진 않아서요, 그러니 보시죠, 저는

00:39:55.320 --> 00:39:57.620
또 하나의 실력 이슈가 아니었습니다.

00:39:58.200 --> 00:40:00.540
제가 딱 제대로 해내겠습니다, 맞습니다.

00:40:00.540 --> 00:40:02.460
그래서 저희 로봇은 초반에는 그랬습니다.

00:40:02.460 --> 00:40:03.560
탬핑을 너무 세게 했습니다.

00:40:03.560 --> 00:40:06.080
왜냐하면, 음, 우연히도

00:40:06.080 --> 00:40:07.040
초기 인간

00:40:07.040 --> 00:40:08.000
시연이

00:40:08.000 --> 00:40:09.680
그러니까, '우선'

00:40:09.680 --> 00:40:11.180
커피 가루가 평평한지 확인해서

00:40:11.180 --> 00:40:11.820
그걸 넣을 수 있게 하려는 것이었기 때문입니다.

00:40:11.820 --> 00:40:13.880
음, 그러고 나서 로봇은

00:40:13.880 --> 00:40:14.690
정말 세게 탬핑해서 거의 스스로를

00:40:14.690 --> 00:40:15.500
들어 올릴 뻔했습니다.

00:40:15.500 --> 00:40:16.000
테이블에서

00:40:16.000 --> 00:40:17.860
저희가 보니, 그건 좀

00:40:17.860 --> 00:40:19.940
과했고, 그래서 그냥, 잘 모르겠지만

00:40:19.940 --> 00:40:22.280
제 생각에는 34에서 50 에피소드 정도였습니다.

00:40:22.280 --> 00:40:23.969
교정의 범위가 정말 작았습니다.

00:40:23.969 --> 00:40:24.840
사람들이 했던 교정이

00:40:24.840 --> 00:40:26.800
그 데이터를 다시 넣어 주면

00:40:26.800 --> 00:40:27.220
그리고 모델은

00:40:27.220 --> 00:40:28.120
실제로 훨씬 더

00:40:28.120 --> 00:40:29.020
부드러워지기 시작했고

00:40:29.020 --> 00:40:30.880
올바른 동작을 수행했으며, 저는 정말

00:40:30.880 --> 00:40:31.240
놀랐습니다.

00:40:31.240 --> 00:40:32.740
왜냐하면, 여러분도 아시다시피

00:40:32.740 --> 00:40:34.480
이 모델은 이런

00:40:34.480 --> 00:40:35.780
수백만, 그리고

00:40:35.780 --> 00:40:36.580
수백만 에피소드로 사전 학습되었는데, 이제는 그저

00:40:36.580 --> 00:40:37.300
조금

00:40:37.300 --> 00:40:38.470
교정을 하는 것뿐인데도

00:40:38.470 --> 00:40:39.640
그게 실제로 통하기 때문입니다, 그래서

00:40:39.640 --> 00:40:41.800
그런 일이 일어나는 것을 보는 것은

00:40:41.800 --> 00:40:42.920
이 계속되는

00:40:42.920 --> 00:40:44.040
학습

00:40:44.040 --> 00:40:44.640
이라는 부분을 가리킨다고 저는 생각했습니다.

00:40:44.640 --> 00:40:46.720
저는 그것이 인상적이지만, 그런데 질문 하나 드려도 되겠습니까.

00:40:46.720 --> 00:40:49.520
그리고 제가 아직도

00:40:49.520 --> 00:40:50.740
걸리는 것은 일반화입니다, 그래서

00:40:50.740 --> 00:40:53.360
제가 탬핑을 더 잘하게 되면

00:40:53.360 --> 00:40:55.100
상자를 접는 데도 더 잘하게 됩니까, 아니면

00:40:55.100 --> 00:40:55.320
그렇지 않습니까.

00:40:56.160 --> 00:41:00.860
음, 이 특정한 경우에는 그렇지 않지만,

00:41:00.860 --> 00:41:03.300
메커니즘은 같아서, 또

00:41:03.300 --> 00:41:05.500
그걸 활용해 '아,'

00:41:05.500 --> 00:41:06.980
제 앞에 상자 두 개가 있고

00:41:06.980 --> 00:41:08.860
그걸 제가 약간 붙여 버렸으며, 저는

00:41:08.860 --> 00:41:10.160
그것들을 떼어내야 합니다, 맞습니까.

00:41:10.160 --> 00:41:13.000
왜냐하면 탬핑 부분에서는 교정 30번을 받을 수 있고,

00:41:13.000 --> 00:41:14.240
탬핑 부분에서 교정 30번을 받고,

00:41:14.240 --> 00:41:15.480
또

00:41:15.480 --> 00:41:16.380
상자를 잡아당겨

00:41:16.380 --> 00:41:19.820
떼어내는 것에서도, 네, 교정 30번을 받지만

00:41:19.820 --> 00:41:22.200
'아, 아시다시피, 이 상자는' 예를 들어

00:41:22.200 --> 00:41:23.320
깔끔하게 접히지 않았고

00:41:23.320 --> 00:41:24.430
이 모든 것이 함께 누적되어 결국

00:41:24.430 --> 00:41:25.540
여러분에게

00:41:25.540 --> 00:41:27.350
더 일반화된 개선을 주는 거군요, 알겠습니다.

00:41:27.350 --> 00:41:29.160
그러면 이것은

00:41:29.160 --> 00:41:29.220
그러니까

00:41:29.220 --> 00:41:30.791
반복 가능한 레시피이지만, 서로

00:41:30.791 --> 00:41:31.920
반드시 교차, 교차

00:41:31.920 --> 00:41:34.820
수분되지는 않는다는 말씀이군요, 네, 저는

00:41:34.820 --> 00:41:35.140
하지만

00:41:35.140 --> 00:41:37.220
규모를 키우면, 저희가

00:41:37.220 --> 00:41:38.730
실제로 어떤 것들이 전이되는 것도

00:41:38.730 --> 00:41:40.240
어느 정도

00:41:40.240 --> 00:41:41.060
A에서 B로, 만약

00:41:41.060 --> 00:41:43.720
여러 작업에 걸쳐 동작이 어느 정도 비슷하다면

00:41:43.720 --> 00:41:45.200
보게 될 것이라고 기대합니다만, 현재로서는, 네, 저는

00:41:45.200 --> 00:41:45.840
그보다는

00:41:45.840 --> 00:41:48.400
반복 가능한 레시피에 더 가깝다고 말하겠습니다, 네, 그리고 저희는

00:41:48.400 --> 00:41:49.620
사전 학습에서 많은 일반화를

00:41:49.620 --> 00:41:50.840
보고 있습니다.

00:41:50.840 --> 00:41:51.480
즉, 학습을

00:41:51.480 --> 00:41:53.140
점점 더 많은 작업과 점점 더 많은 데이터로 할수록

00:41:53.140 --> 00:41:55.320
새 작업을 온보딩하는 것이 훨씬 쉬워진다는 것을

00:41:55.320 --> 00:41:56.980
보게 되거나, 또는

00:41:56.980 --> 00:41:57.920
여러분이

00:41:57.920 --> 00:41:58.860
예상하지 못했던 작업이

00:41:58.860 --> 00:42:00.900
제로샷으로 나타나기도 하는데, 이런 것은 계속 개선되고 있습니다.

00:42:00.900 --> 00:42:02.940
저희는

00:42:02.940 --> 00:42:04.240
음, 시작합니다,

00:42:04.240 --> 00:42:06.680
일정한 주기로 사전 학습 런을 시작하고,

00:42:06.680 --> 00:42:08.820
매번 시작할 때마다

00:42:08.820 --> 00:42:09.220
모델이 계속

00:42:09.220 --> 00:42:10.170
더 좋아지는 것을 보기 시작합니다, 왜냐하면 더 많은

00:42:10.170 --> 00:42:11.120
데이터가

00:42:11.120 --> 00:42:12.230
투입되고, 더 많은 개선을

00:42:12.230 --> 00:42:13.340
저희가 하고

00:42:13.340 --> 00:42:13.520
있기

00:42:13.520 --> 00:42:15.940
때문이며, 사전 학습 과정 등도 포함됩니다.

00:42:15.940 --> 00:42:18.020
그리고 저는 또한, 더

00:42:18.020 --> 00:42:19.400
많은 이런 모델이 배치될수록

00:42:19.400 --> 00:42:20.470
온갖 다른 작업을 하게 되면, 그들은

00:42:20.470 --> 00:42:21.540
또

00:42:21.540 --> 00:42:24.680
데이터를 다시 가져오고, 저는 한

00:42:24.680 --> 00:42:25.120
가지 방식으로

00:42:25.120 --> 00:42:27.640
즉 제가 꽤 확신하는 방식으로, 저희가

00:42:27.640 --> 00:42:29.170
그 과정에서 더 많은 일반화를 보게 될 것입니다.

00:42:29.170 --> 00:42:30.700
즉

00:42:30.700 --> 00:42:31.200
여러분이

00:42:31.200 --> 00:42:32.740
이 모델들을 배포하면, 그 데이터가

00:42:32.740 --> 00:42:34.280
돌아오고

00:42:34.280 --> 00:42:36.000
모델은 더 좋아져서, 여러분은 더 많이 배포할 수 있으며

00:42:36.000 --> 00:42:36.300
더 많이

00:42:36.300 --> 00:42:38.480
배포하면, 모델은 또 더 좋아지고, 여러분은

00:42:38.480 --> 00:42:40.420
더 많이 배포할 수 있고, 이런 식입니다, 네, 그리고

00:42:40.420 --> 00:42:41.840
제가 생각하기에, 아마도

00:42:41.840 --> 00:42:43.800
여러분이 제기하신 이 지점에서, 저희는

00:42:43.800 --> 00:42:46.176
아직 한 가지

00:42:46.176 --> 00:42:47.100
아주 중요한 세부

00:42:47.100 --> 00:42:47.720
요소에 대해

00:42:47.720 --> 00:42:49.500
이 다섯 단계 또는 여섯 단계 레시피에서

00:42:49.500 --> 00:42:51.020
모델이 두 부분으로 이루어진다는 점을

00:42:51.020 --> 00:42:52.240
충분히 이야기하지 않았습니다.

00:42:52.240 --> 00:42:53.610
하나는 정책으로, 그러니까

00:42:53.610 --> 00:42:54.980
교정을 통해

00:42:54.980 --> 00:42:57.100
또 강화학습(RL) 피드백으로 개선하려는 부분이며, 다른 한 부분은

00:42:57.100 --> 00:42:57.880
어떻게

00:42:57.880 --> 00:42:58.930
이 강화학습(RL) 피드백을 실제로 얻느냐는 것입니다, 그래서

00:42:58.930 --> 00:42:59.980
저희는

00:42:59.980 --> 00:43:00.990
조금 이야기했고, 제가 언급했듯이

00:43:00.990 --> 00:43:02.000
여러분도

00:43:02.000 --> 00:43:02.660
아시다시피 사람은

00:43:02.660 --> 00:43:03.750
교정할 수 있고, 그것이 인간 교정

00:43:03.750 --> 00:43:04.840
부분이며,

00:43:04.840 --> 00:43:07.280
강화학습(RL) 피드백 부분은 조금

00:43:07.280 --> 00:43:07.960
다르고, 또

00:43:07.960 --> 00:43:10.460
이미 이런

00:43:10.460 --> 00:43:11.760
일반화의 측면을 어느 정도 갖고 있다고 저는 생각합니다.

00:43:11.760 --> 00:43:13.060
여러분이

00:43:13.060 --> 00:43:13.900
지금

00:43:13.900 --> 00:43:15.920
찾으려고 하시는 것이 바로 이것인데, 저희가

00:43:15.920 --> 00:43:19.000
이를 하는 방식은, 먼저 기본적으로

00:43:19.000 --> 00:43:21.500
사람들에게, 어, 저희에게

00:43:21.500 --> 00:43:23.120
기본적으로 어떤 특정한 시도가

00:43:23.120 --> 00:43:24.740
그

00:43:24.740 --> 00:43:27.140
커피를 만들거나 상자를 다루는 것이 성공했는지

00:43:27.140 --> 00:43:27.700
아닌지를

00:43:27.700 --> 00:43:28.580
라벨로 제공받는 것입니다, 그래서

00:43:28.580 --> 00:43:29.460
이

00:43:29.460 --> 00:43:30.260
에피소드들에는 사람의 라벨이 함께 붙고, 그다음 저희는 어떤 것을

00:43:30.260 --> 00:43:30.680
훈련합니다.

00:43:30.680 --> 00:43:31.900
그것은

00:43:31.900 --> 00:43:32.120
이른바

00:43:32.120 --> 00:43:33.660
가치 함수(value function)라고 하며, 이를 통해

00:43:33.660 --> 00:43:35.200
기본적으로

00:43:35.200 --> 00:43:37.640
제가 현재 어느 지점에 있는지에서

00:43:37.640 --> 00:43:39.520
작업에서 제가

00:43:39.520 --> 00:43:41.560
성공할 가능성이 큰지, 실패할 가능성이 큰지를

00:43:41.560 --> 00:43:43.600
예측하려고 합니다, 그리고 이

00:43:43.600 --> 00:43:45.780
가치 함수는 이후 일종의

00:43:45.780 --> 00:43:46.900
기준선으로

00:43:46.900 --> 00:43:48.610
사용되어, 이 데이터 포인트에 대해

00:43:48.610 --> 00:43:50.320
제가

00:43:50.320 --> 00:43:52.220
그 값을 올려야 하는지, 아니면

00:43:52.220 --> 00:43:53.480
내려야 하는지를

00:43:53.480 --> 00:43:56.800
제가

00:43:56.800 --> 00:43:58.230
성공 쪽으로 가고 있다고 예상하는지, 아니면 더

00:43:58.230 --> 00:43:59.660
가능성이

00:43:59.660 --> 00:44:00.700
to move towards failure

00:44:00.700 --> 00:44:02.840
and one thing that we saw when we

00:44:02.840 --> 00:44:03.850
trained these value functions so those are

00:44:03.850 --> 00:44:04.860
trained

00:44:04.860 --> 00:44:05.920
basically from the same

00:44:05.920 --> 00:44:08.480
kind of backbone the same kind of model

00:44:08.480 --> 00:44:10.110
but they're pre-trained before the actual

00:44:10.110 --> 00:44:11.740
policy

00:44:11.740 --> 00:44:12.140
is trained

00:44:12.140 --> 00:44:14.300
that that actually runs the task when we

00:44:14.300 --> 00:44:15.950
train these value functions we see that

00:44:15.950 --> 00:44:17.600
adding

00:44:17.600 --> 00:44:18.140
more data

00:44:18.140 --> 00:44:19.580
from different tasks actually helps there

00:44:19.580 --> 00:44:21.020
and the

00:44:21.020 --> 00:44:22.470
model starts being actually really quite

00:44:22.470 --> 00:44:23.920
good at

00:44:24.600 --> 00:44:26.700
at least for for certain tasks and knowing

00:44:26.700 --> 00:44:29.340
when it will fail beforehand and before it

00:44:29.340 --> 00:44:30.980
is obvious for me

00:44:30.980 --> 00:44:32.460
for example when i look at a video

00:44:32.460 --> 00:44:35.780
of it trying to insert uh the um

00:44:35.780 --> 00:44:38.900
uh the porter filter thank you

00:44:38.900 --> 00:44:41.720
see i'm i'm not good at making it's

00:44:41.720 --> 00:44:43.700
trying to insert a porter filter into the

00:44:43.700 --> 00:44:44.980
the coffee machine it kind

00:44:44.980 --> 00:44:47.220
of knows that it doesn't quite have the

00:44:47.220 --> 00:44:49.620
right angle before that happens so like 30

00:44:49.620 --> 00:44:50.820
40 steps before that

00:44:50.820 --> 00:44:51.860
actually happens the value function kind

00:44:51.860 --> 00:44:52.900
of if

00:44:52.900 --> 00:44:54.540
you look at the prediction drops and and

00:44:54.540 --> 00:44:55.120
saying oh this

00:44:55.120 --> 00:44:57.220
is not good in this specific episode so

00:44:57.220 --> 00:44:59.282
i i shouldn't include this data

00:44:59.282 --> 00:45:00.280
흥미롭고

00:45:00.280 --> 00:45:00.620
이것은

00:45:00.620 --> 00:45:02.580
더 많은 데이터와 더 많은 과제가 있을수록 더 좋아지고

00:45:02.580 --> 00:45:03.480
그래서 이것은 흥미로운 대조점입니다

00:45:03.480 --> 00:45:04.380
그

00:45:04.380 --> 00:45:05.320
카르파티의

00:45:05.320 --> 00:45:06.620
빨대로 조금씩 빨아들이는 것 같은 비유에

00:45:06.620 --> 00:45:07.920
그렇죠.

00:45:07.920 --> 00:45:08.720
왜냐하면 여러분은, 여러분은 기다리지 않기 때문입니다

00:45:08.720 --> 00:45:09.460
그

00:45:09.460 --> 00:45:09.900
마지막 조각들을

00:45:09.900 --> 00:45:13.120
끝에서는요, 오히려 그렇습니다, 저는

00:45:13.120 --> 00:45:16.060
RL은 정말

00:45:16.060 --> 00:45:17.480
아주 방대한 분야이고, 또

00:45:17.480 --> 00:45:19.150
그에 대한 접근법이 매우 다양하며 사람들은

00:45:19.150 --> 00:45:20.820
종종 그렇습니다.

00:45:20.820 --> 00:45:22.220
RL을 어떤

00:45:22.220 --> 00:45:23.620
정책

00:45:23.620 --> 00:45:23.940
그래디언트

00:45:23.940 --> 00:45:27.880
방법이라든지, 음, 매우 특정한

00:45:27.880 --> 00:45:32.100
온-폴리시 학습 접근법과 연관짓지만, 제게 RL은

00:45:32.100 --> 00:45:32.440
더

00:45:32.440 --> 00:45:34.500
문제 정의에 가깝고, 또 많은

00:45:34.500 --> 00:45:35.710
많은 접근법들이

00:45:35.710 --> 00:45:36.920
그

00:45:36.920 --> 00:45:37.180
여러분이

00:45:37.180 --> 00:45:39.000
말씀하시는 문제를, 즉 여러분이

00:45:39.000 --> 00:45:40.440
보상을 아주 아주

00:45:40.440 --> 00:45:41.620
끝에서만 받게 되고, 그것은 사실상

00:45:41.620 --> 00:45:43.030
매우 긴 지평의 과제에는 확장 가능하지 않아서, 그런 경우에는

00:45:43.030 --> 00:45:44.440
예를 들어

00:45:44.440 --> 00:45:45.410
가치 함수 같은 것들이 있고

00:45:45.410 --> 00:45:46.380
또

00:45:46.380 --> 00:45:47.520
시간차 학습 같은 것들이

00:45:47.520 --> 00:45:48.660
이를

00:45:48.660 --> 00:45:49.820
해결하려고 하며, 여러분이 계속해서

00:45:49.820 --> 00:45:50.980
예측을 하고

00:45:50.980 --> 00:45:52.940
그리고 이를 순차적인 방식으로 수행합니다

00:45:52.940 --> 00:45:56.380
그리고 이것은 아마도 또 다른

00:45:56.380 --> 00:45:57.640
이런 것들 중 하나인데요.

00:45:57.640 --> 00:46:00.480
저는 로보틱스가 정말로

00:46:00.480 --> 00:46:02.000
더 넓은 AI 커뮤니티에 도움이 될 수 있다고 생각하는데, 왜냐하면 우리는

00:46:02.000 --> 00:46:03.520
the

00:46:03.520 --> 00:46:04.320
advantage of

00:46:04.320 --> 00:46:05.660
having a perfect language simulator where

00:46:05.660 --> 00:46:07.000
you can

00:46:07.000 --> 00:46:09.680
run as many simulations as you would like

00:46:09.680 --> 00:46:10.620
instead

00:46:10.620 --> 00:46:11.500
you need to do it in the real

00:46:11.500 --> 00:46:12.860
world so you need to make more efficient

00:46:12.860 --> 00:46:14.260
methods and therefore you need

00:46:14.260 --> 00:46:15.260
to learn value functions and things like

00:46:15.260 --> 00:46:16.260
this

00:46:16.260 --> 00:46:18.220
and i think this will this will be

00:46:18.220 --> 00:46:19.260
really valuable everywhere

00:46:19.260 --> 00:46:21.800
yeah can i push a little bit on

00:46:21.800 --> 00:46:23.430
i'd love to understand you know internet

00:46:23.430 --> 00:46:25.060
video

00:46:25.060 --> 00:46:25.540
seems like

00:46:25.540 --> 00:46:27.000
it's part of the recipe but not a

00:46:27.000 --> 00:46:29.300
huge focus right now as i see it

00:46:29.300 --> 00:46:30.580
like do you think that there's gold

00:46:30.580 --> 00:46:32.480
left to be mined in internet video and

00:46:32.480 --> 00:46:34.680
then if you look at what's happening in

00:46:34.680 --> 00:46:35.860
video models right now

00:46:35.860 --> 00:46:40.260
uh world models um to what extent do

00:46:40.260 --> 00:46:42.320
you think that's going to be a you

00:46:42.320 --> 00:46:43.720
know discontinuous jump in

00:46:43.720 --> 00:46:44.680
model capabilities and you know an

00:46:44.680 --> 00:46:45.640
important part

00:46:45.640 --> 00:46:48.940
of your your model uh pipeline yeah um

00:46:48.940 --> 00:46:49.980
i think maybe

00:46:49.980 --> 00:46:51.560
there are two questions there one is about

00:46:51.560 --> 00:46:52.920
the data like how do you bootstrap

00:46:52.920 --> 00:46:54.280
yourself

00:46:54.280 --> 00:46:55.000
to the point where

00:46:55.000 --> 00:46:57.560
you can start deploying um and the other

00:46:57.560 --> 00:46:59.760
question is you know what about what about

00:46:59.760 --> 00:47:00.640
video models and

00:47:00.640 --> 00:47:02.520
kind of the world model aspects of it

00:47:02.520 --> 00:47:06.260
um so on the data point i i

00:47:06.260 --> 00:47:08.920
think we are now in this bootstrap phase

00:47:08.920 --> 00:47:11.368
where basically anything goes like

00:47:11.368 --> 00:47:12.520
whatever you you

00:47:12.520 --> 00:47:14.420
can figure out how to like add to

00:47:14.420 --> 00:47:14.920
the model

00:47:15.460 --> 00:47:17.860
and to to to to its benefit i

00:47:17.860 --> 00:47:19.760
think it's good whether you can add sim

00:47:19.760 --> 00:47:20.780
whether you can add human

00:47:20.780 --> 00:47:22.530
videos some kind of handheld devices human

00:47:22.530 --> 00:47:24.280
tell

00:47:24.280 --> 00:47:25.460
operations i think it kind of doesn't

00:47:25.460 --> 00:47:26.640
matter

00:47:26.640 --> 00:47:26.840
you

00:47:26.840 --> 00:47:28.380
just need to figure out some way to

00:47:28.380 --> 00:47:29.490
bootstrap yourself to the point where you

00:47:29.490 --> 00:47:30.600
저희는

00:47:30.600 --> 00:47:31.080
이 모델들을 배포할 수 있습니다,

00:47:31.080 --> 00:47:33.340
장기적으로는 그렇다고 생각하기 때문인데요,

00:47:33.340 --> 00:47:34.390
부트스트랩 단계가 있을 것이고

00:47:34.390 --> 00:47:35.440
하지만

00:47:35.440 --> 00:47:35.860
그 다음에는

00:47:35.860 --> 00:47:38.800
배포 단계가 있을 것이며, 저는

00:47:38.800 --> 00:47:40.180
그 배포 단계가

00:47:40.180 --> 00:47:41.560
훨씬

00:47:41.560 --> 00:47:41.740
더

00:47:41.740 --> 00:47:43.500
부트스트랩 단계에서 할 수 있는 어떤 것보다도 더 많은 데이터를

00:47:43.500 --> 00:47:45.520
제공할 것이라고 봅니다, 그래서 지금 저희는

00:47:45.520 --> 00:47:45.840
조금

00:47:45.840 --> 00:47:48.440
묘한 상황에 처해 있고, 많은

00:47:48.440 --> 00:47:49.430
서로 다른 것들을 닥치는 대로 시도하면서 무엇이

00:47:49.430 --> 00:47:50.420
효과가 있는지

00:47:50.420 --> 00:47:51.060
그저

00:47:51.060 --> 00:47:52.920
배포 임계치까지 가려고 하고 있습니다, 알겠습니다, 그리고

00:47:52.920 --> 00:47:54.500
일단 배포할 수 있게 되면 그것이

00:47:54.500 --> 00:47:56.520
압도적으로 더 큰

00:47:56.520 --> 00:47:58.660
그 이전에 할 수 있는 어떤 것보다도

00:47:58.660 --> 00:48:01.580
음, 그러니까 그것도 저희가

00:48:01.580 --> 00:48:02.740
전력 질주하고 있는 방향이고, 그것이

00:48:02.740 --> 00:48:03.540
이런 것들을 배포하기 시작하려는 이유이며

00:48:03.540 --> 00:48:04.100
모델들입니다.

00:48:04.100 --> 00:48:05.660
그래서 저희는 이것을

00:48:05.660 --> 00:48:06.860
아시다시피, 많은

00:48:06.860 --> 00:48:09.698
다양한 작업에서 또 여러

00:48:09.698 --> 00:48:10.880
다양한 환경에서, 그래서

00:48:10.880 --> 00:48:12.820
저희가 아주

00:48:12.820 --> 00:48:13.560
강력한 데이터

00:48:13.560 --> 00:48:17.080
엔진을 갖추게 하려는 것이고, 이제 세계

00:48:17.080 --> 00:48:20.240
모델링 측면에서는, 저는 세계

00:48:20.240 --> 00:48:21.440
모델과 Aurel

00:48:21.440 --> 00:48:22.700
접근법이 어느 정도 같은

00:48:22.700 --> 00:48:23.960
문제를 겨냥하고 있다고

00:48:23.960 --> 00:48:25.700
즉, 반사실(counterfactual)의 문제인데, 어떻게

00:48:25.700 --> 00:48:27.440
여러분이

00:48:27.440 --> 00:48:27.940
또는

00:48:27.940 --> 00:48:28.950
크레딧 할당 문제이기도 합니다, 즉 어떻게

00:48:28.950 --> 00:48:29.960
여러분이

00:48:29.960 --> 00:48:31.260
어떤 행동들이

00:48:31.260 --> 00:48:32.560
과연

00:48:32.560 --> 00:48:32.900
실제로

00:48:32.900 --> 00:48:35.520
성공에 중요했는지 알아내고, 또

00:48:35.520 --> 00:48:37.180
만약 여러분이

00:48:37.180 --> 00:48:37.720
다른

00:48:37.720 --> 00:48:40.100
행동을 했다면 세계가 어떻게 전개됐을지 보는 것인데, 한 가지 방법은

00:48:40.100 --> 00:48:41.090
무슨 일이 일어났을지를 예측하는 것입니다.

00:48:41.090 --> 00:48:42.080
그렇습니다.

00:48:42.080 --> 00:48:42.980
예를 들어

00:48:42.980 --> 00:48:45.320
전체 영상을 시뮬레이션해, 만약 제가

00:48:45.320 --> 00:48:46.170
이 포터필터를 조금

00:48:46.170 --> 00:48:47.020
다르게

00:48:47.020 --> 00:48:48.820
끼웠다면 어디에 도달했을지를

00:48:49.380 --> 00:48:50.920
그리고 이것이 실패인지

00:48:50.920 --> 00:48:52.290
성공인지 보는 식이고, 또는

00:48:52.290 --> 00:48:53.660
강화

00:48:53.660 --> 00:48:54.020
학습으로도

00:48:54.880 --> 00:48:56.050
할 수 있는데, 이것은 약간

00:48:56.050 --> 00:48:57.220
다른

00:48:57.220 --> 00:48:58.140
메커니즘으로 좀 더 암묵적으로 수행되지만

00:48:58.140 --> 00:48:59.060
결국

00:48:59.060 --> 00:49:02.072
근본적으로 매우 비슷한

00:49:02.072 --> 00:49:03.160
문제를 겨냥합니다, 그리고 저희는

00:49:03.160 --> 00:49:04.600
이 모든 접근법을 탐색하면서

00:49:04.600 --> 00:49:06.140
어떻게 하면

00:49:06.140 --> 00:49:09.307
반사실

00:49:09.307 --> 00:49:10.140
문제를 정말로 해결할지

00:49:10.140 --> 00:49:11.440
아직은

00:49:11.440 --> 00:49:14.360
정답이 있다고 보기는 어렵지만, 저희는

00:49:14.360 --> 00:49:16.300
많은 진전을

00:49:16.300 --> 00:49:17.560
강화학습에서

00:49:17.560 --> 00:49:19.420
방금 π*로 보여드렸고

00:49:19.420 --> 00:49:21.540
π*0.6에서도 그렇습니다, 하지만 저는

00:49:21.540 --> 00:49:22.780
아마도

00:49:22.780 --> 00:49:24.430
다른 많은 접근법의 여지도 있다고 봅니다, 좋습니다, 그러면

00:49:24.430 --> 00:49:26.080
저희가

00:49:26.080 --> 00:49:27.700
그

00:49:27.700 --> 00:49:28.400
부트스트랩 단계를

00:49:28.400 --> 00:49:29.260
넘어선 뒤의 고객 배포에 대해

00:49:29.260 --> 00:49:30.120
조금

00:49:30.120 --> 00:49:32.040
고객에게 무엇을 가져가고

00:49:32.040 --> 00:49:32.320
무엇을 판매하십니까

00:49:32.320 --> 00:49:34.540
그리고 음, 시간이 지나면서 그것이 어떻게

00:49:34.540 --> 00:49:35.860
변해갈지 상상해보면, 예를 들어

00:49:35.860 --> 00:49:36.360
고객에게

00:49:36.900 --> 00:49:38.537
완전히 수직 통합된 로봇

00:49:38.537 --> 00:49:39.660
솔루션을 판매하시는 건지, 아니면

00:49:39.660 --> 00:49:41.580
고객이 스스로

00:49:41.580 --> 00:49:41.700
해결해서

00:49:41.700 --> 00:49:42.560
운영에 통합해야 하는 모델을 판매하시는 건지

00:49:42.560 --> 00:49:43.420
전체적으로

00:49:43.420 --> 00:49:45.960
어떻게 작동하는지, 음, 사실

00:49:45.960 --> 00:49:46.660
진짜 답은 저희가

00:49:46.660 --> 00:49:49.700
아직 모른다는 것입니다, 네, 저희는

00:49:49.700 --> 00:49:52.080
지금도 계속 알아가는 중이고, 또

00:49:52.080 --> 00:49:54.240
기술적으로도 아직 꽤 초기

00:49:54.240 --> 00:49:56.540
단계입니다, 보시면 아시겠지만

00:49:56.540 --> 00:49:58.980
저희는 이제 막

00:49:58.980 --> 00:49:59.960
배포가 가능해지는 임계치에

00:49:59.960 --> 00:50:03.860
이런 것들을 배포하기 시작할 수 있게 됐고, 그래서 저희는

00:50:03.860 --> 00:50:05.480
우선

00:50:05.480 --> 00:50:06.240
기술에 먼저

00:50:06.240 --> 00:50:08.060
집중해서 그것을

00:50:08.060 --> 00:50:08.890
정말로 쉽게

00:50:08.890 --> 00:50:09.720
배포할 수 있는 수준까지

00:50:10.360 --> 00:50:11.560
끌어올리고, 저희가 말하는 적용 범위를

00:50:11.560 --> 00:50:12.760
확장하고자 합니다.

00:50:12.760 --> 00:50:17.000
처음에는, 그리고 로봇공학에서

00:50:17.000 --> 00:50:20.960
로봇 스타트업의 역사를 보면 아주 자주

00:50:20.960 --> 00:50:22.270
이런 지점에 이르는데, 기술을 개발하다가

00:50:22.270 --> 00:50:23.580
어느

00:50:23.580 --> 00:50:24.200
일정한

00:50:24.200 --> 00:50:26.120
기간이 지나면, 처음에는 거대한

00:50:26.120 --> 00:50:28.060
비전으로 무엇을 할 수 있어야 하는지

00:50:28.060 --> 00:50:29.220
얼마나 범용적으로

00:50:29.220 --> 00:50:31.560
쓸 수 있을지를 말하지만, 곧바로

00:50:31.560 --> 00:50:32.840
적용하고 싶은 애플리케이션을 선택하면

00:50:32.840 --> 00:50:34.280
여러분은

00:50:34.280 --> 00:50:35.570
좀 막히게 되고, 타협을 시작하며

00:50:35.570 --> 00:50:36.860
또

00:50:36.860 --> 00:50:38.210
아주 특수 목적의

00:50:38.210 --> 00:50:39.560
해결책을

00:50:39.560 --> 00:50:40.810
오로지 그 애플리케이션만을 위해 찾게 되고, 아주 빠르게

00:50:40.810 --> 00:50:42.060
여러분은

00:50:42.060 --> 00:50:43.600
아시다시피, 애플리케이션 회사가 되어

00:50:43.600 --> 00:50:45.140
결국

00:50:45.140 --> 00:50:46.310
예를 들어 창고에서 피킹

00:50:46.310 --> 00:50:47.480
및

00:50:47.480 --> 00:50:50.300
플레이스 로봇에만 집중하게 되고, 그게 전부가 됩니다, 그리고 저희는

00:50:50.300 --> 00:50:51.060
정말로

00:50:51.060 --> 00:50:53.220
그런 미래를 피하고 싶고, 저희에게 기회가 있다고 생각합니다.

00:50:53.220 --> 00:50:55.410
물리적 지능을 정말로 해결할 수 있고

00:50:55.410 --> 00:50:57.600
그

00:50:57.600 --> 00:50:58.160
이렇게 하는

00:50:58.160 --> 00:50:59.660
이점은 어떤 단일

00:50:59.660 --> 00:51:01.160
애플리케이션보다

00:51:01.160 --> 00:51:03.200
지금 우리가 집중할 수 있는 것보다 훨씬 클 것이므로, 저희는

00:51:03.200 --> 00:51:04.000
반드시

00:51:04.000 --> 00:51:05.040
기술이 가능한 한 범용적이고

00:51:05.040 --> 00:51:06.080
또

00:51:06.080 --> 00:51:07.360
가능한 한 쉽게 배포될 수 있도록 하며, 이

00:51:07.360 --> 00:51:08.640
적용 범위가

00:51:08.640 --> 00:51:09.140
가능한 한

00:51:09.140 --> 00:51:10.860
넓어지도록 한 다음, 그다음에

00:51:10.860 --> 00:51:12.580
저희가

00:51:12.580 --> 00:51:15.380
어떻게 상용화할지를 고민하겠습니다, 그리고 말씀하신 것처럼

00:51:15.380 --> 00:51:15.680
그에는

00:51:15.680 --> 00:51:17.360
아시다시피 여러 가지 방법이

00:51:17.360 --> 00:51:18.450
있을 것이고, 아마 저희가

00:51:18.450 --> 00:51:19.540
아직

00:51:19.540 --> 00:51:20.120
떠올리지 못하는

00:51:20.120 --> 00:51:22.020
방법도 있을 텐데, 그것은 기술이 어떻게

00:51:22.020 --> 00:51:23.700
발전하느냐에 달려 있을 것입니다, 예를 들어

00:51:23.700 --> 00:51:25.380
즉

00:51:25.380 --> 00:51:26.020
모델

00:51:26.020 --> 00:51:27.140
제공자가 되거나, 완전한 수직 통합 솔루션을 제공하거나, 또는

00:51:27.140 --> 00:51:28.260
로봇을 판매하거나

00:51:28.260 --> 00:51:30.560
그 밖의 무엇이든 가능하겠지만, 저는

00:51:30.560 --> 00:51:31.440
이 질문에 답하기에는 아직

00:51:31.440 --> 00:51:32.710
조금 이르다고 생각합니다, 다만

00:51:32.710 --> 00:51:33.980
그렇게 하면

00:51:33.980 --> 00:51:35.600
아시다시피, 큰 안도감을 줄 수는 있습니다.

00:51:35.600 --> 00:51:36.780
그냥 하나를 골라서 말입니다.

00:51:36.780 --> 00:51:38.400
알프레드에게도 큰 안도감을 줄 것입니다.

00:51:38.400 --> 00:51:40.240
저희도 그렇게 하면 편하겠지만, 저는

00:51:40.240 --> 00:51:40.980
아직은 너무 이르다고 봅니다.

00:51:41.560 --> 00:51:44.080
아닙니다, 여러분은 정말 거대한 비전을 갖고 계십니다.

00:51:44.080 --> 00:51:45.210
그래서 물리적

00:51:45.210 --> 00:51:46.340
지능에 대해

00:51:46.340 --> 00:51:47.060
연구해 주셔서

00:51:47.060 --> 00:51:50.122
정말, 정말 훌륭한 진전입니다, 특히

00:51:50.122 --> 00:51:51.040
π*

00:51:51.040 --> 00:51:53.500
0.6은 정말로 아주 큰

00:51:53.500 --> 00:51:54.040
돌파구였습니다.

00:51:54.040 --> 00:51:55.410
그래서 그동안의 모든 성과에 대해 축하드립니다.

00:51:55.410 --> 00:51:56.780
진심으로.

00:51:56.780 --> 00:51:59.640
감사합니다, 제가

00:51:59.640 --> 00:52:00.840
꽤 날카로운 질문입니다.

00:52:00.840 --> 00:52:03.300
네, 말씀하신 대로 이 비전은

00:52:03.300 --> 00:52:05.580
굉장히 크고 범위가 넓어서 이렇게

00:52:05.580 --> 00:52:06.920
여러 가지를 하고 계시는데요, 제가

00:52:06.920 --> 00:52:09.347
분명히 이전의 모든

00:52:09.347 --> 00:52:10.560
로봇공학

00:52:10.560 --> 00:52:14.400
시도들을, 음, 많이 연구하셨을 텐데, 대체로 말씀하신 대로

00:52:14.400 --> 00:52:14.620
말씀하신 것처럼요

00:52:14.620 --> 00:52:16.100
응용 위에 또 다른 응용을 덧대고

00:52:16.100 --> 00:52:17.580
그러다 보니

00:52:17.580 --> 00:52:20.820
점점 더 좁아졌고, 가장

00:52:20.820 --> 00:52:21.580
성공적인

00:52:21.580 --> 00:52:23.700
대규모 응용 사례 중 하나가

00:52:23.700 --> 00:52:24.520
자율주행이고

00:52:24.520 --> 00:52:27.050
웨이모나 테슬라는 엄청나게

00:52:27.050 --> 00:52:29.580
잘 해냈습니다

00:52:29.580 --> 00:52:31.660
하지만 제가 다시

00:52:31.660 --> 00:52:34.104
과거로 돌아가 보면, 저는

00:52:34.104 --> 00:52:35.020
자율주행을

00:52:35.020 --> 00:52:36.360
세바스찬 스런이

00:52:36.360 --> 00:52:38.140
TED 무대에 섰을 때 알게 됐고, 저는

00:52:38.140 --> 00:52:43.540
아마 2009년이나 2010년쯤이었던 것 같은데, 그가 이야기했던 게

00:52:43.540 --> 00:52:45.400
그들이 우승했던 것에 대해

00:52:45.400 --> 00:52:47.470
DARPA 챌린지였는데 2007년이었고

00:52:47.470 --> 00:52:49.540
그리고 우리는

00:52:49.540 --> 00:52:52.600
2025년에 있는데도 그 시스템은 겨우

00:52:52.600 --> 00:52:53.300
샌프란시스코에서

00:52:53.820 --> 00:52:55.720
여기까지 내려오는 정도는 이제 좀 합니다

00:52:55.720 --> 00:52:58.060
지금은 하긴 하지만 로컬 도로로만 다니고, 고속도로에는

00:52:58.060 --> 00:52:58.880
아예 올라가지도 못합니다

00:52:58.880 --> 00:53:01.540
그렇게 일반화된 일을 한다면

00:53:01.540 --> 00:53:04.480
활주로, 즉 타임라인을 얼마나 길게

00:53:04.480 --> 00:53:05.160
생각하고 계신지

00:53:05.160 --> 00:53:08.148
일반화와

00:53:08.148 --> 00:53:09.980
성능을요? 네, 그래서

00:53:09.980 --> 00:53:11.880
이 문제에는 어떤 측면들이 있어서

00:53:11.880 --> 00:53:12.080
어떤 것은

00:53:12.080 --> 00:53:14.240
자율주행보다 더 쉽게 만들고, 어떤 것은

00:53:14.240 --> 00:53:17.420
더 어렵게 만듭니다. 네, 음, 한 가지

00:53:17.420 --> 00:53:18.540
더 쉽게 만드는 점은

00:53:19.260 --> 00:53:21.740
우리가

00:53:21.740 --> 00:53:22.540
100% 신뢰할 수 있을 때만 배포할 필요는 없다는 점입니다, 세상에는 정말

00:53:22.540 --> 00:53:23.270
많은

00:53:23.270 --> 00:53:24.800
작업이

00:53:24.800 --> 00:53:25.260
있어서

00:53:25.820 --> 00:53:27.500
신뢰도가 95%만 되어도

00:53:27.500 --> 00:53:29.180
여러분은

00:53:29.180 --> 00:53:30.940
충분히 괜찮습니다, 집에 로봇이

00:53:30.940 --> 00:53:31.220
있어서

00:53:31.220 --> 00:53:32.370
빨래를 개다가 100번 중 한 번

00:53:32.370 --> 00:53:33.520
정도는

00:53:33.520 --> 00:53:34.320
완벽하게 개지 못하더라도요

00:53:34.320 --> 00:53:35.080
여러분은

00:53:35.080 --> 00:53:35.420
충분히

00:53:35.420 --> 00:53:37.800
괜찮고, 그냥 자녀를 불러서

00:53:37.800 --> 00:53:41.100
가서 그걸 개라고 하면 되죠. 맞습니다, 맞습니다, 우리는

00:53:41.100 --> 00:53:42.040
여전히, 여전히

00:53:42.040 --> 00:53:44.823
집안일이 필요하죠. 네, 맞습니다, 음, 그리고

00:53:44.823 --> 00:53:45.900
자율주행은

00:53:45.900 --> 00:53:47.380
그렇지 않죠, 예를 들어

00:53:47.380 --> 00:53:48.820
100번 중 한 번

00:53:48.820 --> 00:53:51.022
치명적으로 실패한다면, 그건 큰

00:53:51.022 --> 00:53:51.940
문제입니다. 네, 음

00:53:51.940 --> 00:53:53.460
그래서 이 기술을 배포하는 측면에서는

00:53:53.460 --> 00:53:53.820
이 기술이

00:53:53.820 --> 00:53:57.420
더 쉬울 수도 있습니다. 또 우리는

00:53:57.420 --> 00:53:59.960
지금은 과거와는 다른

00:53:59.960 --> 00:54:01.320
기술 시대이기 때문입니다

00:54:01.320 --> 00:54:03.600
우리는 비전

00:54:03.600 --> 00:54:04.840
언어 모델, 파운데이션 모델의 시대에 있고

00:54:04.840 --> 00:54:06.080
그 모델들은

00:54:06.080 --> 00:54:07.220
어느 정도의

00:54:07.220 --> 00:54:09.500
상식도 갖고 있으며, 우리는 많은 교훈을 배웠습니다

00:54:09.500 --> 00:54:13.480
2009년에서 2025년 사이에요, 그리고

00:54:13.480 --> 00:54:14.480
그 모든 것의

00:54:14.480 --> 00:54:17.860
이점을 누릴 수 있습니다. 음, 그래서 그것도 정말

00:54:17.860 --> 00:54:18.820
정말 큰 도움이 되고, 이것들은 훨씬 더

00:54:18.820 --> 00:54:19.780
일반

00:54:19.780 --> 00:54:20.800
목적의 해결책입니다

00:54:20.800 --> 00:54:23.680
과거에 우리가 갖고 있던 것보다요. 음, 동시에

00:54:23.680 --> 00:54:25.780
매우 어려운 점들도 있습니다

00:54:25.780 --> 00:54:27.080
그렇죠

00:54:27.080 --> 00:54:28.190
단 하나의 응용만 있는 게 아니라

00:54:28.190 --> 00:54:29.300
이것은

00:54:29.300 --> 00:54:30.510
아주 범용적인 해결책으로

00:54:30.510 --> 00:54:31.720
여러 분야에

00:54:31.720 --> 00:54:32.100
적용될 수 있습니다

00:54:32.100 --> 00:54:33.410
운전뿐만 아니라 조작과

00:54:33.410 --> 00:54:34.720
이동에도

00:54:34.720 --> 00:54:36.800
비행과 온갖 다른 것들에도요

00:54:36.800 --> 00:54:37.960
그리고 저는

00:54:37.960 --> 00:54:39.680
이것이 얼마나 더 어려운지는 지켜봐야 한다고 생각합니다

00:54:39.680 --> 00:54:42.740
지금까지의 경험에 비추어 보면

00:54:42.740 --> 00:54:45.580
그렇게까지

00:54:45.580 --> 00:54:47.720
더 어렵지는 않아 보입니다, 솔직히 말하면

00:54:47.720 --> 00:54:51.980
만약 처음부터 이 문제를

00:54:51.980 --> 00:54:53.480
매우 범용적인

00:54:54.220 --> 00:54:56.460
마인드셋으로 접근하면

00:54:56.460 --> 00:54:57.350
꽤 잘 일반화된다는 게

00:54:57.350 --> 00:54:58.240
드러납니다

00:54:58.240 --> 00:54:59.400
그리고

00:54:59.400 --> 00:55:00.480
저희가 완전히 이해하지 못하는 물리적 지능의 어떤 요소가

00:55:00.480 --> 00:55:01.560
있어서

00:55:01.560 --> 00:55:03.040
그것이 이런 모델들이 일반화하도록

00:55:03.040 --> 00:55:05.180
운전과 커피를 내리는 일 사이에서도

00:55:05.180 --> 00:55:07.320
드론을

00:55:07.320 --> 00:55:08.710
날리고 수술 로봇을 조작하는 것까지도

00:55:08.710 --> 00:55:10.100
비록

00:55:10.100 --> 00:55:11.920
서로 너무 동떨어져 보이더라도요

00:55:11.920 --> 00:55:13.280
그리고 이런 것들은 모두

00:55:13.280 --> 00:55:14.160
서로 다른 모델과

00:55:14.160 --> 00:55:15.867
서로 다른 응용이어야 할 것처럼 보이는데, 이 모델들은

00:55:15.867 --> 00:55:16.940
어떻게든 의미를 찾아

00:55:16.940 --> 00:55:19.220
그 모든 데이터를 이해해 내고, 그것이

00:55:19.220 --> 00:55:19.420
저에게

00:55:19.420 --> 00:55:20.640
큰 희망을 줍니다, 어쩌면 이

00:55:20.640 --> 00:55:22.360
문제가 그렇게까지 더 어렵지 않고

00:55:22.360 --> 00:55:23.320
오히려 더 쉬울 수도 있다는요

00:55:24.860 --> 00:55:27.940
음, 그래서 타당한 질문이라고 생각합니다

00:55:27.940 --> 00:55:29.480
하지만 저는

00:55:29.480 --> 00:55:30.560
우리가 본 것을 근거로

00:55:30.560 --> 00:55:31.890
자율주행에서 본 것만으로 결론을 잘못 내리고 싶지는 않습니다

00:55:31.890 --> 00:55:33.220
훌륭합니다

00:55:33.220 --> 00:55:34.850
축하드립니다, 어떤 성과가

00:55:34.850 --> 00:55:36.480
가장

00:55:36.480 --> 00:55:37.750
인상적이었나요, 그리고 성과 외적으로는 무엇이었나요, 정말

00:55:37.750 --> 00:55:39.020
좋은 질문입니다

00:55:39.020 --> 00:55:42.060
네, 좋은 질문입니다, 사실 제가

00:55:42.060 --> 00:55:42.700
먼저 말씀드리겠습니다, 저는

00:55:42.700 --> 00:55:43.660
영상

00:55:43.660 --> 00:55:44.620
모델들이 정말 인상적이었습니다

00:55:44.620 --> 00:55:47.980
아까 말씀하신 것처럼 저는 몇

00:55:47.980 --> 00:55:49.340
년 전에 그것들을 봤고, 저는

00:55:49.340 --> 00:55:51.420
몇 년 전에 그 일부를

00:55:51.420 --> 00:55:54.060
연구하기도 했는데 이런 추세가

00:55:54.060 --> 00:55:55.320
이렇게, 개선이

00:55:55.320 --> 00:55:57.193
이렇게 가파를 줄은 몰랐습니다, 거의

00:55:57.193 --> 00:55:58.460
구별이 안 될 정도로

00:55:58.460 --> 00:55:59.490
지금은 현실과 구별이 안 되고, 또

00:55:59.490 --> 00:56:00.520
정말 놀라운

00:56:00.520 --> 00:56:03.940
일들을 합니다, 그래서 그게 정말 정말

00:56:03.940 --> 00:56:04.840
인상적이었고

00:56:04.840 --> 00:56:07.520
제게는 정말 놀라웠습니다, 네, 저는

00:56:07.520 --> 00:56:08.420
라고 말하자면, 저는 아직도

00:56:08.420 --> 00:56:10.680
우리가 여기까지 왔다는 사실이 어느 정도는 경이롭고

00:56:10.680 --> 00:56:13.440
정말로

00:56:13.440 --> 00:56:15.160
전반적으로

00:56:15.780 --> 00:56:17.290
제가 정말 예상하지 못했던 수준까지 지능적으로 보이는

00:56:17.290 --> 00:56:18.800
모델들을

00:56:18.800 --> 00:56:21.360
그저, 그러니까, 그냥

00:56:21.360 --> 00:56:22.260
다음 토큰 예측에서

00:56:22.260 --> 00:56:24.300
이렇게 나올 줄은 여전히 놀랍고,

00:56:24.300 --> 00:56:26.500
제가 보는 모든 작은 진전마다, 이를테면

00:56:26.500 --> 00:56:27.480
IMO에서 이기거나

00:56:28.040 --> 00:56:29.970
수학 챌린지에서 이긴다든지, 또는, 적용해서

00:56:29.970 --> 00:56:31.900
그것을

00:56:31.900 --> 00:56:35.240
과학에서 새로운 것들을 찾아내는 데까지 쓰는 것 등에서요.

00:56:35.240 --> 00:56:36.260
네, 올해도

00:56:36.260 --> 00:56:37.920
제가 보면서 '와' 했던 것들이 정말

00:56:37.920 --> 00:56:40.120
너무 많았고, 아직도 아직도

00:56:40.120 --> 00:56:41.180
더 발전할 여지가 크다고 느꼈습니다.

00:56:41.180 --> 00:56:42.700
연초에는 어쩌면

00:56:42.700 --> 00:56:44.660
이런 사전학습이라는

00:56:44.660 --> 00:56:45.660
LLM 비즈니스가

00:56:45.660 --> 00:56:47.820
조금은, 음, 시들해지는 것 같다고

00:56:47.820 --> 00:56:49.030
느꼈는데, 그런데 이제 보니

00:56:49.030 --> 00:56:50.240
이

00:56:50.240 --> 00:56:51.480
거의 두 번째

00:56:51.480 --> 00:56:52.910
숨결 같은, 그러니까 신선한 공기가

00:56:52.910 --> 00:56:54.340
들어오는

00:56:54.340 --> 00:56:55.940
것 같습니다. 네, 여기에 덧붙이자면

00:56:55.940 --> 00:56:56.760
그냥, 바로

00:56:56.760 --> 00:56:58.660
이 모든 게 실제로 작동한다는 사실 자체가

00:56:58.660 --> 00:57:01.780
정말 충격적입니다. 우리는

00:57:01.780 --> 00:57:02.860
이게 얼마나

00:57:02.860 --> 00:57:04.200
말도 안 되는 일인지 제대로 실감하지 못하는 것 같습니다, 그러니까 여러분은

00:57:04.200 --> 00:57:05.540
여러분은

00:57:05.540 --> 00:57:07.810
뇌에서 느슨하게 영감을 받은 이런 것을 만들고

00:57:07.810 --> 00:57:10.080
그 안에

00:57:10.080 --> 00:57:10.680
아주 범용적인

00:57:10.680 --> 00:57:12.120
학습 알고리즘이 있는데, 거기에

00:57:12.120 --> 00:57:13.560
데이터를 넣어주면

00:57:13.560 --> 00:57:15.560
어떤 식으로든 이해해 버리고, 그것을

00:57:15.560 --> 00:57:15.960
훨씬 더

00:57:15.960 --> 00:57:17.160
우리가 이전에 가졌던 어떤 것보다도 잘 해냅니다, 그리고 이건

00:57:17.160 --> 00:57:18.360
로봇에도

00:57:18.360 --> 00:57:20.300
적용되고, 시각에도 적용되고

00:57:20.300 --> 00:57:21.160
언어에도,

00:57:21.160 --> 00:57:24.040
소리에도, 그리고 온갖 다른 것들에도 적용됩니다, 그리고

00:57:24.040 --> 00:57:26.260
제가 생각하기에 잠깐

00:57:26.260 --> 00:57:27.760
멈춰서 그냥 생각해 보면

00:57:27.760 --> 00:57:30.500
그게 어떻게 작동하는지, 그리고 그것이

00:57:30.500 --> 00:57:32.231
실제로 작동한다는 게 정말 완전히

00:57:32.231 --> 00:57:33.180
믿기지 않을 정도로 놀랍습니다, 예를 들면

00:57:33.180 --> 00:57:33.920
우리가

00:57:33.920 --> 00:57:35.320
로봇을 만들어 집에 들여놓을 수 있고,

00:57:35.320 --> 00:57:37.060
그 로봇이 어느 정도는

00:57:37.060 --> 00:57:38.920
한 번도 가본 적 없는 집에서도

00:57:38.920 --> 00:57:39.060
그곳에서

00:57:39.060 --> 00:57:41.800
무엇을 해야 하는지 알거나, 13시간 내내

00:57:41.800 --> 00:57:42.800
계속 커피를 내릴 수도 있다든지, 그런 것들

00:57:42.800 --> 00:57:43.800
같은

00:57:43.800 --> 00:57:45.020
일이 가능합니다. 그리고 이건

00:57:45.020 --> 00:57:48.755
이런 아주 범용적인 어떤 것으로부터 나오는데, 그게

00:57:48.755 --> 00:57:50.000
완전히

00:57:50.000 --> 00:57:51.840
엔드투엔드로 학습되고, 우리가 완전히 이해하지는 못하지만

00:57:51.840 --> 00:57:52.640
그래도

00:57:52.640 --> 00:57:55.100
뭔가를 이해하기 시작하는 것처럼 보입니다, 그게

00:57:55.100 --> 00:57:57.820
제게는 정말 믿기지 않을 정도로 놀랍습니다. 우리는

00:57:57.820 --> 00:57:58.280
시뮬레이션 속에 살고 있습니다.

00:58:00.540 --> 00:58:01.900
그게, 소냐는 우리가

00:58:01.900 --> 00:58:03.260
지금

00:58:03.260 --> 00:58:04.290
시뮬레이션 속에 살고 있다고 믿습니다만, 그래도

00:58:04.290 --> 00:58:05.320
흥미롭습니다.

00:58:05.320 --> 00:58:05.680
그러니까

00:58:05.680 --> 00:58:07.160
과학에서는 큰

00:58:07.160 --> 00:58:08.920
문제를 더 작게, 그리고

00:58:08.920 --> 00:58:09.820
더 작은 문제들로 쪼개라고 가르치고,

00:58:09.820 --> 00:58:11.677
그러다가 결국 누군가가

00:58:11.677 --> 00:58:12.480
그게 어쩌면

00:58:12.480 --> 00:58:16.480
어떤 기계나 로봇을 훈련시키는 최선의 방법은 아니라고

00:58:16.480 --> 00:58:17.020
깨닫게 됩니다,

00:58:17.020 --> 00:58:18.820
어떤 종류든 말입니다. 그리고 솔직히 말해 머신

00:58:18.820 --> 00:58:19.910
러닝, 그러니까 AI 분야도 똑같은

00:58:19.910 --> 00:58:21.000
실수를

00:58:21.000 --> 00:58:21.520
사실

00:58:21.520 --> 00:58:23.520
어느 정도는 저질렀습니다. 우리는 오랫동안

00:58:23.520 --> 00:58:24.650
사람들이 개별 문제들을 푸는 데

00:58:24.650 --> 00:58:25.780
각각의

00:58:25.780 --> 00:58:26.480
문제에

00:58:26.480 --> 00:58:27.800
매우 깊게, 말 그대로 파고들어 왔고, 그러다가

00:58:27.800 --> 00:58:29.120
시간이 지나면서

00:58:29.120 --> 00:58:32.140
'아, 만약'이라는 생각이 생깁니다,

00:58:32.140 --> 00:58:32.780
이걸 전부

00:58:32.780 --> 00:58:33.660
합쳐서 멀티태스크 학습을 할 수 있다면,

00:58:33.660 --> 00:58:34.540
우리가

00:58:34.540 --> 00:58:36.260
그걸 정말 정말 잘할 수 있다면 훨씬

00:58:36.260 --> 00:58:36.680
더 나아질 텐데 말입니다.

00:58:37.180 --> 00:58:39.020
그런데 또 한편으로는, 우리가

00:58:39.020 --> 00:58:40.300
그저 이것으로 전환했을 뿐인데 모든 게 벌어졌다는 사실이

00:58:40.300 --> 00:58:41.580
바로

00:58:41.580 --> 00:58:43.260
그, 여러분도 아시다시피, 일반적인

00:58:43.260 --> 00:58:44.100
사전학습 목표로 바꾸자마자 그냥

00:58:44.100 --> 00:58:44.940
전부

00:58:44.940 --> 00:58:46.840
저절로 따라 나온다는 것, 그 부분이

00:58:46.840 --> 00:58:47.640
정말 놀라운 지점입니다.

00:58:47.640 --> 00:58:49.720
아코디언처럼 프레임워크를 오가는 것이라고 보십니까,

00:58:49.720 --> 00:58:51.300
한 프레임워크에서 다른 프레임워크로 갔다가, 우리가

00:58:51.300 --> 00:58:52.200
큰 문제를

00:58:52.200 --> 00:58:53.920
작은 문제로 쪼개고,

00:58:53.920 --> 00:58:55.580
더 작고 더 작은 것들로 나눠서 한동안은 잘 되다가

00:58:55.580 --> 00:58:56.400
어느 기간 동안은

00:58:56.400 --> 00:58:57.270
그러다 더는 안 되면, 그다음에는 우리가

00:58:57.270 --> 00:58:58.140
이렇게

00:58:58.140 --> 00:58:59.220
'좋습니다, 다시 큰

00:58:59.220 --> 00:59:00.400
문제로 돌아가서 좀 더

00:59:00.400 --> 00:59:02.680
일반적으로 풀어보자' 하면서 왔다 갔다 하는 식으로요. 저는

00:59:02.680 --> 00:59:04.880
우리가 다시 돌아갈 것 같지는 않습니다. 네, 저는

00:59:04.880 --> 00:59:05.900
우리가 다시 돌아갈 것 같지 않습니다. 저는

00:59:05.900 --> 00:59:08.400
접근법도 많고, 또 많은

00:59:08.400 --> 00:59:09.720
사람들이 말하기를, 여러분도

00:59:09.720 --> 00:59:11.020
양쪽의 장점을 모두 가져야 한다고 하고,

00:59:11.020 --> 00:59:12.660
이미 알고 있는 규칙들을 통합하는 어떤 방법이

00:59:12.660 --> 00:59:14.660
필요하다고 말합니다, 예를 들면

00:59:14.660 --> 00:59:15.080
그러니까

00:59:15.080 --> 00:59:16.150
뉴턴 역학 같은 것은 굳이 다시 배울 필요가

00:59:16.150 --> 00:59:17.220
없고

00:59:17.220 --> 00:59:18.980
우리는 이미 어떻게 작동하는지 아니니까,

00:59:18.980 --> 00:59:19.920
그걸 그냥

00:59:19.920 --> 00:59:23.100
어떤 식으로든 가중치에 넣을 수 있지 않느냐는 건데, 그런데

00:59:23.100 --> 00:59:25.300
지금까지 우리가 본 바로는 그건 잘 되지 않습니다.

00:59:25.300 --> 00:59:26.680
이걸 하려고 하면, 오히려

00:59:26.680 --> 00:59:28.380
새로운 것들을 배우는 능력을

00:59:28.380 --> 00:59:31.680
제한하게 되기 쉽고, 저는

00:59:31.680 --> 00:59:32.520
'양쪽의 장점'이라는 게 존재한다고 생각하지 않습니다.

00:59:32.520 --> 00:59:33.920
저는 그냥 끝까지

00:59:33.920 --> 00:59:35.180
학습으로 가야 한다고 생각하고, 그리고 흥미로운 점은

00:59:35.180 --> 00:59:36.440
여러분도

00:59:36.440 --> 00:59:37.860
아시겠지만, 우리가 배우는 방식과

00:59:37.860 --> 00:59:40.480
매우 비슷하다는 것입니다. 만약

00:59:40.480 --> 00:59:41.880
모든 지능을 미리 구워 넣는

00:59:41.880 --> 00:59:43.220
방법이 있었다면, 진화가

00:59:43.220 --> 00:59:44.660
이미 그걸 찾아냈을 겁니다, 그러면 여러분은

00:59:44.660 --> 00:59:45.750
그냥 태어날 때부터, 아시다시피, 모든 것을

00:59:45.750 --> 00:59:46.840
다

00:59:46.840 --> 00:59:47.100
알고 태어났을 텐데,

00:59:47.100 --> 00:59:49.220
알아야 할 것 전부를요. 그런데 우리는 어떤 다른

00:59:49.220 --> 00:59:52.180
종들에서도 이런 걸 봅니다, 예를 들어 사슴은

00:59:52.180 --> 00:59:53.120
태어나면

00:59:53.120 --> 00:59:53.920
거의 그때가 그들이 될 수 있는 만큼 똑똑해서

00:59:53.920 --> 00:59:54.560
그 상태로

00:59:54.560 --> 00:59:56.760
평생 동안 크게 배우지 않습니다.

00:59:56.760 --> 00:59:57.040
평생에 걸쳐

00:59:57.040 --> 00:59:58.850
그런데 인간처럼 지능이 높은 종은

00:59:58.850 --> 01:00:00.660
그러니까, 그러니까

01:00:00.660 --> 01:00:01.740
인간도 그렇지만, 제 생각에는 군중도

01:00:01.740 --> 01:00:02.820
예를 들면

01:00:03.420 --> 01:00:05.344
그들에게는 유년기가 있습니다

01:00:05.344 --> 01:00:06.280
그리고 사춘기 시기도 있습니다

01:00:06.280 --> 01:00:09.580
처음부터 아주 똑똑한 것은 아니지만

01:00:09.580 --> 01:00:11.220
자기 자신의 경험으로부터

01:00:11.220 --> 01:00:12.540
배워야 하고, 미리 완성된 채로 주어지지 않습니다

01:00:12.540 --> 01:00:13.860
그러니까

01:00:13.860 --> 01:00:14.400
어느 정도는

01:00:14.400 --> 01:00:17.960
스스로 쟁취해야 하고, 음,

01:00:17.960 --> 01:00:19.310
거기에는 뭔가 의미가 있다고 생각합니다

01:00:19.310 --> 01:00:20.660
음

01:00:20.660 --> 01:00:22.140
그냥 경험을 해야 합니다

01:00:22.140 --> 01:00:24.520
세상을 경험하고 거기서 배워야 합니다

01:00:24.520 --> 01:00:25.390
그게 우리가 배우고 있는 교훈이라고 생각합니다

01:00:25.390 --> 01:00:26.260
그리고

01:00:26.260 --> 01:00:26.960
머신러닝에서도

01:00:26.960 --> 01:00:30.120
즉 AI에서도 마찬가지로요, 그러니까

01:00:30.120 --> 01:00:32.100
우리는 우리가 어떻게 생각하는지 안다고 생각하지만

01:00:32.100 --> 01:00:33.180
사실은 모릅니다

01:00:33.760 --> 01:00:36.440
그래서 알고리즘이

01:00:36.440 --> 01:00:38.620
데이터에서 그것을 배우게 해야 합니다, 아이를 키우는 것도 마찬가지입니다

01:00:38.620 --> 01:00:39.980
그렇게 생각합니다

01:00:39.980 --> 01:00:41.700
저는 제 아들이 어떻게 생각하는지 안다고 생각하지만

01:00:41.700 --> 01:00:44.500
사실은 그렇지 않습니다, 예, 예, 저도

01:00:44.500 --> 01:00:46.920
어린 딸이 있습니다, 그리고

01:00:46.920 --> 01:00:49.680
정말 놀라운 것은 아이들이 너무 빨리 배운다는 점입니다

01:00:49.680 --> 01:00:51.020
너무 빨리 배우는데, 어디서 그것을

01:00:51.020 --> 01:00:51.760
배웠는지 모르겠습니다

01:00:52.760 --> 01:00:55.517
부모에게서 배웠으면 좋겠습니다, 그녀는

01:00:55.517 --> 01:00:56.620
확실히

01:00:56.620 --> 01:00:57.820
제가 가르치지 않은 몇 가지도 알고 있습니다

01:00:58.980 --> 01:01:00.900
두 분 정말 감사합니다, 정말

01:01:00.900 --> 01:01:01.980
아름다운 미션을 만들고 계십니다, 그리고요

01:01:01.980 --> 01:01:03.060
와주셔서

01:01:03.060 --> 01:01:03.320
감사합니다

01:01:03.320 --> 01:01:05.380
공유해 주셔서 감사합니다, 초대해 주셔서 감사합니다

01:01:05.380 --> 01:01:05.820
감사합니다

01:01:05.820 --> 01:01:35.800
초대해 주셔서 감사합니다

01:01:35.800 --> 01:01:36.020
감사합니다

01:01:36.020 --> 01:01:36.100
당신
