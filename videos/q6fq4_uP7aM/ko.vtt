WEBVTT

00:00:00.320 --> 00:00:05.440
안녕하세요, The Tech Download에 오신 것을 환영합니다. CNBC Original의 새로운 팟캐스트로, 저희는

00:00:05.440 --> 00:00:08.000
가장 중요한 기술 이야기를 풀어드립니다.

00:00:08.000 --> 00:00:11.040
매 시즌마다 하나의 큰 주제에 깊이 들어가, 그것이

00:00:11.040 --> 00:00:15.680
여러분의 돈에 어떤 의미가 있는지, 업계에서 가장 영향력 있는 목소리들의 통찰과 함께 살펴봅니다.

00:00:15.680 --> 00:00:19.680
저는 늘, 결국 이것이 우리가

00:00:19.680 --> 00:00:24.640
앞으로 발명할 것 중 가장 중요한 기술이 될 것이라고 생각해 왔습니다. 그리고 이는 사실 컴퓨터 시대의 자연스러운 진화이기도 합니다.

00:00:24.640 --> 00:00:30.480
이번 시즌에는 거대 기술 기업의 AI 추진을 이끄는 핵심 동력인 구글 딥마인드(Google DeepMind)를 살펴봅니다.

00:00:30.480 --> 00:00:34.240
저희는 이 회사의 핵심 인물들에게 드물게 접근할 기회를 얻었는데, 여기에는

00:00:34.240 --> 00:00:39.920
이번 에피소드의 게스트인 딥마인드 공동 창업자이자 CEO인 데미스 하사비스도 포함됩니다.

00:00:39.920 --> 00:00:42.320
저는 이것이 산업혁명과 비슷할 것이라고 생각합니다.

00:00:42.320 --> 00:00:46.400
하지만 아마 10배 더 크고 10배 더 빠를 것입니다. 그래서

00:00:46.400 --> 00:00:52.240
엄청난 변화가 일어나는 동시에 큰 혼란도 뒤따를 것입니다.

00:00:54.480 --> 00:00:59.920
여러분 안녕하세요, The Tech Download에 오신 것을 환영합니다. 다시 인사드리겠습니다. 저는 아르준 카르팔입니다.

00:00:59.920 --> 00:01:04.080
런던에 기반을 둔 CNBC 선임 기술 특파원이며,

00:01:04.080 --> 00:01:09.280
저와 함께할 아주 특별한 새로운 공동 진행자가 있습니다.

00:01:09.280 --> 00:01:14.480
저는 여기 뉴욕에서 기술 분야를 취재합니다. 주로 애플과 마이크로소프트를 다루지만, 그런데 말입니다,

00:01:14.480 --> 00:01:19.680
저는 15년 넘게 기술 업계를 취재해 왔고,

00:01:19.680 --> 00:01:24.080
전반적인 흐름을 꽤 잘 알고 있다고 생각합니다. 아르준, 이렇게 함께하게 되어 정말 기대됩니다. 저는 그동안

00:01:24.080 --> 00:01:28.560
바다 건너에서 오랫동안 아르준님의 일을 존경해 왔는데, 이제 실제로 함께 협업해 이 일을

00:01:28.560 --> 00:01:32.720
함께하게 되었습니다. 즐거운 시간이 될 것 같습니다.

00:01:32.720 --> 00:01:37.040
저희는 기술을 취재해 온 경험이 거의 30년에 달한다고 생각하는데, 놀라운 점은

00:01:37.040 --> 00:01:41.440
아직도 배울 게 정말 많다는 점입니다. 그리고 이 팟캐스트를 진행하는 동안

00:01:41.440 --> 00:01:47.040
정말 많은 것을 배우고, 매우 흥미로운 사람들을 많이 만나게 될 것이라고 생각합니다. 이번 첫 시즌을

00:01:47.040 --> 00:01:52.880
세계 최고의 AI 연구소 중 하나인 구글 딥마인드(Google DeepMind)를 들여다보는 것으로 시작하게 되어 더욱 기대됩니다.

00:01:53.600 --> 00:01:59.120
청취자와 시청자 여러분을 위해, 구글 딥마인드(Google DeepMind)를 간단히 소개해 드리겠습니다. 딥마인드는

00:01:59.120 --> 00:02:04.240
제가 있는 이 런던에서 2010년에 설립된 회사였습니다. 세 사람이 세운 아주 작은 회사였고,

00:02:04.240 --> 00:02:09.920
창립자는 데미스 하사비스, 셰인 레그, 그리고 지금은 마이크로소프트에 있는 무스타파 술레이만이었습니다. 맞죠? 네.

00:02:09.920 --> 00:02:16.720
사실 저도 거의 1년 전에 무스타파 술레이만을 인터뷰했는데, 그는 기본적으로

00:02:16.720 --> 00:02:21.360
구글에서 데미스가 하는 것과 비슷한 일을 하고 있습니다. 그리고 구글이 어떻게

00:02:21.360 --> 00:02:26.960
말하자면 전 세계 최고 AI 인재들의 인큐베이터 같은 역할을 해 왔는지 보는 것도 흥미롭습니다. 데미스는 당연히

00:02:26.960 --> 00:02:31.760
계속 남아 있었습니다. 그는 그곳에서 딥마인드(DeepMind)를 이끌고 있습니다. 그런데 제가 또 정말 흥미롭다고 생각하는 점은,

00:02:31.760 --> 00:02:37.600
바로 지금의 AI 모멘텀 말입니다, 아르준. 우리는 지난 3년간 이를 겪어 왔고, 또 3년 전

00:02:37.600 --> 00:02:42.480
챗GPT가 등장하면서 구글이 위협받는 것으로 여겨졌습니다. 구글은

00:02:42.480 --> 00:02:47.600
이른바 '코드 레드'를 겪었습니다. 내부적으로 대대적인 조직 개편을 거쳐야 했습니다. 결국,

00:02:47.600 --> 00:02:54.320
데미스가 AI 리더로 부상했습니다. 그리고 아시겠습니까? 2025년은 정말 흥미로운 해였습니다.

00:02:54.320 --> 00:03:00.560
구글의 AI에 있어서요. 구글은 어느 정도 따라잡았고, 어떤 면에서는 챗GPT가

00:03:00.560 --> 00:03:05.840
이미 하던 것을 오히려 넘어섰습니다. 이게 정말 흥미로운 이유는, 이 모든 것의 근본 기술이

00:03:05.840 --> 00:03:10.720
우리가 수년간 이야기해 온 대규모 언어 모델 같은 기술이 구글에서 시작됐기 때문입니다.

00:03:10.720 --> 00:03:16.800
그런데도 구글이 그 기술을 챗GPT가 가져가 주도하도록 내버려 두었다는 인식이 있었습니다. 하지만

00:03:16.800 --> 00:03:22.400
지금은 적어도 제 생각에는 제미니(Gemini)가 챗GPT와 거의 대등하거나, 오히려 더 낫습니다.

00:03:22.400 --> 00:03:27.840
그리고 구글 딥마인드(DeepMind)가 여기에 핵심적인 역할을 합니다. 앞서 2010년에 설립됐다고 말씀드렸습니다. 구글은

00:03:27.840 --> 00:03:33.360
실제로 2014년에 딥마인드(DeepMind)를 인수했습니다. 당시 저는 기술 기자로서 경력이 막 시작된 때였습니다.

00:03:33.360 --> 00:03:38.880
저도 마찬가지였습니다. 구글은 당시 2014년에 딥마인드에 약 4억 파운드를 지불했습니다.

00:03:38.880 --> 00:03:45.040
약 5억4천만 달러였습니다. 오늘날에는 그 지분이 수백억 달러 규모일 수도 있고,

00:03:45.040 --> 00:03:50.400
일부 추정에 따르면 수천억 달러에 이를 수도 있습니다. 그리고 딥마인드는 정말로

00:03:50.400 --> 00:03:57.120
구글 AI의 상당 부분을 책임지고 있습니다. 제미니라는 챗봇, 그 AI는

00:03:57.120 --> 00:04:01.920
구글이 소비자에게 공개한 것이죠. 이것은 딥마인드에서 나오는 기술에 의해 크게 구동됩니다

00:04:01.920 --> 00:04:06.480
딥마인드에서 나온 기술이요. 하지만 그 이전에도 딥마인드는 몇 가지 큰 돌파구를 만들어냈습니다,

00:04:06.480 --> 00:04:12.160
몇 년 전 알파고(AlphaGo)라는 시스템을 공개했을 때 큰 순간이 있었습니다. 이는

00:04:12.160 --> 00:04:17.760
바둑이라는 게임에서 세계 챔피언을 이긴 최초의 컴퓨터 프로그램이었습니다. 바둑은 매우

00:04:17.760 --> 00:04:24.240
복잡한 게임이고, 당시에는 AI의 거대한 도전 과제 중 하나로 여겨졌습니다, 왜냐하면 그것이 너무

00:04:24.240 --> 00:04:28.640
가능한 조합이 너무나 많기 때문입니다. 또 다른 큰 돌파구는, 물론,

00:04:28.640 --> 00:04:33.520
알파폴드(AlphaFold)라는 것이었습니다. 이는 딥마인드에서 개발한 또 다른 AI 시스템으로

00:04:33.520 --> 00:04:39.120
단백질 구조의 3D 모델을 정확하게 예측할 수 있었습니다. 그리고 핵심 아이디어는, 만약

00:04:39.120 --> 00:04:44.320
그렇게 할 수 있다면 의학적 돌파구로 이어질 수 있다는 것입니다. 그래서 이런 과학의 진전이

00:04:44.320 --> 00:04:50.480
딥마인드가 해온 일의 핵심이었습니다. 그리고 분명 이는

00:04:50.480 --> 00:04:56.320
10여 년 전 구글의 큰 베팅이었습니다. 이것이 오늘날 구글을 AI 분야의 세계적 선도 기업으로 만드는 데 도움이 됐기 때문입니다.

00:04:56.320 --> 00:05:00.560
네, 지금 말씀하신 대로 정확합니다. 오랫동안 지켜보며 DeepMind에서 가장 인상적이었던 것은

00:05:00.560 --> 00:05:05.040
그들이 얼마나 과학에 뿌리를 두고 있었는지였습니다. 꼭 소비자 제품을 만들려 했던 것은 아니었고

00:05:05.040 --> 00:05:10.000
지금처럼 소비자 제품을 만들려 했던 것도 아니었습니다. 그들은 정말로 과학의 근본적인

00:05:10.000 --> 00:05:16.880
문제들을 해결하고, AI 기반 신약 개발 시대와 그 밖의 거대한

00:05:16.880 --> 00:05:20.880
복잡한 문제들, 예를 들어 기후변화 같은 것들을 열어가려 했습니다. 데미스가 그 얘기를 많이 하는 것으로 아는데, 오늘도

00:05:20.880 --> 00:05:26.160
대화에서 그 부분을 함께 다루실 겁니다.

00:05:26.160 --> 00:05:33.440
그런 점이 DeepMind의 기반을 마련했습니다. 그럼 CEO인 데미스 하사비스와의 대화를 시작해 보겠습니다.

00:05:33.440 --> 00:05:36.560
데미스, 테크 다운로드에 함께해 주셔서 감사합니다. 정말 감사드립니다.

00:05:36.560 --> 00:05:37.680
초대해 주셔서 감사합니다.

00:05:37.680 --> 00:05:41.440
데미스, 오늘 시간 동안 많은 이야기를 다뤄보겠습니다. 하지만 먼저

00:05:41.440 --> 00:05:46.400
기술 자체부터 시작하고 싶습니다. 저희는 AI와 그 역량에 대해 이야기해 왔고

00:05:46.400 --> 00:05:51.520
그것이 어떻게 지속적으로 개선되고 있는지도 논의해 왔습니다. 이제 기술 업계에서는

00:05:51.520 --> 00:05:56.160
이런 모델과 시스템이 어디까지 좋아질 수 있는지에 대한 대화가 많고, 또

00:05:56.160 --> 00:06:02.800
이른바 스케일링 법칙이라는 개념을 두고 논쟁도 많습니다. 청취자분들을 위해 설명하자면,

00:06:02.800 --> 00:06:08.320
더 많은 연산 자원, 더 많은 데이터, 더 큰 모델이 결국 더 큰 시스템으로 이어진다는 생각입니다. 당신은

00:06:08.320 --> 00:06:14.800
스케일링 법칙을 최대한까지 밀어붙여야 한다고 말씀하셨죠. 그런데 지금은 이런

00:06:14.800 --> 00:06:18.800
스케일링이 발전하는 데 어떤 벽에 부딪히고 있는지, 이러한 모델들이 더

00:06:18.800 --> 00:06:23.920
좋아질 수 있는 능력 측면에서 한계에 도달했는지에 대한 질문이 있습니다. DeepMind에서 개발을 진행해 오신 입장에서 무엇을 보고 계신가요?

00:06:23.920 --> 00:06:31.440
우선 스케일링 법칙은 아주 잘 작동하고 있다고 봅니다. 그래서 저희는 분명히

00:06:31.440 --> 00:06:36.880
더 많은 연산과 데이터, 더 큰 모델을 투입할수록 역량이 늘어나는 것을 보고 있고

00:06:36.880 --> 00:06:43.520
그 추세는 계속되고 있습니다만, 몇 년 전만큼 빠르지는 않을 수 있습니다. 그래서

00:06:43.520 --> 00:06:49.520
수확 체감에 대한 이야기도 나오죠. 하지만 아예 성과가 없는 것과

00:06:49.520 --> 00:06:53.680
기하급수적인 성장은 큰 차이가 있고, 저는 그 중간 어딘가에서 여전히 매우 좋은 성과가 나오고 있다고 생각합니다. 그리고

00:06:53.680 --> 00:06:59.200
그럴 가치가 있습니다. 게다가 AGI, 즉

00:06:59.200 --> 00:07:05.040
범용 인공지능까지 가려면, 아직 한두 가지 큰 혁신이

00:07:05.040 --> 00:07:11.040
기존 아이디어를 스케일업하는 것 외에도 필요하고, 어쩌면 아직 부족할 수도 있습니다.

00:07:11.040 --> 00:07:15.200
AGI 이야기는 곧 더 하겠습니다. 하지만 당신의 관점에서 무엇이 부족하다고 보시나요?

00:07:15.200 --> 00:07:18.640
예를 들어, 우리 모두 여러 챗봇을 직접 이것저것 써 보셨을 텐데요.

00:07:18.640 --> 00:07:25.200
그러면 어떤 면에서는 매우 인상적인 일을 해낸다는 것을 알 수 있습니다.

00:07:25.200 --> 00:07:28.560
하지만 저는 그것들을 일종의 '들쭉날쭉한 지능'이라고 부르는데, 즉

00:07:28.560 --> 00:07:32.480
어떤 것들은 매우 잘합니다. 하지만 다른 어떤 것들은 그들이 하지 못하고, 그들은

00:07:32.480 --> 00:07:38.720
전혀 할 수가 없습니다. 그리고 질문을 특정한 방식으로 던지면, 결함이 있다는 것을 알게 됩니다.

00:07:39.280 --> 00:07:44.400
그리고 비교적 간단한 일들도 하지 못합니다. 그래서 진정한 범용 지능이라면,

00:07:44.400 --> 00:07:48.960
그런 불일치가 보이면 안 되고, 전반적으로 일관돼야 합니다. 또 이런 것들은

00:07:48.960 --> 00:07:52.880
지속적으로 학습하지 못하고, 온라인에서 새로운 것을 배우지도 못합니다. 그리고

00:07:52.880 --> 00:07:57.920
진정으로 독창적인 것들을 만들어내지도 못합니다. 그래서 보고 싶은 능력들이 꽤 많고,

00:07:57.920 --> 00:08:01.200
범용 지능을 위해 필요하지만 오늘날의 시스템에는 빠져 있는 것들이 있습니다.

00:08:01.200 --> 00:08:05.520
정말 흥미롭습니다. 그렇다면 그런 지능형 시스템에 도달하기 위한 핵심 열쇠는 무엇일까요?

00:08:05.520 --> 00:08:09.280
제가 허깅페이스 공동 창업자 토마스 울프와 나눴던 대화를 잠깐 말씀드리고 싶습니다.

00:08:09.280 --> 00:08:13.840
네, 몇 달 전 그가 저와 이야기를 나누면서

00:08:13.840 --> 00:08:17.440
LLM, 특히 대규모 언어 모델에 대한 자신의 견해를 들려주며 이렇게 말했습니다.

00:08:17.440 --> 00:08:20.640
그는 그것들이 정말 훌륭하고, 이런 챗봇을 쓰면 챗봇이 이렇게 말한다고 했습니다.

00:08:20.640 --> 00:08:25.920
"좋은 질문입니다, 좋은 아이디어입니다. 그리고 필요한 정보는 여기 모두 있습니다."라고요. 하지만 부족한 것은

00:08:25.920 --> 00:08:31.200
아마도 이런 시스템들이 새롭고 참신한 아이디어를 스스로 떠올리는 능력이라는 점입니다.

00:08:31.200 --> 00:08:36.240
그리고 특히 당신께서 과학과 AI가 무엇을 할 수 있는지에 큰 관심이 있으시다는 것도 알고 있는데요,

00:08:36.240 --> 00:08:41.280
예를 들어 AI가 새로운 약물을 개발하거나 새로운 질병을 발견하는 등에서 돌파구를 여는 일 말입니다. 그런데 실제로 LLM의 한계가

00:08:41.280 --> 00:08:45.760
바로 그런 노벨상급의 참신한 아이디어를 만들어내지 못한다는 데 있는지도 모릅니다.

00:08:45.760 --> 00:08:46.480
네.

00:08:46.480 --> 00:08:49.120
그래서 어쩌면 어떤 새로운 아키텍처가 필요할지도 모르겠습니다.

00:08:49.120 --> 00:08:51.120
그에 대해 현재 어떻게 생각하십니까?

00:08:51.120 --> 00:08:56.240
제 열정이자 제가 AI에 커리어 전체를 바친 이유는, 제가 보기에 AI가

00:08:56.240 --> 00:09:00.240
결국 과학을 위한 궁극적인 도구가 될 것이라고 생각하기 때문입니다. 그리고 물론 우리는

00:09:00.240 --> 00:09:04.640
알파폴드와 지난 10년간 해온 다양한 과학 연구로 그 점을 보여주었습니다. 하지만 아직도

00:09:04.640 --> 00:09:10.960
AI가 실제로 스스로 새로운 가설을 세울 수 있느냐는 측면에서는 아직 갈 길이 멉니다. 단지

00:09:10.960 --> 00:09:15.920
이미 존재하는 추측을 해결하는 것만으로도 유용하고 인상적이겠지만,

00:09:15.920 --> 00:09:21.680
실제로 새로운 추측, 즉 세상이 어떻게 작동하는지에 대한 새로운 아이디어를 스스로 떠올릴 수 있느냐는 것입니다. 그리고

00:09:21.680 --> 00:09:26.320
지금까지 이런 시스템들은 그것을 하지 못합니다. 그런 능력이 충분하지 않습니다. 그래서

00:09:26.320 --> 00:09:31.680
무언가가 빠져 있는 것 같습니다. 제 생각에는 장기적인

00:09:31.680 --> 00:09:38.240
계획 수립, 더 나은 추론, 그리고 아마도 '세계 모델'이라는 개념 같은 역량이 필요합니다. 즉,

00:09:38.240 --> 00:09:43.840
시스템이 세상의 물리 법칙을 더 잘 이해해, 머릿속에서 시뮬레이션을 돌릴 수 있도록 하는 것입니다.

00:09:44.800 --> 00:09:51.200
자기 가설을 시험하기 위해서입니다.

00:09:51.200 --> 00:09:56.880
이런 일은 최고의 과학자들, 즉 인간 과학자들이 하는 일입니다. 그런데 지금까지 우리의 AI 시스템은 그런 일을 하지 못합니다.

00:09:56.880 --> 00:10:00.160
이 '세계 모델'이라는 개념을 조금 더 이해할 수 있도록 설명해 주실 수 있을까요?

00:10:00.160 --> 00:10:05.040
많은 분들이 처음 듣는 용어일 텐데, 이것이 LLM과 어떻게 다른지 설명해 주시겠습니까?

00:10:05.040 --> 00:10:10.240
LLM과 현재 우리가 사용하는 모델들은 대체로 텍스트 중심입니다.

00:10:10.240 --> 00:10:16.720
물론 우리 기반 모델인 Gemini 같은 것은 이미지, 비디오, 오디오 등도 처리할 수 있어 다양한 모달리티를 다룹니다.

00:10:16.720 --> 00:10:22.720
하지만 여전히 세계의 물리와 인과관계를 실제로 이해하는 문제는 남아 있습니다.

00:10:22.720 --> 00:10:28.240
예를 들어 한 가지가 다른 것에 어떻게 영향을 미치는지, 먼 미래까지 계획할 수 있는지 같은 것들입니다.

00:10:28.240 --> 00:10:32.800
이것들은 모두 연관된 개념이며, 세계가 어떻게 작동하는지 정말로 이해하려면

00:10:32.800 --> 00:10:37.600
세상에 새로운 것을 발명하거나, 이전에는 알려지지 않았던 세계의 어떤 것을 설명할 수 있어야 합니다.

00:10:37.600 --> 00:10:42.880
그것이 기본적으로 과학 이론이 하는 일인데, 그러려면

00:10:42.880 --> 00:10:48.560
세계가 어떻게 작동하는지에 대한 정확한 모델이 필요하며, 직관적 물리에서 시작합니다.

00:10:48.560 --> 00:10:54.560
그리고 세계의 물리가 어떻게 작동하는지에서 시작해 생물학과 경제학까지 아우르게 됩니다.

00:10:55.120 --> 00:10:59.200
그렇다면 인공 일반 지능, 즉 AGI에 도달하게 된다면 세상을 어떻게 그려 보십니까?

00:10:59.200 --> 00:11:03.120
AGI는 대략 인간 수준의 지능인데, 그때 LLM과 세계 모델이 결합해 함께 작동하게 될까요?

00:11:03.120 --> 00:11:07.600
아니면 어떤 의미에서는 세계 모델이 LLM을 대체하게 될까요?

00:11:07.600 --> 00:11:12.160
아니요, 저는 이런 기술들이 어느 정도 수렴할 것이라고 봅니다.

00:11:13.280 --> 00:11:18.640
내부에는 Gemini 같은 LLM, 즉 기반 모델이 깔려 있을 것입니다.

00:11:18.640 --> 00:11:22.560
그것이 핵심 구성 요소가 될 것입니다. 그 부분은 제게 거의 의심의 여지가 없습니다.

00:11:22.560 --> 00:11:29.280
그래서 우리는 그 시스템들의 규모를 가능한 한 크게, 그리고 강력하게 키우려고 해야 합니다.

00:11:29.280 --> 00:11:35.520
하지만 문제는, AGI에 그것만이 필요한 유일한 구성 요소인지 여부입니다.

00:11:35.520 --> 00:11:41.520
그리고 저는 다른 종류의 기술과 다른 역량들도 필요할 것이라고 생각합니다.

00:11:41.520 --> 00:11:48.240
이런 세계 모델 역량과 관련해 우리는 'Genie'라고 부르는 버전도 개발 중이며, 비디오 모델도 보유하고 있습니다.

00:11:48.240 --> 00:11:53.280
VO 같은 최첨단 비디오 모델은 텍스트에서 비디오를 생성할 수 있습니다.

00:11:53.280 --> 00:11:59.360
또 비디오 모델과 Genie 같은 인터랙티브 모델은 일종의 초기 단계의 세계 모델로 볼 수 있습니다.

00:11:59.360 --> 00:12:06.000
초기 단계의 세계 모델에서는, 세계에 대해 현실적인 무언가를 생성할 수 있다면,

00:12:06.000 --> 00:12:10.080
어떤 의미에서는 모델이 그 세계를 이해한다는 뜻입니다. 그렇지 않다면 어떻게 생성했겠습니까?

00:12:10.080 --> 00:12:13.680
데미스, 방금 AGI, 즉 인공 일반 지능을 언급하셨는데요.

00:12:13.680 --> 00:12:18.000
그 정의가 여러 가지로 제각각인 것으로 압니다.

00:12:18.000 --> 00:12:23.520
이전에 AGI가 5~10년 안에 올 수도 있다고 보신다고 하셨는데,

00:12:23.520 --> 00:12:27.920
2025년에 본 큰 진전들을 감안해도 지금도 그 견해가 유효합니까?

00:12:27.920 --> 00:12:30.720
네, 저는 그 전망대로 잘 가고 있다고 생각합니다. 사실 DeepMind를 시작했을 때

00:12:30.720 --> 00:12:35.760
2010년 당시에는 AGI를 만들기 위한 20년짜리 임무가 될 거라고 생각했습니다,

00:12:35.760 --> 00:12:41.440
즉 우리처럼 모든 인지 능력을 발휘할 수 있는 시스템인데요, 예를 들어

00:12:41.440 --> 00:12:47.200
진정한 혁신과 창의성, 계획 수립, 추론 같은 것들 말입니다.

00:12:47.200 --> 00:12:52.400
바로 그런 것들입니다. 그리고 저는 그 목표까지 대략 5~10년 정도 남았다고 보는데,

00:12:52.400 --> 00:12:56.240
이 기술이 얼마나 변혁적인지 생각하면 정말 놀라운 일입니다.

00:12:56.240 --> 00:12:59.120
추가적인 기술적 돌파구가 더 필요할 수도 있다고 하셨는데요. 지금 우리는

00:12:59.120 --> 00:13:03.600
모델이 발전하는 것도 보고 있고, 반도체도 빠르게 진전되는 것을 보고 있습니다.

00:13:03.600 --> 00:13:07.040
현재 병목이 되거나 해결해야 할 과제는 무엇인가요?

00:13:07.040 --> 00:13:10.080
에너지는 계속 거론되는 주제인데요, 예를 들어 "말씀드리자면,"

00:13:10.080 --> 00:13:13.920
칩은 계속 발전시키고 모델도 계속 발전시키겠지만, 어느 시점에서는 우리는

00:13:13.920 --> 00:13:18.720
이 데이터 센터와 AI 모델을 돌릴 만큼의 에너지가 부족해질 수 있다는 얘기입니다.

00:13:18.720 --> 00:13:23.360
네, 네. 음, 그러니까 물리적 제약이 많이 있습니다. 물론,

00:13:23.360 --> 00:13:26.880
그 누구도 칩이 충분했던 적은 없습니다. 다행히 우리는

00:13:26.880 --> 00:13:31.520
GPU뿐 아니라 자체 TPU 라인업도 갖추고 있지만, 그래도 결국 부족합니다.

00:13:31.520 --> 00:13:34.800
전 세계적으로 수요를 감당할 만큼의 연산 칩이 충분하지 않습니다. 그리고 결국

00:13:34.800 --> 00:13:38.880
그 문제는 에너지로도 귀결됩니다. AGI 시대로 갈수록 에너지가 사실상

00:13:38.880 --> 00:13:44.560
지능과 동의어가 될 것이라는 생각도 있습니다. 그런데 흥미로운 점은,

00:13:44.560 --> 00:13:50.320
AI 자체가 여기서 도움이 될 것이라는 점입니다. 기존

00:13:50.320 --> 00:13:55.040
인프라의 효율을 끌어올리는 것뿐 아니라, 소재 설계나 더 나은 태양전지 소재 같은 것에도요.

00:13:55.040 --> 00:13:58.320
또한 핵융합 같은 새로운 돌파구 기술에도 도움이 될 수 있습니다. 우리는

00:13:58.320 --> 00:14:03.680
미국의 Commonwealth Fusion과 협력해 플라즈마를 가두고 핵융합

00:14:03.680 --> 00:14:09.120
원자로를 제어하는 데 도움을 주고 있습니다. 제 개인적 프로젝트 중 하나는 AI로 상온 초전도체

00:14:09.120 --> 00:14:15.280
소재를 만들어낼 수 있느냐는 것입니다. 그래서 AI가 제안하고 우리가 함께 만들 수 있는 돌파구가 여러 가지 있다고 봅니다.

00:14:15.280 --> 00:14:19.840
그런 것들이 에너지 상황을 개선하는 데 도움이 될 것입니다. 실제로 그건,

00:14:19.840 --> 00:14:23.760
제 생각에 AI의 가장 유망한 활용 사례 중 하나입니다. 또 다른 점은,

00:14:23.760 --> 00:14:28.640
이 시스템들이 좋아질수록 매년 효율도 대략 10배씩 개선되고 있다는 것입니다.

00:14:28.640 --> 00:14:33.520
예를 들어 우리 모델 라인업을 보면 Lighthouse 모델과 Gemini의 Pro 버전이 있고

00:14:33.520 --> 00:14:37.680
또 훨씬 효율적인 Flash 버전도 있으며,

00:14:37.680 --> 00:14:42.400
여러 용도로 쓰이는 주력 모델도 있습니다. 이들은 지식 증류 같은 기법을 쓰는데,

00:14:42.400 --> 00:14:46.720
큰 모델이 작은 모델을 가르치고, 그 작은 모델이 정말 매우 효율적으로 동작하는 방식입니다.

00:14:46.720 --> 00:14:50.880
그리고 그런 혁신과 기법들이 점점 더 늘어나면서

00:14:50.880 --> 00:14:56.800
효율 곡선을 계속 낮춰, 와트당 성능이 훨씬 좋아질 것입니다.

00:14:56.800 --> 00:15:00.800
AGI 이야기를 많이 듣는데요, 많은 분들이 이 기술이 얼마나 대단한지 궁금해합니다.

00:15:00.800 --> 00:15:05.440
정말 놀랍고 훌륭하게 들리지만, 이 기술이 널리 퍼지는 것에 대한 두려움도 큽니다.

00:15:05.440 --> 00:15:09.600
그리고 그것이 사람들의 일상과 삶에 미칠 영향에 대한 우려도 큽니다.

00:15:09.600 --> 00:15:12.480
당신 입장에서는 우리가 고려해야 할 것들이 무엇인지,

00:15:12.480 --> 00:15:12.800
네.

00:15:12.800 --> 00:15:16.480
그 관점에서, 일자리 같은 사회적 영향 측면에서,

00:15:16.480 --> 00:15:21.360
이 목표에 도달하면 시간을 어떻게 보낼지 같은 문제든,

00:15:21.360 --> 00:15:25.520
아니면 당신이 이 기술이 인류에 가져올 것이라고 믿는 이점이든요?

00:15:25.520 --> 00:15:29.040
물론 저는 전반적으로 AI가 인류가 발명한 가장

00:15:29.040 --> 00:15:35.440
유익한 기술 중 하나가 될 것이라고 믿습니다. 그래서 제 경력 전체를 그것에 바쳤습니다.

00:15:35.440 --> 00:15:40.480
하지만 그게 저절로 보장되는 것은 아닙니다. 이는 양면적인 기술입니다. 저는

00:15:40.480 --> 00:15:45.360
질병을 치료하는 것 같은 일에 AI를 쓰는 꿈을 꿉니다. 아이소모픽이라는 스핀아웃이 있는데,

00:15:45.360 --> 00:15:50.960
알파폴드의 단백질 접힘 연구, 우리가 몇 년 전에 했던 그 작업을 기반으로 해서

00:15:50.960 --> 00:15:55.440
신약 발견을 가속화하고 모든 질병을 해결하려고 합니다. 저는 이것이 이제,

00:15:55.440 --> 00:16:01.600
향후 10~20년 안에 그런 일이 가능해질 것입니다. 에너지 이야기도 했는데, AI가 가져올 이점은 많다고 봅니다.

00:16:01.600 --> 00:16:05.920
AI가 가져올 놀라운 이점이 많습니다. 하지만 위험도 있습니다. 분명히

00:16:05.920 --> 00:16:11.520
경제적 혼란이 있을 것이고, 이는 산업혁명과 비슷하겠지만

00:16:11.520 --> 00:16:17.760
아마 10배 더 크고 10배 더 빠를 것입니다. 그래서 엄청난 변화가 일어나지만

00:16:17.760 --> 00:16:22.480
동시에 큰 혼란도 뒤따를 것입니다. 그리고 아마 새로운 경제 모델이 필요합니다

00:16:22.480 --> 00:16:28.880
아마도 이를 위해서요. 그리고 AI 사용에 대한 우려로는, 제가 걱정할 만하다고 보는 두 가지가 있는데

00:16:28.880 --> 00:16:33.600
그중 하나는 악의적 행위자들이 이러한 범용 기술을 다른 용도로 전용하는 것입니다

00:16:33.600 --> 00:16:39.360
즉 AI 기술을 해로운 목적에 사용하는 것입니다. 그리고 두 번째는 AGI로 다가갈수록 AI 자체입니다

00:16:39.360 --> 00:16:44.560
그리고 에이전트 기반 시스템으로 갈수록 그렇습니다. 이는 오늘날의 시스템보다 더 자율적으로 일을 하는 시스템입니다

00:16:44.560 --> 00:16:50.480
이런 시스템은 더 자율적으로 행동할 수 있습니다. 그렇다면 그에 대한 가드레일은 무엇이며, 어떻게

00:16:50.480 --> 00:16:57.040
우리가 원하는 일을 계속 하게 하고, 우리가 의도하지 않은 방향으로 벗어나지 않게 할 수 있겠습니까

00:16:57.040 --> 00:17:03.200
예상치 못한 무언가로 향하지 않도록요. 그래서 제가 예견하는 위험은 대체로 이 두 가지입니다

00:17:03.200 --> 00:17:04.640
그런 시스템을 이미 갖추고 있다고 느끼십니까, 아니면

00:17:04.640 --> 00:17:07.360
통제할 수 있는 시스템을 개발하고 있다고 느끼십니까?

00:17:07.360 --> 00:17:11.760
저희는 그 점에 대해 매우 확신하고 있습니다. 아시다시피 저희는

00:17:11.760 --> 00:17:16.640
아주 초기부터 이 시스템의 책임, 안전, 보안에 대해 생각해 왔습니다

00:17:16.640 --> 00:17:20.800
2010년에 딥마인드를 시작했을 때만 해도 당시에는 거의 아무도 AI를 연구하지 않았습니다. 하지만

00:17:20.800 --> 00:17:25.040
저희는 성공을 전제로 계획했고, 성공이란 이런 극도로 강력한 시스템을 뜻한다는 것을 알고 있었습니다

00:17:25.040 --> 00:17:30.080
그래서 그에 따른 동전의 다른 면도 이해했습니다. 그래서 처음부터

00:17:30.080 --> 00:17:33.920
과학적 방법과 과학적 접근을 활용해 매우 신중하게 접근하려고 노력해 왔습니다

00:17:33.920 --> 00:17:38.560
배포하기 전에 우리가 만드는 시스템을 가능한 한 많이 이해하려고요. 물론

00:17:38.560 --> 00:17:41.200
그렇다고 해서 실수를 전혀 하지 않는다는 뜻은 아닙니다. 또한 이것은

00:17:41.200 --> 00:17:46.720
정말 놀랍고 매우 빠르게 움직이는 기술입니다. 하지만 AI 같은 경우에는

00:17:46.720 --> 00:17:52.960
우리는 신중해야 합니다. 저는 스스로를 '신중한 낙관론자'라고 부르며, 저는

00:17:52.960 --> 00:17:57.600
인간의 창의성을 굳게 믿습니다. 충분한 시간과 주의를 기울인다면 과학자로서도

00:17:57.600 --> 00:18:03.600
사회로서도 우리는 이 일을 제대로 해낼 것이라고 봅니다. 하지만 그것은 당연한 일이 아니니, 너무 서둘러서는 안 됩니다

00:18:03.600 --> 00:18:04.160
네

00:18:04.160 --> 00:18:06.400
그리고 우리는 눈을 뜨고 이 일에 들어가야 합니다

00:18:06.400 --> 00:18:10.160
제가 이렇게 여쭌 이유는, 요슈아 벤지오 같은 분들과도 대화하신 것으로 알고 있기 때문입니다

00:18:10.160 --> 00:18:15.280
맥스 테그마크도요. 저도 그분들과 이야기해 봤는데, 그분들은 '제발'이라고 할 정도로

00:18:15.280 --> 00:18:20.800
AGI와 에이전틱 시스템의 세계로 그렇게 빨리 달려들 필요가 있느냐는 입장입니다. 어쩌면 더

00:18:20.800 --> 00:18:26.960
만능형 또는 범용 시스템보다, 특정한 문제를 해결하는 도구 기반 AI가 더 필요하다고도 합니다

00:18:26.960 --> 00:18:32.400
그런 시스템 말입니다. 그리고 그분들이 아마 이런 AGI 시스템 개발 속도를

00:18:32.400 --> 00:18:38.560
늦추자는 주장도 해왔다는 것을 압니다. 당신의 견해로는, 속도를 늦춰야 한다고 보십니까?

00:18:38.560 --> 00:18:42.240
음, 저는 그분들을 잘 알고 있고, 요슈아와 맥스는 특히 잘 압니다. 저희는

00:18:42.240 --> 00:18:46.400
많은 논의를 해왔고 다른 많은 분들과도 논의했습니다. 그리고 사실 저는 그 견해에 어느 정도 공감합니다

00:18:46.400 --> 00:18:51.920
도구 기반 AI를 만든다는 것, 즉 AI를 도구, 혹은 궁극의 도구로 바라보는 것이

00:18:51.920 --> 00:18:58.480
예를 들어 과학을 위해서는 초기 단계에서 AI를 만드는 올바른 방식이라고 생각합니다. 그리고 분명 그것이 저희가

00:18:58.480 --> 00:19:05.440
바라보는 방식이며, 알파폴드처럼 AI를 적용하는 방식이기도 합니다. 하지만 문제는

00:19:05.440 --> 00:19:11.520
우리가 처한 환경이 매우 복잡한 지정학적·기업적 시스템이라는 점입니다. 그리고 이것은 단지

00:19:11.520 --> 00:19:15.520
많은 회사들이 이를 만들려고 한다는 것만의 문제가 아닙니다. 많은 국가들도 이를 만들려고 합니다

00:19:15.520 --> 00:19:21.840
그래서 일종의 경쟁 구도가 있습니다만, 저는 이상적으로는 그런 구도가 없었으면 합니다. 그래서

00:19:21.840 --> 00:19:26.800
이상적인 경우라면 이것은 과학적 시도가 될 것이고, 각 단계는 매우 신중하게

00:19:26.800 --> 00:19:31.760
검토될 것입니다. 하지만 안타깝게도 현실 세계는 그렇지 않습니다

00:19:31.760 --> 00:19:36.880
그래서 우리는 현재 상황에 대해 실용적으로 접근해야 합니다. 그래서 저희가 하려는 것은

00:19:36.880 --> 00:19:42.480
좋은 본보기가 되는 것입니다. 최전선에서 그 이점을 가능한 한 빠르게

00:19:42.480 --> 00:19:48.880
그리고 가능한 한 넓게 확산시키되, 그 과정에서는 가능한 한 책임감 있게

00:19:48.880 --> 00:19:52.880
또한 가능한 한 신중하게 하려는 것입니다. 그리고 저희는 그 균형을 현재 꽤 잘

00:19:52.880 --> 00:19:56.640
맞추고 있다고 생각합니다. 이것이 업계와 분야의 다른 이들에게도 작은 본보기가 되길 바랍니다

00:19:56.640 --> 00:19:59.280
네, 그런 역학도 다루고 싶습니다만, 먼저

00:19:59.280 --> 00:20:02.000
개인적인 관점에서 여쭙고 싶은데요. 예전에 말씀하신 적이 있듯이

00:20:02.000 --> 00:20:05.120
딥마인드라는 미션을 시작하셨다고 하셨잖아요. 기술을 믿고 계시지만,

00:20:05.120 --> 00:20:09.600
경력 중에 “우리가 이걸 정말 해야 하나요?”라고 생각한 순간이 있으셨습니까?

00:20:09.600 --> 00:20:16.560
기술이 얼마나 강력한지 보면, 저는 정말로

00:20:16.560 --> 00:20:22.800
오늘날 사회가 직면한 도전이 너무 많다고 생각합니다. AI와는 별개로 기후, 빈곤,

00:20:22.800 --> 00:20:28.320
물 접근성 같은 것들요. 건강 문제도 있고,

00:20:28.320 --> 00:20:36.240
노화, 인구, 질병도 있습니다. 그리고 아까 이야기했던 에너지 같은 것도요. 그래서 만약

00:20:36.240 --> 00:20:40.720
그러니까, 앞으로 AI만큼 변혁적인 기술이 등장하지 않는다면,

00:20:40.720 --> 00:20:45.360
사회가 이런 도전들을 감당할 수 있을지 저는 정말 걱정될 것입니다.

00:20:45.360 --> 00:20:49.600
흥미롭게도 AI 자체도 그런 도전 중 하나이며, 어쩌면 가장 큰 도전일 수도 있지만,

00:20:49.600 --> 00:20:56.240
동시에 이런 거대한 문제들 가운데 일부를 우리가 견디고 해결하도록

00:20:56.240 --> 00:21:02.080
도와줄 수도 있습니다. 그래서 흥미롭지요. 일종의 양날의 검이고, 저는 늘 그렇게

00:21:02.080 --> 00:21:09.040
믿어 왔습니다. 결국 이것이 우리가 발명할 가장 중요한 기술이 될 것이라고 생각해 왔습니다.

00:21:09.040 --> 00:21:15.440
그리고 이것은 사실 컴퓨터 시대의 자연스러운 진전이라고 생각합니다.

00:21:15.440 --> 00:21:20.240
데미스, 잠깐만요. 게임 업계에서 커리어를 시작하셨다니 정말 놀랍습니다.

00:21:20.240 --> 00:21:21.760
네, “Theme Park”를 공동 개발했습니다.

00:21:21.760 --> 00:21:22.200
네,

00:21:22.200 --> 00:21:26.320
정말 멋졌습니다. 훌륭한 게임이기도 했고요. 아직도 게임을 하십니까?

00:21:26.320 --> 00:21:31.600
네, 저는 게임을 정말 좋아합니다. 제 취미입니다. 요즘은 “리그 오브 레전드” 같은 것을

00:21:31.600 --> 00:21:35.840
두 아들과 제 형제와 함께 작은 팀을 꾸려서 하고 있는데, 봉쇄 기간부터 계속해 왔습니다.

00:21:36.560 --> 00:21:39.837
하지만 네, 저는 축구부터 비디오 게임까지 모든 형태의 게임을 좋아합니다.

00:21:39.837 --> 00:21:44.800
그처럼 영향력도 크고 스트레스도 큰 역할을 하시는데, 게임이 긴장을 푸는 방법이 되십니까?

00:21:44.800 --> 00:21:48.160
그렇습니다, 그렇습니다. 그렇게 말씀드릴 수 있습니다. 그리고 또, 아시다시피,

00:21:48.160 --> 00:21:52.480
과거에는 저에게 훌륭한 창의적 도전이기도 했습니다,

00:21:52.480 --> 00:21:56.560
게임을 만들면서 프로그래밍과 다른 것들을 배웠기 때문입니다.

00:21:56.560 --> 00:22:00.480
저는 선생님만큼 스트레스가 큰 직업은 아니지만, 저도 그게 긴장을 푸는 방법입니다.

00:22:00.480 --> 00:22:01.120
확실합니다.

00:22:01.120 --> 00:22:02.800
집에 가서 콘솔을 켭니다.

00:22:02.800 --> 00:22:04.640
맞습니다, 맞습니다.

00:22:07.120 --> 00:22:12.640
그 짧은 구간만 봐도요, 스티브, 짚어볼 게 정말 많습니다. 지금은 두 가지

00:22:12.640 --> 00:22:17.840
큰 유행어에 집중하고 싶습니다. 첫 번째는 범용 인공지능, 즉 AGI입니다,

00:22:17.840 --> 00:22:22.080
이 개념 말인데요. 정의도 정말 다양하지만, 대체로는

00:22:22.080 --> 00:22:28.400
인간만큼 똑똑하거나 인간보다 더 똑똑한 AI라는 개념입니다. 그리고 많은 대형 AI

00:22:28.400 --> 00:22:35.520
연구소들, 예를 들어 OpenAI나 딥마인드 같은 곳들이 그 AGI 단계에 도달하려고 밀어붙이며 기대하고 있습니다,

00:22:35.520 --> 00:22:40.640
그리고 지금까지는 “대규모 언어 모델”이라는 기법으로 여기에 접근해 왔고,

00:22:40.640 --> 00:22:45.360
이 AI 모델들은 방대한 데이터로 학습하지만 주로 텍스트입니다. 그런데 또 다른

00:22:45.360 --> 00:22:52.720
유행어가 있지요. “월드 모델”, 즉 물리 세계를 이해하는 AI 모델이라는 개념입니다.

00:22:52.720 --> 00:22:56.240
그리고 이 유행어가 정말 인기를 끌고 있지요?

00:22:56.240 --> 00:23:01.520
네. 그리고 이것이 2026년 남은 기간 동안 AI의 큰 주제가 될 것 같습니다,

00:23:01.520 --> 00:23:07.440
심지어 내년까지도요. 왜냐하면 핵심은 LLM이 언어 부분은 확실히 해냈다는 점이기 때문입니다.

00:23:07.440 --> 00:23:13.120
사람이 말하고 쓰는 방식을 흉내 낼 수 있지요. 하지만

00:23:13.120 --> 00:23:18.160
물리 세계에서는 로보틱스와 AI, 물리적 AI를 많이 이야기하는데,

00:23:18.160 --> 00:23:23.600
그런 시스템들은 물이 어떻게 흐르고 공기가 어떻게 움직이는지 등 물리 세계가 어떻게 작동하는지 이해해야 합니다.

00:23:23.600 --> 00:23:28.800
그리고 제가 이 얘기를 데미스에게 꺼냈을 때 가장 인상적이었던 건 그가 “맞습니다”라고 했다는 점입니다,

00:23:28.800 --> 00:23:34.480
더 탐구해야 한다고 했고, 실제로 그는 LLM과 그런

00:23:34.480 --> 00:23:39.920
월드 모델이 서로 수렴한다고 보았습니다. 그가 쓴 표현이 ‘수렴’이었는데, 더

00:23:39.920 --> 00:23:46.080
독특하고 더 강력하며 더 역량 있는 무언가로 이어진다는 뜻입니다. 이런 논쟁은 AI 리더들 사이에서도 벌어지고 있고,

00:23:46.080 --> 00:23:51.440
소셜 미디어에서도요. X나 좋아하는 소셜 미디어를 켜보면, 제가 특히 눈에 띈 사람은

00:23:51.440 --> 00:23:58.560
얀 르쿤입니다. 그는 메타에서 오랫동안 AI를 총괄했는데, 최근에는

00:23:58.560 --> 00:24:03.600
알렉산더 왕과 지난여름 벌어진 대규모 인재 전쟁 속에서 자신이 밀려났다고 느껴, 결국 독립해 자기 일을 시작했는데요,

00:24:03.600 --> 00:24:09.600
지난여름 벌어진 그 인재 전쟁 이후 파이낸셜 타임스와 아주 흥미로운 인터뷰를 했습니다,

00:24:09.600 --> 00:24:14.640
그는 LLM이 우리를 AGI로 이끌 핵심이 아니라고 보며, 말씀하신 대로 모두가 그것을

00:24:14.640 --> 00:24:20.320
쫓고 있습니다. 초지능 AGI든 뭐라고 부르든 간에요. 그의 요지는 LLM은

00:24:20.320 --> 00:24:25.520
길의 일부만 갈 수 있다는 것입니다. 월드 모델과 온갖 다른 것들이 필요하다는 것이고, 그는

00:24:25.520 --> 00:24:31.200
LLM을 넘어 생각하지 않는 메타를 꽤 강하게 비판했는데, 그것이

00:24:31.200 --> 00:24:35.760
그가 떠나 자기 일을 하게 된 이유 중 일부인 듯합니다. 그리고 메타의 큰 경쟁자 중 하나인

00:24:35.760 --> 00:24:40.800
제미니가 이를 공개적으로 이야기하며 데미스가 “그래요, 이걸 해야 합니다. 우리는

00:24:40.800 --> 00:24:46.640
이제 이런 방향을 고민하기 시작해야 합니다”라고 말하는 것을 보는 것이 흥미롭습니다. 이는 로보틱스, 자율주행

00:24:46.640 --> 00:24:51.520
등 많은 것을 가능하게 하고, 우리가 대화하는 이런 AI 모델과 지능형 시스템을 더 잘 이해하도록 도와

00:24:51.520 --> 00:24:57.440
정확한 답을 내놓게 합니다.

00:24:57.440 --> 00:25:01.200
무언가를 입력하면 “스티브, 좋은 질문입니다. 정말 기발한 생각입니다”라고 말하곤 합니다.

00:25:01.200 --> 00:25:04.160
항상 그렇습니다. 그게 전부입니다. 이런 챗봇들의 아첨이죠, 그렇지 않습니까?

00:25:04.160 --> 00:25:08.480
그러면서 “와, 정말 똑똑하시고 이런 질문을 해주시는 게 대단합니다”라고 합니다. 네, 늘 그렇습니다,

00:25:08.480 --> 00:25:12.240
맞습니다. 제가 이 이야기를 꺼낸 이유는 부분적으로 바로 이 지점, 즉 LLM에 대한 점점 커지는 비판 때문입니다.

00:25:12.240 --> 00:25:17.120
LLM에 대한 비판은, 물론 훌륭하고 정보를 제공하긴 하지만, 실제로는,

00:25:17.120 --> 00:25:22.320
LLM을 새로운 아이디어를 만들어낼 수 있는 기반으로 삼는 문제에서는

00:25:22.320 --> 00:25:26.480
참신한 아이디어를 만들어내는 데 한계가 있으며, 이는 부분적으로 데미스가

00:25:26.480 --> 00:25:30.960
말하고자 했던 바라고, 그래서 ‘월드 모델’이라는 개념이 인기를 얻고 있다고 생각합니다.

00:25:31.600 --> 00:25:35.520
말씀하신 대로, 이것이 AI의 다음 단계에서 어떻게 전개될지 지켜보는 것이 흥미로울 것입니다,

00:25:35.520 --> 00:25:40.480
로보틱스, 무인 자동차, 그리고 다른 많은 활용 사례에서도 핵심이 될 것이기 때문입니다.

00:25:40.480 --> 00:25:45.600
네, 그리고 이 팟캐스트를 계속 들으시면, 저는 지금 우리가 살고 있는 이 AI 순간의 로보틱스 측면에 대해 굉장히 냉소적이라는 점을 느끼실 겁니다,

00:25:45.600 --> 00:25:50.960
우리가 보는 로봇들 중 많은 것들이

00:25:50.960 --> 00:25:56.080
말 그대로 꼭두각시입니다. 원격 조종됩니다. 물론 가장 좋은 예는 테슬라 옵티머스

00:25:56.080 --> 00:26:01.760
로봇인데, 처음에는 바디수트를 입은 사람이 춤추는 모습에서 시작했습니다. 지금은 진짜 로봇이지만,

00:26:01.760 --> 00:26:07.200
그래도 여전히 원격 조종입니다. 관제실에 있는 사람들이 실제로 그것을

00:26:07.200 --> 00:26:11.920
인터넷으로 조종하고, 심지어 목소리로 당신에게 말을 걸기도 합니다. 그래서 우리는,

00:26:11.920 --> 00:26:16.320
그래서 제가 만난 로보틱스 업계 사람들은 불과 몇 주 전에도 사무실에 한 대를 가져왔는데, 그들이 말하길

00:26:16.320 --> 00:26:21.440
가장 어려운 건 실제 로봇을 만드는 것이 아니라 훈련시키는 것이며, 바로 그 지점에서 이런 월드 모델이

00:26:21.440 --> 00:26:28.800
필요해질 것이라고 했습니다. 우리가 약속받아 온 것처럼 실제로 자율적으로 작동하게 하기 위해서입니다. 좋습니다.

00:26:28.800 --> 00:26:34.400
데미스, 작동하는 여러 역학을 언급하셨죠? 그리고 물론 상업적 경쟁도

00:26:34.400 --> 00:26:39.280
그중 하나입니다. 오픈AI도 있고, 앤스로픽도 있고, 이런 다양한 AI 연구소들이

00:26:39.280 --> 00:26:45.360
밖에 있습니다. 치열합니다. 그리고 지금까지 제미니 3는 반응이 아주 좋았습니다. 하지만

00:26:45.360 --> 00:26:49.840
한때 사람들은 구글 전체와 그 경쟁 역량을 의심했습니다. 그리고 저는

00:26:49.840 --> 00:26:55.040
그런 시점이 분명히 있었다고 말씀드리겠습니다. 2025년 어느 때였고 그리 오래전도 아니었습니다. 그리고 나서, 아시다시피, 제미니

00:26:55.040 --> 00:27:00.880
3가 제대로 나오면서 많은 사람들을 놀라게 했습니다. 하지만 이 분야는 계속 변합니다.

00:27:00.880 --> 00:27:04.960
그렇다면 지금 경쟁 환경을 어떻게 평가하시겠습니까? 체감은 어떠신가요?

00:27:04.960 --> 00:27:09.920
네, 지금은 매우 치열한 경쟁 환경입니다. 많은 사람들이

00:27:09.920 --> 00:27:14.000
제게 말하더군요. 기술 업계에서 20~30년 일해온 사람들이, 이게 가장 치열한

00:27:14.000 --> 00:27:17.920
환경이라고요. 어쩌면 기술 산업 역사상 가장 치열한 환경일지도 모릅니다.

00:27:18.960 --> 00:27:23.920
그리고, 그러니까, 가장 유능한 플레이어들이 모두, 개인이든

00:27:23.920 --> 00:27:28.720
기술 거인이든 빅테크 기업이든, 최고의 스타트업이든, 모두가

00:27:28.720 --> 00:27:32.880
이제 이 분야에 참여하고 있습니다. 모두가 우리가 20년 넘게 알고 있던 사실을 이해했기 때문이라고 생각합니다.

00:27:32.880 --> 00:27:38.240
즉 이것이 정말 가장 중요한 기술이라는 점입니다. 그래서 어느 정도 예상된 일입니다,

00:27:38.240 --> 00:27:44.640
하지만 어렵기도 하고, 동시에 흥미롭기도 합니다. 그리고 게임 이야기로 돌아가면, 저는 좀,

00:27:44.640 --> 00:27:49.040
저는 아주 어릴 때 잉글랜드 주니어 체스 대표팀에서 체스를 두기 시작했습니다. 그래서 저는 어느 정도

00:27:49.040 --> 00:27:53.360
경쟁 속에서 성장해 왔습니다. 그래서 다행히도 저는 경쟁을 좋아합니다. 사실 많은

00:27:53.360 --> 00:27:58.720
면에서 저는 경쟁을 위해 산다고 할 정도입니다. 그래서 제 큰 부분은 이런 상황에 더 뛰어들고 싶어합니다.

00:27:58.720 --> 00:28:02.160
하지만 다른 한편으로, 제가 말씀드리고 싶은 것은 이것입니다.

00:28:02.160 --> 00:28:06.320
마음 한켠에서는 기업 간, 심지어 국가 간의 개별적인 경쟁보다 훨씬 더 중요한 무언가가 있다는 것을 알고 있습니다.

00:28:06.320 --> 00:28:11.600
그것은 전 세계를 위해, 전체를 위해, 인류 모두를 위해 AGI를 제대로 관리하고 이끌어 가는 일입니다.

00:28:11.600 --> 00:28:18.960
그리고 AI 연구소를 이끄는 리더들이며 이에 영향력을 행사할 수 있는 우리 모두에게는 그런 책임이 있습니다.

00:28:18.960 --> 00:28:23.760
그런 관점을 늘 최우선에 두고 염두에 두는 것이 책무라고 생각합니다.

00:28:23.760 --> 00:28:28.720
우리가 처한 치열한 자본주의적 경쟁 속에서도 말입니다. 그래서 두 가지는 동시에 모두 사실입니다.

00:28:28.720 --> 00:28:32.080
앞서 사람들이 올해 초 AI와 관련해 구글이 무엇을 할지 의문을 제기하던 시점을 말씀하셨는데,

00:28:32.080 --> 00:28:36.800
네. 그때 무엇을 좀 다르게 하셨습니까?

00:28:36.800 --> 00:28:42.240
네, 지난 10년을 되돌아보면,

00:28:42.240 --> 00:28:47.680
구글의 연구 조직인 구글 브레인과 당시의 딥마인드는 비교적 독립적이었습니다.

00:28:47.680 --> 00:28:52.720
또 우리는 오늘날 모두가 사용하는 기술의 약 90%를 사실상 발명했습니다.

00:28:52.720 --> 00:28:56.800
예를 들어 트랜스포머가 그렇습니다. 물론 가장 유명한 사례입니다.

00:28:56.800 --> 00:29:01.360
모든 LLM의 기반이 되는 아키텍처라든지, 알파고처럼

00:29:01.360 --> 00:29:07.200
정말 어려운 문제에서 강화학습을 대규모로 적용해 보인 것들이 있습니다.

00:29:07.200 --> 00:29:11.760
이런 기술을 모두 발명해 놓고도, 돌이켜보면 이를 상용화하고 확장하는 데는 조금 느렸던 편이었습니다.

00:29:12.320 --> 00:29:16.640
그 부분은 오픈AI와 다른 곳들이 매우 잘 해냈습니다.

00:29:16.640 --> 00:29:23.760
그리고 지난 2~3년 동안은 거의 스타트업, 혹은 창업가적 뿌리로 돌아가 더 치열하게, 더 민첩하게 움직여야 했습니다.

00:29:23.760 --> 00:29:29.920
더 빨라지고 제품을 정말 신속히 출시하며 빠른 진전을 이뤄야 했습니다.

00:29:29.920 --> 00:29:34.480
지난 몇 년 동안 여러분이 보신 변화는 제미니로 정점에 이른 제미니 시리즈로 이어졌습니다.

00:29:34.480 --> 00:29:40.480
우리가 매우 만족하는 제미니 시리즈의 최신작인 제미니 3가, 말씀하신 것처럼,

00:29:40.480 --> 00:29:45.280
우리를 다시, 우리가 있어야 한다고 느끼는 리더보드 최상단 가까이로 올려놓았습니다.

00:29:45.280 --> 00:29:46.960
그리고 그 자리를 계속 지킬 수 있다고 보십니까?

00:29:46.960 --> 00:29:49.600
네, 물론 지킬 수 있다고 생각합니다.

00:29:49.600 --> 00:29:56.320
이런 경쟁 속에서 AI 거품에 대한 이야기도 분명히 많습니다.

00:29:56.320 --> 00:30:02.000
특히 일부 기업들의 기업가치를 둘러싸고, 기업들이 천문학적 자금을 조달하고 있습니다.

00:30:02.000 --> 00:30:07.360
거대 기술 기업들은 인프라에 수천억 달러를 지출하고 있습니다.

00:30:07.360 --> 00:30:11.840
그리고 밖에서는 기업들이, 솔직히 말해, 제품이 거의 없는 상태에서도 큰돈을 조달하고 있습니다.

00:30:11.840 --> 00:30:17.040
심지어 수익성이 거의 없거나, 설령 있다 하더라도, 막대한 자금을 조달하고 있습니다.

00:30:17.040 --> 00:30:21.360
그래서 이 거품 논의에서 지금 우리가 어디쯤에 있다고 보십니까? AI 산업이 금융적 거품에 있다고 생각하십니까?

00:30:21.360 --> 00:30:25.440
제 생각에는 이 거품 논의는 이분법으로 볼 문제가 아닙니다.

00:30:25.440 --> 00:30:29.440
산업의 일부는 거품일 수도 있다고 봅니다. 제게는 그렇게 보입니다.

00:30:29.440 --> 00:30:33.440
다른 부분은 아마 그렇지 않을 것입니다. 근본적으로 AI는

00:30:33.440 --> 00:30:38.880
인류가 발명한 것 중 가장 변혁적인 기술이 될 것입니다. 이것이 모든 것을 뒷받침합니다.

00:30:38.880 --> 00:30:42.960
그래서 결국 인터넷 거품과 비슷합니다. 인터넷은 결국 핵심이었습니다.

00:30:42.960 --> 00:30:48.800
그리고 그 시기에 시대를 대표하는 기업들도 일부 탄생했습니다.

00:30:48.800 --> 00:30:52.960
그래서 이런 일은 거의 불가피합니다. 특정 기술이 얼마나 변혁적인지 모두가 깨닫게 되면 과열이 생기고,

00:30:52.960 --> 00:30:59.600
아마 조정 국면도 오며, 그다음에는 실체가 있는 것들이 살아남아 번성할 것입니다.

00:30:59.600 --> 00:31:05.120
제게 특히 문제로 보이는 곳이 있습니다.

00:31:05.120 --> 00:31:09.600
예컨대 비상장 시장에서 수백억 달러 규모의 시드 라운드가 이뤄지고 있습니다.

00:31:09.600 --> 00:31:14.400
그런데 사실상 아직 거의 아무것도 없는 상태에서 그런 투자가 이뤄지기도 합니다.

00:31:14.400 --> 00:31:18.800
이는 장기적으로는 다소 지속 가능하지 않아 보입니다. 저는 거품 자체를 크게 걱정하지는 않습니다.

00:31:18.800 --> 00:31:24.320
제 입장은 구글 딥마인드를 이끄는 입장에서, 어느 쪽으로 흘러가든 대비해야 한다는 것입니다.

00:31:24.320 --> 00:31:28.960
지금처럼 모든 것이 장밋빛으로 기하급수적으로 계속되든,

00:31:28.960 --> 00:31:34.240
어떤 형태로든 거품이 꺼지든, 어느 경우든 우리가 이길 수 있도록 올바른 위치에 있어야 합니다.

00:31:34.240 --> 00:31:38.640
그리고 어느 쪽이든 그 상황을 활용할 수 있어야 합니다.

00:31:38.640 --> 00:31:44.720
그리고 구글의 기본 사업 구조와 그 안에서 AI가 어떻게 맞물리는지를 보면, 앞으로 어떤 방향으로 가든 혜택을 볼 수 있는 좋은 위치에 있다고 봅니다.

00:31:44.720 --> 00:31:48.640
또 가장 큰 경쟁자들 가운데 일부는 현재까지 민간 시장에서 막대한 자금을 조달하는 데 성공한 기업들입니다.

00:31:48.640 --> 00:31:52.640
그래서 설령 어느 시점에 어떤 조정이 오더라도, 버텨낼 수 있다고

00:31:52.640 --> 00:31:56.720
확신하십니까?

00:31:56.720 --> 00:32:00.880
네, 그러니까요. 보십시오, 이게 바로 구글의 탄탄한 재무상태표가 존재하는 이유이고, 또

00:32:00.880 --> 00:32:06.640
우리가 보유한 놀라운 제품들과 서비스 접점들 덕분입니다. 제 생각에는,

00:32:06.640 --> 00:32:13.680
수십 개의 수십억 사용자 규모 제품들이 있고, AI는 자연스럽게 그 모든 제품에

00:32:13.680 --> 00:32:19.200
이메일 워크스페이스이든, 아니면 제미나이 앱 같은 새로운 것이든 적용될 수 있습니다.

00:32:19.200 --> 00:32:23.680
네, 작용하는 역학도 언급하셨습니다. 경쟁을 이야기했고, 또 하나는 지정학입니다,

00:32:23.680 --> 00:32:27.440
물론 중국을 둘러싼 큰 논의 속에서 말씀하신 부분이기도 합니다.

00:32:27.440 --> 00:32:31.840
중국과 미국 간 이런 경쟁 구도에서 말입니다. 하지만 한때는 그런 시점이 있었습니다.

00:32:31.840 --> 00:32:38.080
사람들이 중국과 중국 기업들이 강력한 AI를 만들어낼 역량을 과소평가했습니다.

00:32:38.080 --> 00:32:44.400
모델과 기술을 말입니다. 그런데 실제로 딥시크(DeepSeek)가 한 일을 보면, 일종의

00:32:44.400 --> 00:32:48.480
충격을 줬습니다만, 사실 그보다 더 중요한 건 알리바바 같은 대형 테크 기업들이

00:32:48.480 --> 00:32:53.200
아주 경쟁력 있는 오픈소스 모델들을 내놓고 있다는 점입니다. 그러니 중국이 이 게임에서 빠진 것은 아니지 않습니까?

00:32:53.200 --> 00:32:57.760
전혀 아닙니다. 그리고 사실 제 생각엔 그들이 미국의 최전선, 그러니까

00:32:57.760 --> 00:33:02.560
미국과 서방의 프런티어 모델들에 우리가 1~2년 전 생각했던 것보다 더 가까워졌습니다. 어쩌면

00:33:02.560 --> 00:33:06.880
지금은 몇 달 정도만 뒤처져 있는 수준일 수도 있습니다. 흥미로운 점은,

00:33:06.880 --> 00:33:11.040
그리고 물론 딥시크 팀이나 말씀하신 알리바바처럼 아주 유능한 팀들이 있다는 점입니다. 그런데 질문은,

00:33:11.040 --> 00:33:18.400
그들이 프런티어를 넘어서는, 그 너머의 새로운 무언가를 혁신할 수 있느냐는 것입니다.

00:33:18.400 --> 00:33:23.200
그래서 저는 그들이 따라잡을 수 있고, 프런티어에 아주 가까이 갈 수 있다는 걸 보여줬다고 생각합니다.

00:33:23.200 --> 00:33:28.720
그리고 매우 빠르게 따라잡을 수도요. 하지만 실제로 새로운 트랜스포머 같은,

00:33:29.280 --> 00:33:32.480
그러니까 프런티어를 넘어서는 무언가를 만들어낼 수 있느냐는 아직 보여주지 못했다고 봅니다.

00:33:32.480 --> 00:33:35.600
그게 당신 보시기엔, 어렵게 만드는 요인이 있습니까?

00:33:35.600 --> 00:33:39.200
예를 들어 최첨단 칩 같은 기술 접근 제한 때문입니까?

00:33:39.200 --> 00:33:44.240
아니요, 저는 그보다는 사고방식의 문제라고 생각합니다. 그래서 적어도

00:33:44.240 --> 00:33:49.440
서방의 선도 연구소, 최전선 연구소들이 길러온 부분이고, 저희의 경우를 말씀드리면,

00:33:49.440 --> 00:33:55.600
딥마인드는 현대의 벨 연구소(Bell Labs) 같은 곳이 되려고 하면서, 알려진 것을 규모만 키우는 게 아니라

00:33:55.600 --> 00:34:00.640
혁신과 탐색적 혁신을 장려해 왔습니다. 그리고 물론 그런 일은 이미 매우 어렵습니다. 왜냐하면

00:34:01.360 --> 00:34:04.400
오늘날 그걸 해내려면 세계적 수준의 공학 역량이 필요하기 때문입니다. 그리고 중국은 분명히 그걸 갖추고 있습니다. 질문은,

00:34:04.400 --> 00:34:10.320
문제는 과학적 혁신 부분인데, 이것이 훨씬 더 어렵다는 것입니다.

00:34:10.320 --> 00:34:15.440
즉, 무언가를 발명하는 것은,

00:34:15.440 --> 00:34:21.200
그걸 복제하는 것보다 100배는 더 어렵습니다. 그래서 다음 프런티어에서의 질문은,

00:34:21.200 --> 00:34:27.680
저는 아직 그런 증거를 보지 못했지만, 정말 매우 어렵다는 점입니다.

00:34:27.680 --> 00:34:33.440
스티브, 그 대화에서 제게 가장 인상적이었던 부분 중 하나는 중국에 관한 얘기였습니다.

00:34:33.440 --> 00:34:38.960
저는 중국에서 3년 조금 넘게 살았고, CNBC를 위해 중국에서 보도도 했습니다.

00:34:38.960 --> 00:34:43.760
그곳의 기술 분야를 취재했습니다. 그런데 최근 들어 실제로 중국이

00:34:43.760 --> 00:34:50.560
여러 이유로 AI에서 미국보다 크게 뒤처졌다는 인식이 커졌습니다. 그중 하나는, 중국이

00:34:50.560 --> 00:34:55.120
가장 첨단 칩을 손에 넣지 못해 산업이 뒤처질 수 있다는 것이었습니다. 또 다른 견해는

00:34:55.120 --> 00:34:59.680
그저 혁신을 하지 못하고, 미국 기업들처럼 자본도 없다는 것이었습니다. 하지만 실제로

00:34:59.680 --> 00:35:04.800
데미스의 발언에서 정말 흥미로웠던 점은 중국 AI 모델이 미국보다 불과 몇 달 정도만 뒤처져 있다고 믿는다고 했다는 것입니다.

00:35:04.800 --> 00:35:12.080
즉, 실제로는 크게 뒤처진 것이 아니라는 뜻입니다. 그리고 작년에 우리가 딥

00:35:12.080 --> 00:35:18.960
시크가 전 세계와 시장을 정말 충격에 빠뜨렸던 것을 기억하실 겁니다. 그건 중국도 이 경쟁에 참여하고 있음을 보여줬다고 생각합니다. 그리고 그 이후로,

00:35:18.960 --> 00:35:25.760
딥시크가 처음 나왔을 때만큼 파장을 일으키지는 못했지만, 알리바바는

00:35:25.760 --> 00:35:30.800
세계 최대급이자 중국 최대급 기술 기업 중 하나로서 그 분야의 선두주자였습니다.

00:35:30.800 --> 00:35:36.000
매우 흥미로운 모델들을 개발해 왔는데, 오픈소스 커뮤니티를 보면,

00:35:36.000 --> 00:35:40.720
예를 들어 허깅페이스라는 사이트에서 알리바바의 모델들이 가장

00:35:40.720 --> 00:35:45.680
인기 있는 모델들 가운데 하나라는 것을 볼 수 있고, 제가 이 분야에서 대화한 전문가들은 그것들이 세계에서 가장

00:35:45.680 --> 00:35:50.160
첨단 수준 중 하나라고 말합니다. 그래서 그런 흐름이 보입니다. 그리고 제가 그곳에서 살며

00:35:50.160 --> 00:35:56.320
일해 본 경험으로 말씀드리자면, 중국 기업들은 움직임이 빠릅니다. 전문성도 있고 혁신도 할 수 있어서,

00:35:56.320 --> 00:36:02.400
이런 AI 경쟁에서 그들을 배제하고 생각할 수는 없습니다. 하지만 데미스가 말한 요점도 받아들여야 합니다.

00:36:02.400 --> 00:36:06.800
중국 기업들이 따라잡고 있고 분명 이 경쟁에 뛰어들어 있지만,

00:36:06.800 --> 00:36:11.440
그들이 이런 대규모 돌파구를 만들어낼 능력을 아직 입증하지는 못했다는 점입니다.

00:36:11.440 --> 00:36:15.120
저는 그것이 정말 흥미롭고도 미묘한 관점이라고 생각했습니다. 그리고 또 다른 부분이 있습니다.

00:36:15.120 --> 00:36:20.000
스티브, 당신이 짚어낸 버블, 즉 AI 버블에 대한 데미스의 발언입니다.

00:36:20.000 --> 00:36:24.320
네, 그런데 우선 그가 말한 "몇 달" 얘기로 다시 돌아가보죠.

00:36:24.320 --> 00:36:29.760
1년 전 딥시크는 중국도 해낼 수 있다는 점을 보여줬습니다.

00:36:29.760 --> 00:36:34.320
그것은 훌륭한 대규모 언어 모델이나 챗봇을 만들 수 있다는 사실만의 문제가 아니었습니다.

00:36:34.320 --> 00:36:38.640
가장 강력한 엔비디아 칩 없이도 해냈다는 점이 시장을 흔들었고, 지금 우리가

00:36:38.640 --> 00:36:45.040
미국에서 보고 있는 것도 바로 그것입니다. 이제 아르준은 중국의 엔비디아 칩 접근을 제한하려고 합니다.

00:36:45.040 --> 00:36:49.760
최고 성능은 아니지만 H200 칩을 얻을지도 모른다는 얘기도 나오고,

00:36:49.760 --> 00:36:53.840
그러다 보면 결국 밀수 문제까지 거론되게 됩니다.

00:36:53.840 --> 00:37:00.240
하지만 데미스의 요점대로, 그런 칩들에 완전히 접근하지 못한 상태에서도 정말 몇 달 차이라면,

00:37:00.240 --> 00:37:05.760
이는 칩 분야에서 엔비디아의 두드러짐과 지배력에도 의문을 제기하게 됩니다.

00:37:05.760 --> 00:37:11.920
그리고 네, 버블에 대해 말씀하신 부분도 매우 흥미롭습니다. 왜냐하면 당신이 그에게

00:37:11.920 --> 00:37:16.080
"우리는 지금 버블에 있는 건가요?" 같은 질문을 했고 여러 가지를 물었는데, 그는 기본적으로 이렇게 말했습니다.

00:37:16.080 --> 00:37:20.320
"우리는 구글입니다. 우리는 부자입니다. 상관없습니다. 우리는 돈이 있고, 자유현금흐름이 있어서

00:37:20.320 --> 00:37:25.680
이런 데에 지출할 수 있습니다. 우리 대차대조표가 우리의 초능력입니다. 어떤 이유로든 지출을 줄여야 한다면,

00:37:25.680 --> 00:37:31.040
우리는 그렇게 할 수 있고 괜찮을 겁니다. 하지만 누가 그렇게 못할까요? 오픈AI와 앤스로픽입니다.

00:37:31.040 --> 00:37:36.080
또 다른 선두주자인 xAI도 여기에 포함할 수 있는데요.

00:37:36.080 --> 00:37:41.600
이들의 처지는, 결국 매출을 보여줄 수 있는 지점에 도달할 때까지 끝없이 자금을 조달해야 한다는 점입니다.

00:37:41.600 --> 00:37:48.720
그리고 지속적인 자금 조달 없이도 자생할 수 있을 만큼의 매출과 매출 성장도 보여줘야 합니다. 그런데 만약 자금줄이 마르기 시작하면 말입니다.

00:37:48.720 --> 00:37:54.960
오픈AI와 앤스로픽은 극도로 위험해집니다. 반면 구글, 마이크로소프트, 메타는 현금흐름이 있습니다.

00:37:54.960 --> 00:37:58.960
그래서 다른 프로젝트로 옮겨갈 수 있습니다. 메타는 이미 메타버스로 그런 전환을 해봤습니다.

00:37:58.960 --> 00:38:08.480
이런 기업들은 이미 규모가 크고 마진이 높은 사업을 갖고 있었기 때문에 매우 쉽게 방향 전환을 할 수 있습니다.

00:38:08.480 --> 00:38:14.160
데미스, 많은 분들이 구글의 AI 역량 중 얼마나 큰 부분이 딥마인드에서 나오는지 잊는 것 같습니다.

00:38:14.160 --> 00:38:18.640
그리고 본인과 팀에서 나온다는 점도요. 구글과는 어떻게 협업하시나요?

00:38:18.640 --> 00:38:23.680
그 관계에 대한 관심이 큽니다. 어느 날 순다르 피차이가 전화를 해서 "데미스, 이게 필요해요"라든가, "이런

00:38:23.680 --> 00:38:29.040
제미니나 다른 AI 제품에 대한 아이디어가 있는데 만들 수 있나요?"라고 하나요? 그 관계는 어떤가요?

00:38:29.040 --> 00:38:33.040
네, 지난 3년 동안 우리는 모든 것을 통합해 '구글 딥마인드'로 만들었습니다.

00:38:33.040 --> 00:38:37.520
구글의 모든 AI 연구가 이 한 조직에서 이뤄지며, 일종의 결합체입니다.

00:38:37.520 --> 00:38:43.360
구글 리서치, 구글 브레인, 딥마인드를 합친 형태이고 제가 그 그룹을 이끌고 있습니다.

00:38:43.360 --> 00:38:48.480
그리고 그것은 구글의 엔진실 같은 곳이라고 생각하시면 됩니다. 그래서 모든 AI 기술은

00:38:48.480 --> 00:38:53.760
이 그룹, 즉 우리 그룹에서 만들고, 그다음 구글 전반의 놀라운 제품들로 퍼져 나갑니다.

00:38:53.760 --> 00:38:59.120
그리고 지난 몇 년 동안 우리는 그 기반을 구축해 왔습니다.

00:38:59.120 --> 00:39:03.520
모델뿐만 아니라 거의 구글의 전체 인프라를 설계해

00:39:03.520 --> 00:39:08.080
이런 것들을 믿을 수 없을 만큼 빠르게 출시할 수 있도록요. 이런 모델들은

00:39:08.080 --> 00:39:12.880
거의 주요 접점 전부에 동시에 배포됩니다. 그래서 우리가 새로운 제미니 모델을 출시하면,

00:39:12.880 --> 00:39:18.160
다음 날이나 당일에 검색에도 적용되며, 그 과정이 매우 잘 진행되고 있습니다.

00:39:18.160 --> 00:39:23.760
제 생각에 제미니 2.5 모델에서 우리가 정말 리듬을 탔다고 말씀드릴 수 있습니다.

00:39:23.760 --> 00:39:30.160
그리고 지난 1년 정도 동안 그 과정이 이제 정말 매끄러운 프로세스가 되었습니다.

00:39:30.160 --> 00:39:35.280
앞으로 12개월 동안 그런 모습을 더 보시게 될 겁니다.

00:39:35.280 --> 00:39:39.840
그래서 우리는 스스로를 그런 일을 하는 엔진실이라고 생각하고 그렇게 설명합니다.

00:39:39.840 --> 00:39:46.240
그리고 순다르와 저는 거의 매일 전략적 사안, 기술이 어디로 가야 하는지, 더 큰 구글 조직에 무엇이 필요한지에 대해 이야기합니다.

00:39:46.240 --> 00:39:50.640
그리고 우리는 로드맵과 계획을 사실상 매일 조정합니다.

00:39:50.640 --> 00:39:55.920
그러면서도 AGI에 가장 먼저, 빠르게, 그리고 안전하게 도달한다는 장기 목표를 염두에 둡니다.

00:39:55.920 --> 00:40:00.160
그렇다면 앞으로는 새로운 것들을 더 많이 만들어낼 수 있을 것으로 기대해도 되겠습니까?

00:40:00.160 --> 00:40:04.080
새로운 AI 도구들이 구글 전 제품군에 걸쳐 출시되고 있습니다.

00:40:04.080 --> 00:40:06.200
등등, 그 관계에서 그런 변화를 만들어내셨기 때문입니다.

00:40:06.200 --> 00:40:11.840
네, 맞습니다. 그래서 굉장히 촘촘한 반복 루프가 있습니다.

00:40:11.840 --> 00:40:14.160
아시다시피 저희는 모두 같은 기술 스택을 사용하고 있습니다.

00:40:14.160 --> 00:40:17.520
지금 구축하시는 것의 상당 부분이 구글 제품에 들어갑니다.

00:40:17.520 --> 00:40:21.200
하지만 삼성 같은 회사를 취재하다 보면, 삼성 같은 회사들이 일부를 구축하는 데도 도와주십니다.

00:40:21.200 --> 00:40:26.000
예를 들어 스마트폰 안의 AI 도구 같은 것들입니다.

00:40:26.000 --> 00:40:30.960
네, 말씀하신 것처럼 저희는 많은 파트너와 일하고 있고, 그 점을 매우 자랑스럽게 생각합니다.

00:40:30.960 --> 00:40:36.560
그런 파트너들이 저희 기술의 역량을 보고 선택해 준다는 점입니다.

00:40:36.560 --> 00:40:41.600
그리고 삼성이나 다른 기기 이야기로 넘어가면, 정말 흥미로운 부분이 있습니다.

00:40:41.600 --> 00:40:47.600
저는 엣지 컴퓨팅과 이런 모델들의 더 빠른 버전에 큰 관심이 있습니다.

00:40:47.600 --> 00:40:52.080
그것들이 휴대전화 같은 엣지 기기에서 동작할 뿐 아니라, 저희가 작업 중인 안경 같은 새로운 기기에서도 동작한다는 점입니다.

00:40:52.080 --> 00:40:58.160
그리고 워비 파커 같은 파트너들과 함께 하는 스마트 안경이라는 아이디어도 있습니다.

00:40:58.160 --> 00:41:03.200
아시다시피 구글은 오랫동안 스마트 안경을 연구해 왔습니다.

00:41:03.200 --> 00:41:08.000
하지만 이제 마침내 그에 대한 킬러 앱을 갖게 됐다고 말씀드릴 수 있는데, 그것이 바로 범용 어시스턴트라는 개념입니다.

00:41:08.000 --> 00:41:14.160
그리고 일상생활에서 여러모로 도와주는 것입니다.

00:41:14.160 --> 00:41:17.840
그리고 저는 모든, 모든 대형 디바이스 업체들이 그런 유형의 기술에 관심을 가질 것이라고 봅니다.

00:41:17.840 --> 00:41:21.840
데미스, 시간이 몇 분 남지 않았지만 조금 여쭤보고 싶습니다.

00:41:21.840 --> 00:41:26.640
저는 구글이 2014년에 딥마인드를 인수했을 때 막 기술 기자를 시작했습니다.

00:41:26.640 --> 00:41:30.640
당시 딜 규모가 4억 파운드, 아니 1억 파운드였던 것으로 기억합니다.

00:41:30.640 --> 00:41:35.520
그때는 많은 사람들이 무엇을 하는지 몰랐습니다. 왜 구글이 이 영국 회사를 사는 것인가, 무슨 일이 벌어지는 것인가 싶었습니다.

00:41:36.160 --> 00:41:40.240
가끔 그때를 돌아보며 '아, 우리가 독립적으로 남았어야 했나'라고 생각하신 적이 있습니까?

00:41:40.240 --> 00:41:42.080
아니면 지금까지의 결과에 만족하십니까?

00:41:42.080 --> 00:41:47.360
네, 재미있는 이야기인데요. 당시 검색 부문 책임자였던 앨런 유스타스가 있었습니다.

00:41:47.360 --> 00:41:52.640
그는 래리와 함께 총괄했고, 래리 페이지가 그 딜을 후원했습니다.

00:41:52.640 --> 00:41:56.800
당시 래리 페이지는 CEO였고, 앨런 유스타스는 검색 책임자로서 딜 마무리 작업을 맡았습니다.

00:41:56.800 --> 00:42:01.440
그리고 저는 앨런에게 이것이 구글이 한 인수 중 가장 중요한 인수가 될 것이라고 말씀드렸습니다.

00:42:01.440 --> 00:42:07.360
유튜브나 애드워즈 같은 것들과 다른 인수들이 있었다는 걸 생각하면, 꽤 대단한 말입니다.

00:42:07.360 --> 00:42:12.160
하지만 저는 이것이 얼마나 중요해질지 어느 정도 알고 있었습니다.

00:42:12.160 --> 00:42:17.520
또한 '세상의 정보를 정리한다'는 구글의 미션과 얼마나 잘 맞는지도 알고 있었습니다.

00:42:17.520 --> 00:42:22.960
AI는 그 미션, 즉 정보를 정리하고 이해하는 일에 매우 자연스럽게 들어맞습니다.

00:42:22.960 --> 00:42:27.040
그에 AI보다 더 좋은 도구가 어디 있겠습니까. 그래서 자연스러운 궁합이라고 생각했습니다.

00:42:27.040 --> 00:42:32.640
그리고 저희는 대략 이런 일이 벌어질 거라는 것은 알고 있었고, 지금은 뭐, 모르겠지만 100배, 1,000배쯤 가치가 됐을 수도 있다고 생각했습니다.

00:42:32.640 --> 00:42:37.600
하지만 그때 저는 과학으로 다시 돌아가고 싶었습니다.

00:42:38.320 --> 00:42:43.360
연구를 더 밀고 나가고 싶었고, 2014년 당시에는 연구가 아직 매우 초기 단계였습니다.

00:42:43.360 --> 00:42:47.200
공정하게 말하면, 구글은 세계에서 몇 안 되는 회사 중 하나로, 제 생각엔 이걸 알아볼 수 있었습니다.

00:42:47.200 --> 00:42:51.440
특히 당시의 래리는 이 기술이 얼마나 중요해질지, 무엇이 될 수 있을지,

00:42:51.440 --> 00:42:55.680
그리고 오늘날 우리가 그것을 어떻게 보는지까지도 알아봤습니다.

00:42:55.680 --> 00:43:01.840
그리고 구글의 지원이 없었다면 알파고와 알파폴드, 그리고 우리가 해온 모든 과학적 성과를 그렇게 해내지 못했을 것이라고 생각합니다.

00:43:01.840 --> 00:43:07.040
그들이 제공할 수 있었던 컴퓨팅 자원 규모 덕분입니다. 그래서 저는 전혀 후회가 없습니다.

00:43:07.040 --> 00:43:12.080
그렇다면 테크 CEO, AI CEO들이 이제 세상의 새로운 록스타라는 말씀이신가요? 유럽에서 젠슨 황을 본 적이 있습니다.

00:43:12.080 --> 00:43:17.760
엔비디아 CEO인 그가 모두에게 둘러싸여 따라다니는 모습도 봤습니다.

00:43:17.760 --> 00:43:22.320
젠슨은 최근에 두 분이 대화한다고 했고, 새로운 이미지 생성 도구인 나노 바나나에 대해서도

00:43:22.320 --> 00:43:26.160
아주 좋은 말을 했던 것으로 압니다. 두 분은 어떤 이야기를 나누십니까?

00:43:26.800 --> 00:43:30.400
젠슨은 훌륭한 분입니다. 놀라운 개척자이고, 또한

00:43:30.400 --> 00:43:36.320
제가 존경하는 점이, 20~30년 넘게 자신의 비전을 지켜왔다는 점입니다. 사실 저는 처음에

00:43:36.320 --> 00:43:42.960
90년대에 게임을 위해 GPU를 쓰기 시작했습니다. 물론 그래픽 엔진과 물리 엔진을 만들기 위해서였습니다.

00:43:42.960 --> 00:43:48.240
그래서 제 초기 게임 시절이 이렇게 한 바퀴 돌아, 당시 밀어붙이던 하드웨어가 지금은 AI에 유용하다는 점이

00:43:48.240 --> 00:43:52.320
아이러니하게도 흥미롭습니다.

00:43:52.320 --> 00:43:56.400
저희는 과학, 그리고 과학을 위한 AI에 대해 이야기합니다. 그는 과학과 과학을 위한 AI에 매우 관심이 많습니다.

00:43:56.400 --> 00:44:01.120
알파폴드는 GPU로 학습되었고, 그는 알파폴드와 우리가 하고 있는 일을 정말 좋아합니다.

00:44:01.120 --> 00:44:06.000
특히 신약 개발 분야에서요. 그래서 우리는 대부분 과학을 위한 AI에 대해 이야기합니다.

00:44:06.000 --> 00:44:11.920
많은 데이터 센터가 엔비디아 시스템으로 구축된 건 알고 있는데, 구글도 자체적인

00:44:11.920 --> 00:44:16.800
TPU 칩, 즉 텐서 처리 유닛이 있잖아요. 그 사이에 어떤 경쟁적이면서도 우호적인 관계가 있습니까?

00:44:17.520 --> 00:44:23.120
저희는 운이 좋습니다. 자체 TPU가 있고, TPU를 정말 좋아합니다.

00:44:23.760 --> 00:44:30.160
저희는 보통 내부적으로 최고의 모델을 학습시키는 데 이를 사용합니다. 그리고 사실 최정예 AI 팀들로부터 큰 수요도 확인했습니다.

00:44:30.160 --> 00:44:36.960
대형 모델을 만들거나 매우 큰 AI 모델을 제공하려는 팀들입니다. TPU는

00:44:36.960 --> 00:44:40.880
바로 그런 목적을 위해 특별히 설계되었습니다. 그래서 TPU는 GPU보다 조금 더 특수한 용도라고 할 수 있습니다.

00:44:40.880 --> 00:44:46.720
GPU는 더 범용적이라고 생각하시면 됩니다. 그래서 예를 들어 우리가

00:44:46.720 --> 00:44:52.880
알파폴드처럼 새로운 아키텍처나 새로운 응용을 탐색하려 할 때는 GPU를 사용할 수도 있습니다. 하지만

00:44:52.880 --> 00:44:59.840
최대한으로 스케일을 올려 우리가 아는 것들을 극대화하려 할 때는, 맞춤형 실리콘이 훨씬 더

00:44:59.840 --> 00:45:05.680
효율적입니다. 그래서 저희는 운이 좋게도 둘 다 갖고 있고, 구글과 딥마인드에서 둘 다 사용할 수 있습니다.

00:45:05.680 --> 00:45:10.400
좋습니다, 데미스. 미래를 바라보면 과학과 그 잠재력에 매우 집중하고 계시지요.

00:45:10.400 --> 00:45:16.720
AI가 신약 개발의 새로운 돌파구를 만들고 새로운 질병을 발견할 잠재력도요. 가능성이 정말 큽니다.

00:45:16.720 --> 00:45:23.680
물론 아이소모픽 랩스도 운영하고 계시고요. 이러한 비전으로 가는 길에서 지금 우리는

00:45:23.680 --> 00:45:29.680
AI가 과학 분야의 이런 돌파구들을 열어내는 비전까지, 어디쯤 와 있습니까?

00:45:29.680 --> 00:45:35.520
글쎄요, 저는 지금까지 AI가 과학에 적용된 최고의 사례로 아마 AlphaFold를 항상 꼽습니다.

00:45:35.520 --> 00:45:39.840
그 프로젝트가 정말 자랑스럽습니다. 그리고, 아시다시피, 저희는 50년

00:45:39.840 --> 00:45:44.400
동안 이어진 단백질 접힘(폴딩)이라는 과학의 거대한 난제, 즉 단백질 구조가 어떻게

00:45:44.400 --> 00:45:48.960
형성되는지를 풀어냈고, 전 세계 300만 명이 넘는 연구자들이 핵심 연구에 이를 사용하고 있습니다.

00:45:48.960 --> 00:45:55.440
그래서 이보다 더 혁신적인 기술은 상상하기 어렵습니다. 그리고 제가 정말 보고 싶은 것은

00:45:55.440 --> 00:46:01.040
AlphaFold 같은 사례를 열두 개쯤 더 들 수 있게 되는 것이고, 각각이 자신의 분야를

00:46:01.040 --> 00:46:05.520
과학이나 수학에서 혁신하는 것입니다. 저는 우리가 그 방향으로 잘 가고 있다고 생각합니다.

00:46:05.520 --> 00:46:12.080
그리고 저희는 재료과학, 물리학, 수학, 기상 예측 등에서 그런 프로젝트를 대략 여섯 개 정도 진행하고 있고

00:46:12.080 --> 00:46:16.400
그리고 앞으로 10년 동안 AI가 잘 되고 진전도 순조롭게 이어진다면,

00:46:16.400 --> 00:46:21.760
그리고 우리가 이를 올바르게 사용한다면, 과학적 발견의 새로운 황금기를 열 수 있다고 생각합니다.

00:46:21.760 --> 00:46:26.000
2026년에 AI에서 큰 변화는 무엇이 될 것이라고 보십니까, 어떤 큰 돌파구가,

00:46:26.000 --> 00:46:28.160
어떤 큰 진전이 일어날 것이라고 생각하십니까?

00:46:28.160 --> 00:46:30.960
에이전틱 시스템, 즉 더 자율적으로 일을 할 수 있는 시스템들이

00:46:30.960 --> 00:46:35.760
유용할 만큼 충분히 신뢰할 수 있는 수준이 되기 시작할 것입니다. 그리고 저는 우리가

00:46:35.760 --> 00:46:39.280
향후 12~18개월 안에 로보틱스에서 정말 흥미로운 것들을 보게 될 것이라고 생각합니다. 저희는

00:46:39.280 --> 00:46:44.160
제미니 로보틱스와 함께 매우 야심찬 프로젝트들을 열심히 진행하고 있습니다. 그리고 마지막으로, 아마도,

00:46:44.960 --> 00:46:50.560
기기 안에서 동작하는 AI 시스템도 실제 세계에서 정말 유용하게 쓰이는 모습을 보기 시작할 것이라고 봅니다.

00:46:50.560 --> 00:46:55.840
그리고 제가 가장 기대하는 것은 월드 모델을 더 발전시키는 것입니다,

00:46:55.840 --> 00:47:00.320
효율을 높여 실제로 활용할 수 있게 만드는 것이지요. 어쩌면 범용 모델에서 계획 수립에 쓰일 수도 있습니다.

00:47:00.320 --> 00:47:04.720
좋습니다. 데미스, 방금 마지막 답변은 다음에 우리가 다시 만날 때를 위한 일종의 티저 예고편으로 받아들이겠습니다.

00:47:04.720 --> 00:47:08.960
올해 어느 시점엔가 다시 이야기 나눌 수 있길 바랍니다. 함께해 주셔서 정말 감사합니다.

00:47:08.960 --> 00:47:12.211
감사합니다. 초대해 주셔서 감사합니다

00:47:12.211 --> 00:47:13.600
대화에 불러주셔서요. 좋습니다. 이제 마지막 부분만 남았네요, 네, 네, 네, 그리고

00:47:13.600 --> 00:47:17.600
스티브, 대화의 마지막 부분에서 흥미로웠던 점은

00:47:17.600 --> 00:47:24.000
딥마인드라는 조직과 더 넓은 구글 비즈니스 사이의 관계였습니다. 그리고

00:47:24.000 --> 00:47:29.680
데미스가 구글, 혹은 알파벳의 CEO인 순다르 피차이와

00:47:29.680 --> 00:47:36.800
매일 대화한다는 점과 두 조직이 얼마나 더 통합되어 왔는지였는데요. 이 AI 경쟁을 생각해보면,

00:47:36.800 --> 00:47:43.600
제게 시사하는 바는 구글이 분명히 AI 제품을 시장에 빠르게 내놓는 법을 터득했다는 점입니다.

00:47:43.600 --> 00:47:48.640
하지만 크롬이든 지메일이든 무엇이든, 이런 모든 구글 제품들을 생각해보셔야 합니다.

00:47:48.640 --> 00:47:54.640
그들이 개발하는 구글 AI가 모든 제품 전반에 확산되길 원하고 있고, 이는

00:47:54.640 --> 00:47:59.840
그렇게 되면 일부 제품을 통해 거의 즉시 활용할 수 있는 사용자 기반을 갖게 되는데,

00:47:59.840 --> 00:48:05.680
이런 일부 제품으로 거의 즉각적으로 활용할 수 있는 정말 거대한 사용자 기반이 있습니다.

00:48:05.680 --> 00:48:10.000
그리고 저는 늘, 꽤 오래전부터 말해왔는데, 구글의 가장 큰 강점 중 하나는

00:48:10.000 --> 00:48:15.360
사실 안드로이드 운영체제를, 그리고 그것이 얼마나 거대한지 떠올려보면,

00:48:15.360 --> 00:48:21.680
전 세계 시장점유율이 70% 안팎인데, 이는 엄청난 규모의 사람들과 기기들이라는 뜻이며

00:48:21.680 --> 00:48:26.560
그 위에 구글 AI를 사실상 즉시 설치해 빠르게 사용할 수 있습니다. 그래서

00:48:26.560 --> 00:48:32.480
저는 이들이 시장에 내놓는 측면에서 유리한 위치에 있다고 봅니다. 그리고 분명히, 딥마인드와

00:48:32.480 --> 00:48:37.200
더 넓은 구글 사업 전반 사이의 이 관계는 구글이 지속적으로

00:48:37.200 --> 00:48:42.320
장기적으로 어떤 성공이든 유지하는 데 핵심이 될 것입니다.

00:48:42.320 --> 00:48:46.000
안드로이드 폰의 최대 제조사인 삼성은 이미 제미니를

00:48:46.000 --> 00:48:50.560
자사의 메인 챗봇이자 메인 AI로 탑재하고 있습니다. 저는 조금 놀랐습니다. 삼성이

00:48:50.560 --> 00:48:54.720
예전처럼 자체 모델을 만들려 하지 않았다는 점입니다. 그런데 그렇지 않았고, 그들은 완전히

00:48:54.720 --> 00:49:01.200
제미니에 올인했습니다. 또한 구글과 협력해 새 혼합현실 헤드셋도

00:49:01.200 --> 00:49:06.080
함께 개발하고 있습니다. 또 협업으로 개발 중인 안경도 곧 출시될 예정이며,

00:49:06.080 --> 00:49:11.840
워비 파커 같은 회사들과도 함께 디자인하고 있습니다. 그래서 삼성은 이를 적극적으로 채택했고,

00:49:11.840 --> 00:49:19.120
이것만으로도 제미니에겐 거대한 플랫폼입니다. 삼성이라는 측면만 보더라도, 그 자체로도 그 엄청난

00:49:19.120 --> 00:49:23.920
기존 시장점유율이 매우 큽니다. 그리고 이제 애플에 대해 이야기해보겠습니다. 제미니는 실제로

00:49:23.920 --> 00:49:29.760
불과 몇 달 뒤에 공개될 것으로 예상되는 새 버전의 시리를 구동하는 엔진이 될 것입니다.

00:49:29.760 --> 00:49:36.560
그는 제미니가 더 많은 기기로 확산되는 것을 보게 될 것에 대한 기대도 언급했습니다. 그래서 저는

00:49:36.560 --> 00:49:41.680
애플이 이를 자체적으로 구축할 수 없다는 점을 인식하고, 솔직히

00:49:41.680 --> 00:49:46.960
삼성이 하는 것처럼 “좋습니다, 검증된 이 기술을 그냥 통합하자”라고 한 것은 정말 현명한 판단이라고 봅니다. 우리는 이미

00:49:46.960 --> 00:49:50.720
구글과 훌륭한 협력 관계가 있습니다. 그리고 솔직히 이것은 제가

00:49:50.720 --> 00:49:55.600
수년 동안 보아왔던 구글과는 다른 모습입니다. 예전에는 서로 다른 많은 팀들이

00:49:55.600 --> 00:50:01.280
같은 일을 하고 있었습니다. 즉, 이 대규모 조직 개편 이전에는, 데미스가 AI 전반에 대한 통제권을 갖기 전에는

00:50:01.280 --> 00:50:06.720
구글 내부에 인공지능을 다루는 여러 그룹이 있었고,

00:50:06.720 --> 00:50:12.160
어느 정도 서로 부딪치고 있었습니다. 그런데 순다르 피차이는 “우리는 해야 합니다, 이건 정말 큰

00:50:12.160 --> 00:50:19.840
순간입니다. 모든 것을 재정비해야 합니다”라고 말하며, 모든 것을 데미스 아래로 통합해 딥마인드로 옮겼고,

00:50:19.840 --> 00:50:25.760
그 결과가 지금의 상황입니다. 그리고 2025년에 제미니 3로 큰 성과를 거뒀습니다.

00:50:26.320 --> 00:50:32.000
네, 그리고 소비자 시장에서는 AI 측면에서 경쟁이 점점 더 치열해지고 있습니다.

00:50:32.000 --> 00:50:35.760
특히, 앞서 거품 이야기와 관련해 말씀하셨듯이,

00:50:35.760 --> 00:50:41.280
오픈AI 같은 경쟁자들이 있고, 구글은

00:50:42.160 --> 00:50:46.800
튼튼한 재무상태표와 강한 현금흐름을 갖고 있으며, 막대한 사용자 기반이 있고, 계속

00:50:46.800 --> 00:50:51.760
혁신하고 있습니다. 그리고 그런 조직 개편과 지금 구글이 보여주는 속도를 감안하면,

00:50:51.760 --> 00:50:56.640
이것이 상당한 경쟁

00:50:56.640 --> 00:51:04.240
압박을 오픈AI에 가할 것이라고 봅니다. 특히 2026년 소비자 분야에서는 모든 것이 열려 있습니다.

00:51:04.240 --> 00:51:08.800
네, 그리고 우리는 정말 다양한 것들을 보게 될 것입니다. 저는 올해 오픈AI가

00:51:08.800 --> 00:51:12.320
될 만한 것은 무엇이든 다 시도해 보며 무엇이 통하는지 보려 할 것이라고 봅니다,

00:51:12.320 --> 00:51:17.040
왜냐하면 그들은 엄청난 규모의

00:51:17.040 --> 00:51:23.040
매출을 만들어내야 한다는 압박을 스스로에게 걸어, 자본지출로

00:51:23.040 --> 00:51:27.120
오라클과 함께 이런 대형 데이터센터를 구축하겠다는 약속 등

00:51:27.120 --> 00:51:32.320
이미 확정한 지출을 더 잘

00:51:32.320 --> 00:51:35.920
제품화하고 더 효과적으로 만들지 않으면 실현될 수 없기 때문입니다. 하지만 말씀하신 대로 메타에서도 이런 모습을 보고 있습니다. 참고로,

00:51:35.920 --> 00:51:41.280
메타는 자사의 사용자 기반을 활용할 큰 기회가 있지만, 그걸 어떻게 할지

00:51:41.280 --> 00:51:46.560
구글처럼 해내지는 못했습니다. 그래서 지금은 구글이 대체로 우위를 점하고 있는 느낌입니다.

00:51:46.560 --> 00:51:50.720
딥마인드 미니시리즈 2부는 다음 주에 공개될 예정이고,

00:51:50.720 --> 00:51:56.560
딥마인드의 COO인 릴라 이브라힘과 이야기를 나눌 예정이니 꼭 확인해 보시기 바랍니다. 그리고

00:51:56.560 --> 00:52:01.760
이번 에피소드에 대한 의견이나 생각이 있으시면 저희에게 연락해 주십시오.

00:52:01.760 --> 00:52:06.305
거의 어디서든 저희에게 연락하실 수 있습니다. 여러 소셜미디어 플랫폼에 계시잖아요.

00:52:06.305 --> 00:52:07.840
저는 블루스카이를 이용합니다. 저도 블루스카이를 이용합니다.

00:52:07.840 --> 00:52:09.200
네, 저희는 정말 여기저기 다 있습니다.

00:52:09.840 --> 00:52:13.360
저는 7년 반 전에 인스타그램을 그만뒀는데, 전혀 후회하지 않습니다.

00:52:13.360 --> 00:52:16.400
와, 대단하네요. 네, 이제 둠스크롤링은 끝입니다. 정말 좋습니다.

00:52:16.400 --> 00:52:19.280
이분은 더 이상 둠스크롤링을 하지 않습니다.

00:52:19.280 --> 00:52:32.851
들어 주시고 시청해 주셔서 감사합니다. 다음에 또 뵙겠습니다.
